Search.setIndex({"docnames": ["_dynamo", "amp", "autograd", "backends", "benchmark_utils", "bottleneck", "checkpoint", "community/build_ci_governance", "community/contribution_guide", "community/design", "community/governance", "community/persons_of_interest", "compile/cudagraph_trees", "compile/custom-backends", "compile/deep-dive", "compile/dynamic-shapes", "compile/fake-tensor", "compile/faq", "compile/fine_grained_apis", "compile/generated/torch.compile", "compile/get-started", "compile/guards-overview", "compile/index", "compile/inductor_profiling", "compile/nn-module", "compile/performance-dashboard", "compile/technical-overview", "compile/torchfunc-and-torchcompile", "compile/transformations", "compile/troubleshooting", "complex_numbers", "config_mod", "cpp_extension", "cpp_index", "cuda", "cuda._sanitizer", "cudnn_persistent_rnn", "cudnn_rnn_determinism", "data", "ddp_comm_hooks", "deploy", "distributed", "distributed.algorithms.join", "distributed.checkpoint", "distributed.elastic", "distributed.optim", "distributed.tensor.parallel", "distributions", "dlpack", "elastic/agent", "elastic/customization", "elastic/errors", "elastic/events", "elastic/examples", "elastic/kubernetes", "elastic/metrics", "elastic/multiprocessing", "elastic/quickstart", "elastic/rendezvous", "elastic/run", "elastic/timer", "elastic/train_script", "fft", "fsdp", "func", "func.api", "func.batch_norm", "func.migrating", "func.ux_limitations", "func.whirlwind_tour", "futures", "fx", "generated/onnx_diagnostics_rules/DIAGSYS0001:arg-format-too-verbose", "generated/onnx_diagnostics_rules/FXE0001:fx-tracer-success", "generated/onnx_diagnostics_rules/FXE0002:fx-tracer-failure", "generated/onnx_diagnostics_rules/FXE0003:fx-frontend-aotautograd", "generated/onnx_diagnostics_rules/FXE0004:fx-pass-convert-neg-to-sigmoid", "generated/onnx_diagnostics_rules/FXE0005:fx-ir-add-node", "generated/onnx_diagnostics_rules/FXE0006:atenlib-symbolic-function", "generated/onnx_diagnostics_rules/FXE0007:atenlib-fx-to-onnx", "generated/onnx_diagnostics_rules/FXE0008:fx-node-to-onnx", "generated/onnx_diagnostics_rules/FXE0009:fx-frontend-dynamo-make-fx", "generated/onnx_diagnostics_rules/FXE0010:fx-pass", "generated/onnx_diagnostics_rules/FXE0011:no-symbolic-function-for-call-function", "generated/onnx_diagnostics_rules/FXE0012:unsupported-fx-node-analysis", "generated/onnx_diagnostics_rules/POE0001:node-missing-onnx-shape-inference", "generated/onnx_diagnostics_rules/POE0002:missing-custom-symbolic-function", "generated/onnx_diagnostics_rules/POE0003:missing-standard-symbolic-function", "generated/onnx_diagnostics_rules/POE0004:operator-supported-in-newer-opset-version", "generated/torch.Generator", "generated/torch.Tensor.abs", "generated/torch.Tensor.abs_", "generated/torch.Tensor.absolute", "generated/torch.Tensor.absolute_", "generated/torch.Tensor.acos", "generated/torch.Tensor.acos_", "generated/torch.Tensor.acosh", "generated/torch.Tensor.acosh_", "generated/torch.Tensor.add", "generated/torch.Tensor.add_", "generated/torch.Tensor.addbmm", "generated/torch.Tensor.addbmm_", "generated/torch.Tensor.addcdiv", "generated/torch.Tensor.addcdiv_", "generated/torch.Tensor.addcmul", "generated/torch.Tensor.addcmul_", "generated/torch.Tensor.addmm", "generated/torch.Tensor.addmm_", "generated/torch.Tensor.addmv", "generated/torch.Tensor.addmv_", "generated/torch.Tensor.addr", "generated/torch.Tensor.addr_", "generated/torch.Tensor.adjoint", "generated/torch.Tensor.all", "generated/torch.Tensor.allclose", "generated/torch.Tensor.amax", "generated/torch.Tensor.amin", "generated/torch.Tensor.aminmax", "generated/torch.Tensor.angle", "generated/torch.Tensor.any", "generated/torch.Tensor.apply_", "generated/torch.Tensor.arccos", "generated/torch.Tensor.arccos_", "generated/torch.Tensor.arccosh", "generated/torch.Tensor.arccosh_", "generated/torch.Tensor.arcsin", "generated/torch.Tensor.arcsin_", "generated/torch.Tensor.arcsinh", "generated/torch.Tensor.arcsinh_", "generated/torch.Tensor.arctan", "generated/torch.Tensor.arctan2", "generated/torch.Tensor.arctan2_", "generated/torch.Tensor.arctan_", "generated/torch.Tensor.arctanh", "generated/torch.Tensor.arctanh_", "generated/torch.Tensor.argmax", "generated/torch.Tensor.argmin", "generated/torch.Tensor.argsort", "generated/torch.Tensor.argwhere", "generated/torch.Tensor.as_strided", "generated/torch.Tensor.as_subclass", "generated/torch.Tensor.asin", "generated/torch.Tensor.asin_", "generated/torch.Tensor.asinh", "generated/torch.Tensor.asinh_", "generated/torch.Tensor.atan", "generated/torch.Tensor.atan2", "generated/torch.Tensor.atan2_", "generated/torch.Tensor.atan_", "generated/torch.Tensor.atanh", "generated/torch.Tensor.atanh_", "generated/torch.Tensor.backward", "generated/torch.Tensor.baddbmm", "generated/torch.Tensor.baddbmm_", "generated/torch.Tensor.bernoulli", "generated/torch.Tensor.bernoulli_", "generated/torch.Tensor.bfloat16", "generated/torch.Tensor.bincount", "generated/torch.Tensor.bitwise_and", "generated/torch.Tensor.bitwise_and_", "generated/torch.Tensor.bitwise_left_shift", "generated/torch.Tensor.bitwise_left_shift_", "generated/torch.Tensor.bitwise_not", "generated/torch.Tensor.bitwise_not_", "generated/torch.Tensor.bitwise_or", "generated/torch.Tensor.bitwise_or_", "generated/torch.Tensor.bitwise_right_shift", "generated/torch.Tensor.bitwise_right_shift_", "generated/torch.Tensor.bitwise_xor", "generated/torch.Tensor.bitwise_xor_", "generated/torch.Tensor.bmm", "generated/torch.Tensor.bool", "generated/torch.Tensor.broadcast_to", "generated/torch.Tensor.byte", "generated/torch.Tensor.cauchy_", "generated/torch.Tensor.ccol_indices", "generated/torch.Tensor.cdouble", "generated/torch.Tensor.ceil", "generated/torch.Tensor.ceil_", "generated/torch.Tensor.cfloat", "generated/torch.Tensor.chalf", "generated/torch.Tensor.char", "generated/torch.Tensor.cholesky", "generated/torch.Tensor.cholesky_inverse", "generated/torch.Tensor.cholesky_solve", "generated/torch.Tensor.chunk", "generated/torch.Tensor.clamp", "generated/torch.Tensor.clamp_", "generated/torch.Tensor.clip", "generated/torch.Tensor.clip_", "generated/torch.Tensor.clone", "generated/torch.Tensor.coalesce", "generated/torch.Tensor.col_indices", "generated/torch.Tensor.conj", "generated/torch.Tensor.conj_physical", "generated/torch.Tensor.conj_physical_", "generated/torch.Tensor.contiguous", "generated/torch.Tensor.copy_", "generated/torch.Tensor.copysign", "generated/torch.Tensor.copysign_", "generated/torch.Tensor.corrcoef", "generated/torch.Tensor.cos", "generated/torch.Tensor.cos_", "generated/torch.Tensor.cosh", "generated/torch.Tensor.cosh_", "generated/torch.Tensor.count_nonzero", "generated/torch.Tensor.cov", "generated/torch.Tensor.cpu", "generated/torch.Tensor.cross", "generated/torch.Tensor.crow_indices", "generated/torch.Tensor.cuda", "generated/torch.Tensor.cummax", "generated/torch.Tensor.cummin", "generated/torch.Tensor.cumprod", "generated/torch.Tensor.cumprod_", "generated/torch.Tensor.cumsum", "generated/torch.Tensor.cumsum_", "generated/torch.Tensor.data_ptr", "generated/torch.Tensor.deg2rad", "generated/torch.Tensor.dense_dim", "generated/torch.Tensor.dequantize", "generated/torch.Tensor.det", "generated/torch.Tensor.detach", "generated/torch.Tensor.detach_", "generated/torch.Tensor.device", "generated/torch.Tensor.diag", "generated/torch.Tensor.diag_embed", "generated/torch.Tensor.diagflat", "generated/torch.Tensor.diagonal", "generated/torch.Tensor.diagonal_scatter", "generated/torch.Tensor.diff", "generated/torch.Tensor.digamma", "generated/torch.Tensor.digamma_", "generated/torch.Tensor.dim", "generated/torch.Tensor.dist", "generated/torch.Tensor.div", "generated/torch.Tensor.div_", "generated/torch.Tensor.divide", "generated/torch.Tensor.divide_", "generated/torch.Tensor.dot", "generated/torch.Tensor.double", "generated/torch.Tensor.dsplit", "generated/torch.Tensor.element_size", "generated/torch.Tensor.eq", "generated/torch.Tensor.eq_", "generated/torch.Tensor.equal", "generated/torch.Tensor.erf", "generated/torch.Tensor.erf_", "generated/torch.Tensor.erfc", "generated/torch.Tensor.erfc_", "generated/torch.Tensor.erfinv", "generated/torch.Tensor.erfinv_", "generated/torch.Tensor.exp", "generated/torch.Tensor.exp_", "generated/torch.Tensor.expand", "generated/torch.Tensor.expand_as", "generated/torch.Tensor.expm1", "generated/torch.Tensor.expm1_", "generated/torch.Tensor.exponential_", "generated/torch.Tensor.fill_", "generated/torch.Tensor.fill_diagonal_", "generated/torch.Tensor.fix", "generated/torch.Tensor.fix_", "generated/torch.Tensor.flatten", "generated/torch.Tensor.flip", "generated/torch.Tensor.fliplr", "generated/torch.Tensor.flipud", "generated/torch.Tensor.float", "generated/torch.Tensor.float_power", "generated/torch.Tensor.float_power_", "generated/torch.Tensor.floor", "generated/torch.Tensor.floor_", "generated/torch.Tensor.floor_divide", "generated/torch.Tensor.floor_divide_", "generated/torch.Tensor.fmax", "generated/torch.Tensor.fmin", "generated/torch.Tensor.fmod", "generated/torch.Tensor.fmod_", "generated/torch.Tensor.frac", "generated/torch.Tensor.frac_", "generated/torch.Tensor.frexp", "generated/torch.Tensor.gather", "generated/torch.Tensor.gcd", "generated/torch.Tensor.gcd_", "generated/torch.Tensor.ge", "generated/torch.Tensor.ge_", "generated/torch.Tensor.geometric_", "generated/torch.Tensor.geqrf", "generated/torch.Tensor.ger", "generated/torch.Tensor.get_device", "generated/torch.Tensor.grad", "generated/torch.Tensor.greater", "generated/torch.Tensor.greater_", "generated/torch.Tensor.greater_equal", "generated/torch.Tensor.greater_equal_", "generated/torch.Tensor.gt", "generated/torch.Tensor.gt_", "generated/torch.Tensor.half", "generated/torch.Tensor.hardshrink", "generated/torch.Tensor.heaviside", "generated/torch.Tensor.histc", "generated/torch.Tensor.histogram", "generated/torch.Tensor.hsplit", "generated/torch.Tensor.hypot", "generated/torch.Tensor.hypot_", "generated/torch.Tensor.i0", "generated/torch.Tensor.i0_", "generated/torch.Tensor.igamma", "generated/torch.Tensor.igamma_", "generated/torch.Tensor.igammac", "generated/torch.Tensor.igammac_", "generated/torch.Tensor.imag", "generated/torch.Tensor.index_add", "generated/torch.Tensor.index_add_", "generated/torch.Tensor.index_copy", "generated/torch.Tensor.index_copy_", "generated/torch.Tensor.index_fill", "generated/torch.Tensor.index_fill_", "generated/torch.Tensor.index_put", "generated/torch.Tensor.index_put_", "generated/torch.Tensor.index_reduce", "generated/torch.Tensor.index_reduce_", "generated/torch.Tensor.index_select", "generated/torch.Tensor.indices", "generated/torch.Tensor.inner", "generated/torch.Tensor.int", "generated/torch.Tensor.int_repr", "generated/torch.Tensor.inverse", "generated/torch.Tensor.is_coalesced", "generated/torch.Tensor.is_complex", "generated/torch.Tensor.is_conj", "generated/torch.Tensor.is_contiguous", "generated/torch.Tensor.is_cuda", "generated/torch.Tensor.is_floating_point", "generated/torch.Tensor.is_inference", "generated/torch.Tensor.is_leaf", "generated/torch.Tensor.is_meta", "generated/torch.Tensor.is_pinned", "generated/torch.Tensor.is_quantized", "generated/torch.Tensor.is_set_to", "generated/torch.Tensor.is_shared", "generated/torch.Tensor.is_signed", "generated/torch.Tensor.is_sparse", "generated/torch.Tensor.is_sparse_csr", "generated/torch.Tensor.isclose", "generated/torch.Tensor.isfinite", "generated/torch.Tensor.isinf", "generated/torch.Tensor.isnan", "generated/torch.Tensor.isneginf", "generated/torch.Tensor.isposinf", "generated/torch.Tensor.isreal", "generated/torch.Tensor.istft", "generated/torch.Tensor.item", "generated/torch.Tensor.itemsize", "generated/torch.Tensor.kthvalue", "generated/torch.Tensor.lcm", "generated/torch.Tensor.lcm_", "generated/torch.Tensor.ldexp", "generated/torch.Tensor.ldexp_", "generated/torch.Tensor.le", "generated/torch.Tensor.le_", "generated/torch.Tensor.lerp", "generated/torch.Tensor.lerp_", "generated/torch.Tensor.less", "generated/torch.Tensor.less_", "generated/torch.Tensor.less_equal", "generated/torch.Tensor.less_equal_", "generated/torch.Tensor.lgamma", "generated/torch.Tensor.lgamma_", "generated/torch.Tensor.log", "generated/torch.Tensor.log10", "generated/torch.Tensor.log10_", "generated/torch.Tensor.log1p", "generated/torch.Tensor.log1p_", "generated/torch.Tensor.log2", "generated/torch.Tensor.log2_", "generated/torch.Tensor.log_", "generated/torch.Tensor.log_normal_", "generated/torch.Tensor.logaddexp", "generated/torch.Tensor.logaddexp2", "generated/torch.Tensor.logcumsumexp", "generated/torch.Tensor.logdet", "generated/torch.Tensor.logical_and", "generated/torch.Tensor.logical_and_", "generated/torch.Tensor.logical_not", "generated/torch.Tensor.logical_not_", "generated/torch.Tensor.logical_or", "generated/torch.Tensor.logical_or_", "generated/torch.Tensor.logical_xor", "generated/torch.Tensor.logical_xor_", "generated/torch.Tensor.logit", "generated/torch.Tensor.logit_", "generated/torch.Tensor.logsumexp", "generated/torch.Tensor.long", "generated/torch.Tensor.lt", "generated/torch.Tensor.lt_", "generated/torch.Tensor.lu", "generated/torch.Tensor.lu_solve", "generated/torch.Tensor.map_", "generated/torch.Tensor.masked_fill", "generated/torch.Tensor.masked_fill_", "generated/torch.Tensor.masked_scatter", "generated/torch.Tensor.masked_scatter_", "generated/torch.Tensor.masked_select", "generated/torch.Tensor.matmul", "generated/torch.Tensor.matrix_exp", "generated/torch.Tensor.matrix_power", "generated/torch.Tensor.max", "generated/torch.Tensor.maximum", "generated/torch.Tensor.mean", "generated/torch.Tensor.median", "generated/torch.Tensor.min", "generated/torch.Tensor.minimum", "generated/torch.Tensor.mm", "generated/torch.Tensor.mode", "generated/torch.Tensor.moveaxis", "generated/torch.Tensor.movedim", "generated/torch.Tensor.msort", "generated/torch.Tensor.mul", "generated/torch.Tensor.mul_", "generated/torch.Tensor.multinomial", "generated/torch.Tensor.multiply", "generated/torch.Tensor.multiply_", "generated/torch.Tensor.mv", "generated/torch.Tensor.mvlgamma", "generated/torch.Tensor.mvlgamma_", "generated/torch.Tensor.nan_to_num", "generated/torch.Tensor.nan_to_num_", "generated/torch.Tensor.nanmean", "generated/torch.Tensor.nanmedian", "generated/torch.Tensor.nanquantile", "generated/torch.Tensor.nansum", "generated/torch.Tensor.narrow", "generated/torch.Tensor.narrow_copy", "generated/torch.Tensor.nbytes", "generated/torch.Tensor.ndim", "generated/torch.Tensor.ndimension", "generated/torch.Tensor.ne", "generated/torch.Tensor.ne_", "generated/torch.Tensor.neg", "generated/torch.Tensor.neg_", "generated/torch.Tensor.negative", "generated/torch.Tensor.negative_", "generated/torch.Tensor.nelement", "generated/torch.Tensor.new_empty", "generated/torch.Tensor.new_full", "generated/torch.Tensor.new_ones", "generated/torch.Tensor.new_tensor", "generated/torch.Tensor.new_zeros", "generated/torch.Tensor.nextafter", "generated/torch.Tensor.nextafter_", "generated/torch.Tensor.nonzero", "generated/torch.Tensor.norm", "generated/torch.Tensor.normal_", "generated/torch.Tensor.not_equal", "generated/torch.Tensor.not_equal_", "generated/torch.Tensor.numel", "generated/torch.Tensor.numpy", "generated/torch.Tensor.orgqr", "generated/torch.Tensor.ormqr", "generated/torch.Tensor.outer", "generated/torch.Tensor.permute", "generated/torch.Tensor.pin_memory", "generated/torch.Tensor.pinverse", "generated/torch.Tensor.polygamma", "generated/torch.Tensor.polygamma_", "generated/torch.Tensor.positive", "generated/torch.Tensor.pow", "generated/torch.Tensor.pow_", "generated/torch.Tensor.prod", "generated/torch.Tensor.put_", "generated/torch.Tensor.q_per_channel_axis", "generated/torch.Tensor.q_per_channel_scales", "generated/torch.Tensor.q_per_channel_zero_points", "generated/torch.Tensor.q_scale", "generated/torch.Tensor.q_zero_point", "generated/torch.Tensor.qr", "generated/torch.Tensor.qscheme", "generated/torch.Tensor.quantile", "generated/torch.Tensor.rad2deg", "generated/torch.Tensor.random_", "generated/torch.Tensor.ravel", "generated/torch.Tensor.real", "generated/torch.Tensor.reciprocal", "generated/torch.Tensor.reciprocal_", "generated/torch.Tensor.record_stream", "generated/torch.Tensor.register_hook", "generated/torch.Tensor.remainder", "generated/torch.Tensor.remainder_", "generated/torch.Tensor.renorm", "generated/torch.Tensor.renorm_", "generated/torch.Tensor.repeat", "generated/torch.Tensor.repeat_interleave", "generated/torch.Tensor.requires_grad", "generated/torch.Tensor.requires_grad_", "generated/torch.Tensor.reshape", "generated/torch.Tensor.reshape_as", "generated/torch.Tensor.resize_", "generated/torch.Tensor.resize_as_", "generated/torch.Tensor.resolve_conj", "generated/torch.Tensor.resolve_neg", "generated/torch.Tensor.retain_grad", "generated/torch.Tensor.retains_grad", "generated/torch.Tensor.roll", "generated/torch.Tensor.rot90", "generated/torch.Tensor.round", "generated/torch.Tensor.round_", "generated/torch.Tensor.row_indices", "generated/torch.Tensor.rsqrt", "generated/torch.Tensor.rsqrt_", "generated/torch.Tensor.scatter", "generated/torch.Tensor.scatter_", "generated/torch.Tensor.scatter_add", "generated/torch.Tensor.scatter_add_", "generated/torch.Tensor.scatter_reduce", "generated/torch.Tensor.scatter_reduce_", "generated/torch.Tensor.select", "generated/torch.Tensor.select_scatter", "generated/torch.Tensor.set_", "generated/torch.Tensor.sgn", "generated/torch.Tensor.sgn_", "generated/torch.Tensor.share_memory_", "generated/torch.Tensor.short", "generated/torch.Tensor.sigmoid", "generated/torch.Tensor.sigmoid_", "generated/torch.Tensor.sign", "generated/torch.Tensor.sign_", "generated/torch.Tensor.signbit", "generated/torch.Tensor.sin", "generated/torch.Tensor.sin_", "generated/torch.Tensor.sinc", "generated/torch.Tensor.sinc_", "generated/torch.Tensor.sinh", "generated/torch.Tensor.sinh_", "generated/torch.Tensor.size", "generated/torch.Tensor.slice_scatter", "generated/torch.Tensor.slogdet", "generated/torch.Tensor.smm", "generated/torch.Tensor.softmax", "generated/torch.Tensor.sort", "generated/torch.Tensor.sparse_dim", "generated/torch.Tensor.sparse_mask", "generated/torch.Tensor.sparse_resize_", "generated/torch.Tensor.sparse_resize_and_clear_", "generated/torch.Tensor.split", "generated/torch.Tensor.sqrt", "generated/torch.Tensor.sqrt_", "generated/torch.Tensor.square", "generated/torch.Tensor.square_", "generated/torch.Tensor.squeeze", "generated/torch.Tensor.squeeze_", "generated/torch.Tensor.sspaddmm", "generated/torch.Tensor.std", "generated/torch.Tensor.stft", "generated/torch.Tensor.storage", "generated/torch.Tensor.storage_offset", "generated/torch.Tensor.storage_type", "generated/torch.Tensor.stride", "generated/torch.Tensor.sub", "generated/torch.Tensor.sub_", "generated/torch.Tensor.subtract", "generated/torch.Tensor.subtract_", "generated/torch.Tensor.sum", "generated/torch.Tensor.sum_to_size", "generated/torch.Tensor.svd", "generated/torch.Tensor.swapaxes", "generated/torch.Tensor.swapdims", "generated/torch.Tensor.t", "generated/torch.Tensor.t_", "generated/torch.Tensor.take", "generated/torch.Tensor.take_along_dim", "generated/torch.Tensor.tan", "generated/torch.Tensor.tan_", "generated/torch.Tensor.tanh", "generated/torch.Tensor.tanh_", "generated/torch.Tensor.tensor_split", "generated/torch.Tensor.tile", "generated/torch.Tensor.to", "generated/torch.Tensor.to_dense", "generated/torch.Tensor.to_mkldnn", "generated/torch.Tensor.to_sparse", "generated/torch.Tensor.to_sparse_bsc", "generated/torch.Tensor.to_sparse_bsr", "generated/torch.Tensor.to_sparse_coo", "generated/torch.Tensor.to_sparse_csc", "generated/torch.Tensor.to_sparse_csr", "generated/torch.Tensor.tolist", "generated/torch.Tensor.topk", "generated/torch.Tensor.trace", "generated/torch.Tensor.transpose", "generated/torch.Tensor.transpose_", "generated/torch.Tensor.triangular_solve", "generated/torch.Tensor.tril", "generated/torch.Tensor.tril_", "generated/torch.Tensor.triu", "generated/torch.Tensor.triu_", "generated/torch.Tensor.true_divide", "generated/torch.Tensor.true_divide_", "generated/torch.Tensor.trunc", "generated/torch.Tensor.trunc_", "generated/torch.Tensor.type", "generated/torch.Tensor.type_as", "generated/torch.Tensor.unbind", "generated/torch.Tensor.unflatten", "generated/torch.Tensor.unfold", "generated/torch.Tensor.uniform_", "generated/torch.Tensor.unique", "generated/torch.Tensor.unique_consecutive", "generated/torch.Tensor.unsqueeze", "generated/torch.Tensor.unsqueeze_", "generated/torch.Tensor.untyped_storage", "generated/torch.Tensor.values", "generated/torch.Tensor.var", "generated/torch.Tensor.vdot", "generated/torch.Tensor.view", "generated/torch.Tensor.view_as", "generated/torch.Tensor.vsplit", "generated/torch.Tensor.where", "generated/torch.Tensor.xlogy", "generated/torch.Tensor.xlogy_", "generated/torch.Tensor.zero_", "generated/torch._assert", "generated/torch._foreach_abs", "generated/torch._foreach_abs_", "generated/torch._foreach_acos", "generated/torch._foreach_acos_", "generated/torch._foreach_asin", "generated/torch._foreach_asin_", "generated/torch._foreach_atan", "generated/torch._foreach_atan_", "generated/torch._foreach_ceil", "generated/torch._foreach_ceil_", "generated/torch._foreach_cos", "generated/torch._foreach_cos_", "generated/torch._foreach_cosh", "generated/torch._foreach_cosh_", "generated/torch._foreach_erf", "generated/torch._foreach_erf_", "generated/torch._foreach_erfc", "generated/torch._foreach_erfc_", "generated/torch._foreach_exp", "generated/torch._foreach_exp_", "generated/torch._foreach_expm1", "generated/torch._foreach_expm1_", "generated/torch._foreach_floor", "generated/torch._foreach_floor_", "generated/torch._foreach_frac", "generated/torch._foreach_frac_", "generated/torch._foreach_lgamma", "generated/torch._foreach_lgamma_", "generated/torch._foreach_log", "generated/torch._foreach_log10", "generated/torch._foreach_log10_", "generated/torch._foreach_log1p", "generated/torch._foreach_log1p_", "generated/torch._foreach_log2", "generated/torch._foreach_log2_", "generated/torch._foreach_log_", "generated/torch._foreach_neg", "generated/torch._foreach_neg_", "generated/torch._foreach_reciprocal", "generated/torch._foreach_reciprocal_", "generated/torch._foreach_round", "generated/torch._foreach_round_", "generated/torch._foreach_sigmoid", "generated/torch._foreach_sigmoid_", "generated/torch._foreach_sin", "generated/torch._foreach_sin_", "generated/torch._foreach_sinh", "generated/torch._foreach_sinh_", "generated/torch._foreach_sqrt", "generated/torch._foreach_sqrt_", "generated/torch._foreach_tan", "generated/torch._foreach_tan_", "generated/torch._foreach_trunc", "generated/torch._foreach_trunc_", "generated/torch._foreach_zero_", "generated/torch._logging.set_logs", "generated/torch.abs", "generated/torch.absolute", "generated/torch.acos", "generated/torch.acosh", "generated/torch.add", "generated/torch.addbmm", "generated/torch.addcdiv", "generated/torch.addcmul", "generated/torch.addmm", "generated/torch.addmv", "generated/torch.addr", "generated/torch.adjoint", "generated/torch.all", "generated/torch.allclose", "generated/torch.amax", "generated/torch.amin", "generated/torch.aminmax", "generated/torch.angle", "generated/torch.any", "generated/torch.ao.nn.intrinsic.BNReLU2d", "generated/torch.ao.nn.intrinsic.BNReLU3d", "generated/torch.ao.nn.intrinsic.ConvBn1d", "generated/torch.ao.nn.intrinsic.ConvBn2d", "generated/torch.ao.nn.intrinsic.ConvBn3d", "generated/torch.ao.nn.intrinsic.ConvBnReLU1d", "generated/torch.ao.nn.intrinsic.ConvBnReLU2d", "generated/torch.ao.nn.intrinsic.ConvBnReLU3d", "generated/torch.ao.nn.intrinsic.ConvReLU1d", "generated/torch.ao.nn.intrinsic.ConvReLU2d", "generated/torch.ao.nn.intrinsic.ConvReLU3d", "generated/torch.ao.nn.intrinsic.LinearReLU", "generated/torch.ao.nn.intrinsic.qat.ConvBn1d", "generated/torch.ao.nn.intrinsic.qat.ConvBn2d", "generated/torch.ao.nn.intrinsic.qat.ConvBn3d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d", "generated/torch.ao.nn.intrinsic.qat.ConvReLU2d", "generated/torch.ao.nn.intrinsic.qat.ConvReLU3d", "generated/torch.ao.nn.intrinsic.qat.LinearReLU", "generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats", "generated/torch.ao.nn.intrinsic.qat.update_bn_stats", "generated/torch.ao.nn.intrinsic.quantized.BNReLU2d", "generated/torch.ao.nn.intrinsic.quantized.BNReLU3d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d", "generated/torch.ao.nn.intrinsic.quantized.LinearReLU", "generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU", "generated/torch.ao.nn.qat.Conv2d", "generated/torch.ao.nn.qat.Conv3d", "generated/torch.ao.nn.qat.Linear", "generated/torch.ao.nn.qat.dynamic.Linear", "generated/torch.ao.nn.quantizable.LSTM", "generated/torch.ao.nn.quantizable.MultiheadAttention", "generated/torch.ao.nn.quantized.BatchNorm2d", "generated/torch.ao.nn.quantized.BatchNorm3d", "generated/torch.ao.nn.quantized.Conv1d", "generated/torch.ao.nn.quantized.Conv2d", "generated/torch.ao.nn.quantized.Conv3d", "generated/torch.ao.nn.quantized.ConvTranspose1d", "generated/torch.ao.nn.quantized.ConvTranspose2d", "generated/torch.ao.nn.quantized.ConvTranspose3d", "generated/torch.ao.nn.quantized.ELU", "generated/torch.ao.nn.quantized.Embedding", "generated/torch.ao.nn.quantized.EmbeddingBag", "generated/torch.ao.nn.quantized.FXFloatFunctional", "generated/torch.ao.nn.quantized.FloatFunctional", "generated/torch.ao.nn.quantized.GroupNorm", "generated/torch.ao.nn.quantized.Hardswish", "generated/torch.ao.nn.quantized.InstanceNorm1d", "generated/torch.ao.nn.quantized.InstanceNorm2d", "generated/torch.ao.nn.quantized.InstanceNorm3d", "generated/torch.ao.nn.quantized.LayerNorm", "generated/torch.ao.nn.quantized.LeakyReLU", "generated/torch.ao.nn.quantized.Linear", "generated/torch.ao.nn.quantized.QFunctional", "generated/torch.ao.nn.quantized.ReLU6", "generated/torch.ao.nn.quantized.Sigmoid", "generated/torch.ao.nn.quantized.dynamic.GRU", "generated/torch.ao.nn.quantized.dynamic.GRUCell", "generated/torch.ao.nn.quantized.dynamic.LSTM", "generated/torch.ao.nn.quantized.dynamic.LSTMCell", "generated/torch.ao.nn.quantized.dynamic.Linear", "generated/torch.ao.nn.quantized.dynamic.RNNCell", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d", "generated/torch.ao.nn.quantized.functional.avg_pool2d", "generated/torch.ao.nn.quantized.functional.avg_pool3d", "generated/torch.ao.nn.quantized.functional.celu", "generated/torch.ao.nn.quantized.functional.clamp", "generated/torch.ao.nn.quantized.functional.conv1d", "generated/torch.ao.nn.quantized.functional.conv2d", "generated/torch.ao.nn.quantized.functional.conv3d", "generated/torch.ao.nn.quantized.functional.elu", "generated/torch.ao.nn.quantized.functional.hardsigmoid", "generated/torch.ao.nn.quantized.functional.hardswish", "generated/torch.ao.nn.quantized.functional.hardtanh", "generated/torch.ao.nn.quantized.functional.interpolate", "generated/torch.ao.nn.quantized.functional.leaky_relu", "generated/torch.ao.nn.quantized.functional.linear", "generated/torch.ao.nn.quantized.functional.max_pool1d", "generated/torch.ao.nn.quantized.functional.max_pool2d", "generated/torch.ao.nn.quantized.functional.threshold", "generated/torch.ao.nn.quantized.functional.upsample", "generated/torch.ao.nn.quantized.functional.upsample_bilinear", "generated/torch.ao.nn.quantized.functional.upsample_nearest", "generated/torch.ao.quantization.DeQuantStub", "generated/torch.ao.quantization.QuantStub", "generated/torch.ao.quantization.QuantWrapper", "generated/torch.ao.quantization.add_quant_dequant", "generated/torch.ao.quantization.backend_config.BackendConfig", "generated/torch.ao.quantization.backend_config.BackendPatternConfig", "generated/torch.ao.quantization.backend_config.DTypeConfig", "generated/torch.ao.quantization.backend_config.DTypeWithConstraints", "generated/torch.ao.quantization.backend_config.ObservationType", "generated/torch.ao.quantization.convert", "generated/torch.ao.quantization.default_eval_fn", "generated/torch.ao.quantization.fake_quantize.FakeQuantize", "generated/torch.ao.quantization.fake_quantize.FakeQuantizeBase", "generated/torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize", "generated/torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize", "generated/torch.ao.quantization.fake_quantize.default_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_fused_act_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_histogram_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant", "generated/torch.ao.quantization.fake_quantize.default_weight_fake_quant", "generated/torch.ao.quantization.fake_quantize.disable_fake_quant", "generated/torch.ao.quantization.fake_quantize.disable_observer", "generated/torch.ao.quantization.fake_quantize.enable_fake_quant", "generated/torch.ao.quantization.fake_quantize.enable_observer", "generated/torch.ao.quantization.fuse_modules", "generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig", "generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig", "generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig", "generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry", "generated/torch.ao.quantization.observer.HistogramObserver", "generated/torch.ao.quantization.observer.MinMaxObserver", "generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver", "generated/torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver", "generated/torch.ao.quantization.observer.NoopObserver", "generated/torch.ao.quantization.observer.ObserverBase", "generated/torch.ao.quantization.observer.PerChannelMinMaxObserver", "generated/torch.ao.quantization.observer.PlaceholderObserver", "generated/torch.ao.quantization.observer.RecordingObserver", "generated/torch.ao.quantization.observer.default_debug_observer", "generated/torch.ao.quantization.observer.default_dynamic_quant_observer", "generated/torch.ao.quantization.observer.default_float_qparams_observer", "generated/torch.ao.quantization.observer.default_histogram_observer", "generated/torch.ao.quantization.observer.default_observer", "generated/torch.ao.quantization.observer.default_per_channel_weight_observer", "generated/torch.ao.quantization.observer.default_placeholder_observer", "generated/torch.ao.quantization.observer.default_weight_observer", "generated/torch.ao.quantization.observer.get_observer_state_dict", "generated/torch.ao.quantization.observer.load_observer_state_dict", "generated/torch.ao.quantization.prepare", "generated/torch.ao.quantization.prepare_qat", "generated/torch.ao.quantization.propagate_qconfig_", "generated/torch.ao.quantization.qconfig.QConfig", "generated/torch.ao.quantization.qconfig.default_activation_only_qconfig", "generated/torch.ao.quantization.qconfig.default_debug_qconfig", "generated/torch.ao.quantization.qconfig.default_dynamic_qconfig", "generated/torch.ao.quantization.qconfig.default_per_channel_qconfig", "generated/torch.ao.quantization.qconfig.default_qat_qconfig", "generated/torch.ao.quantization.qconfig.default_qat_qconfig_v2", "generated/torch.ao.quantization.qconfig.default_qconfig", "generated/torch.ao.quantization.qconfig.default_weight_only_qconfig", "generated/torch.ao.quantization.qconfig.float16_dynamic_qconfig", "generated/torch.ao.quantization.qconfig.float16_static_qconfig", "generated/torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig", "generated/torch.ao.quantization.qconfig.per_channel_dynamic_qconfig", "generated/torch.ao.quantization.qconfig_mapping.QConfigMapping", "generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping", "generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping", "generated/torch.ao.quantization.quantize", "generated/torch.ao.quantization.quantize_dynamic", "generated/torch.ao.quantization.quantize_fx.convert_fx", "generated/torch.ao.quantization.quantize_fx.fuse_fx", "generated/torch.ao.quantization.quantize_fx.prepare_fx", "generated/torch.ao.quantization.quantize_fx.prepare_qat_fx", "generated/torch.ao.quantization.quantize_qat", "generated/torch.ao.quantization.swap_module", "generated/torch.arange", "generated/torch.arccos", "generated/torch.arccosh", "generated/torch.arcsin", "generated/torch.arcsinh", "generated/torch.arctan", "generated/torch.arctan2", "generated/torch.arctanh", "generated/torch.are_deterministic_algorithms_enabled", "generated/torch.argmax", "generated/torch.argmin", "generated/torch.argsort", "generated/torch.argwhere", "generated/torch.as_strided", "generated/torch.as_tensor", "generated/torch.asarray", "generated/torch.asin", "generated/torch.asinh", "generated/torch.atan", "generated/torch.atan2", "generated/torch.atanh", "generated/torch.atleast_1d", "generated/torch.atleast_2d", "generated/torch.atleast_3d", "generated/torch.autograd.Function.backward", "generated/torch.autograd.Function.forward", "generated/torch.autograd.Function.jvp", "generated/torch.autograd.Function.vmap", "generated/torch.autograd.backward", "generated/torch.autograd.forward_ad.dual_level", "generated/torch.autograd.forward_ad.make_dual", "generated/torch.autograd.forward_ad.unpack_dual", "generated/torch.autograd.function.FunctionCtx.mark_dirty", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable", "generated/torch.autograd.function.FunctionCtx.save_for_backward", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads", "generated/torch.autograd.functional.hessian", "generated/torch.autograd.functional.hvp", "generated/torch.autograd.functional.jacobian", "generated/torch.autograd.functional.jvp", "generated/torch.autograd.functional.vhp", "generated/torch.autograd.functional.vjp", "generated/torch.autograd.grad", "generated/torch.autograd.gradcheck", "generated/torch.autograd.gradgradcheck", "generated/torch.autograd.graph.Node.metadata", "generated/torch.autograd.graph.Node.name", "generated/torch.autograd.graph.Node.next_functions", "generated/torch.autograd.graph.Node.register_hook", "generated/torch.autograd.graph.Node.register_prehook", "generated/torch.autograd.profiler.load_nvprof", "generated/torch.autograd.profiler.profile.export_chrome_trace", "generated/torch.autograd.profiler.profile.key_averages", "generated/torch.autograd.profiler.profile.self_cpu_time_total", "generated/torch.autograd.profiler.profile.total_average", "generated/torch.autograd.set_multithreading_enabled", "generated/torch.baddbmm", "generated/torch.bartlett_window", "generated/torch.bernoulli", "generated/torch.bincount", "generated/torch.bitwise_and", "generated/torch.bitwise_left_shift", "generated/torch.bitwise_not", "generated/torch.bitwise_or", "generated/torch.bitwise_right_shift", "generated/torch.bitwise_xor", "generated/torch.blackman_window", "generated/torch.block_diag", "generated/torch.bmm", "generated/torch.broadcast_shapes", "generated/torch.broadcast_tensors", "generated/torch.broadcast_to", "generated/torch.bucketize", "generated/torch.can_cast", "generated/torch.cartesian_prod", "generated/torch.cat", "generated/torch.cdist", "generated/torch.ceil", "generated/torch.chain_matmul", "generated/torch.cholesky", "generated/torch.cholesky_inverse", "generated/torch.cholesky_solve", "generated/torch.chunk", "generated/torch.clamp", "generated/torch.clip", "generated/torch.clone", "generated/torch.column_stack", "generated/torch.combinations", "generated/torch.compile", "generated/torch.compiled_with_cxx11_abi", "generated/torch.complex", "generated/torch.concat", "generated/torch.concatenate", "generated/torch.conj", "generated/torch.conj_physical", "generated/torch.copysign", "generated/torch.corrcoef", "generated/torch.cos", "generated/torch.cosh", "generated/torch.count_nonzero", "generated/torch.cov", "generated/torch.cross", "generated/torch.cuda.CUDAGraph", "generated/torch.cuda.CUDAPluggableAllocator", "generated/torch.cuda.Event", "generated/torch.cuda.ExternalStream", "generated/torch.cuda.OutOfMemoryError", "generated/torch.cuda.Stream", "generated/torch.cuda.StreamContext", "generated/torch.cuda.caching_allocator_alloc", "generated/torch.cuda.caching_allocator_delete", "generated/torch.cuda.can_device_access_peer", "generated/torch.cuda.change_current_allocator", "generated/torch.cuda.clock_rate", "generated/torch.cuda.comm.broadcast", "generated/torch.cuda.comm.broadcast_coalesced", "generated/torch.cuda.comm.gather", "generated/torch.cuda.comm.reduce_add", "generated/torch.cuda.comm.scatter", "generated/torch.cuda.current_blas_handle", "generated/torch.cuda.current_device", "generated/torch.cuda.current_stream", "generated/torch.cuda.default_stream", "generated/torch.cuda.device", "generated/torch.cuda.device_count", "generated/torch.cuda.device_of", "generated/torch.cuda.empty_cache", "generated/torch.cuda.get_allocator_backend", "generated/torch.cuda.get_arch_list", "generated/torch.cuda.get_device_capability", "generated/torch.cuda.get_device_name", "generated/torch.cuda.get_device_properties", "generated/torch.cuda.get_gencode_flags", "generated/torch.cuda.get_rng_state", "generated/torch.cuda.get_rng_state_all", "generated/torch.cuda.get_sync_debug_mode", "generated/torch.cuda.graph", "generated/torch.cuda.graph_pool_handle", "generated/torch.cuda.init", "generated/torch.cuda.initial_seed", "generated/torch.cuda.ipc_collect", "generated/torch.cuda.is_available", "generated/torch.cuda.is_current_stream_capturing", "generated/torch.cuda.is_initialized", "generated/torch.cuda.jiterator._create_jit_fn", "generated/torch.cuda.jiterator._create_multi_output_jit_fn", "generated/torch.cuda.list_gpu_processes", "generated/torch.cuda.make_graphed_callables", "generated/torch.cuda.manual_seed", "generated/torch.cuda.manual_seed_all", "generated/torch.cuda.max_memory_allocated", "generated/torch.cuda.max_memory_cached", "generated/torch.cuda.max_memory_reserved", "generated/torch.cuda.mem_get_info", "generated/torch.cuda.memory_allocated", "generated/torch.cuda.memory_cached", "generated/torch.cuda.memory_reserved", "generated/torch.cuda.memory_snapshot", "generated/torch.cuda.memory_stats", "generated/torch.cuda.memory_summary", "generated/torch.cuda.memory_usage", "generated/torch.cuda.nvtx.mark", "generated/torch.cuda.nvtx.range_pop", "generated/torch.cuda.nvtx.range_push", "generated/torch.cuda.power_draw", "generated/torch.cuda.reset_max_memory_allocated", "generated/torch.cuda.reset_max_memory_cached", "generated/torch.cuda.reset_peak_memory_stats", "generated/torch.cuda.seed", "generated/torch.cuda.seed_all", "generated/torch.cuda.set_device", "generated/torch.cuda.set_per_process_memory_fraction", "generated/torch.cuda.set_rng_state", "generated/torch.cuda.set_rng_state_all", "generated/torch.cuda.set_stream", "generated/torch.cuda.set_sync_debug_mode", "generated/torch.cuda.stream", "generated/torch.cuda.synchronize", "generated/torch.cuda.temperature", "generated/torch.cuda.utilization", "generated/torch.cummax", "generated/torch.cummin", "generated/torch.cumprod", "generated/torch.cumsum", "generated/torch.cumulative_trapezoid", "generated/torch.deg2rad", "generated/torch.dequantize", "generated/torch.det", "generated/torch.diag", "generated/torch.diag_embed", "generated/torch.diagflat", "generated/torch.diagonal", "generated/torch.diagonal_scatter", "generated/torch.diff", "generated/torch.digamma", "generated/torch.dist", "generated/torch.div", "generated/torch.divide", "generated/torch.dot", "generated/torch.dsplit", "generated/torch.dstack", "generated/torch.einsum", "generated/torch.empty", "generated/torch.empty_like", "generated/torch.empty_strided", "generated/torch.enable_grad", "generated/torch.eq", "generated/torch.equal", "generated/torch.erf", "generated/torch.erfc", "generated/torch.erfinv", "generated/torch.exp", "generated/torch.exp2", "generated/torch.expm1", "generated/torch.eye", "generated/torch.fake_quantize_per_channel_affine", "generated/torch.fake_quantize_per_tensor_affine", "generated/torch.fft.fft", "generated/torch.fft.fft2", "generated/torch.fft.fftfreq", "generated/torch.fft.fftn", "generated/torch.fft.fftshift", "generated/torch.fft.hfft", "generated/torch.fft.hfft2", "generated/torch.fft.hfftn", "generated/torch.fft.ifft", "generated/torch.fft.ifft2", "generated/torch.fft.ifftn", "generated/torch.fft.ifftshift", "generated/torch.fft.ihfft", "generated/torch.fft.ihfft2", "generated/torch.fft.ihfftn", "generated/torch.fft.irfft", "generated/torch.fft.irfft2", "generated/torch.fft.irfftn", "generated/torch.fft.rfft", "generated/torch.fft.rfft2", "generated/torch.fft.rfftfreq", "generated/torch.fft.rfftn", "generated/torch.fix", "generated/torch.flatten", "generated/torch.flip", "generated/torch.fliplr", "generated/torch.flipud", "generated/torch.float_power", "generated/torch.floor", "generated/torch.floor_divide", "generated/torch.fmax", "generated/torch.fmin", "generated/torch.fmod", "generated/torch.frac", "generated/torch.frexp", "generated/torch.from_dlpack", "generated/torch.from_numpy", "generated/torch.frombuffer", "generated/torch.full", "generated/torch.full_like", "generated/torch.func.functional_call", "generated/torch.func.functionalize", "generated/torch.func.grad", "generated/torch.func.grad_and_value", "generated/torch.func.hessian", "generated/torch.func.jacfwd", "generated/torch.func.jacrev", "generated/torch.func.jvp", "generated/torch.func.linearize", "generated/torch.func.replace_all_batch_norm_modules_", "generated/torch.func.stack_module_state", "generated/torch.func.vjp", "generated/torch.func.vmap", "generated/torch.gather", "generated/torch.gcd", "generated/torch.ge", "generated/torch.geqrf", "generated/torch.ger", "generated/torch.get_default_dtype", "generated/torch.get_deterministic_debug_mode", "generated/torch.get_float32_matmul_precision", "generated/torch.get_num_interop_threads", "generated/torch.get_num_threads", "generated/torch.get_rng_state", "generated/torch.gradient", "generated/torch.greater", "generated/torch.greater_equal", "generated/torch.gt", "generated/torch.hamming_window", "generated/torch.hann_window", "generated/torch.heaviside", "generated/torch.histc", "generated/torch.histogram", "generated/torch.histogramdd", "generated/torch.hsplit", "generated/torch.hspmm", "generated/torch.hstack", "generated/torch.hypot", "generated/torch.i0", "generated/torch.igamma", "generated/torch.igammac", "generated/torch.imag", "generated/torch.index_add", "generated/torch.index_copy", "generated/torch.index_reduce", "generated/torch.index_select", "generated/torch.inference_mode", "generated/torch.initial_seed", "generated/torch.inner", "generated/torch.inverse", "generated/torch.is_complex", "generated/torch.is_conj", "generated/torch.is_deterministic_algorithms_warn_only_enabled", "generated/torch.is_floating_point", "generated/torch.is_grad_enabled", "generated/torch.is_inference_mode_enabled", "generated/torch.is_nonzero", "generated/torch.is_storage", "generated/torch.is_tensor", "generated/torch.is_warn_always_enabled", "generated/torch.isclose", "generated/torch.isfinite", "generated/torch.isin", "generated/torch.isinf", "generated/torch.isnan", "generated/torch.isneginf", "generated/torch.isposinf", "generated/torch.isreal", "generated/torch.istft", "generated/torch.jit.Attribute", "generated/torch.jit.ScriptFunction", "generated/torch.jit.ScriptModule", "generated/torch.jit.annotate", "generated/torch.jit.enable_onednn_fusion", "generated/torch.jit.fork", "generated/torch.jit.freeze", "generated/torch.jit.ignore", "generated/torch.jit.isinstance", "generated/torch.jit.load", "generated/torch.jit.onednn_fusion_enabled", "generated/torch.jit.optimize_for_inference", "generated/torch.jit.save", "generated/torch.jit.script", "generated/torch.jit.script_if_tracing", "generated/torch.jit.set_fusion_strategy", "generated/torch.jit.strict_fusion", "generated/torch.jit.trace", "generated/torch.jit.trace_module", "generated/torch.jit.unused", "generated/torch.jit.wait", "generated/torch.kaiser_window", "generated/torch.kron", "generated/torch.kthvalue", "generated/torch.lcm", "generated/torch.ldexp", "generated/torch.le", "generated/torch.lerp", "generated/torch.less", "generated/torch.less_equal", "generated/torch.lgamma", "generated/torch.linalg.cholesky", "generated/torch.linalg.cholesky_ex", "generated/torch.linalg.cond", "generated/torch.linalg.cross", "generated/torch.linalg.det", "generated/torch.linalg.diagonal", "generated/torch.linalg.eig", "generated/torch.linalg.eigh", "generated/torch.linalg.eigvals", "generated/torch.linalg.eigvalsh", "generated/torch.linalg.householder_product", "generated/torch.linalg.inv", "generated/torch.linalg.inv_ex", "generated/torch.linalg.ldl_factor", "generated/torch.linalg.ldl_factor_ex", "generated/torch.linalg.ldl_solve", "generated/torch.linalg.lstsq", "generated/torch.linalg.lu", "generated/torch.linalg.lu_factor", "generated/torch.linalg.lu_factor_ex", "generated/torch.linalg.lu_solve", "generated/torch.linalg.matmul", "generated/torch.linalg.matrix_exp", "generated/torch.linalg.matrix_norm", "generated/torch.linalg.matrix_power", "generated/torch.linalg.matrix_rank", "generated/torch.linalg.multi_dot", "generated/torch.linalg.norm", "generated/torch.linalg.pinv", "generated/torch.linalg.qr", "generated/torch.linalg.slogdet", "generated/torch.linalg.solve", "generated/torch.linalg.solve_ex", "generated/torch.linalg.solve_triangular", "generated/torch.linalg.svd", "generated/torch.linalg.svdvals", "generated/torch.linalg.tensorinv", "generated/torch.linalg.tensorsolve", "generated/torch.linalg.vander", "generated/torch.linalg.vecdot", "generated/torch.linalg.vector_norm", "generated/torch.linspace", "generated/torch.load", "generated/torch.lobpcg", "generated/torch.log", "generated/torch.log10", "generated/torch.log1p", "generated/torch.log2", "generated/torch.logaddexp", "generated/torch.logaddexp2", "generated/torch.logcumsumexp", "generated/torch.logdet", "generated/torch.logical_and", "generated/torch.logical_not", "generated/torch.logical_or", "generated/torch.logical_xor", "generated/torch.logit", "generated/torch.logspace", "generated/torch.logsumexp", "generated/torch.lt", "generated/torch.lu", "generated/torch.lu_solve", "generated/torch.lu_unpack", "generated/torch.manual_seed", "generated/torch.masked_select", "generated/torch.matmul", "generated/torch.matrix_exp", "generated/torch.matrix_power", "generated/torch.max", "generated/torch.maximum", "generated/torch.mean", "generated/torch.median", "generated/torch.meshgrid", "generated/torch.min", "generated/torch.minimum", "generated/torch.mm", "generated/torch.mode", "generated/torch.moveaxis", "generated/torch.movedim", "generated/torch.mps.current_allocated_memory", "generated/torch.mps.driver_allocated_memory", "generated/torch.mps.empty_cache", "generated/torch.mps.get_rng_state", "generated/torch.mps.manual_seed", "generated/torch.mps.profiler.profile", "generated/torch.mps.profiler.start", "generated/torch.mps.profiler.stop", "generated/torch.mps.seed", "generated/torch.mps.set_per_process_memory_fraction", "generated/torch.mps.set_rng_state", "generated/torch.mps.synchronize", "generated/torch.msort", "generated/torch.mul", "generated/torch.multinomial", "generated/torch.multiply", "generated/torch.mv", "generated/torch.mvlgamma", "generated/torch.nan_to_num", "generated/torch.nanmean", "generated/torch.nanmedian", "generated/torch.nanquantile", "generated/torch.nansum", "generated/torch.narrow", "generated/torch.narrow_copy", "generated/torch.ne", "generated/torch.neg", "generated/torch.negative", "generated/torch.nextafter", "generated/torch.nn.AdaptiveAvgPool1d", "generated/torch.nn.AdaptiveAvgPool2d", "generated/torch.nn.AdaptiveAvgPool3d", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss", "generated/torch.nn.AdaptiveMaxPool1d", "generated/torch.nn.AdaptiveMaxPool2d", "generated/torch.nn.AdaptiveMaxPool3d", "generated/torch.nn.AlphaDropout", "generated/torch.nn.AvgPool1d", "generated/torch.nn.AvgPool2d", "generated/torch.nn.AvgPool3d", "generated/torch.nn.BCELoss", "generated/torch.nn.BCEWithLogitsLoss", "generated/torch.nn.BatchNorm1d", "generated/torch.nn.BatchNorm2d", "generated/torch.nn.BatchNorm3d", "generated/torch.nn.Bilinear", "generated/torch.nn.CELU", "generated/torch.nn.CTCLoss", "generated/torch.nn.ChannelShuffle", "generated/torch.nn.ConstantPad1d", "generated/torch.nn.ConstantPad2d", "generated/torch.nn.ConstantPad3d", "generated/torch.nn.Conv1d", "generated/torch.nn.Conv2d", "generated/torch.nn.Conv3d", "generated/torch.nn.ConvTranspose1d", "generated/torch.nn.ConvTranspose2d", "generated/torch.nn.ConvTranspose3d", "generated/torch.nn.CosineEmbeddingLoss", "generated/torch.nn.CosineSimilarity", "generated/torch.nn.CrossEntropyLoss", "generated/torch.nn.DataParallel", "generated/torch.nn.Dropout", "generated/torch.nn.Dropout1d", "generated/torch.nn.Dropout2d", "generated/torch.nn.Dropout3d", "generated/torch.nn.ELU", "generated/torch.nn.Embedding", "generated/torch.nn.EmbeddingBag", "generated/torch.nn.FeatureAlphaDropout", "generated/torch.nn.Flatten", "generated/torch.nn.Fold", "generated/torch.nn.FractionalMaxPool2d", "generated/torch.nn.FractionalMaxPool3d", "generated/torch.nn.GELU", "generated/torch.nn.GLU", "generated/torch.nn.GRU", "generated/torch.nn.GRUCell", "generated/torch.nn.GaussianNLLLoss", "generated/torch.nn.GroupNorm", "generated/torch.nn.Hardshrink", "generated/torch.nn.Hardsigmoid", "generated/torch.nn.Hardswish", "generated/torch.nn.Hardtanh", "generated/torch.nn.HingeEmbeddingLoss", "generated/torch.nn.HuberLoss", "generated/torch.nn.Identity", "generated/torch.nn.InstanceNorm1d", "generated/torch.nn.InstanceNorm2d", "generated/torch.nn.InstanceNorm3d", "generated/torch.nn.KLDivLoss", "generated/torch.nn.L1Loss", "generated/torch.nn.LPPool1d", "generated/torch.nn.LPPool2d", "generated/torch.nn.LSTM", "generated/torch.nn.LSTMCell", "generated/torch.nn.LayerNorm", "generated/torch.nn.LazyBatchNorm1d", "generated/torch.nn.LazyBatchNorm2d", "generated/torch.nn.LazyBatchNorm3d", "generated/torch.nn.LazyConv1d", "generated/torch.nn.LazyConv2d", "generated/torch.nn.LazyConv3d", "generated/torch.nn.LazyConvTranspose1d", "generated/torch.nn.LazyConvTranspose2d", "generated/torch.nn.LazyConvTranspose3d", "generated/torch.nn.LazyInstanceNorm1d", "generated/torch.nn.LazyInstanceNorm2d", "generated/torch.nn.LazyInstanceNorm3d", "generated/torch.nn.LazyLinear", "generated/torch.nn.LeakyReLU", "generated/torch.nn.Linear", "generated/torch.nn.LocalResponseNorm", "generated/torch.nn.LogSigmoid", "generated/torch.nn.LogSoftmax", "generated/torch.nn.MSELoss", "generated/torch.nn.MarginRankingLoss", "generated/torch.nn.MaxPool1d", "generated/torch.nn.MaxPool2d", "generated/torch.nn.MaxPool3d", "generated/torch.nn.MaxUnpool1d", "generated/torch.nn.MaxUnpool2d", "generated/torch.nn.MaxUnpool3d", "generated/torch.nn.Mish", "generated/torch.nn.Module", "generated/torch.nn.ModuleDict", "generated/torch.nn.ModuleList", "generated/torch.nn.MultiLabelMarginLoss", "generated/torch.nn.MultiLabelSoftMarginLoss", "generated/torch.nn.MultiMarginLoss", "generated/torch.nn.MultiheadAttention", "generated/torch.nn.NLLLoss", "generated/torch.nn.PReLU", "generated/torch.nn.PairwiseDistance", "generated/torch.nn.ParameterDict", "generated/torch.nn.ParameterList", "generated/torch.nn.PixelShuffle", "generated/torch.nn.PixelUnshuffle", "generated/torch.nn.PoissonNLLLoss", "generated/torch.nn.RNN", "generated/torch.nn.RNNBase", "generated/torch.nn.RNNCell", "generated/torch.nn.RReLU", "generated/torch.nn.ReLU", "generated/torch.nn.ReLU6", "generated/torch.nn.ReflectionPad1d", "generated/torch.nn.ReflectionPad2d", "generated/torch.nn.ReflectionPad3d", "generated/torch.nn.ReplicationPad1d", "generated/torch.nn.ReplicationPad2d", "generated/torch.nn.ReplicationPad3d", "generated/torch.nn.SELU", "generated/torch.nn.Sequential", "generated/torch.nn.SiLU", "generated/torch.nn.Sigmoid", "generated/torch.nn.SmoothL1Loss", "generated/torch.nn.SoftMarginLoss", "generated/torch.nn.Softmax", "generated/torch.nn.Softmax2d", "generated/torch.nn.Softmin", "generated/torch.nn.Softplus", "generated/torch.nn.Softshrink", "generated/torch.nn.Softsign", "generated/torch.nn.SyncBatchNorm", "generated/torch.nn.Tanh", "generated/torch.nn.Tanhshrink", "generated/torch.nn.Threshold", "generated/torch.nn.Transformer", "generated/torch.nn.TransformerDecoder", "generated/torch.nn.TransformerDecoderLayer", "generated/torch.nn.TransformerEncoder", "generated/torch.nn.TransformerEncoderLayer", "generated/torch.nn.TripletMarginLoss", "generated/torch.nn.TripletMarginWithDistanceLoss", "generated/torch.nn.Unflatten", "generated/torch.nn.Unfold", "generated/torch.nn.Upsample", "generated/torch.nn.UpsamplingBilinear2d", "generated/torch.nn.UpsamplingNearest2d", "generated/torch.nn.ZeroPad1d", "generated/torch.nn.ZeroPad2d", "generated/torch.nn.ZeroPad3d", "generated/torch.nn.functional.adaptive_avg_pool1d", "generated/torch.nn.functional.adaptive_avg_pool2d", "generated/torch.nn.functional.adaptive_avg_pool3d", "generated/torch.nn.functional.adaptive_max_pool1d", "generated/torch.nn.functional.adaptive_max_pool2d", "generated/torch.nn.functional.adaptive_max_pool3d", "generated/torch.nn.functional.affine_grid", "generated/torch.nn.functional.alpha_dropout", "generated/torch.nn.functional.avg_pool1d", "generated/torch.nn.functional.avg_pool2d", "generated/torch.nn.functional.avg_pool3d", "generated/torch.nn.functional.batch_norm", "generated/torch.nn.functional.bilinear", "generated/torch.nn.functional.binary_cross_entropy", "generated/torch.nn.functional.binary_cross_entropy_with_logits", "generated/torch.nn.functional.celu", "generated/torch.nn.functional.conv1d", "generated/torch.nn.functional.conv2d", "generated/torch.nn.functional.conv3d", "generated/torch.nn.functional.conv_transpose1d", "generated/torch.nn.functional.conv_transpose2d", "generated/torch.nn.functional.conv_transpose3d", "generated/torch.nn.functional.cosine_embedding_loss", "generated/torch.nn.functional.cosine_similarity", "generated/torch.nn.functional.cross_entropy", "generated/torch.nn.functional.ctc_loss", "generated/torch.nn.functional.dropout", "generated/torch.nn.functional.dropout1d", "generated/torch.nn.functional.dropout2d", "generated/torch.nn.functional.dropout3d", "generated/torch.nn.functional.elu", "generated/torch.nn.functional.elu_", "generated/torch.nn.functional.embedding", "generated/torch.nn.functional.embedding_bag", "generated/torch.nn.functional.feature_alpha_dropout", "generated/torch.nn.functional.fold", "generated/torch.nn.functional.fractional_max_pool2d", "generated/torch.nn.functional.fractional_max_pool3d", "generated/torch.nn.functional.gaussian_nll_loss", "generated/torch.nn.functional.gelu", "generated/torch.nn.functional.glu", "generated/torch.nn.functional.grid_sample", "generated/torch.nn.functional.group_norm", "generated/torch.nn.functional.gumbel_softmax", "generated/torch.nn.functional.hardshrink", "generated/torch.nn.functional.hardsigmoid", "generated/torch.nn.functional.hardswish", "generated/torch.nn.functional.hardtanh", "generated/torch.nn.functional.hardtanh_", "generated/torch.nn.functional.hinge_embedding_loss", "generated/torch.nn.functional.huber_loss", "generated/torch.nn.functional.instance_norm", "generated/torch.nn.functional.interpolate", "generated/torch.nn.functional.kl_div", "generated/torch.nn.functional.l1_loss", "generated/torch.nn.functional.layer_norm", "generated/torch.nn.functional.leaky_relu", "generated/torch.nn.functional.leaky_relu_", "generated/torch.nn.functional.linear", "generated/torch.nn.functional.local_response_norm", "generated/torch.nn.functional.log_softmax", "generated/torch.nn.functional.logsigmoid", "generated/torch.nn.functional.lp_pool1d", "generated/torch.nn.functional.lp_pool2d", "generated/torch.nn.functional.margin_ranking_loss", "generated/torch.nn.functional.max_pool1d", "generated/torch.nn.functional.max_pool2d", "generated/torch.nn.functional.max_pool3d", "generated/torch.nn.functional.max_unpool1d", "generated/torch.nn.functional.max_unpool2d", "generated/torch.nn.functional.max_unpool3d", "generated/torch.nn.functional.mish", "generated/torch.nn.functional.mse_loss", "generated/torch.nn.functional.multi_margin_loss", "generated/torch.nn.functional.multilabel_margin_loss", "generated/torch.nn.functional.multilabel_soft_margin_loss", "generated/torch.nn.functional.nll_loss", "generated/torch.nn.functional.normalize", "generated/torch.nn.functional.one_hot", "generated/torch.nn.functional.pad", "generated/torch.nn.functional.pairwise_distance", "generated/torch.nn.functional.pdist", "generated/torch.nn.functional.pixel_shuffle", "generated/torch.nn.functional.pixel_unshuffle", "generated/torch.nn.functional.poisson_nll_loss", "generated/torch.nn.functional.prelu", "generated/torch.nn.functional.relu", "generated/torch.nn.functional.relu6", "generated/torch.nn.functional.relu_", "generated/torch.nn.functional.rrelu", "generated/torch.nn.functional.rrelu_", "generated/torch.nn.functional.scaled_dot_product_attention", "generated/torch.nn.functional.selu", "generated/torch.nn.functional.sigmoid", "generated/torch.nn.functional.silu", "generated/torch.nn.functional.smooth_l1_loss", "generated/torch.nn.functional.soft_margin_loss", "generated/torch.nn.functional.softmax", "generated/torch.nn.functional.softmin", "generated/torch.nn.functional.softplus", "generated/torch.nn.functional.softshrink", "generated/torch.nn.functional.softsign", "generated/torch.nn.functional.tanh", "generated/torch.nn.functional.tanhshrink", "generated/torch.nn.functional.threshold", "generated/torch.nn.functional.threshold_", "generated/torch.nn.functional.torch.nn.parallel.data_parallel", "generated/torch.nn.functional.triplet_margin_loss", "generated/torch.nn.functional.triplet_margin_with_distance_loss", "generated/torch.nn.functional.unfold", "generated/torch.nn.functional.upsample", "generated/torch.nn.functional.upsample_bilinear", "generated/torch.nn.functional.upsample_nearest", "generated/torch.nn.modules.lazy.LazyModuleMixin", "generated/torch.nn.modules.module.register_module_backward_hook", "generated/torch.nn.modules.module.register_module_buffer_registration_hook", "generated/torch.nn.modules.module.register_module_forward_hook", "generated/torch.nn.modules.module.register_module_forward_pre_hook", "generated/torch.nn.modules.module.register_module_full_backward_hook", "generated/torch.nn.modules.module.register_module_full_backward_pre_hook", "generated/torch.nn.modules.module.register_module_module_registration_hook", "generated/torch.nn.modules.module.register_module_parameter_registration_hook", "generated/torch.nn.parallel.DistributedDataParallel", "generated/torch.nn.parameter.Parameter", "generated/torch.nn.parameter.UninitializedBuffer", "generated/torch.nn.parameter.UninitializedParameter", "generated/torch.nn.utils.clip_grad_norm_", "generated/torch.nn.utils.clip_grad_value_", "generated/torch.nn.utils.parameters_to_vector", "generated/torch.nn.utils.parametrizations.orthogonal", "generated/torch.nn.utils.parametrizations.spectral_norm", "generated/torch.nn.utils.parametrize.ParametrizationList", "generated/torch.nn.utils.parametrize.cached", "generated/torch.nn.utils.parametrize.is_parametrized", "generated/torch.nn.utils.parametrize.register_parametrization", "generated/torch.nn.utils.parametrize.remove_parametrizations", "generated/torch.nn.utils.prune.BasePruningMethod", "generated/torch.nn.utils.prune.CustomFromMask", "generated/torch.nn.utils.prune.Identity", "generated/torch.nn.utils.prune.L1Unstructured", "generated/torch.nn.utils.prune.LnStructured", "generated/torch.nn.utils.prune.PruningContainer", "generated/torch.nn.utils.prune.RandomStructured", "generated/torch.nn.utils.prune.RandomUnstructured", "generated/torch.nn.utils.prune.custom_from_mask", "generated/torch.nn.utils.prune.global_unstructured", "generated/torch.nn.utils.prune.identity", "generated/torch.nn.utils.prune.is_pruned", "generated/torch.nn.utils.prune.l1_unstructured", "generated/torch.nn.utils.prune.ln_structured", "generated/torch.nn.utils.prune.random_structured", "generated/torch.nn.utils.prune.random_unstructured", "generated/torch.nn.utils.prune.remove", "generated/torch.nn.utils.remove_spectral_norm", "generated/torch.nn.utils.remove_weight_norm", "generated/torch.nn.utils.rnn.PackedSequence", "generated/torch.nn.utils.rnn.pack_padded_sequence", "generated/torch.nn.utils.rnn.pack_sequence", "generated/torch.nn.utils.rnn.pad_packed_sequence", "generated/torch.nn.utils.rnn.pad_sequence", "generated/torch.nn.utils.rnn.unpack_sequence", "generated/torch.nn.utils.rnn.unpad_sequence", "generated/torch.nn.utils.skip_init", "generated/torch.nn.utils.spectral_norm", "generated/torch.nn.utils.stateless.functional_call", "generated/torch.nn.utils.vector_to_parameters", "generated/torch.nn.utils.weight_norm", "generated/torch.no_grad", "generated/torch.nonzero", "generated/torch.norm", "generated/torch.normal", "generated/torch.not_equal", "generated/torch.numel", "generated/torch.ones", "generated/torch.ones_like", "generated/torch.onnx.ExportOptions", "generated/torch.onnx.ExportOutput", "generated/torch.onnx.ExportOutputSerializer", "generated/torch.onnx.JitScalarType", "generated/torch.onnx.verification.GraphInfo", "generated/torch.onnx.verification.VerificationOptions", "generated/torch.optim.ASGD", "generated/torch.optim.Adadelta", "generated/torch.optim.Adagrad", "generated/torch.optim.Adam", "generated/torch.optim.AdamW", "generated/torch.optim.Adamax", "generated/torch.optim.LBFGS", "generated/torch.optim.NAdam", "generated/torch.optim.Optimizer.add_param_group", "generated/torch.optim.Optimizer.load_state_dict", "generated/torch.optim.Optimizer.state_dict", "generated/torch.optim.Optimizer.step", "generated/torch.optim.Optimizer.zero_grad", "generated/torch.optim.RAdam", "generated/torch.optim.RMSprop", "generated/torch.optim.Rprop", "generated/torch.optim.SGD", "generated/torch.optim.SparseAdam", "generated/torch.optim.lr_scheduler.ChainedScheduler", "generated/torch.optim.lr_scheduler.ConstantLR", "generated/torch.optim.lr_scheduler.CosineAnnealingLR", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts", "generated/torch.optim.lr_scheduler.CyclicLR", "generated/torch.optim.lr_scheduler.ExponentialLR", "generated/torch.optim.lr_scheduler.LambdaLR", "generated/torch.optim.lr_scheduler.LinearLR", "generated/torch.optim.lr_scheduler.MultiStepLR", "generated/torch.optim.lr_scheduler.MultiplicativeLR", "generated/torch.optim.lr_scheduler.OneCycleLR", "generated/torch.optim.lr_scheduler.PolynomialLR", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau", "generated/torch.optim.lr_scheduler.SequentialLR", "generated/torch.optim.lr_scheduler.StepLR", "generated/torch.orgqr", "generated/torch.ormqr", "generated/torch.outer", "generated/torch.pca_lowrank", "generated/torch.permute", "generated/torch.pinverse", "generated/torch.poisson", "generated/torch.polar", "generated/torch.polygamma", "generated/torch.positive", "generated/torch.pow", "generated/torch.prod", "generated/torch.promote_types", "generated/torch.qr", "generated/torch.quantile", "generated/torch.quantize_per_channel", "generated/torch.quantize_per_tensor", "generated/torch.quantized_batch_norm", "generated/torch.quantized_max_pool1d", "generated/torch.quantized_max_pool2d", "generated/torch.quasirandom.SobolEngine", "generated/torch.rad2deg", "generated/torch.rand", "generated/torch.rand_like", "generated/torch.randint", "generated/torch.randint_like", "generated/torch.randn", "generated/torch.randn_like", "generated/torch.randperm", "generated/torch.range", "generated/torch.ravel", "generated/torch.real", "generated/torch.reciprocal", "generated/torch.remainder", "generated/torch.renorm", "generated/torch.repeat_interleave", "generated/torch.reshape", "generated/torch.resolve_conj", "generated/torch.resolve_neg", "generated/torch.result_type", "generated/torch.roll", "generated/torch.rot90", "generated/torch.round", "generated/torch.row_stack", "generated/torch.rsqrt", "generated/torch.save", "generated/torch.scatter", "generated/torch.scatter_add", "generated/torch.scatter_reduce", "generated/torch.searchsorted", "generated/torch.seed", "generated/torch.select", "generated/torch.select_scatter", "generated/torch.set_default_device", "generated/torch.set_default_dtype", "generated/torch.set_default_tensor_type", "generated/torch.set_deterministic_debug_mode", "generated/torch.set_float32_matmul_precision", "generated/torch.set_flush_denormal", "generated/torch.set_grad_enabled", "generated/torch.set_num_interop_threads", "generated/torch.set_num_threads", "generated/torch.set_printoptions", "generated/torch.set_rng_state", "generated/torch.set_warn_always", "generated/torch.sgn", "generated/torch.sigmoid", "generated/torch.sign", "generated/torch.signal.windows.bartlett", "generated/torch.signal.windows.blackman", "generated/torch.signal.windows.cosine", "generated/torch.signal.windows.exponential", "generated/torch.signal.windows.gaussian", "generated/torch.signal.windows.general_cosine", "generated/torch.signal.windows.general_hamming", "generated/torch.signal.windows.hamming", "generated/torch.signal.windows.hann", "generated/torch.signal.windows.kaiser", "generated/torch.signal.windows.nuttall", "generated/torch.signbit", "generated/torch.sin", "generated/torch.sinc", "generated/torch.sinh", "generated/torch.slice_scatter", "generated/torch.slogdet", "generated/torch.smm", "generated/torch.softmax", "generated/torch.sort", "generated/torch.sparse.addmm", "generated/torch.sparse.check_sparse_tensor_invariants", "generated/torch.sparse.log_softmax", "generated/torch.sparse.mm", "generated/torch.sparse.sampled_addmm", "generated/torch.sparse.softmax", "generated/torch.sparse.spdiags", "generated/torch.sparse.sum", "generated/torch.sparse_bsc_tensor", "generated/torch.sparse_bsr_tensor", "generated/torch.sparse_compressed_tensor", "generated/torch.sparse_coo_tensor", "generated/torch.sparse_csc_tensor", "generated/torch.sparse_csr_tensor", "generated/torch.split", "generated/torch.sqrt", "generated/torch.square", "generated/torch.squeeze", "generated/torch.sspaddmm", "generated/torch.stack", "generated/torch.std", "generated/torch.std_mean", "generated/torch.stft", "generated/torch.sub", "generated/torch.subtract", "generated/torch.sum", "generated/torch.svd", "generated/torch.svd_lowrank", "generated/torch.swapaxes", "generated/torch.swapdims", "generated/torch.sym_float", "generated/torch.sym_int", "generated/torch.sym_max", "generated/torch.sym_min", "generated/torch.sym_not", "generated/torch.t", "generated/torch.take", "generated/torch.take_along_dim", "generated/torch.tan", "generated/torch.tanh", "generated/torch.tensor", "generated/torch.tensor_split", "generated/torch.tensordot", "generated/torch.tile", "generated/torch.topk", "generated/torch.trace", "generated/torch.transpose", "generated/torch.trapezoid", "generated/torch.trapz", "generated/torch.triangular_solve", "generated/torch.tril", "generated/torch.tril_indices", "generated/torch.triu", "generated/torch.triu_indices", "generated/torch.true_divide", "generated/torch.trunc", "generated/torch.unbind", "generated/torch.unflatten", "generated/torch.unique", "generated/torch.unique_consecutive", "generated/torch.unsqueeze", "generated/torch.use_deterministic_algorithms", "generated/torch.vander", "generated/torch.var", "generated/torch.var_mean", "generated/torch.vdot", "generated/torch.view_as_complex", "generated/torch.view_as_real", "generated/torch.vmap", "generated/torch.vsplit", "generated/torch.vstack", "generated/torch.where", "generated/torch.xlogy", "generated/torch.zeros", "generated/torch.zeros_like", "hub", "index", "ir", "jit", "jit_builtin_functions", "jit_language_reference", "jit_language_reference_v2", "jit_python_reference", "jit_unsupported", "jit_utils", "library", "linalg", "logging", "masked", "mobile_optimizer", "model_zoo", "monitor", "mps", "multiprocessing", "name_inference", "named_tensor", "nested", "nn", "nn.functional", "nn.init", "notes/amp_examples", "notes/autograd", "notes/broadcasting", "notes/cpu_threading_torchscript_inference", "notes/cuda", "notes/ddp", "notes/extending", "notes/extending.func", "notes/faq", "notes/gradcheck", "notes/hip", "notes/large_scale_deployments", "notes/modules", "notes/mps", "notes/multiprocessing", "notes/numerical_accuracy", "notes/randomness", "notes/serialization", "notes/windows", "onnx", "onnx_diagnostics", "onnx_supported_aten_ops", "optim", "package", "pipeline", "profiler", "quantization", "quantization-accuracy-debugging", "quantization-backend-configuration", "quantization-support", "random", "rpc", "rpc/distributed_autograd", "rpc/rref", "signal", "sparse", "special", "storage", "tensor_attributes", "tensor_view", "tensorboard", "tensors", "testing", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.overrides", "type_info"], "filenames": ["_dynamo.rst", "amp.rst", "autograd.rst", "backends.rst", "benchmark_utils.rst", "bottleneck.rst", "checkpoint.rst", "community/build_ci_governance.rst", "community/contribution_guide.rst", "community/design.rst", "community/governance.rst", "community/persons_of_interest.rst", "compile/cudagraph_trees.rst", "compile/custom-backends.rst", "compile/deep-dive.rst", "compile/dynamic-shapes.rst", "compile/fake-tensor.rst", "compile/faq.rst", "compile/fine_grained_apis.rst", "compile/generated/torch.compile.rst", "compile/get-started.rst", "compile/guards-overview.rst", "compile/index.rst", "compile/inductor_profiling.rst", "compile/nn-module.rst", "compile/performance-dashboard.rst", "compile/technical-overview.rst", "compile/torchfunc-and-torchcompile.rst", "compile/transformations.rst", "compile/troubleshooting.rst", "complex_numbers.rst", "config_mod.rst", "cpp_extension.rst", "cpp_index.rst", "cuda.rst", "cuda._sanitizer.rst", "cudnn_persistent_rnn.rst", "cudnn_rnn_determinism.rst", "data.rst", "ddp_comm_hooks.rst", "deploy.rst", "distributed.rst", "distributed.algorithms.join.rst", "distributed.checkpoint.rst", "distributed.elastic.rst", "distributed.optim.rst", "distributed.tensor.parallel.rst", "distributions.rst", "dlpack.rst", "elastic/agent.rst", "elastic/customization.rst", "elastic/errors.rst", "elastic/events.rst", "elastic/examples.rst", "elastic/kubernetes.rst", "elastic/metrics.rst", "elastic/multiprocessing.rst", "elastic/quickstart.rst", "elastic/rendezvous.rst", "elastic/run.rst", "elastic/timer.rst", "elastic/train_script.rst", "fft.rst", "fsdp.rst", "func.rst", "func.api.rst", "func.batch_norm.rst", "func.migrating.rst", "func.ux_limitations.rst", "func.whirlwind_tour.rst", "futures.rst", "fx.rst", "generated/onnx_diagnostics_rules/DIAGSYS0001:arg-format-too-verbose.md", "generated/onnx_diagnostics_rules/FXE0001:fx-tracer-success.md", "generated/onnx_diagnostics_rules/FXE0002:fx-tracer-failure.md", "generated/onnx_diagnostics_rules/FXE0003:fx-frontend-aotautograd.md", "generated/onnx_diagnostics_rules/FXE0004:fx-pass-convert-neg-to-sigmoid.md", "generated/onnx_diagnostics_rules/FXE0005:fx-ir-add-node.md", "generated/onnx_diagnostics_rules/FXE0006:atenlib-symbolic-function.md", "generated/onnx_diagnostics_rules/FXE0007:atenlib-fx-to-onnx.md", "generated/onnx_diagnostics_rules/FXE0008:fx-node-to-onnx.md", "generated/onnx_diagnostics_rules/FXE0009:fx-frontend-dynamo-make-fx.md", "generated/onnx_diagnostics_rules/FXE0010:fx-pass.md", "generated/onnx_diagnostics_rules/FXE0011:no-symbolic-function-for-call-function.md", "generated/onnx_diagnostics_rules/FXE0012:unsupported-fx-node-analysis.md", "generated/onnx_diagnostics_rules/POE0001:node-missing-onnx-shape-inference.md", "generated/onnx_diagnostics_rules/POE0002:missing-custom-symbolic-function.md", "generated/onnx_diagnostics_rules/POE0003:missing-standard-symbolic-function.md", "generated/onnx_diagnostics_rules/POE0004:operator-supported-in-newer-opset-version.md", "generated/torch.Generator.rst", "generated/torch.Tensor.abs.rst", "generated/torch.Tensor.abs_.rst", "generated/torch.Tensor.absolute.rst", "generated/torch.Tensor.absolute_.rst", "generated/torch.Tensor.acos.rst", "generated/torch.Tensor.acos_.rst", "generated/torch.Tensor.acosh.rst", "generated/torch.Tensor.acosh_.rst", "generated/torch.Tensor.add.rst", "generated/torch.Tensor.add_.rst", "generated/torch.Tensor.addbmm.rst", "generated/torch.Tensor.addbmm_.rst", "generated/torch.Tensor.addcdiv.rst", "generated/torch.Tensor.addcdiv_.rst", "generated/torch.Tensor.addcmul.rst", "generated/torch.Tensor.addcmul_.rst", "generated/torch.Tensor.addmm.rst", "generated/torch.Tensor.addmm_.rst", "generated/torch.Tensor.addmv.rst", "generated/torch.Tensor.addmv_.rst", "generated/torch.Tensor.addr.rst", "generated/torch.Tensor.addr_.rst", "generated/torch.Tensor.adjoint.rst", "generated/torch.Tensor.all.rst", "generated/torch.Tensor.allclose.rst", "generated/torch.Tensor.amax.rst", "generated/torch.Tensor.amin.rst", "generated/torch.Tensor.aminmax.rst", "generated/torch.Tensor.angle.rst", "generated/torch.Tensor.any.rst", "generated/torch.Tensor.apply_.rst", "generated/torch.Tensor.arccos.rst", "generated/torch.Tensor.arccos_.rst", "generated/torch.Tensor.arccosh.rst", "generated/torch.Tensor.arccosh_.rst", "generated/torch.Tensor.arcsin.rst", "generated/torch.Tensor.arcsin_.rst", "generated/torch.Tensor.arcsinh.rst", "generated/torch.Tensor.arcsinh_.rst", "generated/torch.Tensor.arctan.rst", "generated/torch.Tensor.arctan2.rst", "generated/torch.Tensor.arctan2_.rst", "generated/torch.Tensor.arctan_.rst", "generated/torch.Tensor.arctanh.rst", "generated/torch.Tensor.arctanh_.rst", "generated/torch.Tensor.argmax.rst", "generated/torch.Tensor.argmin.rst", "generated/torch.Tensor.argsort.rst", "generated/torch.Tensor.argwhere.rst", "generated/torch.Tensor.as_strided.rst", "generated/torch.Tensor.as_subclass.rst", "generated/torch.Tensor.asin.rst", "generated/torch.Tensor.asin_.rst", "generated/torch.Tensor.asinh.rst", "generated/torch.Tensor.asinh_.rst", "generated/torch.Tensor.atan.rst", "generated/torch.Tensor.atan2.rst", "generated/torch.Tensor.atan2_.rst", "generated/torch.Tensor.atan_.rst", "generated/torch.Tensor.atanh.rst", "generated/torch.Tensor.atanh_.rst", "generated/torch.Tensor.backward.rst", "generated/torch.Tensor.baddbmm.rst", "generated/torch.Tensor.baddbmm_.rst", "generated/torch.Tensor.bernoulli.rst", "generated/torch.Tensor.bernoulli_.rst", "generated/torch.Tensor.bfloat16.rst", "generated/torch.Tensor.bincount.rst", "generated/torch.Tensor.bitwise_and.rst", "generated/torch.Tensor.bitwise_and_.rst", "generated/torch.Tensor.bitwise_left_shift.rst", "generated/torch.Tensor.bitwise_left_shift_.rst", "generated/torch.Tensor.bitwise_not.rst", "generated/torch.Tensor.bitwise_not_.rst", "generated/torch.Tensor.bitwise_or.rst", "generated/torch.Tensor.bitwise_or_.rst", "generated/torch.Tensor.bitwise_right_shift.rst", "generated/torch.Tensor.bitwise_right_shift_.rst", "generated/torch.Tensor.bitwise_xor.rst", "generated/torch.Tensor.bitwise_xor_.rst", "generated/torch.Tensor.bmm.rst", "generated/torch.Tensor.bool.rst", "generated/torch.Tensor.broadcast_to.rst", "generated/torch.Tensor.byte.rst", "generated/torch.Tensor.cauchy_.rst", "generated/torch.Tensor.ccol_indices.rst", "generated/torch.Tensor.cdouble.rst", "generated/torch.Tensor.ceil.rst", "generated/torch.Tensor.ceil_.rst", "generated/torch.Tensor.cfloat.rst", "generated/torch.Tensor.chalf.rst", "generated/torch.Tensor.char.rst", "generated/torch.Tensor.cholesky.rst", "generated/torch.Tensor.cholesky_inverse.rst", "generated/torch.Tensor.cholesky_solve.rst", "generated/torch.Tensor.chunk.rst", "generated/torch.Tensor.clamp.rst", "generated/torch.Tensor.clamp_.rst", "generated/torch.Tensor.clip.rst", "generated/torch.Tensor.clip_.rst", "generated/torch.Tensor.clone.rst", "generated/torch.Tensor.coalesce.rst", "generated/torch.Tensor.col_indices.rst", "generated/torch.Tensor.conj.rst", "generated/torch.Tensor.conj_physical.rst", "generated/torch.Tensor.conj_physical_.rst", "generated/torch.Tensor.contiguous.rst", "generated/torch.Tensor.copy_.rst", "generated/torch.Tensor.copysign.rst", "generated/torch.Tensor.copysign_.rst", "generated/torch.Tensor.corrcoef.rst", "generated/torch.Tensor.cos.rst", "generated/torch.Tensor.cos_.rst", "generated/torch.Tensor.cosh.rst", "generated/torch.Tensor.cosh_.rst", "generated/torch.Tensor.count_nonzero.rst", "generated/torch.Tensor.cov.rst", "generated/torch.Tensor.cpu.rst", "generated/torch.Tensor.cross.rst", "generated/torch.Tensor.crow_indices.rst", "generated/torch.Tensor.cuda.rst", "generated/torch.Tensor.cummax.rst", "generated/torch.Tensor.cummin.rst", "generated/torch.Tensor.cumprod.rst", "generated/torch.Tensor.cumprod_.rst", "generated/torch.Tensor.cumsum.rst", "generated/torch.Tensor.cumsum_.rst", "generated/torch.Tensor.data_ptr.rst", "generated/torch.Tensor.deg2rad.rst", "generated/torch.Tensor.dense_dim.rst", "generated/torch.Tensor.dequantize.rst", "generated/torch.Tensor.det.rst", "generated/torch.Tensor.detach.rst", "generated/torch.Tensor.detach_.rst", "generated/torch.Tensor.device.rst", "generated/torch.Tensor.diag.rst", "generated/torch.Tensor.diag_embed.rst", "generated/torch.Tensor.diagflat.rst", "generated/torch.Tensor.diagonal.rst", "generated/torch.Tensor.diagonal_scatter.rst", "generated/torch.Tensor.diff.rst", "generated/torch.Tensor.digamma.rst", "generated/torch.Tensor.digamma_.rst", "generated/torch.Tensor.dim.rst", "generated/torch.Tensor.dist.rst", "generated/torch.Tensor.div.rst", "generated/torch.Tensor.div_.rst", "generated/torch.Tensor.divide.rst", "generated/torch.Tensor.divide_.rst", "generated/torch.Tensor.dot.rst", "generated/torch.Tensor.double.rst", "generated/torch.Tensor.dsplit.rst", "generated/torch.Tensor.element_size.rst", "generated/torch.Tensor.eq.rst", "generated/torch.Tensor.eq_.rst", "generated/torch.Tensor.equal.rst", "generated/torch.Tensor.erf.rst", "generated/torch.Tensor.erf_.rst", "generated/torch.Tensor.erfc.rst", "generated/torch.Tensor.erfc_.rst", "generated/torch.Tensor.erfinv.rst", "generated/torch.Tensor.erfinv_.rst", "generated/torch.Tensor.exp.rst", "generated/torch.Tensor.exp_.rst", "generated/torch.Tensor.expand.rst", "generated/torch.Tensor.expand_as.rst", "generated/torch.Tensor.expm1.rst", "generated/torch.Tensor.expm1_.rst", "generated/torch.Tensor.exponential_.rst", "generated/torch.Tensor.fill_.rst", "generated/torch.Tensor.fill_diagonal_.rst", "generated/torch.Tensor.fix.rst", "generated/torch.Tensor.fix_.rst", "generated/torch.Tensor.flatten.rst", "generated/torch.Tensor.flip.rst", "generated/torch.Tensor.fliplr.rst", "generated/torch.Tensor.flipud.rst", "generated/torch.Tensor.float.rst", "generated/torch.Tensor.float_power.rst", "generated/torch.Tensor.float_power_.rst", "generated/torch.Tensor.floor.rst", "generated/torch.Tensor.floor_.rst", "generated/torch.Tensor.floor_divide.rst", "generated/torch.Tensor.floor_divide_.rst", "generated/torch.Tensor.fmax.rst", "generated/torch.Tensor.fmin.rst", "generated/torch.Tensor.fmod.rst", "generated/torch.Tensor.fmod_.rst", "generated/torch.Tensor.frac.rst", "generated/torch.Tensor.frac_.rst", "generated/torch.Tensor.frexp.rst", "generated/torch.Tensor.gather.rst", "generated/torch.Tensor.gcd.rst", "generated/torch.Tensor.gcd_.rst", "generated/torch.Tensor.ge.rst", "generated/torch.Tensor.ge_.rst", "generated/torch.Tensor.geometric_.rst", "generated/torch.Tensor.geqrf.rst", "generated/torch.Tensor.ger.rst", "generated/torch.Tensor.get_device.rst", "generated/torch.Tensor.grad.rst", "generated/torch.Tensor.greater.rst", "generated/torch.Tensor.greater_.rst", "generated/torch.Tensor.greater_equal.rst", "generated/torch.Tensor.greater_equal_.rst", "generated/torch.Tensor.gt.rst", "generated/torch.Tensor.gt_.rst", "generated/torch.Tensor.half.rst", "generated/torch.Tensor.hardshrink.rst", "generated/torch.Tensor.heaviside.rst", "generated/torch.Tensor.histc.rst", "generated/torch.Tensor.histogram.rst", "generated/torch.Tensor.hsplit.rst", "generated/torch.Tensor.hypot.rst", "generated/torch.Tensor.hypot_.rst", "generated/torch.Tensor.i0.rst", "generated/torch.Tensor.i0_.rst", "generated/torch.Tensor.igamma.rst", "generated/torch.Tensor.igamma_.rst", "generated/torch.Tensor.igammac.rst", "generated/torch.Tensor.igammac_.rst", "generated/torch.Tensor.imag.rst", "generated/torch.Tensor.index_add.rst", "generated/torch.Tensor.index_add_.rst", "generated/torch.Tensor.index_copy.rst", "generated/torch.Tensor.index_copy_.rst", "generated/torch.Tensor.index_fill.rst", "generated/torch.Tensor.index_fill_.rst", "generated/torch.Tensor.index_put.rst", "generated/torch.Tensor.index_put_.rst", "generated/torch.Tensor.index_reduce.rst", "generated/torch.Tensor.index_reduce_.rst", "generated/torch.Tensor.index_select.rst", "generated/torch.Tensor.indices.rst", "generated/torch.Tensor.inner.rst", "generated/torch.Tensor.int.rst", "generated/torch.Tensor.int_repr.rst", "generated/torch.Tensor.inverse.rst", "generated/torch.Tensor.is_coalesced.rst", "generated/torch.Tensor.is_complex.rst", "generated/torch.Tensor.is_conj.rst", "generated/torch.Tensor.is_contiguous.rst", "generated/torch.Tensor.is_cuda.rst", "generated/torch.Tensor.is_floating_point.rst", "generated/torch.Tensor.is_inference.rst", "generated/torch.Tensor.is_leaf.rst", "generated/torch.Tensor.is_meta.rst", "generated/torch.Tensor.is_pinned.rst", "generated/torch.Tensor.is_quantized.rst", "generated/torch.Tensor.is_set_to.rst", "generated/torch.Tensor.is_shared.rst", "generated/torch.Tensor.is_signed.rst", "generated/torch.Tensor.is_sparse.rst", "generated/torch.Tensor.is_sparse_csr.rst", "generated/torch.Tensor.isclose.rst", "generated/torch.Tensor.isfinite.rst", "generated/torch.Tensor.isinf.rst", "generated/torch.Tensor.isnan.rst", "generated/torch.Tensor.isneginf.rst", "generated/torch.Tensor.isposinf.rst", "generated/torch.Tensor.isreal.rst", "generated/torch.Tensor.istft.rst", "generated/torch.Tensor.item.rst", "generated/torch.Tensor.itemsize.rst", "generated/torch.Tensor.kthvalue.rst", "generated/torch.Tensor.lcm.rst", "generated/torch.Tensor.lcm_.rst", "generated/torch.Tensor.ldexp.rst", "generated/torch.Tensor.ldexp_.rst", "generated/torch.Tensor.le.rst", "generated/torch.Tensor.le_.rst", "generated/torch.Tensor.lerp.rst", "generated/torch.Tensor.lerp_.rst", "generated/torch.Tensor.less.rst", "generated/torch.Tensor.less_.rst", "generated/torch.Tensor.less_equal.rst", "generated/torch.Tensor.less_equal_.rst", "generated/torch.Tensor.lgamma.rst", "generated/torch.Tensor.lgamma_.rst", "generated/torch.Tensor.log.rst", "generated/torch.Tensor.log10.rst", "generated/torch.Tensor.log10_.rst", "generated/torch.Tensor.log1p.rst", "generated/torch.Tensor.log1p_.rst", "generated/torch.Tensor.log2.rst", "generated/torch.Tensor.log2_.rst", "generated/torch.Tensor.log_.rst", "generated/torch.Tensor.log_normal_.rst", "generated/torch.Tensor.logaddexp.rst", "generated/torch.Tensor.logaddexp2.rst", "generated/torch.Tensor.logcumsumexp.rst", "generated/torch.Tensor.logdet.rst", "generated/torch.Tensor.logical_and.rst", "generated/torch.Tensor.logical_and_.rst", "generated/torch.Tensor.logical_not.rst", "generated/torch.Tensor.logical_not_.rst", "generated/torch.Tensor.logical_or.rst", "generated/torch.Tensor.logical_or_.rst", "generated/torch.Tensor.logical_xor.rst", "generated/torch.Tensor.logical_xor_.rst", "generated/torch.Tensor.logit.rst", "generated/torch.Tensor.logit_.rst", "generated/torch.Tensor.logsumexp.rst", "generated/torch.Tensor.long.rst", "generated/torch.Tensor.lt.rst", "generated/torch.Tensor.lt_.rst", "generated/torch.Tensor.lu.rst", "generated/torch.Tensor.lu_solve.rst", "generated/torch.Tensor.map_.rst", "generated/torch.Tensor.masked_fill.rst", "generated/torch.Tensor.masked_fill_.rst", "generated/torch.Tensor.masked_scatter.rst", "generated/torch.Tensor.masked_scatter_.rst", "generated/torch.Tensor.masked_select.rst", "generated/torch.Tensor.matmul.rst", "generated/torch.Tensor.matrix_exp.rst", "generated/torch.Tensor.matrix_power.rst", "generated/torch.Tensor.max.rst", "generated/torch.Tensor.maximum.rst", "generated/torch.Tensor.mean.rst", "generated/torch.Tensor.median.rst", "generated/torch.Tensor.min.rst", "generated/torch.Tensor.minimum.rst", "generated/torch.Tensor.mm.rst", "generated/torch.Tensor.mode.rst", "generated/torch.Tensor.moveaxis.rst", "generated/torch.Tensor.movedim.rst", "generated/torch.Tensor.msort.rst", "generated/torch.Tensor.mul.rst", "generated/torch.Tensor.mul_.rst", "generated/torch.Tensor.multinomial.rst", "generated/torch.Tensor.multiply.rst", "generated/torch.Tensor.multiply_.rst", "generated/torch.Tensor.mv.rst", "generated/torch.Tensor.mvlgamma.rst", "generated/torch.Tensor.mvlgamma_.rst", "generated/torch.Tensor.nan_to_num.rst", "generated/torch.Tensor.nan_to_num_.rst", "generated/torch.Tensor.nanmean.rst", "generated/torch.Tensor.nanmedian.rst", "generated/torch.Tensor.nanquantile.rst", "generated/torch.Tensor.nansum.rst", "generated/torch.Tensor.narrow.rst", "generated/torch.Tensor.narrow_copy.rst", "generated/torch.Tensor.nbytes.rst", "generated/torch.Tensor.ndim.rst", "generated/torch.Tensor.ndimension.rst", "generated/torch.Tensor.ne.rst", "generated/torch.Tensor.ne_.rst", "generated/torch.Tensor.neg.rst", "generated/torch.Tensor.neg_.rst", "generated/torch.Tensor.negative.rst", "generated/torch.Tensor.negative_.rst", "generated/torch.Tensor.nelement.rst", "generated/torch.Tensor.new_empty.rst", "generated/torch.Tensor.new_full.rst", "generated/torch.Tensor.new_ones.rst", "generated/torch.Tensor.new_tensor.rst", "generated/torch.Tensor.new_zeros.rst", "generated/torch.Tensor.nextafter.rst", "generated/torch.Tensor.nextafter_.rst", "generated/torch.Tensor.nonzero.rst", "generated/torch.Tensor.norm.rst", "generated/torch.Tensor.normal_.rst", "generated/torch.Tensor.not_equal.rst", "generated/torch.Tensor.not_equal_.rst", "generated/torch.Tensor.numel.rst", "generated/torch.Tensor.numpy.rst", "generated/torch.Tensor.orgqr.rst", "generated/torch.Tensor.ormqr.rst", "generated/torch.Tensor.outer.rst", "generated/torch.Tensor.permute.rst", "generated/torch.Tensor.pin_memory.rst", "generated/torch.Tensor.pinverse.rst", "generated/torch.Tensor.polygamma.rst", "generated/torch.Tensor.polygamma_.rst", "generated/torch.Tensor.positive.rst", "generated/torch.Tensor.pow.rst", "generated/torch.Tensor.pow_.rst", "generated/torch.Tensor.prod.rst", "generated/torch.Tensor.put_.rst", "generated/torch.Tensor.q_per_channel_axis.rst", "generated/torch.Tensor.q_per_channel_scales.rst", "generated/torch.Tensor.q_per_channel_zero_points.rst", "generated/torch.Tensor.q_scale.rst", "generated/torch.Tensor.q_zero_point.rst", "generated/torch.Tensor.qr.rst", "generated/torch.Tensor.qscheme.rst", "generated/torch.Tensor.quantile.rst", "generated/torch.Tensor.rad2deg.rst", "generated/torch.Tensor.random_.rst", "generated/torch.Tensor.ravel.rst", "generated/torch.Tensor.real.rst", "generated/torch.Tensor.reciprocal.rst", "generated/torch.Tensor.reciprocal_.rst", "generated/torch.Tensor.record_stream.rst", "generated/torch.Tensor.register_hook.rst", "generated/torch.Tensor.remainder.rst", "generated/torch.Tensor.remainder_.rst", "generated/torch.Tensor.renorm.rst", "generated/torch.Tensor.renorm_.rst", "generated/torch.Tensor.repeat.rst", "generated/torch.Tensor.repeat_interleave.rst", "generated/torch.Tensor.requires_grad.rst", "generated/torch.Tensor.requires_grad_.rst", "generated/torch.Tensor.reshape.rst", "generated/torch.Tensor.reshape_as.rst", "generated/torch.Tensor.resize_.rst", "generated/torch.Tensor.resize_as_.rst", "generated/torch.Tensor.resolve_conj.rst", "generated/torch.Tensor.resolve_neg.rst", "generated/torch.Tensor.retain_grad.rst", "generated/torch.Tensor.retains_grad.rst", "generated/torch.Tensor.roll.rst", "generated/torch.Tensor.rot90.rst", "generated/torch.Tensor.round.rst", "generated/torch.Tensor.round_.rst", "generated/torch.Tensor.row_indices.rst", "generated/torch.Tensor.rsqrt.rst", "generated/torch.Tensor.rsqrt_.rst", "generated/torch.Tensor.scatter.rst", "generated/torch.Tensor.scatter_.rst", "generated/torch.Tensor.scatter_add.rst", "generated/torch.Tensor.scatter_add_.rst", "generated/torch.Tensor.scatter_reduce.rst", "generated/torch.Tensor.scatter_reduce_.rst", "generated/torch.Tensor.select.rst", "generated/torch.Tensor.select_scatter.rst", "generated/torch.Tensor.set_.rst", "generated/torch.Tensor.sgn.rst", "generated/torch.Tensor.sgn_.rst", "generated/torch.Tensor.share_memory_.rst", "generated/torch.Tensor.short.rst", "generated/torch.Tensor.sigmoid.rst", "generated/torch.Tensor.sigmoid_.rst", "generated/torch.Tensor.sign.rst", "generated/torch.Tensor.sign_.rst", "generated/torch.Tensor.signbit.rst", "generated/torch.Tensor.sin.rst", "generated/torch.Tensor.sin_.rst", "generated/torch.Tensor.sinc.rst", "generated/torch.Tensor.sinc_.rst", "generated/torch.Tensor.sinh.rst", "generated/torch.Tensor.sinh_.rst", "generated/torch.Tensor.size.rst", "generated/torch.Tensor.slice_scatter.rst", "generated/torch.Tensor.slogdet.rst", "generated/torch.Tensor.smm.rst", "generated/torch.Tensor.softmax.rst", "generated/torch.Tensor.sort.rst", "generated/torch.Tensor.sparse_dim.rst", "generated/torch.Tensor.sparse_mask.rst", "generated/torch.Tensor.sparse_resize_.rst", "generated/torch.Tensor.sparse_resize_and_clear_.rst", "generated/torch.Tensor.split.rst", "generated/torch.Tensor.sqrt.rst", "generated/torch.Tensor.sqrt_.rst", "generated/torch.Tensor.square.rst", "generated/torch.Tensor.square_.rst", "generated/torch.Tensor.squeeze.rst", "generated/torch.Tensor.squeeze_.rst", "generated/torch.Tensor.sspaddmm.rst", "generated/torch.Tensor.std.rst", "generated/torch.Tensor.stft.rst", "generated/torch.Tensor.storage.rst", "generated/torch.Tensor.storage_offset.rst", "generated/torch.Tensor.storage_type.rst", "generated/torch.Tensor.stride.rst", "generated/torch.Tensor.sub.rst", "generated/torch.Tensor.sub_.rst", "generated/torch.Tensor.subtract.rst", "generated/torch.Tensor.subtract_.rst", "generated/torch.Tensor.sum.rst", "generated/torch.Tensor.sum_to_size.rst", "generated/torch.Tensor.svd.rst", "generated/torch.Tensor.swapaxes.rst", "generated/torch.Tensor.swapdims.rst", "generated/torch.Tensor.t.rst", "generated/torch.Tensor.t_.rst", "generated/torch.Tensor.take.rst", "generated/torch.Tensor.take_along_dim.rst", "generated/torch.Tensor.tan.rst", "generated/torch.Tensor.tan_.rst", "generated/torch.Tensor.tanh.rst", "generated/torch.Tensor.tanh_.rst", "generated/torch.Tensor.tensor_split.rst", "generated/torch.Tensor.tile.rst", "generated/torch.Tensor.to.rst", "generated/torch.Tensor.to_dense.rst", "generated/torch.Tensor.to_mkldnn.rst", "generated/torch.Tensor.to_sparse.rst", "generated/torch.Tensor.to_sparse_bsc.rst", "generated/torch.Tensor.to_sparse_bsr.rst", "generated/torch.Tensor.to_sparse_coo.rst", "generated/torch.Tensor.to_sparse_csc.rst", "generated/torch.Tensor.to_sparse_csr.rst", "generated/torch.Tensor.tolist.rst", "generated/torch.Tensor.topk.rst", "generated/torch.Tensor.trace.rst", "generated/torch.Tensor.transpose.rst", "generated/torch.Tensor.transpose_.rst", "generated/torch.Tensor.triangular_solve.rst", "generated/torch.Tensor.tril.rst", "generated/torch.Tensor.tril_.rst", "generated/torch.Tensor.triu.rst", "generated/torch.Tensor.triu_.rst", "generated/torch.Tensor.true_divide.rst", "generated/torch.Tensor.true_divide_.rst", "generated/torch.Tensor.trunc.rst", "generated/torch.Tensor.trunc_.rst", "generated/torch.Tensor.type.rst", "generated/torch.Tensor.type_as.rst", "generated/torch.Tensor.unbind.rst", "generated/torch.Tensor.unflatten.rst", "generated/torch.Tensor.unfold.rst", "generated/torch.Tensor.uniform_.rst", "generated/torch.Tensor.unique.rst", "generated/torch.Tensor.unique_consecutive.rst", "generated/torch.Tensor.unsqueeze.rst", "generated/torch.Tensor.unsqueeze_.rst", "generated/torch.Tensor.untyped_storage.rst", "generated/torch.Tensor.values.rst", "generated/torch.Tensor.var.rst", "generated/torch.Tensor.vdot.rst", "generated/torch.Tensor.view.rst", "generated/torch.Tensor.view_as.rst", "generated/torch.Tensor.vsplit.rst", "generated/torch.Tensor.where.rst", "generated/torch.Tensor.xlogy.rst", "generated/torch.Tensor.xlogy_.rst", "generated/torch.Tensor.zero_.rst", "generated/torch._assert.rst", "generated/torch._foreach_abs.rst", "generated/torch._foreach_abs_.rst", "generated/torch._foreach_acos.rst", "generated/torch._foreach_acos_.rst", "generated/torch._foreach_asin.rst", "generated/torch._foreach_asin_.rst", "generated/torch._foreach_atan.rst", "generated/torch._foreach_atan_.rst", "generated/torch._foreach_ceil.rst", "generated/torch._foreach_ceil_.rst", "generated/torch._foreach_cos.rst", "generated/torch._foreach_cos_.rst", "generated/torch._foreach_cosh.rst", "generated/torch._foreach_cosh_.rst", "generated/torch._foreach_erf.rst", "generated/torch._foreach_erf_.rst", "generated/torch._foreach_erfc.rst", "generated/torch._foreach_erfc_.rst", "generated/torch._foreach_exp.rst", "generated/torch._foreach_exp_.rst", "generated/torch._foreach_expm1.rst", "generated/torch._foreach_expm1_.rst", "generated/torch._foreach_floor.rst", "generated/torch._foreach_floor_.rst", "generated/torch._foreach_frac.rst", "generated/torch._foreach_frac_.rst", "generated/torch._foreach_lgamma.rst", "generated/torch._foreach_lgamma_.rst", "generated/torch._foreach_log.rst", "generated/torch._foreach_log10.rst", "generated/torch._foreach_log10_.rst", "generated/torch._foreach_log1p.rst", "generated/torch._foreach_log1p_.rst", "generated/torch._foreach_log2.rst", "generated/torch._foreach_log2_.rst", "generated/torch._foreach_log_.rst", "generated/torch._foreach_neg.rst", "generated/torch._foreach_neg_.rst", "generated/torch._foreach_reciprocal.rst", "generated/torch._foreach_reciprocal_.rst", "generated/torch._foreach_round.rst", "generated/torch._foreach_round_.rst", "generated/torch._foreach_sigmoid.rst", "generated/torch._foreach_sigmoid_.rst", "generated/torch._foreach_sin.rst", "generated/torch._foreach_sin_.rst", "generated/torch._foreach_sinh.rst", "generated/torch._foreach_sinh_.rst", "generated/torch._foreach_sqrt.rst", "generated/torch._foreach_sqrt_.rst", "generated/torch._foreach_tan.rst", "generated/torch._foreach_tan_.rst", "generated/torch._foreach_trunc.rst", "generated/torch._foreach_trunc_.rst", "generated/torch._foreach_zero_.rst", "generated/torch._logging.set_logs.rst", "generated/torch.abs.rst", "generated/torch.absolute.rst", "generated/torch.acos.rst", "generated/torch.acosh.rst", "generated/torch.add.rst", "generated/torch.addbmm.rst", "generated/torch.addcdiv.rst", "generated/torch.addcmul.rst", "generated/torch.addmm.rst", "generated/torch.addmv.rst", "generated/torch.addr.rst", "generated/torch.adjoint.rst", "generated/torch.all.rst", "generated/torch.allclose.rst", "generated/torch.amax.rst", "generated/torch.amin.rst", "generated/torch.aminmax.rst", "generated/torch.angle.rst", "generated/torch.any.rst", "generated/torch.ao.nn.intrinsic.BNReLU2d.rst", "generated/torch.ao.nn.intrinsic.BNReLU3d.rst", "generated/torch.ao.nn.intrinsic.ConvBn1d.rst", "generated/torch.ao.nn.intrinsic.ConvBn2d.rst", "generated/torch.ao.nn.intrinsic.ConvBn3d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU1d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU2d.rst", "generated/torch.ao.nn.intrinsic.ConvBnReLU3d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU1d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn1d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBn3d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU1d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvBnReLU3d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.qat.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.qat.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.qat.freeze_bn_stats.rst", "generated/torch.ao.nn.intrinsic.qat.update_bn_stats.rst", "generated/torch.ao.nn.intrinsic.quantized.BNReLU2d.rst", "generated/torch.ao.nn.intrinsic.quantized.BNReLU3d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU1d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU2d.rst", "generated/torch.ao.nn.intrinsic.quantized.ConvReLU3d.rst", "generated/torch.ao.nn.intrinsic.quantized.LinearReLU.rst", "generated/torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU.rst", "generated/torch.ao.nn.qat.Conv2d.rst", "generated/torch.ao.nn.qat.Conv3d.rst", "generated/torch.ao.nn.qat.Linear.rst", "generated/torch.ao.nn.qat.dynamic.Linear.rst", "generated/torch.ao.nn.quantizable.LSTM.rst", "generated/torch.ao.nn.quantizable.MultiheadAttention.rst", "generated/torch.ao.nn.quantized.BatchNorm2d.rst", "generated/torch.ao.nn.quantized.BatchNorm3d.rst", "generated/torch.ao.nn.quantized.Conv1d.rst", "generated/torch.ao.nn.quantized.Conv2d.rst", "generated/torch.ao.nn.quantized.Conv3d.rst", "generated/torch.ao.nn.quantized.ConvTranspose1d.rst", "generated/torch.ao.nn.quantized.ConvTranspose2d.rst", "generated/torch.ao.nn.quantized.ConvTranspose3d.rst", "generated/torch.ao.nn.quantized.ELU.rst", "generated/torch.ao.nn.quantized.Embedding.rst", "generated/torch.ao.nn.quantized.EmbeddingBag.rst", "generated/torch.ao.nn.quantized.FXFloatFunctional.rst", "generated/torch.ao.nn.quantized.FloatFunctional.rst", "generated/torch.ao.nn.quantized.GroupNorm.rst", "generated/torch.ao.nn.quantized.Hardswish.rst", "generated/torch.ao.nn.quantized.InstanceNorm1d.rst", "generated/torch.ao.nn.quantized.InstanceNorm2d.rst", "generated/torch.ao.nn.quantized.InstanceNorm3d.rst", "generated/torch.ao.nn.quantized.LayerNorm.rst", "generated/torch.ao.nn.quantized.LeakyReLU.rst", "generated/torch.ao.nn.quantized.Linear.rst", "generated/torch.ao.nn.quantized.QFunctional.rst", "generated/torch.ao.nn.quantized.ReLU6.rst", "generated/torch.ao.nn.quantized.Sigmoid.rst", "generated/torch.ao.nn.quantized.dynamic.GRU.rst", "generated/torch.ao.nn.quantized.dynamic.GRUCell.rst", "generated/torch.ao.nn.quantized.dynamic.LSTM.rst", "generated/torch.ao.nn.quantized.dynamic.LSTMCell.rst", "generated/torch.ao.nn.quantized.dynamic.Linear.rst", "generated/torch.ao.nn.quantized.dynamic.RNNCell.rst", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool2d.rst", "generated/torch.ao.nn.quantized.functional.adaptive_avg_pool3d.rst", "generated/torch.ao.nn.quantized.functional.avg_pool2d.rst", "generated/torch.ao.nn.quantized.functional.avg_pool3d.rst", "generated/torch.ao.nn.quantized.functional.celu.rst", "generated/torch.ao.nn.quantized.functional.clamp.rst", "generated/torch.ao.nn.quantized.functional.conv1d.rst", "generated/torch.ao.nn.quantized.functional.conv2d.rst", "generated/torch.ao.nn.quantized.functional.conv3d.rst", "generated/torch.ao.nn.quantized.functional.elu.rst", "generated/torch.ao.nn.quantized.functional.hardsigmoid.rst", "generated/torch.ao.nn.quantized.functional.hardswish.rst", "generated/torch.ao.nn.quantized.functional.hardtanh.rst", "generated/torch.ao.nn.quantized.functional.interpolate.rst", "generated/torch.ao.nn.quantized.functional.leaky_relu.rst", "generated/torch.ao.nn.quantized.functional.linear.rst", "generated/torch.ao.nn.quantized.functional.max_pool1d.rst", "generated/torch.ao.nn.quantized.functional.max_pool2d.rst", "generated/torch.ao.nn.quantized.functional.threshold.rst", "generated/torch.ao.nn.quantized.functional.upsample.rst", "generated/torch.ao.nn.quantized.functional.upsample_bilinear.rst", "generated/torch.ao.nn.quantized.functional.upsample_nearest.rst", "generated/torch.ao.quantization.DeQuantStub.rst", "generated/torch.ao.quantization.QuantStub.rst", "generated/torch.ao.quantization.QuantWrapper.rst", "generated/torch.ao.quantization.add_quant_dequant.rst", "generated/torch.ao.quantization.backend_config.BackendConfig.rst", "generated/torch.ao.quantization.backend_config.BackendPatternConfig.rst", "generated/torch.ao.quantization.backend_config.DTypeConfig.rst", "generated/torch.ao.quantization.backend_config.DTypeWithConstraints.rst", "generated/torch.ao.quantization.backend_config.ObservationType.rst", "generated/torch.ao.quantization.convert.rst", "generated/torch.ao.quantization.default_eval_fn.rst", "generated/torch.ao.quantization.fake_quantize.FakeQuantize.rst", "generated/torch.ao.quantization.fake_quantize.FakeQuantizeBase.rst", "generated/torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize.rst", "generated/torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize.rst", "generated/torch.ao.quantization.fake_quantize.default_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_fused_act_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_histogram_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.default_weight_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.disable_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.disable_observer.rst", "generated/torch.ao.quantization.fake_quantize.enable_fake_quant.rst", "generated/torch.ao.quantization.fake_quantize.enable_observer.rst", "generated/torch.ao.quantization.fuse_modules.rst", "generated/torch.ao.quantization.fx.custom_config.ConvertCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.FuseCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.PrepareCustomConfig.rst", "generated/torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry.rst", "generated/torch.ao.quantization.observer.HistogramObserver.rst", "generated/torch.ao.quantization.observer.MinMaxObserver.rst", "generated/torch.ao.quantization.observer.MovingAverageMinMaxObserver.rst", "generated/torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver.rst", "generated/torch.ao.quantization.observer.NoopObserver.rst", "generated/torch.ao.quantization.observer.ObserverBase.rst", "generated/torch.ao.quantization.observer.PerChannelMinMaxObserver.rst", "generated/torch.ao.quantization.observer.PlaceholderObserver.rst", "generated/torch.ao.quantization.observer.RecordingObserver.rst", "generated/torch.ao.quantization.observer.default_debug_observer.rst", "generated/torch.ao.quantization.observer.default_dynamic_quant_observer.rst", "generated/torch.ao.quantization.observer.default_float_qparams_observer.rst", "generated/torch.ao.quantization.observer.default_histogram_observer.rst", "generated/torch.ao.quantization.observer.default_observer.rst", "generated/torch.ao.quantization.observer.default_per_channel_weight_observer.rst", "generated/torch.ao.quantization.observer.default_placeholder_observer.rst", "generated/torch.ao.quantization.observer.default_weight_observer.rst", "generated/torch.ao.quantization.observer.get_observer_state_dict.rst", "generated/torch.ao.quantization.observer.load_observer_state_dict.rst", "generated/torch.ao.quantization.prepare.rst", "generated/torch.ao.quantization.prepare_qat.rst", "generated/torch.ao.quantization.propagate_qconfig_.rst", "generated/torch.ao.quantization.qconfig.QConfig.rst", "generated/torch.ao.quantization.qconfig.default_activation_only_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_debug_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_dynamic_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_per_channel_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_qat_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_qat_qconfig_v2.rst", "generated/torch.ao.quantization.qconfig.default_qconfig.rst", "generated/torch.ao.quantization.qconfig.default_weight_only_qconfig.rst", "generated/torch.ao.quantization.qconfig.float16_dynamic_qconfig.rst", "generated/torch.ao.quantization.qconfig.float16_static_qconfig.rst", "generated/torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig.rst", "generated/torch.ao.quantization.qconfig.per_channel_dynamic_qconfig.rst", "generated/torch.ao.quantization.qconfig_mapping.QConfigMapping.rst", "generated/torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping.rst", "generated/torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping.rst", "generated/torch.ao.quantization.quantize.rst", "generated/torch.ao.quantization.quantize_dynamic.rst", "generated/torch.ao.quantization.quantize_fx.convert_fx.rst", "generated/torch.ao.quantization.quantize_fx.fuse_fx.rst", "generated/torch.ao.quantization.quantize_fx.prepare_fx.rst", "generated/torch.ao.quantization.quantize_fx.prepare_qat_fx.rst", "generated/torch.ao.quantization.quantize_qat.rst", "generated/torch.ao.quantization.swap_module.rst", "generated/torch.arange.rst", "generated/torch.arccos.rst", "generated/torch.arccosh.rst", "generated/torch.arcsin.rst", "generated/torch.arcsinh.rst", "generated/torch.arctan.rst", "generated/torch.arctan2.rst", "generated/torch.arctanh.rst", "generated/torch.are_deterministic_algorithms_enabled.rst", "generated/torch.argmax.rst", "generated/torch.argmin.rst", "generated/torch.argsort.rst", "generated/torch.argwhere.rst", "generated/torch.as_strided.rst", "generated/torch.as_tensor.rst", "generated/torch.asarray.rst", "generated/torch.asin.rst", "generated/torch.asinh.rst", "generated/torch.atan.rst", "generated/torch.atan2.rst", "generated/torch.atanh.rst", "generated/torch.atleast_1d.rst", "generated/torch.atleast_2d.rst", "generated/torch.atleast_3d.rst", "generated/torch.autograd.Function.backward.rst", "generated/torch.autograd.Function.forward.rst", "generated/torch.autograd.Function.jvp.rst", "generated/torch.autograd.Function.vmap.rst", "generated/torch.autograd.backward.rst", "generated/torch.autograd.forward_ad.dual_level.rst", "generated/torch.autograd.forward_ad.make_dual.rst", "generated/torch.autograd.forward_ad.unpack_dual.rst", "generated/torch.autograd.function.FunctionCtx.mark_dirty.rst", "generated/torch.autograd.function.FunctionCtx.mark_non_differentiable.rst", "generated/torch.autograd.function.FunctionCtx.save_for_backward.rst", "generated/torch.autograd.function.FunctionCtx.set_materialize_grads.rst", "generated/torch.autograd.functional.hessian.rst", "generated/torch.autograd.functional.hvp.rst", "generated/torch.autograd.functional.jacobian.rst", "generated/torch.autograd.functional.jvp.rst", "generated/torch.autograd.functional.vhp.rst", "generated/torch.autograd.functional.vjp.rst", "generated/torch.autograd.grad.rst", "generated/torch.autograd.gradcheck.rst", "generated/torch.autograd.gradgradcheck.rst", "generated/torch.autograd.graph.Node.metadata.rst", "generated/torch.autograd.graph.Node.name.rst", "generated/torch.autograd.graph.Node.next_functions.rst", "generated/torch.autograd.graph.Node.register_hook.rst", "generated/torch.autograd.graph.Node.register_prehook.rst", "generated/torch.autograd.profiler.load_nvprof.rst", "generated/torch.autograd.profiler.profile.export_chrome_trace.rst", "generated/torch.autograd.profiler.profile.key_averages.rst", "generated/torch.autograd.profiler.profile.self_cpu_time_total.rst", "generated/torch.autograd.profiler.profile.total_average.rst", "generated/torch.autograd.set_multithreading_enabled.rst", "generated/torch.baddbmm.rst", "generated/torch.bartlett_window.rst", "generated/torch.bernoulli.rst", "generated/torch.bincount.rst", "generated/torch.bitwise_and.rst", "generated/torch.bitwise_left_shift.rst", "generated/torch.bitwise_not.rst", "generated/torch.bitwise_or.rst", "generated/torch.bitwise_right_shift.rst", "generated/torch.bitwise_xor.rst", "generated/torch.blackman_window.rst", "generated/torch.block_diag.rst", "generated/torch.bmm.rst", "generated/torch.broadcast_shapes.rst", "generated/torch.broadcast_tensors.rst", "generated/torch.broadcast_to.rst", "generated/torch.bucketize.rst", "generated/torch.can_cast.rst", "generated/torch.cartesian_prod.rst", "generated/torch.cat.rst", "generated/torch.cdist.rst", "generated/torch.ceil.rst", "generated/torch.chain_matmul.rst", "generated/torch.cholesky.rst", "generated/torch.cholesky_inverse.rst", "generated/torch.cholesky_solve.rst", "generated/torch.chunk.rst", "generated/torch.clamp.rst", "generated/torch.clip.rst", "generated/torch.clone.rst", "generated/torch.column_stack.rst", "generated/torch.combinations.rst", "generated/torch.compile.rst", "generated/torch.compiled_with_cxx11_abi.rst", "generated/torch.complex.rst", "generated/torch.concat.rst", "generated/torch.concatenate.rst", "generated/torch.conj.rst", "generated/torch.conj_physical.rst", "generated/torch.copysign.rst", "generated/torch.corrcoef.rst", "generated/torch.cos.rst", "generated/torch.cosh.rst", "generated/torch.count_nonzero.rst", "generated/torch.cov.rst", "generated/torch.cross.rst", "generated/torch.cuda.CUDAGraph.rst", "generated/torch.cuda.CUDAPluggableAllocator.rst", "generated/torch.cuda.Event.rst", "generated/torch.cuda.ExternalStream.rst", "generated/torch.cuda.OutOfMemoryError.rst", "generated/torch.cuda.Stream.rst", "generated/torch.cuda.StreamContext.rst", "generated/torch.cuda.caching_allocator_alloc.rst", "generated/torch.cuda.caching_allocator_delete.rst", "generated/torch.cuda.can_device_access_peer.rst", "generated/torch.cuda.change_current_allocator.rst", "generated/torch.cuda.clock_rate.rst", "generated/torch.cuda.comm.broadcast.rst", "generated/torch.cuda.comm.broadcast_coalesced.rst", "generated/torch.cuda.comm.gather.rst", "generated/torch.cuda.comm.reduce_add.rst", "generated/torch.cuda.comm.scatter.rst", "generated/torch.cuda.current_blas_handle.rst", "generated/torch.cuda.current_device.rst", "generated/torch.cuda.current_stream.rst", "generated/torch.cuda.default_stream.rst", "generated/torch.cuda.device.rst", "generated/torch.cuda.device_count.rst", "generated/torch.cuda.device_of.rst", "generated/torch.cuda.empty_cache.rst", "generated/torch.cuda.get_allocator_backend.rst", "generated/torch.cuda.get_arch_list.rst", "generated/torch.cuda.get_device_capability.rst", "generated/torch.cuda.get_device_name.rst", "generated/torch.cuda.get_device_properties.rst", "generated/torch.cuda.get_gencode_flags.rst", "generated/torch.cuda.get_rng_state.rst", "generated/torch.cuda.get_rng_state_all.rst", "generated/torch.cuda.get_sync_debug_mode.rst", "generated/torch.cuda.graph.rst", "generated/torch.cuda.graph_pool_handle.rst", "generated/torch.cuda.init.rst", "generated/torch.cuda.initial_seed.rst", "generated/torch.cuda.ipc_collect.rst", "generated/torch.cuda.is_available.rst", "generated/torch.cuda.is_current_stream_capturing.rst", "generated/torch.cuda.is_initialized.rst", "generated/torch.cuda.jiterator._create_jit_fn.rst", "generated/torch.cuda.jiterator._create_multi_output_jit_fn.rst", "generated/torch.cuda.list_gpu_processes.rst", "generated/torch.cuda.make_graphed_callables.rst", "generated/torch.cuda.manual_seed.rst", "generated/torch.cuda.manual_seed_all.rst", "generated/torch.cuda.max_memory_allocated.rst", "generated/torch.cuda.max_memory_cached.rst", "generated/torch.cuda.max_memory_reserved.rst", "generated/torch.cuda.mem_get_info.rst", "generated/torch.cuda.memory_allocated.rst", "generated/torch.cuda.memory_cached.rst", "generated/torch.cuda.memory_reserved.rst", "generated/torch.cuda.memory_snapshot.rst", "generated/torch.cuda.memory_stats.rst", "generated/torch.cuda.memory_summary.rst", "generated/torch.cuda.memory_usage.rst", "generated/torch.cuda.nvtx.mark.rst", "generated/torch.cuda.nvtx.range_pop.rst", "generated/torch.cuda.nvtx.range_push.rst", "generated/torch.cuda.power_draw.rst", "generated/torch.cuda.reset_max_memory_allocated.rst", "generated/torch.cuda.reset_max_memory_cached.rst", "generated/torch.cuda.reset_peak_memory_stats.rst", "generated/torch.cuda.seed.rst", "generated/torch.cuda.seed_all.rst", "generated/torch.cuda.set_device.rst", "generated/torch.cuda.set_per_process_memory_fraction.rst", "generated/torch.cuda.set_rng_state.rst", "generated/torch.cuda.set_rng_state_all.rst", "generated/torch.cuda.set_stream.rst", "generated/torch.cuda.set_sync_debug_mode.rst", "generated/torch.cuda.stream.rst", "generated/torch.cuda.synchronize.rst", "generated/torch.cuda.temperature.rst", "generated/torch.cuda.utilization.rst", "generated/torch.cummax.rst", "generated/torch.cummin.rst", "generated/torch.cumprod.rst", "generated/torch.cumsum.rst", "generated/torch.cumulative_trapezoid.rst", "generated/torch.deg2rad.rst", "generated/torch.dequantize.rst", "generated/torch.det.rst", "generated/torch.diag.rst", "generated/torch.diag_embed.rst", "generated/torch.diagflat.rst", "generated/torch.diagonal.rst", "generated/torch.diagonal_scatter.rst", "generated/torch.diff.rst", "generated/torch.digamma.rst", "generated/torch.dist.rst", "generated/torch.div.rst", "generated/torch.divide.rst", "generated/torch.dot.rst", "generated/torch.dsplit.rst", "generated/torch.dstack.rst", "generated/torch.einsum.rst", "generated/torch.empty.rst", "generated/torch.empty_like.rst", "generated/torch.empty_strided.rst", "generated/torch.enable_grad.rst", "generated/torch.eq.rst", "generated/torch.equal.rst", "generated/torch.erf.rst", "generated/torch.erfc.rst", "generated/torch.erfinv.rst", "generated/torch.exp.rst", "generated/torch.exp2.rst", "generated/torch.expm1.rst", "generated/torch.eye.rst", "generated/torch.fake_quantize_per_channel_affine.rst", "generated/torch.fake_quantize_per_tensor_affine.rst", "generated/torch.fft.fft.rst", "generated/torch.fft.fft2.rst", "generated/torch.fft.fftfreq.rst", "generated/torch.fft.fftn.rst", "generated/torch.fft.fftshift.rst", "generated/torch.fft.hfft.rst", "generated/torch.fft.hfft2.rst", "generated/torch.fft.hfftn.rst", "generated/torch.fft.ifft.rst", "generated/torch.fft.ifft2.rst", "generated/torch.fft.ifftn.rst", "generated/torch.fft.ifftshift.rst", "generated/torch.fft.ihfft.rst", "generated/torch.fft.ihfft2.rst", "generated/torch.fft.ihfftn.rst", "generated/torch.fft.irfft.rst", "generated/torch.fft.irfft2.rst", "generated/torch.fft.irfftn.rst", "generated/torch.fft.rfft.rst", "generated/torch.fft.rfft2.rst", "generated/torch.fft.rfftfreq.rst", "generated/torch.fft.rfftn.rst", "generated/torch.fix.rst", "generated/torch.flatten.rst", "generated/torch.flip.rst", "generated/torch.fliplr.rst", "generated/torch.flipud.rst", "generated/torch.float_power.rst", "generated/torch.floor.rst", "generated/torch.floor_divide.rst", "generated/torch.fmax.rst", "generated/torch.fmin.rst", "generated/torch.fmod.rst", "generated/torch.frac.rst", "generated/torch.frexp.rst", "generated/torch.from_dlpack.rst", "generated/torch.from_numpy.rst", "generated/torch.frombuffer.rst", "generated/torch.full.rst", "generated/torch.full_like.rst", "generated/torch.func.functional_call.rst", "generated/torch.func.functionalize.rst", "generated/torch.func.grad.rst", "generated/torch.func.grad_and_value.rst", "generated/torch.func.hessian.rst", "generated/torch.func.jacfwd.rst", "generated/torch.func.jacrev.rst", "generated/torch.func.jvp.rst", "generated/torch.func.linearize.rst", "generated/torch.func.replace_all_batch_norm_modules_.rst", "generated/torch.func.stack_module_state.rst", "generated/torch.func.vjp.rst", "generated/torch.func.vmap.rst", "generated/torch.gather.rst", "generated/torch.gcd.rst", "generated/torch.ge.rst", "generated/torch.geqrf.rst", "generated/torch.ger.rst", "generated/torch.get_default_dtype.rst", "generated/torch.get_deterministic_debug_mode.rst", "generated/torch.get_float32_matmul_precision.rst", "generated/torch.get_num_interop_threads.rst", "generated/torch.get_num_threads.rst", "generated/torch.get_rng_state.rst", "generated/torch.gradient.rst", "generated/torch.greater.rst", "generated/torch.greater_equal.rst", "generated/torch.gt.rst", "generated/torch.hamming_window.rst", "generated/torch.hann_window.rst", "generated/torch.heaviside.rst", "generated/torch.histc.rst", "generated/torch.histogram.rst", "generated/torch.histogramdd.rst", "generated/torch.hsplit.rst", "generated/torch.hspmm.rst", "generated/torch.hstack.rst", "generated/torch.hypot.rst", "generated/torch.i0.rst", "generated/torch.igamma.rst", "generated/torch.igammac.rst", "generated/torch.imag.rst", "generated/torch.index_add.rst", "generated/torch.index_copy.rst", "generated/torch.index_reduce.rst", "generated/torch.index_select.rst", "generated/torch.inference_mode.rst", "generated/torch.initial_seed.rst", "generated/torch.inner.rst", "generated/torch.inverse.rst", "generated/torch.is_complex.rst", "generated/torch.is_conj.rst", "generated/torch.is_deterministic_algorithms_warn_only_enabled.rst", "generated/torch.is_floating_point.rst", "generated/torch.is_grad_enabled.rst", "generated/torch.is_inference_mode_enabled.rst", "generated/torch.is_nonzero.rst", "generated/torch.is_storage.rst", "generated/torch.is_tensor.rst", "generated/torch.is_warn_always_enabled.rst", "generated/torch.isclose.rst", "generated/torch.isfinite.rst", "generated/torch.isin.rst", "generated/torch.isinf.rst", "generated/torch.isnan.rst", "generated/torch.isneginf.rst", "generated/torch.isposinf.rst", "generated/torch.isreal.rst", "generated/torch.istft.rst", "generated/torch.jit.Attribute.rst", "generated/torch.jit.ScriptFunction.rst", "generated/torch.jit.ScriptModule.rst", "generated/torch.jit.annotate.rst", "generated/torch.jit.enable_onednn_fusion.rst", "generated/torch.jit.fork.rst", "generated/torch.jit.freeze.rst", "generated/torch.jit.ignore.rst", "generated/torch.jit.isinstance.rst", "generated/torch.jit.load.rst", "generated/torch.jit.onednn_fusion_enabled.rst", "generated/torch.jit.optimize_for_inference.rst", "generated/torch.jit.save.rst", "generated/torch.jit.script.rst", "generated/torch.jit.script_if_tracing.rst", "generated/torch.jit.set_fusion_strategy.rst", "generated/torch.jit.strict_fusion.rst", "generated/torch.jit.trace.rst", "generated/torch.jit.trace_module.rst", "generated/torch.jit.unused.rst", "generated/torch.jit.wait.rst", "generated/torch.kaiser_window.rst", "generated/torch.kron.rst", "generated/torch.kthvalue.rst", "generated/torch.lcm.rst", "generated/torch.ldexp.rst", "generated/torch.le.rst", "generated/torch.lerp.rst", "generated/torch.less.rst", "generated/torch.less_equal.rst", "generated/torch.lgamma.rst", "generated/torch.linalg.cholesky.rst", "generated/torch.linalg.cholesky_ex.rst", "generated/torch.linalg.cond.rst", "generated/torch.linalg.cross.rst", "generated/torch.linalg.det.rst", "generated/torch.linalg.diagonal.rst", "generated/torch.linalg.eig.rst", "generated/torch.linalg.eigh.rst", "generated/torch.linalg.eigvals.rst", "generated/torch.linalg.eigvalsh.rst", "generated/torch.linalg.householder_product.rst", "generated/torch.linalg.inv.rst", "generated/torch.linalg.inv_ex.rst", "generated/torch.linalg.ldl_factor.rst", "generated/torch.linalg.ldl_factor_ex.rst", "generated/torch.linalg.ldl_solve.rst", "generated/torch.linalg.lstsq.rst", "generated/torch.linalg.lu.rst", "generated/torch.linalg.lu_factor.rst", "generated/torch.linalg.lu_factor_ex.rst", "generated/torch.linalg.lu_solve.rst", "generated/torch.linalg.matmul.rst", "generated/torch.linalg.matrix_exp.rst", "generated/torch.linalg.matrix_norm.rst", "generated/torch.linalg.matrix_power.rst", "generated/torch.linalg.matrix_rank.rst", "generated/torch.linalg.multi_dot.rst", "generated/torch.linalg.norm.rst", "generated/torch.linalg.pinv.rst", "generated/torch.linalg.qr.rst", "generated/torch.linalg.slogdet.rst", "generated/torch.linalg.solve.rst", "generated/torch.linalg.solve_ex.rst", "generated/torch.linalg.solve_triangular.rst", "generated/torch.linalg.svd.rst", "generated/torch.linalg.svdvals.rst", "generated/torch.linalg.tensorinv.rst", "generated/torch.linalg.tensorsolve.rst", "generated/torch.linalg.vander.rst", "generated/torch.linalg.vecdot.rst", "generated/torch.linalg.vector_norm.rst", "generated/torch.linspace.rst", "generated/torch.load.rst", "generated/torch.lobpcg.rst", "generated/torch.log.rst", "generated/torch.log10.rst", "generated/torch.log1p.rst", "generated/torch.log2.rst", "generated/torch.logaddexp.rst", "generated/torch.logaddexp2.rst", "generated/torch.logcumsumexp.rst", "generated/torch.logdet.rst", "generated/torch.logical_and.rst", "generated/torch.logical_not.rst", "generated/torch.logical_or.rst", "generated/torch.logical_xor.rst", "generated/torch.logit.rst", "generated/torch.logspace.rst", "generated/torch.logsumexp.rst", "generated/torch.lt.rst", "generated/torch.lu.rst", "generated/torch.lu_solve.rst", "generated/torch.lu_unpack.rst", "generated/torch.manual_seed.rst", "generated/torch.masked_select.rst", "generated/torch.matmul.rst", "generated/torch.matrix_exp.rst", "generated/torch.matrix_power.rst", "generated/torch.max.rst", "generated/torch.maximum.rst", "generated/torch.mean.rst", "generated/torch.median.rst", "generated/torch.meshgrid.rst", "generated/torch.min.rst", "generated/torch.minimum.rst", "generated/torch.mm.rst", "generated/torch.mode.rst", "generated/torch.moveaxis.rst", "generated/torch.movedim.rst", "generated/torch.mps.current_allocated_memory.rst", "generated/torch.mps.driver_allocated_memory.rst", "generated/torch.mps.empty_cache.rst", "generated/torch.mps.get_rng_state.rst", "generated/torch.mps.manual_seed.rst", "generated/torch.mps.profiler.profile.rst", "generated/torch.mps.profiler.start.rst", "generated/torch.mps.profiler.stop.rst", "generated/torch.mps.seed.rst", "generated/torch.mps.set_per_process_memory_fraction.rst", "generated/torch.mps.set_rng_state.rst", "generated/torch.mps.synchronize.rst", "generated/torch.msort.rst", "generated/torch.mul.rst", "generated/torch.multinomial.rst", "generated/torch.multiply.rst", "generated/torch.mv.rst", "generated/torch.mvlgamma.rst", "generated/torch.nan_to_num.rst", "generated/torch.nanmean.rst", "generated/torch.nanmedian.rst", "generated/torch.nanquantile.rst", "generated/torch.nansum.rst", "generated/torch.narrow.rst", "generated/torch.narrow_copy.rst", "generated/torch.ne.rst", "generated/torch.neg.rst", "generated/torch.negative.rst", "generated/torch.nextafter.rst", "generated/torch.nn.AdaptiveAvgPool1d.rst", "generated/torch.nn.AdaptiveAvgPool2d.rst", "generated/torch.nn.AdaptiveAvgPool3d.rst", "generated/torch.nn.AdaptiveLogSoftmaxWithLoss.rst", "generated/torch.nn.AdaptiveMaxPool1d.rst", "generated/torch.nn.AdaptiveMaxPool2d.rst", "generated/torch.nn.AdaptiveMaxPool3d.rst", "generated/torch.nn.AlphaDropout.rst", "generated/torch.nn.AvgPool1d.rst", "generated/torch.nn.AvgPool2d.rst", "generated/torch.nn.AvgPool3d.rst", "generated/torch.nn.BCELoss.rst", "generated/torch.nn.BCEWithLogitsLoss.rst", "generated/torch.nn.BatchNorm1d.rst", "generated/torch.nn.BatchNorm2d.rst", "generated/torch.nn.BatchNorm3d.rst", "generated/torch.nn.Bilinear.rst", "generated/torch.nn.CELU.rst", "generated/torch.nn.CTCLoss.rst", "generated/torch.nn.ChannelShuffle.rst", "generated/torch.nn.ConstantPad1d.rst", "generated/torch.nn.ConstantPad2d.rst", "generated/torch.nn.ConstantPad3d.rst", "generated/torch.nn.Conv1d.rst", "generated/torch.nn.Conv2d.rst", "generated/torch.nn.Conv3d.rst", "generated/torch.nn.ConvTranspose1d.rst", "generated/torch.nn.ConvTranspose2d.rst", "generated/torch.nn.ConvTranspose3d.rst", "generated/torch.nn.CosineEmbeddingLoss.rst", "generated/torch.nn.CosineSimilarity.rst", "generated/torch.nn.CrossEntropyLoss.rst", "generated/torch.nn.DataParallel.rst", "generated/torch.nn.Dropout.rst", "generated/torch.nn.Dropout1d.rst", "generated/torch.nn.Dropout2d.rst", "generated/torch.nn.Dropout3d.rst", "generated/torch.nn.ELU.rst", "generated/torch.nn.Embedding.rst", "generated/torch.nn.EmbeddingBag.rst", "generated/torch.nn.FeatureAlphaDropout.rst", "generated/torch.nn.Flatten.rst", "generated/torch.nn.Fold.rst", "generated/torch.nn.FractionalMaxPool2d.rst", "generated/torch.nn.FractionalMaxPool3d.rst", "generated/torch.nn.GELU.rst", "generated/torch.nn.GLU.rst", "generated/torch.nn.GRU.rst", "generated/torch.nn.GRUCell.rst", "generated/torch.nn.GaussianNLLLoss.rst", "generated/torch.nn.GroupNorm.rst", "generated/torch.nn.Hardshrink.rst", "generated/torch.nn.Hardsigmoid.rst", "generated/torch.nn.Hardswish.rst", "generated/torch.nn.Hardtanh.rst", "generated/torch.nn.HingeEmbeddingLoss.rst", "generated/torch.nn.HuberLoss.rst", "generated/torch.nn.Identity.rst", "generated/torch.nn.InstanceNorm1d.rst", "generated/torch.nn.InstanceNorm2d.rst", "generated/torch.nn.InstanceNorm3d.rst", "generated/torch.nn.KLDivLoss.rst", "generated/torch.nn.L1Loss.rst", "generated/torch.nn.LPPool1d.rst", "generated/torch.nn.LPPool2d.rst", "generated/torch.nn.LSTM.rst", "generated/torch.nn.LSTMCell.rst", "generated/torch.nn.LayerNorm.rst", "generated/torch.nn.LazyBatchNorm1d.rst", "generated/torch.nn.LazyBatchNorm2d.rst", "generated/torch.nn.LazyBatchNorm3d.rst", "generated/torch.nn.LazyConv1d.rst", "generated/torch.nn.LazyConv2d.rst", "generated/torch.nn.LazyConv3d.rst", "generated/torch.nn.LazyConvTranspose1d.rst", "generated/torch.nn.LazyConvTranspose2d.rst", "generated/torch.nn.LazyConvTranspose3d.rst", "generated/torch.nn.LazyInstanceNorm1d.rst", "generated/torch.nn.LazyInstanceNorm2d.rst", "generated/torch.nn.LazyInstanceNorm3d.rst", "generated/torch.nn.LazyLinear.rst", "generated/torch.nn.LeakyReLU.rst", "generated/torch.nn.Linear.rst", "generated/torch.nn.LocalResponseNorm.rst", "generated/torch.nn.LogSigmoid.rst", "generated/torch.nn.LogSoftmax.rst", "generated/torch.nn.MSELoss.rst", "generated/torch.nn.MarginRankingLoss.rst", "generated/torch.nn.MaxPool1d.rst", "generated/torch.nn.MaxPool2d.rst", "generated/torch.nn.MaxPool3d.rst", "generated/torch.nn.MaxUnpool1d.rst", "generated/torch.nn.MaxUnpool2d.rst", "generated/torch.nn.MaxUnpool3d.rst", "generated/torch.nn.Mish.rst", "generated/torch.nn.Module.rst", "generated/torch.nn.ModuleDict.rst", "generated/torch.nn.ModuleList.rst", "generated/torch.nn.MultiLabelMarginLoss.rst", "generated/torch.nn.MultiLabelSoftMarginLoss.rst", "generated/torch.nn.MultiMarginLoss.rst", "generated/torch.nn.MultiheadAttention.rst", "generated/torch.nn.NLLLoss.rst", "generated/torch.nn.PReLU.rst", "generated/torch.nn.PairwiseDistance.rst", "generated/torch.nn.ParameterDict.rst", "generated/torch.nn.ParameterList.rst", "generated/torch.nn.PixelShuffle.rst", "generated/torch.nn.PixelUnshuffle.rst", "generated/torch.nn.PoissonNLLLoss.rst", "generated/torch.nn.RNN.rst", "generated/torch.nn.RNNBase.rst", "generated/torch.nn.RNNCell.rst", "generated/torch.nn.RReLU.rst", "generated/torch.nn.ReLU.rst", "generated/torch.nn.ReLU6.rst", "generated/torch.nn.ReflectionPad1d.rst", "generated/torch.nn.ReflectionPad2d.rst", "generated/torch.nn.ReflectionPad3d.rst", "generated/torch.nn.ReplicationPad1d.rst", "generated/torch.nn.ReplicationPad2d.rst", "generated/torch.nn.ReplicationPad3d.rst", "generated/torch.nn.SELU.rst", "generated/torch.nn.Sequential.rst", "generated/torch.nn.SiLU.rst", "generated/torch.nn.Sigmoid.rst", "generated/torch.nn.SmoothL1Loss.rst", "generated/torch.nn.SoftMarginLoss.rst", "generated/torch.nn.Softmax.rst", "generated/torch.nn.Softmax2d.rst", "generated/torch.nn.Softmin.rst", "generated/torch.nn.Softplus.rst", "generated/torch.nn.Softshrink.rst", "generated/torch.nn.Softsign.rst", "generated/torch.nn.SyncBatchNorm.rst", "generated/torch.nn.Tanh.rst", "generated/torch.nn.Tanhshrink.rst", "generated/torch.nn.Threshold.rst", "generated/torch.nn.Transformer.rst", "generated/torch.nn.TransformerDecoder.rst", "generated/torch.nn.TransformerDecoderLayer.rst", "generated/torch.nn.TransformerEncoder.rst", "generated/torch.nn.TransformerEncoderLayer.rst", "generated/torch.nn.TripletMarginLoss.rst", "generated/torch.nn.TripletMarginWithDistanceLoss.rst", "generated/torch.nn.Unflatten.rst", "generated/torch.nn.Unfold.rst", "generated/torch.nn.Upsample.rst", "generated/torch.nn.UpsamplingBilinear2d.rst", "generated/torch.nn.UpsamplingNearest2d.rst", "generated/torch.nn.ZeroPad1d.rst", "generated/torch.nn.ZeroPad2d.rst", "generated/torch.nn.ZeroPad3d.rst", "generated/torch.nn.functional.adaptive_avg_pool1d.rst", "generated/torch.nn.functional.adaptive_avg_pool2d.rst", "generated/torch.nn.functional.adaptive_avg_pool3d.rst", "generated/torch.nn.functional.adaptive_max_pool1d.rst", "generated/torch.nn.functional.adaptive_max_pool2d.rst", "generated/torch.nn.functional.adaptive_max_pool3d.rst", "generated/torch.nn.functional.affine_grid.rst", "generated/torch.nn.functional.alpha_dropout.rst", "generated/torch.nn.functional.avg_pool1d.rst", "generated/torch.nn.functional.avg_pool2d.rst", "generated/torch.nn.functional.avg_pool3d.rst", "generated/torch.nn.functional.batch_norm.rst", "generated/torch.nn.functional.bilinear.rst", "generated/torch.nn.functional.binary_cross_entropy.rst", "generated/torch.nn.functional.binary_cross_entropy_with_logits.rst", "generated/torch.nn.functional.celu.rst", "generated/torch.nn.functional.conv1d.rst", "generated/torch.nn.functional.conv2d.rst", "generated/torch.nn.functional.conv3d.rst", "generated/torch.nn.functional.conv_transpose1d.rst", "generated/torch.nn.functional.conv_transpose2d.rst", "generated/torch.nn.functional.conv_transpose3d.rst", "generated/torch.nn.functional.cosine_embedding_loss.rst", "generated/torch.nn.functional.cosine_similarity.rst", "generated/torch.nn.functional.cross_entropy.rst", "generated/torch.nn.functional.ctc_loss.rst", "generated/torch.nn.functional.dropout.rst", "generated/torch.nn.functional.dropout1d.rst", "generated/torch.nn.functional.dropout2d.rst", "generated/torch.nn.functional.dropout3d.rst", "generated/torch.nn.functional.elu.rst", "generated/torch.nn.functional.elu_.rst", "generated/torch.nn.functional.embedding.rst", "generated/torch.nn.functional.embedding_bag.rst", "generated/torch.nn.functional.feature_alpha_dropout.rst", "generated/torch.nn.functional.fold.rst", "generated/torch.nn.functional.fractional_max_pool2d.rst", "generated/torch.nn.functional.fractional_max_pool3d.rst", "generated/torch.nn.functional.gaussian_nll_loss.rst", "generated/torch.nn.functional.gelu.rst", "generated/torch.nn.functional.glu.rst", "generated/torch.nn.functional.grid_sample.rst", "generated/torch.nn.functional.group_norm.rst", "generated/torch.nn.functional.gumbel_softmax.rst", "generated/torch.nn.functional.hardshrink.rst", "generated/torch.nn.functional.hardsigmoid.rst", "generated/torch.nn.functional.hardswish.rst", "generated/torch.nn.functional.hardtanh.rst", "generated/torch.nn.functional.hardtanh_.rst", "generated/torch.nn.functional.hinge_embedding_loss.rst", "generated/torch.nn.functional.huber_loss.rst", "generated/torch.nn.functional.instance_norm.rst", "generated/torch.nn.functional.interpolate.rst", "generated/torch.nn.functional.kl_div.rst", "generated/torch.nn.functional.l1_loss.rst", "generated/torch.nn.functional.layer_norm.rst", "generated/torch.nn.functional.leaky_relu.rst", "generated/torch.nn.functional.leaky_relu_.rst", "generated/torch.nn.functional.linear.rst", "generated/torch.nn.functional.local_response_norm.rst", "generated/torch.nn.functional.log_softmax.rst", "generated/torch.nn.functional.logsigmoid.rst", "generated/torch.nn.functional.lp_pool1d.rst", "generated/torch.nn.functional.lp_pool2d.rst", "generated/torch.nn.functional.margin_ranking_loss.rst", "generated/torch.nn.functional.max_pool1d.rst", "generated/torch.nn.functional.max_pool2d.rst", "generated/torch.nn.functional.max_pool3d.rst", "generated/torch.nn.functional.max_unpool1d.rst", "generated/torch.nn.functional.max_unpool2d.rst", "generated/torch.nn.functional.max_unpool3d.rst", "generated/torch.nn.functional.mish.rst", "generated/torch.nn.functional.mse_loss.rst", "generated/torch.nn.functional.multi_margin_loss.rst", "generated/torch.nn.functional.multilabel_margin_loss.rst", "generated/torch.nn.functional.multilabel_soft_margin_loss.rst", "generated/torch.nn.functional.nll_loss.rst", "generated/torch.nn.functional.normalize.rst", "generated/torch.nn.functional.one_hot.rst", "generated/torch.nn.functional.pad.rst", "generated/torch.nn.functional.pairwise_distance.rst", "generated/torch.nn.functional.pdist.rst", "generated/torch.nn.functional.pixel_shuffle.rst", "generated/torch.nn.functional.pixel_unshuffle.rst", "generated/torch.nn.functional.poisson_nll_loss.rst", "generated/torch.nn.functional.prelu.rst", "generated/torch.nn.functional.relu.rst", "generated/torch.nn.functional.relu6.rst", "generated/torch.nn.functional.relu_.rst", "generated/torch.nn.functional.rrelu.rst", "generated/torch.nn.functional.rrelu_.rst", "generated/torch.nn.functional.scaled_dot_product_attention.rst", "generated/torch.nn.functional.selu.rst", "generated/torch.nn.functional.sigmoid.rst", "generated/torch.nn.functional.silu.rst", "generated/torch.nn.functional.smooth_l1_loss.rst", "generated/torch.nn.functional.soft_margin_loss.rst", "generated/torch.nn.functional.softmax.rst", "generated/torch.nn.functional.softmin.rst", "generated/torch.nn.functional.softplus.rst", "generated/torch.nn.functional.softshrink.rst", "generated/torch.nn.functional.softsign.rst", "generated/torch.nn.functional.tanh.rst", "generated/torch.nn.functional.tanhshrink.rst", "generated/torch.nn.functional.threshold.rst", "generated/torch.nn.functional.threshold_.rst", "generated/torch.nn.functional.torch.nn.parallel.data_parallel.rst", "generated/torch.nn.functional.triplet_margin_loss.rst", "generated/torch.nn.functional.triplet_margin_with_distance_loss.rst", "generated/torch.nn.functional.unfold.rst", "generated/torch.nn.functional.upsample.rst", "generated/torch.nn.functional.upsample_bilinear.rst", "generated/torch.nn.functional.upsample_nearest.rst", "generated/torch.nn.modules.lazy.LazyModuleMixin.rst", "generated/torch.nn.modules.module.register_module_backward_hook.rst", "generated/torch.nn.modules.module.register_module_buffer_registration_hook.rst", "generated/torch.nn.modules.module.register_module_forward_hook.rst", "generated/torch.nn.modules.module.register_module_forward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_hook.rst", "generated/torch.nn.modules.module.register_module_full_backward_pre_hook.rst", "generated/torch.nn.modules.module.register_module_module_registration_hook.rst", "generated/torch.nn.modules.module.register_module_parameter_registration_hook.rst", "generated/torch.nn.parallel.DistributedDataParallel.rst", "generated/torch.nn.parameter.Parameter.rst", "generated/torch.nn.parameter.UninitializedBuffer.rst", "generated/torch.nn.parameter.UninitializedParameter.rst", "generated/torch.nn.utils.clip_grad_norm_.rst", "generated/torch.nn.utils.clip_grad_value_.rst", "generated/torch.nn.utils.parameters_to_vector.rst", "generated/torch.nn.utils.parametrizations.orthogonal.rst", "generated/torch.nn.utils.parametrizations.spectral_norm.rst", "generated/torch.nn.utils.parametrize.ParametrizationList.rst", "generated/torch.nn.utils.parametrize.cached.rst", "generated/torch.nn.utils.parametrize.is_parametrized.rst", "generated/torch.nn.utils.parametrize.register_parametrization.rst", "generated/torch.nn.utils.parametrize.remove_parametrizations.rst", "generated/torch.nn.utils.prune.BasePruningMethod.rst", "generated/torch.nn.utils.prune.CustomFromMask.rst", "generated/torch.nn.utils.prune.Identity.rst", "generated/torch.nn.utils.prune.L1Unstructured.rst", "generated/torch.nn.utils.prune.LnStructured.rst", "generated/torch.nn.utils.prune.PruningContainer.rst", "generated/torch.nn.utils.prune.RandomStructured.rst", "generated/torch.nn.utils.prune.RandomUnstructured.rst", "generated/torch.nn.utils.prune.custom_from_mask.rst", "generated/torch.nn.utils.prune.global_unstructured.rst", "generated/torch.nn.utils.prune.identity.rst", "generated/torch.nn.utils.prune.is_pruned.rst", "generated/torch.nn.utils.prune.l1_unstructured.rst", "generated/torch.nn.utils.prune.ln_structured.rst", "generated/torch.nn.utils.prune.random_structured.rst", "generated/torch.nn.utils.prune.random_unstructured.rst", "generated/torch.nn.utils.prune.remove.rst", "generated/torch.nn.utils.remove_spectral_norm.rst", "generated/torch.nn.utils.remove_weight_norm.rst", "generated/torch.nn.utils.rnn.PackedSequence.rst", "generated/torch.nn.utils.rnn.pack_padded_sequence.rst", "generated/torch.nn.utils.rnn.pack_sequence.rst", "generated/torch.nn.utils.rnn.pad_packed_sequence.rst", "generated/torch.nn.utils.rnn.pad_sequence.rst", "generated/torch.nn.utils.rnn.unpack_sequence.rst", "generated/torch.nn.utils.rnn.unpad_sequence.rst", "generated/torch.nn.utils.skip_init.rst", "generated/torch.nn.utils.spectral_norm.rst", "generated/torch.nn.utils.stateless.functional_call.rst", "generated/torch.nn.utils.vector_to_parameters.rst", "generated/torch.nn.utils.weight_norm.rst", "generated/torch.no_grad.rst", "generated/torch.nonzero.rst", "generated/torch.norm.rst", "generated/torch.normal.rst", "generated/torch.not_equal.rst", "generated/torch.numel.rst", "generated/torch.ones.rst", "generated/torch.ones_like.rst", "generated/torch.onnx.ExportOptions.rst", "generated/torch.onnx.ExportOutput.rst", "generated/torch.onnx.ExportOutputSerializer.rst", "generated/torch.onnx.JitScalarType.rst", "generated/torch.onnx.verification.GraphInfo.rst", "generated/torch.onnx.verification.VerificationOptions.rst", "generated/torch.optim.ASGD.rst", "generated/torch.optim.Adadelta.rst", "generated/torch.optim.Adagrad.rst", "generated/torch.optim.Adam.rst", "generated/torch.optim.AdamW.rst", "generated/torch.optim.Adamax.rst", "generated/torch.optim.LBFGS.rst", "generated/torch.optim.NAdam.rst", "generated/torch.optim.Optimizer.add_param_group.rst", "generated/torch.optim.Optimizer.load_state_dict.rst", "generated/torch.optim.Optimizer.state_dict.rst", "generated/torch.optim.Optimizer.step.rst", "generated/torch.optim.Optimizer.zero_grad.rst", "generated/torch.optim.RAdam.rst", "generated/torch.optim.RMSprop.rst", "generated/torch.optim.Rprop.rst", "generated/torch.optim.SGD.rst", "generated/torch.optim.SparseAdam.rst", "generated/torch.optim.lr_scheduler.ChainedScheduler.rst", "generated/torch.optim.lr_scheduler.ConstantLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingLR.rst", "generated/torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.rst", "generated/torch.optim.lr_scheduler.CyclicLR.rst", "generated/torch.optim.lr_scheduler.ExponentialLR.rst", "generated/torch.optim.lr_scheduler.LambdaLR.rst", "generated/torch.optim.lr_scheduler.LinearLR.rst", "generated/torch.optim.lr_scheduler.MultiStepLR.rst", "generated/torch.optim.lr_scheduler.MultiplicativeLR.rst", "generated/torch.optim.lr_scheduler.OneCycleLR.rst", "generated/torch.optim.lr_scheduler.PolynomialLR.rst", "generated/torch.optim.lr_scheduler.ReduceLROnPlateau.rst", "generated/torch.optim.lr_scheduler.SequentialLR.rst", "generated/torch.optim.lr_scheduler.StepLR.rst", "generated/torch.orgqr.rst", "generated/torch.ormqr.rst", "generated/torch.outer.rst", "generated/torch.pca_lowrank.rst", "generated/torch.permute.rst", "generated/torch.pinverse.rst", "generated/torch.poisson.rst", "generated/torch.polar.rst", "generated/torch.polygamma.rst", "generated/torch.positive.rst", "generated/torch.pow.rst", "generated/torch.prod.rst", "generated/torch.promote_types.rst", "generated/torch.qr.rst", "generated/torch.quantile.rst", "generated/torch.quantize_per_channel.rst", "generated/torch.quantize_per_tensor.rst", "generated/torch.quantized_batch_norm.rst", "generated/torch.quantized_max_pool1d.rst", "generated/torch.quantized_max_pool2d.rst", "generated/torch.quasirandom.SobolEngine.rst", "generated/torch.rad2deg.rst", "generated/torch.rand.rst", "generated/torch.rand_like.rst", "generated/torch.randint.rst", "generated/torch.randint_like.rst", "generated/torch.randn.rst", "generated/torch.randn_like.rst", "generated/torch.randperm.rst", "generated/torch.range.rst", "generated/torch.ravel.rst", "generated/torch.real.rst", "generated/torch.reciprocal.rst", "generated/torch.remainder.rst", "generated/torch.renorm.rst", "generated/torch.repeat_interleave.rst", "generated/torch.reshape.rst", "generated/torch.resolve_conj.rst", "generated/torch.resolve_neg.rst", "generated/torch.result_type.rst", "generated/torch.roll.rst", "generated/torch.rot90.rst", "generated/torch.round.rst", "generated/torch.row_stack.rst", "generated/torch.rsqrt.rst", "generated/torch.save.rst", "generated/torch.scatter.rst", "generated/torch.scatter_add.rst", "generated/torch.scatter_reduce.rst", "generated/torch.searchsorted.rst", "generated/torch.seed.rst", "generated/torch.select.rst", "generated/torch.select_scatter.rst", "generated/torch.set_default_device.rst", "generated/torch.set_default_dtype.rst", "generated/torch.set_default_tensor_type.rst", "generated/torch.set_deterministic_debug_mode.rst", "generated/torch.set_float32_matmul_precision.rst", "generated/torch.set_flush_denormal.rst", "generated/torch.set_grad_enabled.rst", "generated/torch.set_num_interop_threads.rst", "generated/torch.set_num_threads.rst", "generated/torch.set_printoptions.rst", "generated/torch.set_rng_state.rst", "generated/torch.set_warn_always.rst", "generated/torch.sgn.rst", "generated/torch.sigmoid.rst", "generated/torch.sign.rst", "generated/torch.signal.windows.bartlett.rst", "generated/torch.signal.windows.blackman.rst", "generated/torch.signal.windows.cosine.rst", "generated/torch.signal.windows.exponential.rst", "generated/torch.signal.windows.gaussian.rst", "generated/torch.signal.windows.general_cosine.rst", "generated/torch.signal.windows.general_hamming.rst", "generated/torch.signal.windows.hamming.rst", "generated/torch.signal.windows.hann.rst", "generated/torch.signal.windows.kaiser.rst", "generated/torch.signal.windows.nuttall.rst", "generated/torch.signbit.rst", "generated/torch.sin.rst", "generated/torch.sinc.rst", "generated/torch.sinh.rst", "generated/torch.slice_scatter.rst", "generated/torch.slogdet.rst", "generated/torch.smm.rst", "generated/torch.softmax.rst", "generated/torch.sort.rst", "generated/torch.sparse.addmm.rst", "generated/torch.sparse.check_sparse_tensor_invariants.rst", "generated/torch.sparse.log_softmax.rst", "generated/torch.sparse.mm.rst", "generated/torch.sparse.sampled_addmm.rst", "generated/torch.sparse.softmax.rst", "generated/torch.sparse.spdiags.rst", "generated/torch.sparse.sum.rst", "generated/torch.sparse_bsc_tensor.rst", "generated/torch.sparse_bsr_tensor.rst", "generated/torch.sparse_compressed_tensor.rst", "generated/torch.sparse_coo_tensor.rst", "generated/torch.sparse_csc_tensor.rst", "generated/torch.sparse_csr_tensor.rst", "generated/torch.split.rst", "generated/torch.sqrt.rst", "generated/torch.square.rst", "generated/torch.squeeze.rst", "generated/torch.sspaddmm.rst", "generated/torch.stack.rst", "generated/torch.std.rst", "generated/torch.std_mean.rst", "generated/torch.stft.rst", "generated/torch.sub.rst", "generated/torch.subtract.rst", "generated/torch.sum.rst", "generated/torch.svd.rst", "generated/torch.svd_lowrank.rst", "generated/torch.swapaxes.rst", "generated/torch.swapdims.rst", "generated/torch.sym_float.rst", "generated/torch.sym_int.rst", "generated/torch.sym_max.rst", "generated/torch.sym_min.rst", "generated/torch.sym_not.rst", "generated/torch.t.rst", "generated/torch.take.rst", "generated/torch.take_along_dim.rst", "generated/torch.tan.rst", "generated/torch.tanh.rst", "generated/torch.tensor.rst", "generated/torch.tensor_split.rst", "generated/torch.tensordot.rst", "generated/torch.tile.rst", "generated/torch.topk.rst", "generated/torch.trace.rst", "generated/torch.transpose.rst", "generated/torch.trapezoid.rst", "generated/torch.trapz.rst", "generated/torch.triangular_solve.rst", "generated/torch.tril.rst", "generated/torch.tril_indices.rst", "generated/torch.triu.rst", "generated/torch.triu_indices.rst", "generated/torch.true_divide.rst", "generated/torch.trunc.rst", "generated/torch.unbind.rst", "generated/torch.unflatten.rst", "generated/torch.unique.rst", "generated/torch.unique_consecutive.rst", "generated/torch.unsqueeze.rst", "generated/torch.use_deterministic_algorithms.rst", "generated/torch.vander.rst", "generated/torch.var.rst", "generated/torch.var_mean.rst", "generated/torch.vdot.rst", "generated/torch.view_as_complex.rst", "generated/torch.view_as_real.rst", "generated/torch.vmap.rst", "generated/torch.vsplit.rst", "generated/torch.vstack.rst", "generated/torch.where.rst", "generated/torch.xlogy.rst", "generated/torch.zeros.rst", "generated/torch.zeros_like.rst", "hub.rst", "index.rst", "ir.rst", "jit.rst", "jit_builtin_functions.rst", "jit_language_reference.rst", "jit_language_reference_v2.rst", "jit_python_reference.rst", "jit_unsupported.rst", "jit_utils.rst", "library.rst", "linalg.rst", "logging.rst", "masked.rst", "mobile_optimizer.rst", "model_zoo.rst", "monitor.rst", "mps.rst", "multiprocessing.rst", "name_inference.rst", "named_tensor.rst", "nested.rst", "nn.rst", "nn.functional.rst", "nn.init.rst", "notes/amp_examples.rst", "notes/autograd.rst", "notes/broadcasting.rst", "notes/cpu_threading_torchscript_inference.rst", "notes/cuda.rst", "notes/ddp.rst", "notes/extending.rst", "notes/extending.func.rst", "notes/faq.rst", "notes/gradcheck.rst", "notes/hip.rst", "notes/large_scale_deployments.rst", "notes/modules.rst", "notes/mps.rst", "notes/multiprocessing.rst", "notes/numerical_accuracy.rst", "notes/randomness.rst", "notes/serialization.rst", "notes/windows.rst", "onnx.rst", "onnx_diagnostics.rst", "onnx_supported_aten_ops.rst", "optim.rst", "package.rst", "pipeline.rst", "profiler.rst", "quantization.rst", "quantization-accuracy-debugging.rst", "quantization-backend-configuration.rst", "quantization-support.rst", "random.rst", "rpc.rst", "rpc/distributed_autograd.rst", "rpc/rref.rst", "signal.rst", "sparse.rst", "special.rst", "storage.rst", "tensor_attributes.rst", "tensor_view.rst", "tensorboard.rst", "tensors.rst", "testing.rst", "torch.rst", "torch.ao.ns._numeric_suite.rst", "torch.ao.ns._numeric_suite_fx.rst", "torch.overrides.rst", "type_info.rst"], "titles": ["torch._dynamo", "Automatic Mixed Precision package - torch.amp", "Automatic differentiation package - torch.autograd", "torch.backends", "Benchmark Utils - torch.utils.benchmark", "torch.utils.bottleneck", "torch.utils.checkpoint", "PyTorch Governance | Build + CI", "PyTorch Contribution Guide", "PyTorch Design Philosophy", "PyTorch Governance | Mechanics", "PyTorch Governance | Maintainers", "CUDAGraph Trees", "Custom Backends", "TorchDynamo Deeper Dive", "Dynamic shapes", "Fake tensor", "Frequently Asked Questions", "TorchDynamo APIs to control fine-grained tracing", "torch.compile", "Getting Started", "Guards Overview", "torch.compile", "TorchInductor GPU Profiling", "PyTorch 2.0 NNModule Support", "PyTorch 2.0 Performance Dashboard", "Technical Overview", "torch.func interaction with torch.compile", "Writing Graph Transformations on ATen IR", "PyTorch 2.0 Troubleshooting", "Complex Numbers", "torch.__config__", "torch.utils.cpp_extension", "C++", "torch.cuda", "CUDA Stream Sanitizer", "&lt;no title&gt;", "&lt;no title&gt;", "torch.utils.data", "DDP Communication Hooks", "torch::deploy has been moved to pytorch/multipy", "Distributed communication package - torch.distributed", "Generic Join Context Manager", "Distributed Checkpoint - torch.distributed.checkpoint", "Torch Distributed Elastic", "Distributed Optimizers", "Tensor Parallelism - torch.distributed.tensor.parallel", "Probability distributions - torch.distributions", "torch.utils.dlpack", "Elastic Agent", "Customization", "Error Propagation", "Events", "Examples", "TorchElastic Kubernetes", "Metrics", "Multiprocessing", "Quickstart", "Rendezvous", "torchrun (Elastic Launch)", "Expiration Timers", "Train script", "torch.fft", "FullyShardedDataParallel", "torch.func", "torch.func API Reference", "Patching Batch Norm", "Migrating from functorch to torch.func", "UX Limitations", "torch.func Whirlwind Tour", "torch.futures", "torch.fx", "DIAGSYS0001:arg-format-too-verbose", "FXE0001:fx-tracer-success", "FXE0002:fx-tracer-failure", "FXE0003:fx-frontend-aotautograd", "FXE0004:fx-pass-convert-neg-to-sigmoid", "FXE0005:fx-ir-add-node", "FXE0006:atenlib-symbolic-function", "FXE0007:atenlib-fx-to-onnx", "FXE0008:fx-node-to-onnx", "FXE0009:fx-frontend-dynamo-make-fx", "FXE0010:fx-pass", "FXE0011:no-symbolic-function-for-call-function", "FXE0012:unsupported-fx-node-analysis", "POE0001:node-missing-onnx-shape-inference", "POE0002:missing-custom-symbolic-function", "POE0003:missing-standard-symbolic-function", "POE0004:operator-supported-in-newer-opset-version", "Generator", "torch.Tensor.abs", "torch.Tensor.abs_", "torch.Tensor.absolute", "torch.Tensor.absolute_", "torch.Tensor.acos", "torch.Tensor.acos_", "torch.Tensor.acosh", "torch.Tensor.acosh_", "torch.Tensor.add", "torch.Tensor.add_", "torch.Tensor.addbmm", "torch.Tensor.addbmm_", "torch.Tensor.addcdiv", "torch.Tensor.addcdiv_", "torch.Tensor.addcmul", "torch.Tensor.addcmul_", "torch.Tensor.addmm", "torch.Tensor.addmm_", "torch.Tensor.addmv", "torch.Tensor.addmv_", "torch.Tensor.addr", "torch.Tensor.addr_", "torch.Tensor.adjoint", "torch.Tensor.all", "torch.Tensor.allclose", "torch.Tensor.amax", "torch.Tensor.amin", "torch.Tensor.aminmax", "torch.Tensor.angle", "torch.Tensor.any", "torch.Tensor.apply_", "torch.Tensor.arccos", "torch.Tensor.arccos_", "torch.Tensor.arccosh", "torch.Tensor.arccosh_", "torch.Tensor.arcsin", "torch.Tensor.arcsin_", "torch.Tensor.arcsinh", "torch.Tensor.arcsinh_", "torch.Tensor.arctan", "torch.Tensor.arctan2", "torch.Tensor.arctan2_", "torch.Tensor.arctan_", "torch.Tensor.arctanh", "torch.Tensor.arctanh_", "torch.Tensor.argmax", "torch.Tensor.argmin", "torch.Tensor.argsort", "torch.Tensor.argwhere", "torch.Tensor.as_strided", "torch.Tensor.as_subclass", "torch.Tensor.asin", "torch.Tensor.asin_", "torch.Tensor.asinh", "torch.Tensor.asinh_", "torch.Tensor.atan", "torch.Tensor.atan2", "torch.Tensor.atan2_", "torch.Tensor.atan_", "torch.Tensor.atanh", "torch.Tensor.atanh_", "torch.Tensor.backward", "torch.Tensor.baddbmm", "torch.Tensor.baddbmm_", "torch.Tensor.bernoulli", "torch.Tensor.bernoulli_", "torch.Tensor.bfloat16", "torch.Tensor.bincount", "torch.Tensor.bitwise_and", "torch.Tensor.bitwise_and_", "torch.Tensor.bitwise_left_shift", "torch.Tensor.bitwise_left_shift_", "torch.Tensor.bitwise_not", "torch.Tensor.bitwise_not_", "torch.Tensor.bitwise_or", "torch.Tensor.bitwise_or_", "torch.Tensor.bitwise_right_shift", "torch.Tensor.bitwise_right_shift_", "torch.Tensor.bitwise_xor", "torch.Tensor.bitwise_xor_", "torch.Tensor.bmm", "torch.Tensor.bool", "torch.Tensor.broadcast_to", "torch.Tensor.byte", "torch.Tensor.cauchy_", "torch.Tensor.ccol_indices", "torch.Tensor.cdouble", "torch.Tensor.ceil", "torch.Tensor.ceil_", "torch.Tensor.cfloat", "torch.Tensor.chalf", "torch.Tensor.char", "torch.Tensor.cholesky", "torch.Tensor.cholesky_inverse", "torch.Tensor.cholesky_solve", "torch.Tensor.chunk", "torch.Tensor.clamp", "torch.Tensor.clamp_", "torch.Tensor.clip", "torch.Tensor.clip_", "torch.Tensor.clone", "torch.Tensor.coalesce", "torch.Tensor.col_indices", "torch.Tensor.conj", "torch.Tensor.conj_physical", "torch.Tensor.conj_physical_", "torch.Tensor.contiguous", "torch.Tensor.copy_", "torch.Tensor.copysign", "torch.Tensor.copysign_", "torch.Tensor.corrcoef", "torch.Tensor.cos", "torch.Tensor.cos_", "torch.Tensor.cosh", "torch.Tensor.cosh_", "torch.Tensor.count_nonzero", "torch.Tensor.cov", "torch.Tensor.cpu", "torch.Tensor.cross", "torch.Tensor.crow_indices", "torch.Tensor.cuda", "torch.Tensor.cummax", "torch.Tensor.cummin", "torch.Tensor.cumprod", "torch.Tensor.cumprod_", "torch.Tensor.cumsum", "torch.Tensor.cumsum_", "torch.Tensor.data_ptr", "torch.Tensor.deg2rad", "torch.Tensor.dense_dim", "torch.Tensor.dequantize", "torch.Tensor.det", "torch.Tensor.detach", "torch.Tensor.detach_", "torch.Tensor.device", "torch.Tensor.diag", "torch.Tensor.diag_embed", "torch.Tensor.diagflat", "torch.Tensor.diagonal", "torch.Tensor.diagonal_scatter", "torch.Tensor.diff", "torch.Tensor.digamma", "torch.Tensor.digamma_", "torch.Tensor.dim", "torch.Tensor.dist", "torch.Tensor.div", "torch.Tensor.div_", "torch.Tensor.divide", "torch.Tensor.divide_", "torch.Tensor.dot", "torch.Tensor.double", "torch.Tensor.dsplit", "torch.Tensor.element_size", "torch.Tensor.eq", "torch.Tensor.eq_", "torch.Tensor.equal", "torch.Tensor.erf", "torch.Tensor.erf_", "torch.Tensor.erfc", "torch.Tensor.erfc_", "torch.Tensor.erfinv", "torch.Tensor.erfinv_", "torch.Tensor.exp", "torch.Tensor.exp_", "torch.Tensor.expand", "torch.Tensor.expand_as", "torch.Tensor.expm1", "torch.Tensor.expm1_", "torch.Tensor.exponential_", "torch.Tensor.fill_", "torch.Tensor.fill_diagonal_", "torch.Tensor.fix", "torch.Tensor.fix_", "torch.Tensor.flatten", "torch.Tensor.flip", "torch.Tensor.fliplr", "torch.Tensor.flipud", "torch.Tensor.float", "torch.Tensor.float_power", "torch.Tensor.float_power_", "torch.Tensor.floor", "torch.Tensor.floor_", "torch.Tensor.floor_divide", "torch.Tensor.floor_divide_", "torch.Tensor.fmax", "torch.Tensor.fmin", "torch.Tensor.fmod", "torch.Tensor.fmod_", "torch.Tensor.frac", "torch.Tensor.frac_", "torch.Tensor.frexp", "torch.Tensor.gather", "torch.Tensor.gcd", "torch.Tensor.gcd_", "torch.Tensor.ge", "torch.Tensor.ge_", "torch.Tensor.geometric_", "torch.Tensor.geqrf", "torch.Tensor.ger", "torch.Tensor.get_device", "torch.Tensor.grad", "torch.Tensor.greater", "torch.Tensor.greater_", "torch.Tensor.greater_equal", "torch.Tensor.greater_equal_", "torch.Tensor.gt", "torch.Tensor.gt_", "torch.Tensor.half", "torch.Tensor.hardshrink", "torch.Tensor.heaviside", "torch.Tensor.histc", "torch.Tensor.histogram", "torch.Tensor.hsplit", "torch.Tensor.hypot", "torch.Tensor.hypot_", "torch.Tensor.i0", "torch.Tensor.i0_", "torch.Tensor.igamma", "torch.Tensor.igamma_", "torch.Tensor.igammac", "torch.Tensor.igammac_", "torch.Tensor.imag", "torch.Tensor.index_add", "torch.Tensor.index_add_", "torch.Tensor.index_copy", "torch.Tensor.index_copy_", "torch.Tensor.index_fill", "torch.Tensor.index_fill_", "torch.Tensor.index_put", "torch.Tensor.index_put_", "torch.Tensor.index_reduce", "torch.Tensor.index_reduce_", "torch.Tensor.index_select", "torch.Tensor.indices", "torch.Tensor.inner", "torch.Tensor.int", "torch.Tensor.int_repr", "torch.Tensor.inverse", "torch.Tensor.is_coalesced", "torch.Tensor.is_complex", "torch.Tensor.is_conj", "torch.Tensor.is_contiguous", "torch.Tensor.is_cuda", "torch.Tensor.is_floating_point", "torch.Tensor.is_inference", "torch.Tensor.is_leaf", "torch.Tensor.is_meta", "torch.Tensor.is_pinned", "torch.Tensor.is_quantized", "torch.Tensor.is_set_to", "torch.Tensor.is_shared", "torch.Tensor.is_signed", "torch.Tensor.is_sparse", "torch.Tensor.is_sparse_csr", "torch.Tensor.isclose", "torch.Tensor.isfinite", "torch.Tensor.isinf", "torch.Tensor.isnan", "torch.Tensor.isneginf", "torch.Tensor.isposinf", "torch.Tensor.isreal", "torch.Tensor.istft", "torch.Tensor.item", "torch.Tensor.itemsize", "torch.Tensor.kthvalue", "torch.Tensor.lcm", "torch.Tensor.lcm_", "torch.Tensor.ldexp", "torch.Tensor.ldexp_", "torch.Tensor.le", "torch.Tensor.le_", "torch.Tensor.lerp", "torch.Tensor.lerp_", "torch.Tensor.less", "torch.Tensor.less_", "torch.Tensor.less_equal", "torch.Tensor.less_equal_", "torch.Tensor.lgamma", "torch.Tensor.lgamma_", "torch.Tensor.log", "torch.Tensor.log10", "torch.Tensor.log10_", "torch.Tensor.log1p", "torch.Tensor.log1p_", "torch.Tensor.log2", "torch.Tensor.log2_", "torch.Tensor.log_", "torch.Tensor.log_normal_", "torch.Tensor.logaddexp", "torch.Tensor.logaddexp2", "torch.Tensor.logcumsumexp", "torch.Tensor.logdet", "torch.Tensor.logical_and", "torch.Tensor.logical_and_", "torch.Tensor.logical_not", "torch.Tensor.logical_not_", "torch.Tensor.logical_or", "torch.Tensor.logical_or_", "torch.Tensor.logical_xor", "torch.Tensor.logical_xor_", "torch.Tensor.logit", "torch.Tensor.logit_", "torch.Tensor.logsumexp", "torch.Tensor.long", "torch.Tensor.lt", "torch.Tensor.lt_", "torch.Tensor.lu", "torch.Tensor.lu_solve", "torch.Tensor.map_", "torch.Tensor.masked_fill", "torch.Tensor.masked_fill_", "torch.Tensor.masked_scatter", "torch.Tensor.masked_scatter_", "torch.Tensor.masked_select", "torch.Tensor.matmul", "torch.Tensor.matrix_exp", "torch.Tensor.matrix_power", "torch.Tensor.max", "torch.Tensor.maximum", "torch.Tensor.mean", "torch.Tensor.median", "torch.Tensor.min", "torch.Tensor.minimum", "torch.Tensor.mm", "torch.Tensor.mode", "torch.Tensor.moveaxis", "torch.Tensor.movedim", "torch.Tensor.msort", "torch.Tensor.mul", "torch.Tensor.mul_", "torch.Tensor.multinomial", "torch.Tensor.multiply", "torch.Tensor.multiply_", "torch.Tensor.mv", "torch.Tensor.mvlgamma", "torch.Tensor.mvlgamma_", "torch.Tensor.nan_to_num", "torch.Tensor.nan_to_num_", "torch.Tensor.nanmean", "torch.Tensor.nanmedian", "torch.Tensor.nanquantile", "torch.Tensor.nansum", "torch.Tensor.narrow", "torch.Tensor.narrow_copy", "torch.Tensor.nbytes", "torch.Tensor.ndim", "torch.Tensor.ndimension", "torch.Tensor.ne", "torch.Tensor.ne_", "torch.Tensor.neg", "torch.Tensor.neg_", "torch.Tensor.negative", "torch.Tensor.negative_", "torch.Tensor.nelement", "torch.Tensor.new_empty", "torch.Tensor.new_full", "torch.Tensor.new_ones", "torch.Tensor.new_tensor", "torch.Tensor.new_zeros", "torch.Tensor.nextafter", "torch.Tensor.nextafter_", "torch.Tensor.nonzero", "torch.Tensor.norm", "torch.Tensor.normal_", "torch.Tensor.not_equal", "torch.Tensor.not_equal_", "torch.Tensor.numel", "torch.Tensor.numpy", "torch.Tensor.orgqr", "torch.Tensor.ormqr", "torch.Tensor.outer", "torch.Tensor.permute", "torch.Tensor.pin_memory", "torch.Tensor.pinverse", "torch.Tensor.polygamma", "torch.Tensor.polygamma_", "torch.Tensor.positive", "torch.Tensor.pow", "torch.Tensor.pow_", "torch.Tensor.prod", "torch.Tensor.put_", "torch.Tensor.q_per_channel_axis", "torch.Tensor.q_per_channel_scales", "torch.Tensor.q_per_channel_zero_points", "torch.Tensor.q_scale", "torch.Tensor.q_zero_point", "torch.Tensor.qr", "torch.Tensor.qscheme", "torch.Tensor.quantile", "torch.Tensor.rad2deg", "torch.Tensor.random_", "torch.Tensor.ravel", "torch.Tensor.real", "torch.Tensor.reciprocal", "torch.Tensor.reciprocal_", "torch.Tensor.record_stream", "torch.Tensor.register_hook", "torch.Tensor.remainder", "torch.Tensor.remainder_", "torch.Tensor.renorm", "torch.Tensor.renorm_", "torch.Tensor.repeat", "torch.Tensor.repeat_interleave", "torch.Tensor.requires_grad", "torch.Tensor.requires_grad_", "torch.Tensor.reshape", "torch.Tensor.reshape_as", "torch.Tensor.resize_", "torch.Tensor.resize_as_", "torch.Tensor.resolve_conj", "torch.Tensor.resolve_neg", "torch.Tensor.retain_grad", "torch.Tensor.retains_grad", "torch.Tensor.roll", "torch.Tensor.rot90", "torch.Tensor.round", "torch.Tensor.round_", "torch.Tensor.row_indices", "torch.Tensor.rsqrt", "torch.Tensor.rsqrt_", "torch.Tensor.scatter", "torch.Tensor.scatter_", "torch.Tensor.scatter_add", "torch.Tensor.scatter_add_", "torch.Tensor.scatter_reduce", "torch.Tensor.scatter_reduce_", "torch.Tensor.select", "torch.Tensor.select_scatter", "torch.Tensor.set_", "torch.Tensor.sgn", "torch.Tensor.sgn_", "torch.Tensor.share_memory_", "torch.Tensor.short", "torch.Tensor.sigmoid", "torch.Tensor.sigmoid_", "torch.Tensor.sign", "torch.Tensor.sign_", "torch.Tensor.signbit", "torch.Tensor.sin", "torch.Tensor.sin_", "torch.Tensor.sinc", "torch.Tensor.sinc_", "torch.Tensor.sinh", "torch.Tensor.sinh_", "torch.Tensor.size", "torch.Tensor.slice_scatter", "torch.Tensor.slogdet", "torch.Tensor.smm", "torch.Tensor.softmax", "torch.Tensor.sort", "torch.Tensor.sparse_dim", "torch.Tensor.sparse_mask", "torch.Tensor.sparse_resize_", "torch.Tensor.sparse_resize_and_clear_", "torch.Tensor.split", "torch.Tensor.sqrt", "torch.Tensor.sqrt_", "torch.Tensor.square", "torch.Tensor.square_", "torch.Tensor.squeeze", "torch.Tensor.squeeze_", "torch.Tensor.sspaddmm", "torch.Tensor.std", "torch.Tensor.stft", "torch.Tensor.storage", "torch.Tensor.storage_offset", "torch.Tensor.storage_type", "torch.Tensor.stride", "torch.Tensor.sub", "torch.Tensor.sub_", "torch.Tensor.subtract", "torch.Tensor.subtract_", "torch.Tensor.sum", "torch.Tensor.sum_to_size", "torch.Tensor.svd", "torch.Tensor.swapaxes", "torch.Tensor.swapdims", "torch.Tensor.t", "torch.Tensor.t_", "torch.Tensor.take", "torch.Tensor.take_along_dim", "torch.Tensor.tan", "torch.Tensor.tan_", "torch.Tensor.tanh", "torch.Tensor.tanh_", "torch.Tensor.tensor_split", "torch.Tensor.tile", "torch.Tensor.to", "torch.Tensor.to_dense", "torch.Tensor.to_mkldnn", "torch.Tensor.to_sparse", "torch.Tensor.to_sparse_bsc", "torch.Tensor.to_sparse_bsr", "torch.Tensor.to_sparse_coo", "torch.Tensor.to_sparse_csc", "torch.Tensor.to_sparse_csr", "torch.Tensor.tolist", "torch.Tensor.topk", "torch.Tensor.trace", "torch.Tensor.transpose", "torch.Tensor.transpose_", "torch.Tensor.triangular_solve", "torch.Tensor.tril", "torch.Tensor.tril_", "torch.Tensor.triu", "torch.Tensor.triu_", "torch.Tensor.true_divide", "torch.Tensor.true_divide_", "torch.Tensor.trunc", "torch.Tensor.trunc_", "torch.Tensor.type", "torch.Tensor.type_as", "torch.Tensor.unbind", "torch.Tensor.unflatten", "torch.Tensor.unfold", "torch.Tensor.uniform_", "torch.Tensor.unique", "torch.Tensor.unique_consecutive", "torch.Tensor.unsqueeze", "torch.Tensor.unsqueeze_", "torch.Tensor.untyped_storage", "torch.Tensor.values", "torch.Tensor.var", "torch.Tensor.vdot", "torch.Tensor.view", "torch.Tensor.view_as", "torch.Tensor.vsplit", "torch.Tensor.where", "torch.Tensor.xlogy", "torch.Tensor.xlogy_", "torch.Tensor.zero_", "torch._assert", "torch._foreach_abs", "torch._foreach_abs_", "torch._foreach_acos", "torch._foreach_acos_", "torch._foreach_asin", "torch._foreach_asin_", "torch._foreach_atan", "torch._foreach_atan_", "torch._foreach_ceil", "torch._foreach_ceil_", "torch._foreach_cos", "torch._foreach_cos_", "torch._foreach_cosh", "torch._foreach_cosh_", "torch._foreach_erf", "torch._foreach_erf_", "torch._foreach_erfc", "torch._foreach_erfc_", "torch._foreach_exp", "torch._foreach_exp_", "torch._foreach_expm1", "torch._foreach_expm1_", "torch._foreach_floor", "torch._foreach_floor_", "torch._foreach_frac", "torch._foreach_frac_", "torch._foreach_lgamma", "torch._foreach_lgamma_", "torch._foreach_log", "torch._foreach_log10", "torch._foreach_log10_", "torch._foreach_log1p", "torch._foreach_log1p_", "torch._foreach_log2", "torch._foreach_log2_", "torch._foreach_log_", "torch._foreach_neg", "torch._foreach_neg_", "torch._foreach_reciprocal", "torch._foreach_reciprocal_", "torch._foreach_round", "torch._foreach_round_", "torch._foreach_sigmoid", "torch._foreach_sigmoid_", "torch._foreach_sin", "torch._foreach_sin_", "torch._foreach_sinh", "torch._foreach_sinh_", "torch._foreach_sqrt", "torch._foreach_sqrt_", "torch._foreach_tan", "torch._foreach_tan_", "torch._foreach_trunc", "torch._foreach_trunc_", "torch._foreach_zero_", "torch._logging.set_logs", "torch.abs", "torch.absolute", "torch.acos", "torch.acosh", "torch.add", "torch.addbmm", "torch.addcdiv", "torch.addcmul", "torch.addmm", "torch.addmv", "torch.addr", "torch.adjoint", "torch.all", "torch.allclose", "torch.amax", "torch.amin", "torch.aminmax", "torch.angle", "torch.any", "BNReLU2d", "BNReLU3d", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "ConvBn1d", "ConvBn2d", "ConvBn3d", "ConvBnReLU1d", "ConvBnReLU2d", "ConvBnReLU3d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "freeze_bn_stats", "update_bn_stats", "BNReLU2d", "BNReLU3d", "ConvReLU1d", "ConvReLU2d", "ConvReLU3d", "LinearReLU", "LinearReLU", "Conv2d", "Conv3d", "Linear", "Linear", "LSTM", "MultiheadAttention", "BatchNorm2d", "BatchNorm3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "ELU", "Embedding", "EmbeddingBag", "FXFloatFunctional", "FloatFunctional", "GroupNorm", "Hardswish", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "LayerNorm", "LeakyReLU", "Linear", "QFunctional", "ReLU6", "Sigmoid", "GRU", "GRUCell", "LSTM", "LSTMCell", "Linear", "RNNCell", "adaptive_avg_pool2d", "adaptive_avg_pool3d", "avg_pool2d", "avg_pool3d", "celu", "clamp", "conv1d", "conv2d", "conv3d", "elu", "hardsigmoid", "hardswish", "hardtanh", "interpolate", "leaky_relu", "linear", "max_pool1d", "max_pool2d", "threshold", "upsample", "upsample_bilinear", "upsample_nearest", "DeQuantStub", "QuantStub", "QuantWrapper", "add_quant_dequant", "BackendConfig", "BackendPatternConfig", "DTypeConfig", "DTypeWithConstraints", "ObservationType", "convert", "default_eval_fn", "FakeQuantize", "FakeQuantizeBase", "FixedQParamsFakeQuantize", "FusedMovingAvgObsFakeQuantize", "default_fake_quant", "default_fused_act_fake_quant", "default_fused_per_channel_wt_fake_quant", "default_fused_wt_fake_quant", "default_histogram_fake_quant", "default_per_channel_weight_fake_quant", "default_weight_fake_quant", "disable_fake_quant", "disable_observer", "enable_fake_quant", "enable_observer", "fuse_modules", "ConvertCustomConfig", "FuseCustomConfig", "PrepareCustomConfig", "StandaloneModuleConfigEntry", "HistogramObserver", "MinMaxObserver", "MovingAverageMinMaxObserver", "MovingAveragePerChannelMinMaxObserver", "NoopObserver", "ObserverBase", "PerChannelMinMaxObserver", "PlaceholderObserver", "RecordingObserver", "default_debug_observer", "default_dynamic_quant_observer", "default_float_qparams_observer", "default_histogram_observer", "default_observer", "default_per_channel_weight_observer", "default_placeholder_observer", "default_weight_observer", "get_observer_state_dict", "load_observer_state_dict", "prepare", "prepare_qat", "propagate_qconfig", "QConfig", "default_activation_only_qconfig", "default_debug_qconfig", "default_dynamic_qconfig", "default_per_channel_qconfig", "default_qat_qconfig", "default_qat_qconfig_v2", "default_qconfig", "default_weight_only_qconfig", "float16_dynamic_qconfig", "float16_static_qconfig", "float_qparams_weight_only_qconfig", "per_channel_dynamic_qconfig", "QConfigMapping", "get_default_qat_qconfig_mapping", "get_default_qconfig_mapping", "quantize", "quantize_dynamic", "convert_fx", "fuse_fx", "prepare_fx", "prepare_qat_fx", "quantize_qat", "swap_module", "torch.arange", "torch.arccos", "torch.arccosh", "torch.arcsin", "torch.arcsinh", "torch.arctan", "torch.arctan2", "torch.arctanh", "torch.are_deterministic_algorithms_enabled", "torch.argmax", "torch.argmin", "torch.argsort", "torch.argwhere", "torch.as_strided", "torch.as_tensor", "torch.asarray", "torch.asin", "torch.asinh", "torch.atan", "torch.atan2", "torch.atanh", "torch.atleast_1d", "torch.atleast_2d", "torch.atleast_3d", "torch.autograd.Function.backward", "torch.autograd.Function.forward", "torch.autograd.Function.jvp", "torch.autograd.Function.vmap", "torch.autograd.backward", "dual_level", "torch.autograd.forward_ad.make_dual", "torch.autograd.forward_ad.unpack_dual", "torch.autograd.function.FunctionCtx.mark_dirty", "torch.autograd.function.FunctionCtx.mark_non_differentiable", "torch.autograd.function.FunctionCtx.save_for_backward", "torch.autograd.function.FunctionCtx.set_materialize_grads", "torch.autograd.functional.hessian", "torch.autograd.functional.hvp", "torch.autograd.functional.jacobian", "torch.autograd.functional.jvp", "torch.autograd.functional.vhp", "torch.autograd.functional.vjp", "torch.autograd.grad", "torch.autograd.gradcheck", "torch.autograd.gradgradcheck", "torch.autograd.graph.Node.metadata", "torch.autograd.graph.Node.name", "torch.autograd.graph.Node.next_functions", "torch.autograd.graph.Node.register_hook", "torch.autograd.graph.Node.register_prehook", "torch.autograd.profiler.load_nvprof", "torch.autograd.profiler.profile.export_chrome_trace", "torch.autograd.profiler.profile.key_averages", "torch.autograd.profiler.profile.self_cpu_time_total", "torch.autograd.profiler.profile.total_average", "set_multithreading_enabled", "torch.baddbmm", "torch.bartlett_window", "torch.bernoulli", "torch.bincount", "torch.bitwise_and", "torch.bitwise_left_shift", "torch.bitwise_not", "torch.bitwise_or", "torch.bitwise_right_shift", "torch.bitwise_xor", "torch.blackman_window", "torch.block_diag", "torch.bmm", "torch.broadcast_shapes", "torch.broadcast_tensors", "torch.broadcast_to", "torch.bucketize", "torch.can_cast", "torch.cartesian_prod", "torch.cat", "torch.cdist", "torch.ceil", "torch.chain_matmul", "torch.cholesky", "torch.cholesky_inverse", "torch.cholesky_solve", "torch.chunk", "torch.clamp", "torch.clip", "torch.clone", "torch.column_stack", "torch.combinations", "torch.compile", "torch.compiled_with_cxx11_abi", "torch.complex", "torch.concat", "torch.concatenate", "torch.conj", "torch.conj_physical", "torch.copysign", "torch.corrcoef", "torch.cos", "torch.cosh", "torch.count_nonzero", "torch.cov", "torch.cross", "CUDAGraph", "CUDAPluggableAllocator", "Event", "ExternalStream", "torch.cuda.OutOfMemoryError", "Stream", "StreamContext", "torch.cuda.caching_allocator_alloc", "torch.cuda.caching_allocator_delete", "torch.cuda.can_device_access_peer", "torch.cuda.change_current_allocator", "torch.cuda.clock_rate", "torch.cuda.comm.broadcast", "torch.cuda.comm.broadcast_coalesced", "torch.cuda.comm.gather", "torch.cuda.comm.reduce_add", "torch.cuda.comm.scatter", "torch.cuda.current_blas_handle", "torch.cuda.current_device", "torch.cuda.current_stream", "torch.cuda.default_stream", "device", "torch.cuda.device_count", "device_of", "torch.cuda.empty_cache", "torch.cuda.get_allocator_backend", "torch.cuda.get_arch_list", "torch.cuda.get_device_capability", "torch.cuda.get_device_name", "torch.cuda.get_device_properties", "torch.cuda.get_gencode_flags", "torch.cuda.get_rng_state", "torch.cuda.get_rng_state_all", "torch.cuda.get_sync_debug_mode", "graph", "torch.cuda.graph_pool_handle", "torch.cuda.init", "torch.cuda.initial_seed", "torch.cuda.ipc_collect", "torch.cuda.is_available", "torch.cuda.is_current_stream_capturing", "torch.cuda.is_initialized", "torch.cuda.jiterator._create_jit_fn", "torch.cuda.jiterator._create_multi_output_jit_fn", "torch.cuda.list_gpu_processes", "torch.cuda.make_graphed_callables", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "torch.cuda.max_memory_allocated", "torch.cuda.max_memory_cached", "torch.cuda.max_memory_reserved", "torch.cuda.mem_get_info", "torch.cuda.memory_allocated", "torch.cuda.memory_cached", "torch.cuda.memory_reserved", "torch.cuda.memory_snapshot", "torch.cuda.memory_stats", "torch.cuda.memory_summary", "torch.cuda.memory_usage", "torch.cuda.nvtx.mark", "torch.cuda.nvtx.range_pop", "torch.cuda.nvtx.range_push", "torch.cuda.power_draw", "torch.cuda.reset_max_memory_allocated", "torch.cuda.reset_max_memory_cached", "torch.cuda.reset_peak_memory_stats", "torch.cuda.seed", "torch.cuda.seed_all", "torch.cuda.set_device", "torch.cuda.set_per_process_memory_fraction", "torch.cuda.set_rng_state", "torch.cuda.set_rng_state_all", "torch.cuda.set_stream", "torch.cuda.set_sync_debug_mode", "torch.cuda.stream", "torch.cuda.synchronize", "torch.cuda.temperature", "torch.cuda.utilization", "torch.cummax", "torch.cummin", "torch.cumprod", "torch.cumsum", "torch.cumulative_trapezoid", "torch.deg2rad", "torch.dequantize", "torch.det", "torch.diag", "torch.diag_embed", "torch.diagflat", "torch.diagonal", "torch.diagonal_scatter", "torch.diff", "torch.digamma", "torch.dist", "torch.div", "torch.divide", "torch.dot", "torch.dsplit", "torch.dstack", "torch.einsum", "torch.empty", "torch.empty_like", "torch.empty_strided", "enable_grad", "torch.eq", "torch.equal", "torch.erf", "torch.erfc", "torch.erfinv", "torch.exp", "torch.exp2", "torch.expm1", "torch.eye", "torch.fake_quantize_per_channel_affine", "torch.fake_quantize_per_tensor_affine", "torch.fft.fft", "torch.fft.fft2", "torch.fft.fftfreq", "torch.fft.fftn", "torch.fft.fftshift", "torch.fft.hfft", "torch.fft.hfft2", "torch.fft.hfftn", "torch.fft.ifft", "torch.fft.ifft2", "torch.fft.ifftn", "torch.fft.ifftshift", "torch.fft.ihfft", "torch.fft.ihfft2", "torch.fft.ihfftn", "torch.fft.irfft", "torch.fft.irfft2", "torch.fft.irfftn", "torch.fft.rfft", "torch.fft.rfft2", "torch.fft.rfftfreq", "torch.fft.rfftn", "torch.fix", "torch.flatten", "torch.flip", "torch.fliplr", "torch.flipud", "torch.float_power", "torch.floor", "torch.floor_divide", "torch.fmax", "torch.fmin", "torch.fmod", "torch.frac", "torch.frexp", "torch.from_dlpack", "torch.from_numpy", "torch.frombuffer", "torch.full", "torch.full_like", "torch.func.functional_call", "torch.func.functionalize", "torch.func.grad", "torch.func.grad_and_value", "torch.func.hessian", "torch.func.jacfwd", "torch.func.jacrev", "torch.func.jvp", "torch.func.linearize", "torch.func.replace_all_batch_norm_modules_", "torch.func.stack_module_state", "torch.func.vjp", "torch.func.vmap", "torch.gather", "torch.gcd", "torch.ge", "torch.geqrf", "torch.ger", "torch.get_default_dtype", "torch.get_deterministic_debug_mode", "torch.get_float32_matmul_precision", "torch.get_num_interop_threads", "torch.get_num_threads", "torch.get_rng_state", "torch.gradient", "torch.greater", "torch.greater_equal", "torch.gt", "torch.hamming_window", "torch.hann_window", "torch.heaviside", "torch.histc", "torch.histogram", "torch.histogramdd", "torch.hsplit", "torch.hspmm", "torch.hstack", "torch.hypot", "torch.i0", "torch.igamma", "torch.igammac", "torch.imag", "torch.index_add", "torch.index_copy", "torch.index_reduce", "torch.index_select", "inference_mode", "torch.initial_seed", "torch.inner", "torch.inverse", "torch.is_complex", "torch.is_conj", "torch.is_deterministic_algorithms_warn_only_enabled", "torch.is_floating_point", "torch.is_grad_enabled", "torch.is_inference_mode_enabled", "torch.is_nonzero", "torch.is_storage", "torch.is_tensor", "torch.is_warn_always_enabled", "torch.isclose", "torch.isfinite", "torch.isin", "torch.isinf", "torch.isnan", "torch.isneginf", "torch.isposinf", "torch.isreal", "torch.istft", "Attribute", "ScriptFunction", "ScriptModule", "torch.jit.annotate", "torch.jit.enable_onednn_fusion", "torch.jit.fork", "torch.jit.freeze", "torch.jit.ignore", "torch.jit.isinstance", "torch.jit.load", "torch.jit.onednn_fusion_enabled", "torch.jit.optimize_for_inference", "torch.jit.save", "torch.jit.script", "torch.jit.script_if_tracing", "torch.jit.set_fusion_strategy", "strict_fusion", "torch.jit.trace", "torch.jit.trace_module", "torch.jit.unused", "torch.jit.wait", "torch.kaiser_window", "torch.kron", "torch.kthvalue", "torch.lcm", "torch.ldexp", "torch.le", "torch.lerp", "torch.less", "torch.less_equal", "torch.lgamma", "torch.linalg.cholesky", "torch.linalg.cholesky_ex", "torch.linalg.cond", "torch.linalg.cross", "torch.linalg.det", "torch.linalg.diagonal", "torch.linalg.eig", "torch.linalg.eigh", "torch.linalg.eigvals", "torch.linalg.eigvalsh", "torch.linalg.householder_product", "torch.linalg.inv", "torch.linalg.inv_ex", "torch.linalg.ldl_factor", "torch.linalg.ldl_factor_ex", "torch.linalg.ldl_solve", "torch.linalg.lstsq", "torch.linalg.lu", "torch.linalg.lu_factor", "torch.linalg.lu_factor_ex", "torch.linalg.lu_solve", "torch.linalg.matmul", "torch.linalg.matrix_exp", "torch.linalg.matrix_norm", "torch.linalg.matrix_power", "torch.linalg.matrix_rank", "torch.linalg.multi_dot", "torch.linalg.norm", "torch.linalg.pinv", "torch.linalg.qr", "torch.linalg.slogdet", "torch.linalg.solve", "torch.linalg.solve_ex", "torch.linalg.solve_triangular", "torch.linalg.svd", "torch.linalg.svdvals", "torch.linalg.tensorinv", "torch.linalg.tensorsolve", "torch.linalg.vander", "torch.linalg.vecdot", "torch.linalg.vector_norm", "torch.linspace", "torch.load", "torch.lobpcg", "torch.log", "torch.log10", "torch.log1p", "torch.log2", "torch.logaddexp", "torch.logaddexp2", "torch.logcumsumexp", "torch.logdet", "torch.logical_and", "torch.logical_not", "torch.logical_or", "torch.logical_xor", "torch.logit", "torch.logspace", "torch.logsumexp", "torch.lt", "torch.lu", "torch.lu_solve", "torch.lu_unpack", "torch.manual_seed", "torch.masked_select", "torch.matmul", "torch.matrix_exp", "torch.matrix_power", "torch.max", "torch.maximum", "torch.mean", "torch.median", "torch.meshgrid", "torch.min", "torch.minimum", "torch.mm", "torch.mode", "torch.moveaxis", "torch.movedim", "torch.mps.current_allocated_memory", "torch.mps.driver_allocated_memory", "torch.mps.empty_cache", "torch.mps.get_rng_state", "torch.mps.manual_seed", "torch.mps.profiler.profile", "torch.mps.profiler.start", "torch.mps.profiler.stop", "torch.mps.seed", "torch.mps.set_per_process_memory_fraction", "torch.mps.set_rng_state", "torch.mps.synchronize", "torch.msort", "torch.mul", "torch.multinomial", "torch.multiply", "torch.mv", "torch.mvlgamma", "torch.nan_to_num", "torch.nanmean", "torch.nanmedian", "torch.nanquantile", "torch.nansum", "torch.narrow", "torch.narrow_copy", "torch.ne", "torch.neg", "torch.negative", "torch.nextafter", "AdaptiveAvgPool1d", "AdaptiveAvgPool2d", "AdaptiveAvgPool3d", "AdaptiveLogSoftmaxWithLoss", "AdaptiveMaxPool1d", "AdaptiveMaxPool2d", "AdaptiveMaxPool3d", "AlphaDropout", "AvgPool1d", "AvgPool2d", "AvgPool3d", "BCELoss", "BCEWithLogitsLoss", "BatchNorm1d", "BatchNorm2d", "BatchNorm3d", "Bilinear", "CELU", "CTCLoss", "ChannelShuffle", "ConstantPad1d", "ConstantPad2d", "ConstantPad3d", "Conv1d", "Conv2d", "Conv3d", "ConvTranspose1d", "ConvTranspose2d", "ConvTranspose3d", "CosineEmbeddingLoss", "CosineSimilarity", "CrossEntropyLoss", "DataParallel", "Dropout", "Dropout1d", "Dropout2d", "Dropout3d", "ELU", "Embedding", "EmbeddingBag", "FeatureAlphaDropout", "Flatten", "Fold", "FractionalMaxPool2d", "FractionalMaxPool3d", "GELU", "GLU", "GRU", "GRUCell", "GaussianNLLLoss", "GroupNorm", "Hardshrink", "Hardsigmoid", "Hardswish", "Hardtanh", "HingeEmbeddingLoss", "HuberLoss", "Identity", "InstanceNorm1d", "InstanceNorm2d", "InstanceNorm3d", "KLDivLoss", "L1Loss", "LPPool1d", "LPPool2d", "LSTM", "LSTMCell", "LayerNorm", "LazyBatchNorm1d", "LazyBatchNorm2d", "LazyBatchNorm3d", "LazyConv1d", "LazyConv2d", "LazyConv3d", "LazyConvTranspose1d", "LazyConvTranspose2d", "LazyConvTranspose3d", "LazyInstanceNorm1d", "LazyInstanceNorm2d", "LazyInstanceNorm3d", "LazyLinear", "LeakyReLU", "Linear", "LocalResponseNorm", "LogSigmoid", "LogSoftmax", "MSELoss", "MarginRankingLoss", "MaxPool1d", "MaxPool2d", "MaxPool3d", "MaxUnpool1d", "MaxUnpool2d", "MaxUnpool3d", "Mish", "Module", "ModuleDict", "ModuleList", "MultiLabelMarginLoss", "MultiLabelSoftMarginLoss", "MultiMarginLoss", "MultiheadAttention", "NLLLoss", "PReLU", "PairwiseDistance", "ParameterDict", "ParameterList", "PixelShuffle", "PixelUnshuffle", "PoissonNLLLoss", "RNN", "RNNBase", "RNNCell", "RReLU", "ReLU", "ReLU6", "ReflectionPad1d", "ReflectionPad2d", "ReflectionPad3d", "ReplicationPad1d", "ReplicationPad2d", "ReplicationPad3d", "SELU", "Sequential", "SiLU", "Sigmoid", "SmoothL1Loss", "SoftMarginLoss", "Softmax", "Softmax2d", "Softmin", "Softplus", "Softshrink", "Softsign", "SyncBatchNorm", "Tanh", "Tanhshrink", "Threshold", "Transformer", "TransformerDecoder", "TransformerDecoderLayer", "TransformerEncoder", "TransformerEncoderLayer", "TripletMarginLoss", "TripletMarginWithDistanceLoss", "Unflatten", "Unfold", "Upsample", "UpsamplingBilinear2d", "UpsamplingNearest2d", "ZeroPad1d", "ZeroPad2d", "ZeroPad3d", "torch.nn.functional.adaptive_avg_pool1d", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool3d", "torch.nn.functional.adaptive_max_pool1d", "torch.nn.functional.adaptive_max_pool2d", "torch.nn.functional.adaptive_max_pool3d", "torch.nn.functional.affine_grid", "torch.nn.functional.alpha_dropout", "torch.nn.functional.avg_pool1d", "torch.nn.functional.avg_pool2d", "torch.nn.functional.avg_pool3d", "torch.nn.functional.batch_norm", "torch.nn.functional.bilinear", "torch.nn.functional.binary_cross_entropy", "torch.nn.functional.binary_cross_entropy_with_logits", "torch.nn.functional.celu", "torch.nn.functional.conv1d", "torch.nn.functional.conv2d", "torch.nn.functional.conv3d", "torch.nn.functional.conv_transpose1d", "torch.nn.functional.conv_transpose2d", "torch.nn.functional.conv_transpose3d", "torch.nn.functional.cosine_embedding_loss", "torch.nn.functional.cosine_similarity", "torch.nn.functional.cross_entropy", "torch.nn.functional.ctc_loss", "torch.nn.functional.dropout", "torch.nn.functional.dropout1d", "torch.nn.functional.dropout2d", "torch.nn.functional.dropout3d", "torch.nn.functional.elu", "torch.nn.functional.elu_", "torch.nn.functional.embedding", "torch.nn.functional.embedding_bag", "torch.nn.functional.feature_alpha_dropout", "torch.nn.functional.fold", "torch.nn.functional.fractional_max_pool2d", "torch.nn.functional.fractional_max_pool3d", "torch.nn.functional.gaussian_nll_loss", "torch.nn.functional.gelu", "torch.nn.functional.glu", "torch.nn.functional.grid_sample", "torch.nn.functional.group_norm", "torch.nn.functional.gumbel_softmax", "torch.nn.functional.hardshrink", "torch.nn.functional.hardsigmoid", "torch.nn.functional.hardswish", "torch.nn.functional.hardtanh", "torch.nn.functional.hardtanh_", "torch.nn.functional.hinge_embedding_loss", "torch.nn.functional.huber_loss", "torch.nn.functional.instance_norm", "torch.nn.functional.interpolate", "torch.nn.functional.kl_div", "torch.nn.functional.l1_loss", "torch.nn.functional.layer_norm", "torch.nn.functional.leaky_relu", "torch.nn.functional.leaky_relu_", "torch.nn.functional.linear", "torch.nn.functional.local_response_norm", "torch.nn.functional.log_softmax", "torch.nn.functional.logsigmoid", "torch.nn.functional.lp_pool1d", "torch.nn.functional.lp_pool2d", "torch.nn.functional.margin_ranking_loss", "torch.nn.functional.max_pool1d", "torch.nn.functional.max_pool2d", "torch.nn.functional.max_pool3d", "torch.nn.functional.max_unpool1d", "torch.nn.functional.max_unpool2d", "torch.nn.functional.max_unpool3d", "torch.nn.functional.mish", "torch.nn.functional.mse_loss", "torch.nn.functional.multi_margin_loss", "torch.nn.functional.multilabel_margin_loss", "torch.nn.functional.multilabel_soft_margin_loss", "torch.nn.functional.nll_loss", "torch.nn.functional.normalize", "torch.nn.functional.one_hot", "torch.nn.functional.pad", "torch.nn.functional.pairwise_distance", "torch.nn.functional.pdist", "torch.nn.functional.pixel_shuffle", "torch.nn.functional.pixel_unshuffle", "torch.nn.functional.poisson_nll_loss", "torch.nn.functional.prelu", "torch.nn.functional.relu", "torch.nn.functional.relu6", "torch.nn.functional.relu_", "torch.nn.functional.rrelu", "torch.nn.functional.rrelu_", "torch.nn.functional.scaled_dot_product_attention", "torch.nn.functional.selu", "torch.nn.functional.sigmoid", "torch.nn.functional.silu", "torch.nn.functional.smooth_l1_loss", "torch.nn.functional.soft_margin_loss", "torch.nn.functional.softmax", "torch.nn.functional.softmin", "torch.nn.functional.softplus", "torch.nn.functional.softshrink", "torch.nn.functional.softsign", "torch.nn.functional.tanh", "torch.nn.functional.tanhshrink", "torch.nn.functional.threshold", "torch.nn.functional.threshold_", "torch.nn.functional.torch.nn.parallel.data_parallel", "torch.nn.functional.triplet_margin_loss", "torch.nn.functional.triplet_margin_with_distance_loss", "torch.nn.functional.unfold", "torch.nn.functional.upsample", "torch.nn.functional.upsample_bilinear", "torch.nn.functional.upsample_nearest", "LazyModuleMixin", "torch.nn.modules.module.register_module_backward_hook", "torch.nn.modules.module.register_module_buffer_registration_hook", "torch.nn.modules.module.register_module_forward_hook", "torch.nn.modules.module.register_module_forward_pre_hook", "torch.nn.modules.module.register_module_full_backward_hook", "torch.nn.modules.module.register_module_full_backward_pre_hook", "torch.nn.modules.module.register_module_module_registration_hook", "torch.nn.modules.module.register_module_parameter_registration_hook", "DistributedDataParallel", "Parameter", "UninitializedBuffer", "UninitializedParameter", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_value_", "torch.nn.utils.parameters_to_vector", "torch.nn.utils.parametrizations.orthogonal", "torch.nn.utils.parametrizations.spectral_norm", "ParametrizationList", "torch.nn.utils.parametrize.cached", "torch.nn.utils.parametrize.is_parametrized", "torch.nn.utils.parametrize.register_parametrization", "torch.nn.utils.parametrize.remove_parametrizations", "BasePruningMethod", "CustomFromMask", "Identity", "L1Unstructured", "LnStructured", "PruningContainer", "RandomStructured", "RandomUnstructured", "torch.nn.utils.prune.custom_from_mask", "torch.nn.utils.prune.global_unstructured", "torch.nn.utils.prune.identity", "torch.nn.utils.prune.is_pruned", "torch.nn.utils.prune.l1_unstructured", "torch.nn.utils.prune.ln_structured", "torch.nn.utils.prune.random_structured", "torch.nn.utils.prune.random_unstructured", "torch.nn.utils.prune.remove", "torch.nn.utils.remove_spectral_norm", "torch.nn.utils.remove_weight_norm", "PackedSequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.unpack_sequence", "torch.nn.utils.rnn.unpad_sequence", "torch.nn.utils.skip_init", "torch.nn.utils.spectral_norm", "torch.nn.utils.stateless.functional_call", "torch.nn.utils.vector_to_parameters", "torch.nn.utils.weight_norm", "no_grad", "torch.nonzero", "torch.norm", "torch.normal", "torch.not_equal", "torch.numel", "torch.ones", "torch.ones_like", "ExportOptions", "ExportOutput", "ExportOutputSerializer", "JitScalarType", "GraphInfo", "VerificationOptions", "ASGD", "Adadelta", "Adagrad", "Adam", "AdamW", "Adamax", "LBFGS", "NAdam", "torch.optim.Optimizer.add_param_group", "torch.optim.Optimizer.load_state_dict", "torch.optim.Optimizer.state_dict", "torch.optim.Optimizer.step", "torch.optim.Optimizer.zero_grad", "RAdam", "RMSprop", "Rprop", "SGD", "SparseAdam", "ChainedScheduler", "ConstantLR", "CosineAnnealingLR", "CosineAnnealingWarmRestarts", "CyclicLR", "ExponentialLR", "LambdaLR", "LinearLR", "MultiStepLR", "MultiplicativeLR", "OneCycleLR", "PolynomialLR", "ReduceLROnPlateau", "SequentialLR", "StepLR", "torch.orgqr", "torch.ormqr", "torch.outer", "torch.pca_lowrank", "torch.permute", "torch.pinverse", "torch.poisson", "torch.polar", "torch.polygamma", "torch.positive", "torch.pow", "torch.prod", "torch.promote_types", "torch.qr", "torch.quantile", "torch.quantize_per_channel", "torch.quantize_per_tensor", "torch.quantized_batch_norm", "torch.quantized_max_pool1d", "torch.quantized_max_pool2d", "SobolEngine", "torch.rad2deg", "torch.rand", "torch.rand_like", "torch.randint", "torch.randint_like", "torch.randn", "torch.randn_like", "torch.randperm", "torch.range", "torch.ravel", "torch.real", "torch.reciprocal", "torch.remainder", "torch.renorm", "torch.repeat_interleave", "torch.reshape", "torch.resolve_conj", "torch.resolve_neg", "torch.result_type", "torch.roll", "torch.rot90", "torch.round", "torch.row_stack", "torch.rsqrt", "torch.save", "torch.scatter", "torch.scatter_add", "torch.scatter_reduce", "torch.searchsorted", "torch.seed", "torch.select", "torch.select_scatter", "torch.set_default_device", "torch.set_default_dtype", "torch.set_default_tensor_type", "torch.set_deterministic_debug_mode", "torch.set_float32_matmul_precision", "torch.set_flush_denormal", "set_grad_enabled", "torch.set_num_interop_threads", "torch.set_num_threads", "torch.set_printoptions", "torch.set_rng_state", "torch.set_warn_always", "torch.sgn", "torch.sigmoid", "torch.sign", "torch.signal.windows.bartlett", "torch.signal.windows.blackman", "torch.signal.windows.cosine", "torch.signal.windows.exponential", "torch.signal.windows.gaussian", "torch.signal.windows.general_cosine", "torch.signal.windows.general_hamming", "torch.signal.windows.hamming", "torch.signal.windows.hann", "torch.signal.windows.kaiser", "torch.signal.windows.nuttall", "torch.signbit", "torch.sin", "torch.sinc", "torch.sinh", "torch.slice_scatter", "torch.slogdet", "torch.smm", "torch.softmax", "torch.sort", "torch.sparse.addmm", "check_sparse_tensor_invariants", "torch.sparse.log_softmax", "torch.sparse.mm", "torch.sparse.sampled_addmm", "torch.sparse.softmax", "torch.sparse.spdiags", "torch.sparse.sum", "torch.sparse_bsc_tensor", "torch.sparse_bsr_tensor", "torch.sparse_compressed_tensor", "torch.sparse_coo_tensor", "torch.sparse_csc_tensor", "torch.sparse_csr_tensor", "torch.split", "torch.sqrt", "torch.square", "torch.squeeze", "torch.sspaddmm", "torch.stack", "torch.std", "torch.std_mean", "torch.stft", "torch.sub", "torch.subtract", "torch.sum", "torch.svd", "torch.svd_lowrank", "torch.swapaxes", "torch.swapdims", "torch.sym_float", "torch.sym_int", "torch.sym_max", "torch.sym_min", "torch.sym_not", "torch.t", "torch.take", "torch.take_along_dim", "torch.tan", "torch.tanh", "torch.tensor", "torch.tensor_split", "torch.tensordot", "torch.tile", "torch.topk", "torch.trace", "torch.transpose", "torch.trapezoid", "torch.trapz", "torch.triangular_solve", "torch.tril", "torch.tril_indices", "torch.triu", "torch.triu_indices", "torch.true_divide", "torch.trunc", "torch.unbind", "torch.unflatten", "torch.unique", "torch.unique_consecutive", "torch.unsqueeze", "torch.use_deterministic_algorithms", "torch.vander", "torch.var", "torch.var_mean", "torch.vdot", "torch.view_as_complex", "torch.view_as_real", "torch.vmap", "torch.vsplit", "torch.vstack", "torch.where", "torch.xlogy", "torch.zeros", "torch.zeros_like", "torch.hub", "PyTorch documentation", "IRs", "TorchScript", "TorchScript Builtins", "TorchScript Language Reference", "TorchScript Language Reference", "Python Language Reference Coverage", "TorchScript Unsupported PyTorch Constructs", "JIT Utils - torch.utils.jit", "torch.library", "torch.linalg", "torch._logging", "torch.masked", "torch.utils.mobile_optimizer", "torch.utils.model_zoo", "torch.monitor", "torch.mps", "Multiprocessing package - torch.multiprocessing", "Named Tensors operator coverage", "Named Tensors", "torch.nested", "torch.nn", "torch.nn.functional", "torch.nn.init", "CUDA Automatic Mixed Precision examples", "Autograd mechanics", "Broadcasting semantics", "CPU threading and TorchScript inference", "CUDA semantics", "Distributed Data Parallel", "Extending PyTorch", "Extending torch.func with autograd.Function", "Frequently Asked Questions", "Gradcheck mechanics", "HIP (ROCm) semantics", "Features for large-scale deployments", "Modules", "MPS backend", "Multiprocessing best practices", "Numerical accuracy", "Reproducibility", "Serialization semantics", "Windows FAQ", "torch.onnx", "torch.onnx diagnostics", "ONNX supported TorchScript operators", "torch.optim", "torch.package", "Pipeline Parallelism", "torch.profiler", "Quantization", "Quantization Accuracy Debugging", "Quantization Backend Configuration", "Quantization API Reference", "torch.random", "Distributed RPC Framework", "Distributed Autograd Design", "Remote Reference Protocol", "torch.signal", "torch.sparse", "torch.special", "torch.Storage", "Tensor Attributes", "Tensor Views", "torch.utils.tensorboard", "torch.Tensor", "torch.testing", "torch", "torch.ao.ns._numeric_suite", "torch.ao.ns._numeric_suite_fx", "torch.overrides", "Type Info"], "terms": {"thi": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 70, 71, 83, 84, 85, 120, 151, 155, 196, 197, 207, 210, 222, 223, 224, 255, 260, 289, 290, 313, 321, 323, 335, 337, 340, 352, 444, 445, 446, 447, 448, 457, 485, 486, 491, 493, 494, 495, 496, 497, 498, 501, 502, 511, 513, 515, 521, 553, 563, 580, 581, 582, 584, 585, 586, 600, 601, 611, 614, 615, 677, 681, 683, 686, 690, 691, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 732, 733, 734, 741, 745, 746, 747, 748, 749, 750, 751, 752, 754, 756, 757, 772, 773, 774, 775, 776, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 796, 797, 799, 807, 808, 809, 810, 812, 813, 814, 816, 817, 818, 819, 820, 821, 822, 823, 851, 856, 858, 859, 871, 872, 873, 874, 875, 882, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 910, 911, 914, 917, 918, 921, 923, 926, 930, 931, 938, 940, 941, 944, 945, 947, 955, 956, 958, 963, 964, 965, 966, 967, 969, 970, 971, 974, 985, 987, 990, 991, 992, 994, 995, 998, 999, 1000, 1001, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1014, 1016, 1019, 1020, 1021, 1027, 1028, 1030, 1031, 1032, 1036, 1037, 1038, 1044, 1045, 1046, 1051, 1053, 1054, 1058, 1061, 1062, 1063, 1067, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1102, 1103, 1104, 1105, 1106, 1109, 1110, 1111, 1114, 1116, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1133, 1135, 1136, 1137, 1143, 1147, 1153, 1155, 1165, 1177, 1187, 1188, 1190, 1191, 1193, 1195, 1196, 1197, 1199, 1200, 1201, 1204, 1205, 1206, 1207, 1209, 1210, 1211, 1212, 1213, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1261, 1262, 1265, 1267, 1270, 1279, 1280, 1284, 1287, 1289, 1290, 1291, 1292, 1294, 1295, 1296, 1303, 1304, 1314, 1317, 1318, 1319, 1320, 1322, 1330, 1334, 1338, 1339, 1340, 1341, 1342, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1370, 1371, 1374, 1375, 1377, 1382, 1383, 1385, 1386, 1387, 1388, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1407, 1409, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1428, 1429, 1432, 1434, 1437, 1438, 1450, 1453, 1455, 1458, 1461, 1467, 1468, 1469, 1470, 1473, 1474, 1475, 1476, 1486, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1516, 1517, 1521, 1523, 1525, 1532, 1538, 1540, 1545, 1546, 1547, 1557, 1559, 1561, 1571, 1577, 1578, 1586, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1609, 1610, 1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1635, 1636, 1637, 1638, 1639, 1642, 1643, 1644, 1646, 1647, 1649, 1650, 1654, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1686, 1687, 1689, 1691, 1693, 1695, 1696, 1697, 1701, 1705, 1707, 1714, 1718, 1723, 1727, 1729, 1736, 1743, 1745, 1746, 1747, 1749, 1750, 1751, 1753, 1756, 1758, 1759, 1777, 1782, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1800, 1802, 1803, 1804, 1807, 1808, 1810, 1811, 1817, 1819, 1823, 1825, 1829, 1831, 1839, 1840, 1841, 1842, 1843, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1867, 1869, 1870, 1871, 1873, 1874, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929], "modul": [0, 1, 2, 4, 6, 7, 9, 13, 16, 17, 19, 22, 23, 27, 28, 29, 30, 32, 35, 39, 41, 43, 45, 46, 50, 52, 55, 58, 59, 63, 64, 66, 486, 677, 683, 686, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 735, 736, 737, 742, 743, 744, 753, 758, 759, 760, 761, 762, 785, 786, 787, 788, 789, 790, 794, 796, 797, 799, 807, 808, 809, 810, 811, 812, 813, 814, 816, 817, 818, 819, 820, 821, 822, 823, 824, 835, 836, 837, 851, 854, 855, 856, 857, 858, 859, 861, 910, 911, 918, 930, 950, 1009, 1119, 1128, 1129, 1131, 1165, 1188, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1199, 1200, 1201, 1205, 1206, 1207, 1261, 1284, 1294, 1330, 1334, 1340, 1341, 1342, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1375, 1377, 1385, 1386, 1387, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1423, 1424, 1432, 1433, 1438, 1450, 1455, 1461, 1465, 1512, 1513, 1586, 1593, 1602, 1603, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1638, 1642, 1643, 1644, 1646, 1678, 1739, 1783, 1850, 1857, 1858, 1864, 1869, 1871, 1873, 1875, 1877, 1878, 1881, 1885, 1886, 1887, 1890, 1893, 1895, 1896, 1898, 1900, 1901, 1904, 1906, 1907, 1910, 1911, 1913, 1916, 1917, 1918, 1922, 1925, 1926, 1927, 1928], "i": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 18, 19, 20, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 34, 35, 36, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 73, 74, 75, 83, 84, 85, 88, 89, 98, 151, 154, 155, 156, 171, 173, 176, 179, 180, 181, 191, 192, 196, 197, 207, 209, 210, 219, 224, 240, 254, 255, 267, 290, 297, 311, 313, 315, 319, 321, 323, 325, 328, 329, 330, 331, 332, 333, 335, 336, 338, 340, 341, 342, 343, 352, 393, 400, 402, 406, 447, 457, 470, 471, 480, 482, 485, 486, 491, 493, 494, 495, 496, 497, 498, 501, 502, 511, 513, 515, 518, 521, 522, 534, 540, 541, 542, 554, 557, 577, 578, 580, 581, 582, 584, 585, 586, 600, 601, 604, 611, 614, 615, 617, 621, 677, 678, 680, 681, 683, 684, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 720, 721, 722, 723, 724, 731, 732, 733, 734, 735, 736, 737, 738, 740, 741, 746, 747, 748, 749, 750, 751, 752, 753, 755, 756, 757, 758, 760, 761, 762, 765, 766, 769, 770, 771, 772, 773, 774, 775, 776, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 794, 796, 798, 799, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 816, 817, 818, 821, 823, 824, 830, 835, 836, 837, 854, 855, 856, 858, 859, 862, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 910, 911, 914, 917, 918, 919, 920, 921, 923, 926, 928, 930, 931, 934, 935, 936, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 968, 969, 970, 971, 972, 973, 975, 976, 978, 980, 983, 984, 985, 987, 991, 992, 995, 998, 999, 1000, 1002, 1003, 1004, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1050, 1051, 1052, 1053, 1054, 1055, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1073, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1102, 1103, 1104, 1105, 1106, 1107, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1132, 1134, 1135, 1136, 1137, 1143, 1146, 1147, 1148, 1149, 1151, 1152, 1153, 1154, 1155, 1156, 1160, 1164, 1165, 1167, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1191, 1193, 1194, 1195, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1205, 1206, 1207, 1209, 1210, 1211, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1269, 1270, 1272, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1310, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1450, 1451, 1453, 1454, 1455, 1457, 1458, 1461, 1462, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1486, 1489, 1490, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1516, 1517, 1518, 1519, 1520, 1521, 1523, 1532, 1533, 1538, 1540, 1542, 1543, 1545, 1546, 1547, 1556, 1557, 1559, 1561, 1562, 1563, 1564, 1565, 1571, 1574, 1577, 1578, 1586, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1635, 1636, 1637, 1638, 1639, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1650, 1654, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1696, 1697, 1700, 1701, 1703, 1704, 1705, 1706, 1707, 1708, 1714, 1716, 1717, 1718, 1720, 1721, 1723, 1724, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1734, 1735, 1736, 1738, 1739, 1743, 1745, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1754, 1755, 1756, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1774, 1776, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1799, 1800, 1802, 1803, 1804, 1807, 1808, 1809, 1810, 1811, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1839, 1840, 1841, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1867, 1869, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1904, 1906, 1907, 1908, 1909, 1910, 1911, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929], "an": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 23, 25, 26, 27, 28, 30, 32, 33, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 84, 89, 151, 155, 191, 222, 242, 254, 313, 315, 321, 323, 328, 335, 511, 513, 515, 534, 542, 557, 604, 611, 614, 677, 684, 685, 732, 738, 739, 740, 753, 757, 762, 776, 782, 784, 786, 789, 793, 812, 814, 820, 823, 851, 858, 859, 861, 875, 876, 877, 886, 888, 889, 890, 892, 894, 896, 898, 899, 900, 901, 902, 903, 904, 905, 906, 912, 913, 914, 921, 937, 947, 950, 955, 956, 958, 964, 966, 967, 969, 976, 977, 978, 979, 980, 998, 999, 1006, 1007, 1009, 1021, 1023, 1033, 1037, 1038, 1048, 1061, 1063, 1065, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1103, 1106, 1114, 1116, 1119, 1120, 1123, 1124, 1125, 1127, 1129, 1131, 1132, 1135, 1143, 1151, 1152, 1153, 1187, 1188, 1190, 1193, 1194, 1197, 1200, 1201, 1203, 1205, 1206, 1207, 1208, 1219, 1220, 1225, 1226, 1231, 1233, 1235, 1238, 1239, 1243, 1246, 1248, 1251, 1252, 1259, 1261, 1262, 1279, 1281, 1284, 1290, 1307, 1312, 1321, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1341, 1342, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1370, 1371, 1374, 1382, 1386, 1387, 1390, 1391, 1392, 1394, 1404, 1405, 1406, 1407, 1409, 1410, 1412, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1424, 1428, 1429, 1430, 1432, 1433, 1434, 1435, 1437, 1439, 1441, 1450, 1453, 1455, 1456, 1457, 1461, 1466, 1468, 1469, 1470, 1473, 1475, 1476, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1488, 1496, 1497, 1498, 1499, 1500, 1501, 1506, 1512, 1513, 1515, 1516, 1517, 1521, 1532, 1539, 1540, 1542, 1543, 1545, 1546, 1547, 1571, 1575, 1590, 1592, 1593, 1596, 1602, 1606, 1607, 1608, 1609, 1612, 1613, 1614, 1621, 1638, 1645, 1647, 1649, 1654, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1707, 1712, 1713, 1714, 1733, 1735, 1739, 1747, 1750, 1759, 1765, 1785, 1788, 1789, 1793, 1796, 1804, 1808, 1822, 1823, 1839, 1840, 1841, 1843, 1848, 1849, 1850, 1851, 1856, 1858, 1860, 1861, 1862, 1863, 1864, 1865, 1867, 1869, 1870, 1871, 1873, 1874, 1875, 1876, 1877, 1878, 1879, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1906, 1907, 1908, 1909, 1910, 1911, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929], "earli": [0, 16, 21, 35, 39, 49, 70, 1361, 1362, 1363, 1367, 1858, 1908, 1909, 1926, 1927], "prototyp": [0, 35, 41, 677, 898, 900, 904, 905, 906, 1199, 1858, 1869, 1870, 1873, 1877, 1878, 1894, 1899, 1911, 1913, 1920, 1926, 1927], "subject": [0, 3, 4, 15, 22, 25, 30, 35, 41, 45, 46, 63, 70, 71, 862, 1571, 1602, 1863, 1876, 1877, 1883, 1888, 1901, 1902, 1906, 1907, 1908, 1909, 1913, 1920, 1925, 1926, 1927], "chang": [0, 1, 2, 3, 4, 8, 12, 15, 16, 18, 20, 21, 22, 24, 25, 29, 30, 35, 39, 41, 43, 45, 46, 47, 49, 57, 63, 64, 67, 68, 70, 71, 140, 222, 254, 321, 457, 494, 497, 515, 518, 553, 614, 677, 816, 874, 905, 906, 955, 956, 963, 964, 965, 974, 985, 987, 998, 999, 1006, 1007, 1009, 1051, 1099, 1119, 1137, 1143, 1164, 1187, 1190, 1200, 1201, 1220, 1231, 1233, 1234, 1235, 1238, 1251, 1291, 1362, 1365, 1383, 1392, 1422, 1453, 1474, 1486, 1521, 1545, 1546, 1547, 1571, 1593, 1594, 1602, 1604, 1605, 1611, 1614, 1615, 1644, 1648, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1683, 1686, 1687, 1689, 1691, 1693, 1707, 1747, 1751, 1788, 1799, 1802, 1803, 1804, 1828, 1845, 1846, 1857, 1858, 1860, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1891, 1892, 1894, 1897, 1899, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1909, 1913, 1915, 1917, 1919, 1920, 1921, 1922, 1923, 1925, 1926, 1927], "allow_in_graph": [0, 18, 1858], "fn": [0, 2, 13, 18, 20, 21, 22, 28, 29, 49, 50, 51, 55, 60, 63, 71, 910, 911, 1121, 1127, 1131, 1190, 1191, 1202, 1207, 1422, 1850, 1860, 1862, 1863, 1867, 1875, 1883, 1893, 1913], "sourc": [0, 1, 2, 3, 4, 5, 6, 10, 17, 18, 19, 21, 29, 31, 32, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 58, 60, 63, 70, 71, 151, 197, 210, 312, 313, 321, 340, 351, 396, 401, 402, 415, 416, 452, 470, 486, 511, 513, 515, 518, 521, 544, 553, 554, 556, 583, 600, 603, 606, 607, 621, 677, 692, 693, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 833, 834, 835, 836, 837, 838, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 870, 883, 884, 885, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 910, 911, 912, 913, 914, 916, 917, 929, 931, 932, 936, 938, 940, 950, 951, 964, 965, 966, 967, 969, 970, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 985, 986, 987, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1063, 1067, 1114, 1116, 1132, 1138, 1139, 1142, 1161, 1162, 1163, 1165, 1166, 1171, 1176, 1177, 1178, 1188, 1190, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1204, 1205, 1206, 1207, 1208, 1261, 1262, 1282, 1291, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1481, 1482, 1486, 1487, 1491, 1493, 1494, 1495, 1502, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1512, 1513, 1514, 1515, 1518, 1520, 1521, 1522, 1523, 1525, 1526, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1539, 1540, 1542, 1543, 1544, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1564, 1566, 1567, 1569, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1581, 1582, 1583, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1649, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1697, 1714, 1739, 1744, 1747, 1748, 1749, 1750, 1751, 1753, 1756, 1757, 1758, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1783, 1789, 1796, 1804, 1809, 1812, 1813, 1814, 1815, 1816, 1824, 1843, 1857, 1860, 1861, 1862, 1867, 1869, 1870, 1871, 1872, 1873, 1875, 1877, 1878, 1881, 1890, 1892, 1893, 1897, 1901, 1902, 1904, 1906, 1907, 1908, 1912, 1913, 1914, 1919, 1922, 1924, 1925, 1926, 1927, 1928], "custom": [0, 1, 2, 4, 6, 16, 18, 19, 21, 26, 32, 33, 38, 41, 42, 43, 44, 45, 46, 51, 54, 55, 57, 63, 83, 84, 497, 790, 794, 811, 812, 813, 814, 835, 837, 856, 857, 858, 859, 896, 950, 965, 974, 1038, 1190, 1422, 1465, 1470, 1471, 1616, 1625, 1642, 1683, 1858, 1864, 1867, 1869, 1875, 1876, 1883, 1893, 1898, 1899, 1900, 1902, 1911, 1912, 1926], "which": [0, 1, 2, 3, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 35, 38, 39, 42, 43, 45, 46, 47, 48, 49, 51, 56, 57, 58, 59, 60, 63, 67, 68, 70, 71, 89, 151, 289, 313, 315, 317, 319, 321, 335, 471, 485, 486, 497, 511, 513, 515, 534, 557, 601, 604, 614, 621, 681, 694, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 757, 761, 778, 787, 788, 794, 796, 816, 820, 823, 835, 851, 854, 855, 856, 858, 873, 877, 882, 889, 890, 891, 892, 898, 899, 900, 901, 902, 903, 904, 910, 911, 914, 921, 934, 937, 940, 944, 950, 960, 961, 962, 963, 964, 969, 976, 977, 978, 979, 980, 991, 992, 993, 1020, 1022, 1027, 1028, 1039, 1041, 1046, 1050, 1051, 1052, 1053, 1054, 1063, 1079, 1084, 1087, 1091, 1094, 1097, 1102, 1103, 1104, 1105, 1106, 1111, 1114, 1119, 1120, 1123, 1124, 1125, 1126, 1127, 1131, 1132, 1135, 1152, 1164, 1175, 1181, 1187, 1188, 1190, 1191, 1193, 1199, 1200, 1201, 1205, 1222, 1225, 1226, 1235, 1239, 1241, 1242, 1245, 1246, 1250, 1252, 1253, 1255, 1258, 1259, 1261, 1267, 1283, 1290, 1295, 1312, 1318, 1321, 1322, 1328, 1329, 1330, 1332, 1333, 1334, 1336, 1337, 1340, 1341, 1342, 1345, 1351, 1352, 1354, 1355, 1358, 1359, 1366, 1373, 1374, 1383, 1385, 1386, 1387, 1388, 1390, 1391, 1392, 1394, 1408, 1412, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1427, 1428, 1450, 1453, 1455, 1457, 1461, 1470, 1471, 1503, 1520, 1521, 1523, 1533, 1540, 1558, 1559, 1577, 1578, 1586, 1593, 1602, 1609, 1611, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1632, 1644, 1646, 1649, 1657, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1697, 1709, 1723, 1727, 1729, 1730, 1734, 1736, 1743, 1747, 1756, 1758, 1776, 1781, 1784, 1785, 1787, 1788, 1796, 1799, 1823, 1828, 1829, 1832, 1833, 1834, 1835, 1839, 1840, 1842, 1843, 1850, 1857, 1860, 1862, 1863, 1865, 1869, 1870, 1871, 1872, 1873, 1875, 1877, 1878, 1881, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1898, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1911, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929], "function": [0, 1, 3, 4, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 28, 29, 30, 32, 33, 34, 35, 37, 38, 42, 43, 45, 46, 48, 49, 51, 55, 56, 58, 59, 63, 66, 68, 70, 84, 89, 120, 151, 196, 260, 289, 298, 321, 486, 491, 494, 515, 538, 553, 677, 686, 690, 691, 695, 696, 745, 754, 755, 757, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 787, 788, 789, 790, 794, 795, 797, 811, 812, 813, 814, 821, 823, 835, 838, 851, 854, 856, 858, 859, 860, 874, 875, 890, 891, 892, 893, 904, 905, 906, 910, 911, 914, 917, 919, 928, 930, 938, 940, 944, 947, 950, 955, 956, 963, 964, 965, 967, 969, 971, 974, 991, 992, 995, 1000, 1001, 1006, 1007, 1009, 1010, 1011, 1012, 1014, 1019, 1020, 1027, 1028, 1030, 1031, 1032, 1036, 1046, 1051, 1053, 1054, 1061, 1063, 1067, 1079, 1080, 1082, 1102, 1106, 1109, 1110, 1111, 1114, 1116, 1119, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1135, 1136, 1143, 1147, 1148, 1149, 1151, 1153, 1161, 1162, 1163, 1165, 1177, 1187, 1188, 1189, 1190, 1191, 1193, 1195, 1196, 1200, 1201, 1202, 1203, 1205, 1207, 1209, 1210, 1211, 1213, 1218, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1237, 1238, 1239, 1241, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1261, 1262, 1265, 1267, 1276, 1279, 1280, 1284, 1287, 1290, 1292, 1294, 1295, 1296, 1314, 1317, 1318, 1334, 1338, 1344, 1345, 1347, 1348, 1349, 1356, 1360, 1364, 1367, 1372, 1373, 1374, 1375, 1376, 1378, 1379, 1380, 1381, 1382, 1388, 1390, 1391, 1392, 1393, 1408, 1411, 1412, 1414, 1421, 1422, 1427, 1428, 1430, 1437, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1450, 1451, 1452, 1453, 1455, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1465, 1467, 1469, 1470, 1471, 1473, 1475, 1477, 1478, 1479, 1594, 1598, 1599, 1602, 1609, 1610, 1614, 1625, 1635, 1636, 1637, 1639, 1642, 1643, 1644, 1647, 1649, 1650, 1654, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1672, 1674, 1675, 1676, 1677, 1679, 1682, 1683, 1685, 1688, 1689, 1690, 1695, 1696, 1697, 1701, 1707, 1714, 1718, 1723, 1736, 1745, 1746, 1747, 1750, 1753, 1759, 1767, 1771, 1772, 1777, 1780, 1782, 1783, 1784, 1785, 1787, 1793, 1800, 1804, 1810, 1811, 1819, 1823, 1825, 1829, 1839, 1840, 1841, 1843, 1847, 1848, 1849, 1850, 1851, 1856, 1857, 1858, 1859, 1864, 1867, 1869, 1872, 1873, 1875, 1877, 1881, 1884, 1886, 1887, 1888, 1890, 1893, 1894, 1897, 1899, 1902, 1904, 1905, 1906, 1907, 1908, 1910, 1912, 1913, 1914, 1915, 1920, 1922, 1924, 1925, 1926, 1927], "torchdynamo": [0, 9, 13, 15, 19, 20, 21, 26, 677, 950, 1655, 1858, 1869], "includ": [0, 1, 2, 3, 4, 5, 6, 8, 10, 13, 14, 16, 17, 20, 24, 25, 29, 32, 33, 38, 39, 41, 43, 55, 58, 59, 63, 71, 84, 321, 515, 580, 765, 766, 856, 858, 1091, 1093, 1151, 1188, 1190, 1191, 1219, 1298, 1299, 1335, 1336, 1337, 1343, 1345, 1359, 1368, 1376, 1409, 1418, 1419, 1420, 1422, 1428, 1466, 1467, 1468, 1469, 1472, 1488, 1489, 1490, 1505, 1518, 1538, 1602, 1636, 1637, 1639, 1772, 1832, 1833, 1834, 1835, 1857, 1860, 1862, 1863, 1870, 1871, 1873, 1875, 1883, 1885, 1886, 1890, 1893, 1894, 1899, 1901, 1907, 1908, 1913, 1915, 1922, 1925, 1928], "gener": [0, 2, 3, 4, 8, 9, 12, 13, 14, 15, 16, 17, 18, 20, 21, 23, 24, 28, 29, 32, 38, 39, 41, 47, 51, 52, 59, 63, 64, 65, 154, 155, 174, 258, 286, 377, 420, 453, 480, 605, 677, 906, 920, 995, 998, 1006, 1007, 1010, 1011, 1030, 1031, 1033, 1034, 1035, 1063, 1085, 1086, 1120, 1131, 1142, 1147, 1166, 1194, 1199, 1210, 1221, 1226, 1235, 1252, 1253, 1257, 1262, 1282, 1290, 1301, 1302, 1303, 1304, 1305, 1306, 1308, 1312, 1358, 1369, 1383, 1465, 1473, 1474, 1486, 1593, 1610, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1643, 1650, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1695, 1697, 1700, 1714, 1716, 1718, 1719, 1720, 1722, 1744, 1757, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1809, 1824, 1828, 1844, 1850, 1858, 1860, 1861, 1862, 1863, 1864, 1865, 1869, 1871, 1876, 1881, 1883, 1886, 1888, 1890, 1891, 1893, 1894, 1900, 1901, 1904, 1905, 1907, 1912, 1913, 1914, 1917, 1920, 1922, 1924, 1926, 1928], "graph": [0, 6, 9, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 26, 41, 43, 47, 63, 83, 84, 140, 151, 222, 223, 677, 744, 789, 790, 812, 813, 814, 820, 823, 890, 896, 904, 950, 964, 999, 1004, 1009, 1120, 1190, 1193, 1194, 1199, 1201, 1205, 1602, 1657, 1659, 1664, 1665, 1858, 1863, 1869, 1871, 1879, 1882, 1887, 1888, 1891, 1894, 1895, 1901, 1905, 1909, 1910, 1911, 1913, 1914, 1915, 1917, 1922, 1927], "similar": [0, 8, 10, 15, 16, 17, 21, 24, 29, 38, 41, 47, 55, 63, 68, 70, 71, 491, 513, 709, 710, 711, 712, 713, 714, 717, 727, 728, 729, 730, 742, 743, 753, 761, 799, 874, 889, 931, 936, 949, 1109, 1110, 1190, 1356, 1357, 1369, 1382, 1385, 1386, 1387, 1422, 1470, 1503, 1635, 1649, 1650, 1678, 1701, 1729, 1736, 1785, 1819, 1825, 1841, 1862, 1863, 1875, 1876, 1878, 1883, 1885, 1886, 1888, 1889, 1891, 1897, 1901, 1905, 1906, 1908, 1913, 1914, 1917, 1918, 1923, 1929], "fx": [0, 9, 13, 14, 15, 16, 17, 20, 21, 26, 28, 29, 83, 744, 812, 813, 814, 815, 857, 1120, 1858, 1902, 1909, 1910], "wrap": [0, 1, 2, 13, 17, 21, 26, 29, 33, 38, 39, 41, 45, 51, 60, 63, 67, 68, 71, 260, 787, 788, 967, 1120, 1190, 1205, 1359, 1422, 1461, 1597, 1602, 1612, 1638, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1860, 1861, 1863, 1870, 1882, 1883, 1886, 1887, 1888, 1889, 1894, 1900, 1901, 1906, 1907, 1908, 1913, 1914, 1925, 1927, 1928], "my_custom_funct": [0, 71], "optim": [0, 1, 2, 3, 8, 9, 12, 13, 15, 17, 19, 21, 26, 29, 30, 32, 33, 39, 41, 42, 43, 47, 63, 71, 816, 905, 914, 950, 1063, 1129, 1190, 1194, 1199, 1201, 1205, 1206, 1245, 1262, 1340, 1341, 1342, 1358, 1365, 1385, 1386, 1387, 1422, 1425, 1426, 1427, 1428, 1454, 1461, 1469, 1571, 1593, 1602, 1609, 1614, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1697, 1858, 1860, 1862, 1871, 1877, 1881, 1885, 1886, 1887, 1888, 1890, 1891, 1894, 1896, 1901, 1907, 1908, 1917], "def": [0, 1, 2, 12, 13, 15, 17, 19, 20, 21, 22, 27, 28, 29, 38, 39, 41, 42, 43, 47, 49, 50, 51, 55, 56, 59, 60, 61, 63, 65, 67, 68, 69, 70, 71, 398, 789, 790, 858, 859, 887, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 950, 1067, 1119, 1120, 1121, 1123, 1124, 1125, 1127, 1129, 1130, 1131, 1165, 1188, 1190, 1191, 1193, 1194, 1195, 1196, 1200, 1201, 1204, 1205, 1206, 1207, 1422, 1423, 1424, 1432, 1433, 1471, 1593, 1602, 1614, 1647, 1656, 1657, 1783, 1850, 1857, 1860, 1862, 1863, 1867, 1877, 1882, 1883, 1885, 1887, 1888, 1889, 1890, 1894, 1896, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1913, 1914, 1915, 1928], "x": [0, 1, 2, 4, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 27, 29, 30, 32, 38, 39, 41, 47, 49, 55, 63, 65, 66, 68, 69, 70, 71, 174, 254, 258, 286, 289, 311, 313, 315, 317, 321, 352, 377, 447, 482, 491, 497, 555, 557, 580, 604, 605, 614, 689, 755, 757, 767, 776, 777, 781, 782, 793, 796, 799, 817, 818, 858, 859, 875, 881, 883, 884, 885, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 932, 933, 934, 937, 938, 950, 955, 958, 961, 962, 1006, 1007, 1046, 1053, 1057, 1058, 1063, 1067, 1077, 1078, 1079, 1080, 1082, 1083, 1088, 1089, 1091, 1093, 1097, 1098, 1100, 1103, 1104, 1105, 1113, 1119, 1121, 1123, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1143, 1160, 1164, 1165, 1177, 1195, 1196, 1200, 1201, 1204, 1205, 1206, 1207, 1211, 1221, 1234, 1235, 1239, 1242, 1246, 1250, 1252, 1255, 1256, 1257, 1258, 1259, 1262, 1267, 1268, 1269, 1277, 1280, 1283, 1284, 1291, 1316, 1317, 1321, 1322, 1328, 1329, 1338, 1339, 1340, 1341, 1342, 1344, 1356, 1358, 1364, 1370, 1371, 1372, 1374, 1375, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1385, 1386, 1387, 1389, 1390, 1391, 1392, 1393, 1394, 1408, 1411, 1412, 1413, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1429, 1430, 1431, 1432, 1433, 1437, 1439, 1440, 1441, 1442, 1449, 1451, 1452, 1453, 1454, 1456, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1470, 1471, 1474, 1495, 1519, 1521, 1525, 1526, 1532, 1536, 1540, 1551, 1556, 1561, 1565, 1567, 1572, 1573, 1574, 1578, 1579, 1581, 1582, 1583, 1590, 1593, 1610, 1612, 1614, 1635, 1636, 1637, 1638, 1639, 1644, 1647, 1648, 1649, 1656, 1659, 1662, 1683, 1697, 1698, 1709, 1711, 1725, 1728, 1729, 1731, 1732, 1734, 1735, 1739, 1743, 1753, 1781, 1785, 1799, 1802, 1803, 1804, 1810, 1811, 1817, 1823, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1841, 1842, 1844, 1845, 1846, 1848, 1849, 1850, 1853, 1857, 1860, 1861, 1862, 1863, 1864, 1875, 1876, 1877, 1881, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1891, 1892, 1894, 1895, 1900, 1901, 1905, 1908, 1913, 1917, 1918, 1920, 1922, 1923, 1925, 1926, 1927], "add": [0, 1, 2, 4, 8, 12, 13, 14, 15, 18, 23, 28, 29, 33, 34, 38, 41, 43, 45, 55, 58, 63, 69, 70, 71, 83, 99, 290, 313, 511, 513, 683, 684, 685, 688, 744, 745, 754, 787, 790, 835, 856, 858, 859, 979, 1009, 1020, 1063, 1120, 1190, 1201, 1330, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1398, 1399, 1400, 1401, 1402, 1403, 1422, 1424, 1428, 1429, 1433, 1436, 1523, 1564, 1593, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1800, 1857, 1859, 1860, 1861, 1862, 1863, 1867, 1871, 1873, 1876, 1878, 1882, 1884, 1885, 1888, 1889, 1892, 1893, 1894, 1901, 1902, 1903, 1905, 1907, 1908, 1909, 1910, 1911, 1913, 1914, 1915, 1917, 1920, 1921, 1922, 1926, 1927, 1928], "1": [0, 1, 2, 4, 12, 13, 14, 15, 17, 20, 21, 23, 28, 29, 30, 32, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 55, 56, 58, 61, 63, 67, 68, 69, 70, 71, 89, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 137, 152, 153, 174, 192, 206, 209, 226, 228, 229, 230, 242, 254, 258, 263, 286, 289, 311, 312, 313, 315, 317, 321, 352, 377, 401, 402, 444, 446, 447, 453, 470, 480, 482, 486, 491, 494, 497, 511, 513, 515, 534, 535, 539, 541, 551, 552, 553, 555, 557, 558, 559, 560, 561, 578, 580, 581, 582, 584, 585, 604, 605, 612, 614, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 709, 710, 711, 712, 713, 714, 715, 716, 720, 721, 722, 723, 724, 727, 728, 731, 733, 734, 735, 736, 737, 738, 739, 740, 741, 743, 748, 749, 750, 753, 754, 755, 757, 767, 769, 770, 771, 772, 775, 779, 780, 782, 793, 805, 806, 816, 817, 818, 819, 822, 824, 852, 858, 859, 862, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 887, 891, 894, 896, 897, 898, 899, 900, 901, 902, 903, 910, 911, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 931, 932, 933, 934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 948, 949, 951, 952, 955, 956, 957, 958, 959, 960, 961, 962, 963, 975, 1006, 1007, 1022, 1026, 1033, 1037, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1060, 1061, 1062, 1063, 1066, 1067, 1068, 1069, 1073, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1132, 1133, 1134, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1160, 1161, 1164, 1165, 1167, 1175, 1177, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1194, 1200, 1201, 1205, 1206, 1209, 1210, 1211, 1213, 1214, 1215, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1232, 1233, 1235, 1236, 1237, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1265, 1267, 1269, 1270, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1295, 1296, 1297, 1307, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1364, 1365, 1366, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1379, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1460, 1461, 1464, 1465, 1467, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1486, 1488, 1491, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1510, 1511, 1512, 1513, 1515, 1516, 1517, 1519, 1520, 1521, 1523, 1525, 1527, 1528, 1529, 1530, 1531, 1539, 1541, 1545, 1546, 1547, 1553, 1556, 1557, 1558, 1559, 1561, 1562, 1563, 1565, 1569, 1570, 1571, 1572, 1573, 1575, 1577, 1578, 1579, 1581, 1586, 1587, 1588, 1589, 1590, 1593, 1602, 1609, 1610, 1614, 1619, 1620, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1635, 1636, 1637, 1638, 1640, 1641, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1696, 1697, 1698, 1700, 1701, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1739, 1743, 1746, 1747, 1748, 1749, 1750, 1752, 1753, 1756, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1776, 1777, 1781, 1782, 1783, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1858, 1859, 1861, 1862, 1863, 1864, 1867, 1870, 1871, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1885, 1886, 1888, 1890, 1891, 1892, 1894, 1897, 1898, 1899, 1900, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1910, 1913, 1914, 1915, 1917, 1918, 1920, 1921, 1922, 1923, 1924, 1925, 1927, 1928, 1929], "return": [0, 1, 2, 3, 4, 6, 12, 13, 14, 15, 16, 17, 19, 20, 21, 22, 27, 28, 29, 30, 31, 32, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 56, 58, 60, 63, 64, 65, 67, 68, 69, 70, 71, 89, 120, 154, 156, 171, 173, 176, 179, 180, 181, 191, 192, 196, 197, 207, 209, 210, 217, 219, 220, 222, 233, 240, 242, 254, 260, 267, 289, 297, 311, 319, 323, 325, 326, 328, 329, 330, 331, 333, 337, 339, 341, 352, 377, 393, 434, 444, 445, 446, 447, 448, 457, 471, 472, 473, 474, 475, 477, 482, 486, 494, 495, 496, 511, 513, 522, 534, 540, 541, 553, 554, 555, 556, 557, 577, 578, 579, 580, 586, 600, 601, 604, 606, 610, 611, 614, 681, 689, 690, 692, 693, 694, 695, 696, 732, 763, 764, 767, 768, 772, 773, 774, 775, 778, 781, 788, 789, 790, 791, 811, 812, 813, 814, 833, 837, 838, 851, 852, 853, 854, 856, 857, 858, 859, 860, 861, 862, 870, 871, 872, 873, 874, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 910, 911, 914, 915, 916, 919, 920, 921, 928, 929, 931, 934, 936, 938, 939, 940, 941, 942, 943, 944, 945, 947, 949, 950, 951, 955, 956, 958, 959, 960, 962, 963, 964, 966, 967, 969, 973, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 989, 990, 991, 992, 993, 994, 995, 996, 997, 998, 999, 1001, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1024, 1025, 1026, 1027, 1028, 1029, 1038, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1053, 1054, 1057, 1063, 1064, 1065, 1066, 1067, 1068, 1073, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1099, 1102, 1103, 1104, 1105, 1106, 1107, 1111, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1134, 1135, 1138, 1139, 1140, 1141, 1142, 1146, 1147, 1148, 1150, 1151, 1152, 1156, 1160, 1164, 1165, 1166, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1186, 1187, 1188, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1204, 1205, 1206, 1207, 1208, 1209, 1211, 1214, 1215, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1231, 1232, 1233, 1235, 1236, 1237, 1238, 1239, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1256, 1257, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1269, 1270, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1295, 1298, 1299, 1301, 1307, 1312, 1317, 1318, 1320, 1321, 1322, 1323, 1324, 1326, 1330, 1331, 1332, 1333, 1338, 1339, 1356, 1357, 1358, 1359, 1366, 1370, 1371, 1382, 1388, 1389, 1412, 1413, 1414, 1415, 1416, 1417, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1432, 1433, 1436, 1450, 1453, 1454, 1455, 1456, 1457, 1461, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1491, 1493, 1494, 1495, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1520, 1521, 1522, 1523, 1525, 1526, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1539, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1564, 1566, 1567, 1569, 1571, 1572, 1574, 1575, 1576, 1577, 1578, 1584, 1586, 1587, 1588, 1589, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1606, 1608, 1609, 1610, 1611, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1627, 1628, 1629, 1630, 1631, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1656, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1671, 1672, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1697, 1698, 1700, 1703, 1704, 1705, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1728, 1729, 1730, 1731, 1732, 1733, 1736, 1738, 1743, 1744, 1745, 1746, 1752, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1781, 1783, 1784, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1803, 1804, 1807, 1808, 1809, 1817, 1818, 1819, 1820, 1821, 1822, 1824, 1826, 1827, 1828, 1831, 1832, 1833, 1834, 1835, 1837, 1838, 1839, 1840, 1841, 1842, 1844, 1846, 1848, 1849, 1850, 1853, 1855, 1856, 1857, 1860, 1864, 1867, 1871, 1872, 1873, 1875, 1877, 1878, 1881, 1882, 1883, 1885, 1886, 1888, 1889, 1891, 1892, 1893, 1894, 1897, 1899, 1900, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1912, 1913, 1914, 1917, 1918, 1919, 1920, 1921, 1923, 1924, 1925, 1926, 1927, 1928, 1929], "Will": [0, 11, 12, 24, 41, 63, 71, 1793, 1862, 1877, 1901], "captur": [0, 2, 12, 14, 15, 17, 21, 27, 29, 33, 71, 677, 964, 966, 998, 1004, 1009, 1193, 1664, 1665, 1860, 1864, 1869, 1888, 1889, 1892, 1901, 1905, 1908, 1927], "singl": [0, 3, 4, 6, 12, 15, 16, 17, 20, 21, 22, 26, 28, 29, 32, 39, 41, 43, 45, 46, 47, 49, 51, 57, 58, 63, 64, 66, 67, 68, 69, 70, 71, 254, 677, 692, 693, 763, 764, 765, 766, 769, 770, 771, 811, 891, 898, 899, 900, 901, 902, 903, 904, 919, 928, 932, 958, 962, 1006, 1009, 1119, 1121, 1122, 1125, 1127, 1131, 1147, 1148, 1152, 1175, 1189, 1190, 1205, 1206, 1209, 1267, 1291, 1303, 1304, 1328, 1329, 1332, 1333, 1336, 1337, 1339, 1350, 1351, 1352, 1354, 1355, 1358, 1359, 1370, 1371, 1377, 1390, 1391, 1394, 1416, 1417, 1422, 1430, 1434, 1435, 1450, 1461, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1516, 1517, 1518, 1545, 1546, 1547, 1589, 1595, 1597, 1600, 1601, 1602, 1606, 1607, 1608, 1644, 1645, 1664, 1665, 1667, 1672, 1678, 1683, 1704, 1730, 1796, 1802, 1803, 1840, 1841, 1843, 1845, 1846, 1850, 1858, 1860, 1862, 1863, 1870, 1871, 1875, 1877, 1878, 1883, 1885, 1886, 1888, 1889, 1891, 1894, 1896, 1897, 1898, 1899, 1901, 1904, 1905, 1906, 1907, 1908, 1914, 1915, 1917, 1920, 1923, 1924, 1927], "contain": [0, 1, 2, 3, 4, 6, 13, 16, 21, 23, 25, 28, 29, 30, 32, 33, 38, 41, 42, 45, 46, 47, 49, 51, 52, 56, 59, 63, 70, 71, 84, 89, 151, 155, 192, 196, 209, 290, 311, 313, 315, 319, 321, 470, 482, 541, 600, 604, 683, 694, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 757, 811, 834, 838, 874, 889, 890, 898, 899, 900, 901, 902, 903, 904, 914, 918, 919, 920, 928, 930, 934, 957, 958, 962, 965, 976, 977, 978, 979, 980, 1009, 1063, 1097, 1098, 1100, 1106, 1126, 1127, 1130, 1131, 1147, 1148, 1151, 1152, 1160, 1164, 1181, 1188, 1190, 1191, 1196, 1197, 1200, 1205, 1206, 1209, 1220, 1226, 1227, 1228, 1229, 1231, 1233, 1235, 1236, 1252, 1261, 1279, 1283, 1290, 1312, 1318, 1330, 1339, 1358, 1359, 1365, 1366, 1369, 1374, 1375, 1377, 1382, 1392, 1393, 1414, 1422, 1423, 1424, 1429, 1432, 1437, 1439, 1450, 1454, 1461, 1473, 1504, 1512, 1513, 1515, 1586, 1593, 1596, 1597, 1602, 1610, 1611, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1642, 1643, 1646, 1648, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1697, 1700, 1725, 1739, 1743, 1803, 1804, 1808, 1824, 1831, 1833, 1835, 1840, 1841, 1846, 1850, 1858, 1860, 1862, 1863, 1864, 1870, 1873, 1877, 1878, 1882, 1883, 1887, 1888, 1889, 1890, 1891, 1893, 1894, 1897, 1899, 1901, 1904, 1905, 1906, 1907, 1908, 1910, 1911, 1913, 1915, 1917, 1919, 1920, 1922, 1923, 1925, 1926, 1927, 1928], "disallow_in_graph": [0, 1858], "exclud": [0, 6, 10, 14, 39, 58, 71, 1152, 1366, 1513, 1561, 1659, 1832, 1833, 1834, 1835, 1892, 1905, 1914], "forc": [0, 1, 2, 12, 14, 32, 35, 63, 457, 877, 1002, 1193, 1204, 1208, 1758, 1857, 1860, 1863, 1882, 1886, 1922, 1925], "break": [0, 8, 12, 14, 15, 18, 19, 21, 23, 24, 47, 66, 71, 677, 890, 950, 1190, 1235, 1422, 1736, 1756, 1858, 1864, 1869, 1887, 1904], "sub": [0, 28, 51, 63, 70, 559, 811, 858, 859, 1201, 1205, 1206, 1287, 1290, 1292, 1434, 1435, 1465, 1466, 1468, 1728, 1806, 1823, 1857, 1859, 1860, 1861, 1876, 1878, 1883, 1901, 1903, 1917, 1920], "give": [0, 1, 4, 5, 8, 10, 12, 15, 16, 18, 20, 22, 25, 29, 35, 38, 39, 43, 45, 57, 63, 71, 905, 906, 962, 1081, 1083, 1084, 1086, 1090, 1099, 1123, 1124, 1125, 1203, 1219, 1226, 1350, 1351, 1352, 1427, 1473, 1474, 1609, 1648, 1664, 1665, 1804, 1843, 1857, 1860, 1875, 1877, 1881, 1883, 1886, 1888, 1889, 1891, 1892, 1894, 1898, 1901, 1904, 1906, 1917, 1928], "two": [0, 1, 2, 4, 5, 6, 7, 9, 12, 13, 15, 16, 20, 29, 30, 32, 33, 35, 38, 39, 41, 42, 43, 45, 47, 49, 55, 56, 58, 59, 63, 67, 68, 71, 580, 581, 582, 584, 585, 604, 614, 677, 689, 691, 757, 790, 884, 887, 900, 905, 938, 940, 973, 1012, 1014, 1042, 1043, 1051, 1060, 1063, 1069, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1109, 1110, 1119, 1129, 1151, 1153, 1179, 1188, 1190, 1200, 1203, 1210, 1213, 1215, 1220, 1222, 1225, 1226, 1231, 1232, 1237, 1242, 1245, 1246, 1248, 1249, 1251, 1253, 1258, 1261, 1284, 1287, 1290, 1292, 1295, 1319, 1336, 1338, 1339, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1369, 1374, 1382, 1383, 1389, 1391, 1392, 1413, 1414, 1416, 1422, 1425, 1426, 1427, 1429, 1430, 1436, 1437, 1453, 1454, 1469, 1470, 1471, 1473, 1493, 1494, 1504, 1523, 1533, 1540, 1556, 1564, 1571, 1609, 1614, 1636, 1646, 1648, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1682, 1683, 1685, 1689, 1708, 1723, 1736, 1788, 1793, 1808, 1824, 1828, 1829, 1831, 1847, 1851, 1857, 1859, 1860, 1862, 1863, 1867, 1869, 1870, 1876, 1877, 1878, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1894, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1909, 1913, 1914, 1915, 1917, 1918, 1922, 1923, 1924, 1926, 1927], "each": [0, 1, 2, 3, 6, 10, 12, 14, 17, 18, 19, 20, 21, 23, 24, 25, 28, 29, 32, 38, 39, 41, 42, 43, 45, 46, 47, 49, 51, 56, 59, 60, 61, 63, 64, 66, 68, 69, 71, 84, 98, 120, 154, 155, 398, 402, 491, 511, 513, 515, 542, 604, 614, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 680, 683, 690, 692, 693, 696, 732, 757, 789, 837, 838, 856, 858, 859, 862, 874, 883, 884, 885, 886, 888, 889, 890, 895, 904, 918, 921, 930, 934, 938, 939, 941, 944, 948, 950, 962, 975, 976, 980, 1009, 1012, 1014, 1020, 1022, 1026, 1029, 1035, 1040, 1041, 1042, 1043, 1046, 1047, 1058, 1061, 1063, 1080, 1082, 1083, 1084, 1085, 1086, 1088, 1089, 1092, 1093, 1094, 1095, 1096, 1098, 1100, 1104, 1105, 1107, 1112, 1116, 1121, 1122, 1126, 1130, 1131, 1132, 1143, 1149, 1151, 1152, 1153, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1190, 1205, 1206, 1211, 1243, 1261, 1262, 1277, 1279, 1287, 1289, 1290, 1291, 1292, 1295, 1297, 1303, 1304, 1312, 1318, 1320, 1330, 1335, 1338, 1339, 1343, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1374, 1375, 1377, 1382, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1394, 1402, 1403, 1407, 1409, 1413, 1414, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1436, 1437, 1439, 1450, 1453, 1454, 1456, 1461, 1464, 1470, 1471, 1473, 1491, 1493, 1494, 1499, 1500, 1501, 1504, 1505, 1507, 1508, 1509, 1512, 1513, 1514, 1518, 1521, 1531, 1533, 1556, 1557, 1559, 1561, 1564, 1571, 1584, 1593, 1598, 1599, 1602, 1635, 1636, 1638, 1648, 1649, 1650, 1656, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1700, 1704, 1705, 1708, 1715, 1723, 1728, 1729, 1734, 1738, 1743, 1756, 1767, 1773, 1789, 1790, 1791, 1792, 1794, 1795, 1796, 1807, 1808, 1823, 1825, 1826, 1829, 1840, 1841, 1844, 1850, 1851, 1857, 1862, 1863, 1869, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1893, 1894, 1896, 1897, 1898, 1899, 1901, 1904, 1906, 1907, 1908, 1913, 1914, 1915, 1917, 1918, 1920, 1922, 1923, 1924, 1926, 1927], "op": [0, 2, 5, 12, 13, 16, 17, 18, 19, 20, 21, 23, 28, 29, 41, 71, 83, 151, 501, 521, 601, 754, 789, 790, 791, 820, 823, 851, 858, 859, 890, 896, 904, 940, 950, 970, 985, 987, 991, 992, 1006, 1007, 1032, 1036, 1038, 1120, 1140, 1191, 1203, 1205, 1206, 1267, 1438, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1695, 1754, 1831, 1858, 1859, 1863, 1867, 1869, 1870, 1871, 1873, 1876, 1877, 1885, 1886, 1887, 1888, 1896, 1905, 1907, 1908, 1909, 1910, 1911, 1919, 1921, 1923, 1927], "forbid_in_graph": [0, 1858], "assert": [0, 15, 28, 29, 38, 39, 47, 65, 67, 68, 69, 71, 621, 908, 910, 911, 1121, 1123, 1124, 1125, 1126, 1129, 1130, 1131, 1188, 1193, 1194, 1199, 1658, 1850, 1862, 1864, 1888, 1889, 1894, 1905, 1908, 1924], "ar": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 32, 33, 35, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 51, 52, 55, 56, 58, 59, 60, 63, 65, 66, 67, 68, 70, 71, 83, 89, 98, 151, 254, 319, 321, 335, 336, 339, 377, 402, 447, 470, 480, 485, 497, 511, 515, 541, 577, 586, 614, 677, 686, 687, 688, 694, 732, 753, 757, 758, 760, 761, 762, 776, 779, 780, 782, 783, 784, 789, 790, 791, 792, 793, 796, 811, 812, 813, 814, 816, 817, 818, 819, 822, 837, 851, 855, 856, 857, 858, 859, 862, 871, 872, 883, 884, 885, 887, 890, 896, 898, 899, 900, 901, 902, 903, 905, 906, 919, 928, 929, 931, 932, 934, 937, 943, 950, 952, 957, 958, 961, 962, 965, 966, 967, 969, 970, 972, 977, 989, 1000, 1006, 1009, 1010, 1020, 1030, 1037, 1046, 1051, 1055, 1058, 1063, 1079, 1080, 1081, 1082, 1084, 1086, 1091, 1093, 1099, 1102, 1104, 1105, 1109, 1110, 1111, 1119, 1120, 1125, 1127, 1129, 1130, 1131, 1135, 1143, 1147, 1148, 1150, 1152, 1165, 1167, 1179, 1180, 1182, 1183, 1186, 1187, 1188, 1190, 1191, 1194, 1196, 1197, 1200, 1203, 1205, 1206, 1211, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1242, 1244, 1245, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1254, 1256, 1259, 1260, 1261, 1262, 1271, 1272, 1273, 1274, 1276, 1277, 1279, 1281, 1282, 1284, 1287, 1290, 1291, 1292, 1295, 1297, 1312, 1316, 1317, 1318, 1319, 1320, 1330, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1366, 1367, 1369, 1374, 1375, 1376, 1377, 1382, 1385, 1386, 1387, 1388, 1389, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1436, 1437, 1439, 1450, 1453, 1454, 1455, 1461, 1465, 1467, 1469, 1470, 1471, 1473, 1474, 1486, 1492, 1493, 1494, 1504, 1505, 1512, 1513, 1514, 1515, 1521, 1532, 1533, 1556, 1559, 1561, 1564, 1571, 1589, 1590, 1591, 1592, 1593, 1598, 1599, 1602, 1603, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1612, 1614, 1621, 1635, 1639, 1642, 1643, 1644, 1645, 1647, 1649, 1650, 1656, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1685, 1688, 1689, 1701, 1707, 1708, 1714, 1723, 1726, 1727, 1734, 1736, 1747, 1748, 1751, 1781, 1782, 1783, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1800, 1803, 1804, 1807, 1808, 1817, 1819, 1823, 1825, 1826, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1843, 1844, 1845, 1846, 1850, 1858, 1860, 1861, 1862, 1863, 1864, 1865, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1878, 1879, 1881, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1903, 1904, 1906, 1907, 1908, 1909, 1911, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1928, 1929], "present": [0, 4, 10, 18, 24, 38, 41, 58, 63, 1188, 1279, 1330, 1392, 1432, 1635, 1658, 1804, 1857, 1872, 1875, 1876, 1877, 1882, 1883, 1886, 1888, 1891, 1894, 1901, 1905, 1914, 1917, 1920], "while": [0, 1, 3, 4, 6, 8, 9, 16, 17, 18, 20, 21, 23, 29, 30, 32, 38, 39, 41, 42, 43, 47, 60, 63, 68, 70, 71, 692, 693, 732, 851, 881, 889, 967, 1038, 1120, 1152, 1190, 1193, 1205, 1206, 1262, 1318, 1330, 1346, 1383, 1385, 1386, 1387, 1392, 1422, 1428, 1440, 1453, 1461, 1465, 1540, 1602, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1649, 1743, 1864, 1869, 1870, 1877, 1878, 1882, 1883, 1886, 1889, 1890, 1891, 1894, 1896, 1898, 1901, 1904, 1906, 1908, 1911, 1913, 1915, 1917, 1918, 1921, 1922, 1923], "trace": [0, 1, 2, 13, 15, 16, 17, 19, 20, 21, 23, 24, 27, 29, 33, 35, 38, 39, 41, 51, 73, 74, 75, 912, 913, 914, 950, 1063, 1193, 1201, 1202, 1206, 1262, 1303, 1304, 1305, 1660, 1858, 1861, 1862, 1863, 1865, 1883, 1886, 1887, 1899, 1903, 1905, 1922], "If": [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 30, 32, 33, 36, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 56, 57, 58, 59, 61, 63, 64, 65, 66, 67, 68, 70, 71, 83, 84, 98, 151, 155, 196, 207, 210, 254, 315, 319, 321, 444, 445, 446, 447, 448, 457, 470, 480, 494, 497, 515, 518, 534, 542, 577, 578, 580, 581, 582, 584, 585, 600, 604, 614, 677, 683, 686, 687, 688, 690, 692, 693, 694, 696, 732, 753, 757, 761, 776, 778, 782, 791, 792, 814, 817, 818, 819, 822, 851, 855, 858, 862, 871, 872, 873, 874, 875, 876, 877, 886, 888, 889, 890, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 918, 919, 921, 928, 930, 931, 932, 934, 938, 940, 941, 942, 943, 944, 945, 952, 955, 956, 957, 961, 962, 963, 966, 967, 969, 971, 974, 976, 978, 980, 987, 998, 1004, 1009, 1010, 1030, 1033, 1044, 1045, 1046, 1050, 1051, 1052, 1053, 1054, 1063, 1064, 1065, 1066, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1106, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1130, 1131, 1132, 1143, 1147, 1148, 1150, 1151, 1152, 1153, 1164, 1167, 1181, 1187, 1190, 1193, 1194, 1195, 1197, 1199, 1201, 1202, 1205, 1206, 1209, 1210, 1211, 1215, 1219, 1220, 1225, 1226, 1228, 1229, 1231, 1232, 1233, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1250, 1252, 1253, 1255, 1256, 1257, 1259, 1260, 1261, 1262, 1272, 1276, 1277, 1279, 1281, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1307, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1321, 1330, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1370, 1371, 1374, 1375, 1376, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1398, 1399, 1400, 1401, 1402, 1403, 1407, 1409, 1413, 1414, 1415, 1416, 1417, 1422, 1423, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1436, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1453, 1454, 1461, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1473, 1474, 1477, 1478, 1479, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1516, 1517, 1521, 1523, 1525, 1532, 1533, 1538, 1540, 1542, 1543, 1545, 1546, 1547, 1556, 1557, 1558, 1561, 1564, 1565, 1571, 1577, 1578, 1589, 1590, 1602, 1603, 1606, 1607, 1609, 1610, 1611, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1635, 1636, 1637, 1638, 1642, 1643, 1644, 1647, 1648, 1649, 1653, 1654, 1656, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1695, 1696, 1701, 1705, 1707, 1708, 1712, 1713, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1728, 1729, 1734, 1736, 1739, 1743, 1745, 1747, 1750, 1751, 1756, 1758, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1781, 1784, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1799, 1802, 1803, 1804, 1807, 1808, 1822, 1823, 1825, 1826, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1840, 1841, 1843, 1844, 1845, 1846, 1850, 1855, 1856, 1857, 1860, 1863, 1865, 1867, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1891, 1892, 1893, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1911, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1928], "you": [0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 21, 22, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 37, 38, 39, 41, 45, 46, 47, 49, 50, 55, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 70, 71, 83, 84, 151, 254, 335, 447, 497, 677, 686, 731, 732, 745, 754, 778, 886, 887, 888, 889, 890, 895, 896, 898, 899, 900, 904, 932, 950, 964, 987, 998, 1000, 1009, 1010, 1030, 1063, 1119, 1120, 1123, 1124, 1125, 1126, 1131, 1165, 1190, 1194, 1195, 1202, 1205, 1206, 1207, 1235, 1253, 1261, 1284, 1291, 1294, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1392, 1418, 1419, 1420, 1422, 1427, 1428, 1429, 1437, 1456, 1465, 1467, 1469, 1474, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1532, 1538, 1571, 1589, 1590, 1593, 1602, 1610, 1636, 1644, 1647, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1689, 1707, 1730, 1739, 1747, 1790, 1791, 1792, 1794, 1795, 1799, 1850, 1857, 1860, 1862, 1863, 1865, 1867, 1870, 1871, 1873, 1875, 1876, 1878, 1881, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1909, 1911, 1912, 1913, 1914, 1915, 1917, 1920, 1921, 1922, 1923, 1924, 1925, 1928], "want": [0, 1, 2, 8, 9, 10, 13, 14, 15, 16, 17, 18, 20, 22, 23, 24, 27, 28, 32, 38, 41, 46, 47, 55, 63, 65, 66, 67, 68, 70, 71, 447, 494, 497, 778, 788, 835, 1002, 1119, 1120, 1202, 1205, 1206, 1291, 1370, 1371, 1474, 1516, 1517, 1532, 1590, 1602, 1603, 1644, 1647, 1664, 1665, 1678, 1739, 1857, 1867, 1870, 1882, 1883, 1885, 1886, 1888, 1889, 1891, 1894, 1901, 1904, 1905, 1908, 1917, 1922, 1923, 1926], "instead": [0, 1, 2, 4, 6, 9, 10, 12, 13, 15, 16, 17, 18, 21, 24, 28, 29, 32, 38, 39, 41, 43, 46, 47, 49, 55, 58, 59, 63, 66, 67, 68, 71, 222, 406, 457, 497, 511, 745, 754, 765, 766, 790, 814, 823, 877, 887, 898, 899, 900, 901, 904, 905, 934, 940, 1098, 1100, 1124, 1125, 1126, 1127, 1130, 1131, 1136, 1177, 1188, 1190, 1191, 1195, 1219, 1220, 1226, 1228, 1244, 1247, 1253, 1259, 1290, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1356, 1358, 1359, 1361, 1362, 1363, 1367, 1374, 1382, 1388, 1389, 1390, 1391, 1392, 1413, 1414, 1415, 1416, 1417, 1422, 1425, 1426, 1427, 1429, 1436, 1437, 1449, 1453, 1454, 1455, 1461, 1470, 1488, 1489, 1490, 1493, 1494, 1504, 1514, 1521, 1533, 1545, 1546, 1547, 1556, 1564, 1577, 1602, 1644, 1658, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1682, 1683, 1689, 1712, 1713, 1723, 1743, 1747, 1789, 1804, 1808, 1843, 1850, 1860, 1862, 1863, 1870, 1877, 1881, 1882, 1883, 1887, 1888, 1889, 1890, 1891, 1892, 1896, 1898, 1899, 1900, 1901, 1904, 1905, 1907, 1908, 1911, 1914, 1917, 1924, 1925, 1927, 1928], "us": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 30, 32, 33, 34, 36, 38, 42, 43, 45, 46, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 63, 64, 66, 67, 68, 69, 70, 83, 84, 89, 98, 120, 151, 155, 192, 209, 319, 321, 335, 342, 343, 406, 434, 447, 457, 485, 486, 494, 497, 511, 515, 518, 541, 554, 580, 581, 582, 584, 585, 614, 677, 683, 686, 709, 710, 711, 712, 713, 714, 717, 726, 727, 728, 729, 730, 732, 745, 754, 757, 765, 766, 769, 770, 771, 776, 778, 782, 783, 784, 787, 790, 791, 792, 793, 796, 799, 804, 812, 813, 814, 816, 817, 818, 819, 820, 821, 822, 823, 824, 828, 829, 830, 831, 834, 851, 855, 856, 858, 859, 862, 875, 876, 877, 886, 887, 888, 890, 891, 892, 893, 895, 896, 898, 899, 900, 901, 904, 905, 906, 910, 911, 914, 917, 918, 919, 920, 928, 930, 931, 938, 940, 942, 950, 955, 958, 960, 963, 964, 965, 966, 967, 969, 971, 972, 974, 977, 987, 988, 991, 992, 998, 1002, 1006, 1008, 1009, 1010, 1012, 1014, 1015, 1020, 1021, 1030, 1032, 1033, 1039, 1044, 1045, 1046, 1055, 1063, 1064, 1066, 1076, 1077, 1078, 1081, 1083, 1091, 1093, 1097, 1099, 1106, 1108, 1111, 1117, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1135, 1136, 1140, 1141, 1143, 1147, 1148, 1149, 1150, 1164, 1165, 1177, 1187, 1188, 1190, 1191, 1194, 1195, 1196, 1197, 1199, 1200, 1201, 1202, 1203, 1205, 1206, 1207, 1209, 1211, 1213, 1221, 1225, 1226, 1228, 1229, 1230, 1232, 1233, 1234, 1235, 1236, 1237, 1242, 1243, 1244, 1246, 1247, 1253, 1254, 1255, 1259, 1260, 1261, 1262, 1267, 1270, 1276, 1279, 1280, 1283, 1284, 1289, 1290, 1291, 1294, 1300, 1312, 1317, 1319, 1320, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1374, 1375, 1376, 1377, 1382, 1383, 1385, 1386, 1387, 1388, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1408, 1409, 1410, 1415, 1416, 1417, 1418, 1419, 1422, 1424, 1428, 1429, 1430, 1431, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1453, 1455, 1458, 1461, 1469, 1470, 1471, 1472, 1474, 1477, 1478, 1479, 1486, 1488, 1489, 1490, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1516, 1517, 1521, 1523, 1530, 1532, 1533, 1540, 1545, 1546, 1547, 1557, 1559, 1565, 1571, 1575, 1577, 1578, 1586, 1590, 1591, 1592, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1609, 1610, 1611, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1636, 1637, 1638, 1642, 1643, 1644, 1646, 1647, 1649, 1650, 1653, 1656, 1658, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1686, 1687, 1689, 1690, 1692, 1693, 1695, 1705, 1707, 1708, 1709, 1712, 1713, 1714, 1716, 1718, 1720, 1722, 1723, 1729, 1736, 1739, 1744, 1745, 1747, 1748, 1749, 1751, 1753, 1754, 1755, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1776, 1781, 1783, 1784, 1786, 1787, 1790, 1791, 1792, 1793, 1794, 1795, 1804, 1807, 1808, 1809, 1822, 1826, 1829, 1833, 1835, 1840, 1842, 1843, 1847, 1850, 1855, 1857, 1858, 1859, 1860, 1861, 1863, 1864, 1865, 1867, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1879, 1881, 1882, 1885, 1887, 1889, 1890, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1902, 1907, 1909, 1911, 1912, 1913, 1914, 1915, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1927, 1928], "todo": [0, 12, 16, 24, 72, 77, 78, 79, 80, 81, 82, 83, 84, 823, 856, 858, 859, 1927], "voz": 0, "we": [0, 1, 2, 3, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 38, 39, 41, 43, 45, 46, 47, 48, 49, 58, 59, 61, 63, 64, 65, 66, 67, 68, 70, 71, 494, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 776, 782, 785, 786, 788, 790, 791, 835, 854, 856, 858, 859, 862, 890, 891, 894, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 919, 928, 963, 1020, 1063, 1081, 1083, 1084, 1085, 1086, 1093, 1098, 1099, 1100, 1114, 1123, 1124, 1126, 1131, 1143, 1147, 1148, 1164, 1188, 1190, 1193, 1194, 1201, 1203, 1205, 1245, 1248, 1253, 1261, 1262, 1281, 1312, 1330, 1338, 1339, 1388, 1422, 1474, 1521, 1523, 1532, 1590, 1597, 1602, 1609, 1611, 1620, 1622, 1625, 1629, 1630, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1680, 1686, 1691, 1708, 1850, 1857, 1858, 1860, 1862, 1863, 1865, 1867, 1870, 1871, 1875, 1876, 1877, 1878, 1883, 1886, 1888, 1889, 1890, 1891, 1892, 1894, 1896, 1897, 1900, 1901, 1904, 1905, 1906, 1908, 1909, 1911, 1913, 1914, 1915, 1917, 1920, 1922, 1925, 1926, 1927], "now": [0, 1, 2, 12, 15, 16, 18, 20, 21, 23, 27, 28, 29, 41, 46, 48, 55, 59, 60, 63, 68, 71, 222, 494, 897, 904, 978, 1006, 1027, 1028, 1114, 1137, 1187, 1188, 1194, 1205, 1239, 1419, 1438, 1474, 1593, 1614, 1625, 1667, 1748, 1799, 1804, 1860, 1870, 1876, 1877, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1894, 1895, 1901, 1905, 1908, 1914, 1915, 1917, 1925, 1928], "have": [0, 1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 38, 41, 42, 43, 45, 47, 48, 49, 50, 51, 55, 56, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 71, 89, 154, 155, 222, 223, 313, 315, 321, 335, 398, 402, 447, 457, 470, 485, 486, 501, 511, 513, 515, 518, 541, 614, 677, 686, 690, 692, 693, 694, 696, 812, 814, 838, 877, 886, 890, 898, 900, 910, 911, 919, 920, 928, 937, 938, 962, 969, 978, 979, 1009, 1020, 1054, 1062, 1069, 1083, 1093, 1098, 1100, 1114, 1119, 1120, 1131, 1132, 1133, 1147, 1148, 1151, 1152, 1164, 1165, 1187, 1189, 1190, 1193, 1194, 1197, 1199, 1201, 1202, 1203, 1204, 1205, 1206, 1211, 1212, 1221, 1225, 1226, 1242, 1249, 1250, 1253, 1255, 1261, 1270, 1272, 1277, 1284, 1287, 1289, 1290, 1291, 1292, 1294, 1295, 1312, 1317, 1318, 1320, 1322, 1330, 1334, 1338, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1359, 1365, 1366, 1370, 1371, 1376, 1381, 1385, 1386, 1387, 1414, 1422, 1425, 1426, 1427, 1428, 1429, 1469, 1471, 1503, 1512, 1513, 1516, 1517, 1521, 1538, 1556, 1558, 1561, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1606, 1607, 1609, 1611, 1614, 1638, 1642, 1647, 1649, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1705, 1731, 1732, 1746, 1759, 1782, 1785, 1789, 1790, 1791, 1792, 1794, 1795, 1802, 1803, 1804, 1807, 1808, 1819, 1823, 1829, 1831, 1843, 1845, 1846, 1848, 1850, 1852, 1857, 1860, 1861, 1862, 1863, 1865, 1867, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1909, 1912, 1913, 1914, 1915, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1928], "some": [0, 1, 2, 4, 8, 9, 10, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 28, 29, 32, 37, 38, 39, 41, 43, 46, 47, 49, 51, 59, 60, 63, 66, 68, 69, 70, 71, 476, 494, 564, 686, 745, 950, 1016, 1020, 1023, 1063, 1084, 1086, 1094, 1095, 1096, 1111, 1120, 1131, 1165, 1187, 1188, 1190, 1191, 1200, 1203, 1205, 1235, 1253, 1259, 1284, 1291, 1294, 1330, 1334, 1338, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1382, 1385, 1386, 1387, 1388, 1389, 1392, 1413, 1414, 1422, 1425, 1426, 1427, 1429, 1436, 1437, 1453, 1454, 1470, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1506, 1533, 1538, 1556, 1559, 1564, 1571, 1593, 1602, 1603, 1604, 1605, 1609, 1642, 1677, 1683, 1689, 1707, 1727, 1751, 1758, 1772, 1808, 1850, 1857, 1860, 1861, 1862, 1863, 1864, 1867, 1868, 1869, 1870, 1871, 1875, 1876, 1877, 1882, 1883, 1886, 1888, 1889, 1890, 1891, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1907, 1908, 1909, 1911, 1913, 1914, 1915, 1917, 1922], "more": [0, 1, 2, 3, 4, 5, 9, 10, 13, 15, 16, 17, 18, 20, 21, 23, 26, 29, 30, 32, 33, 34, 37, 38, 39, 41, 42, 47, 48, 49, 50, 54, 57, 58, 59, 60, 63, 66, 67, 68, 69, 71, 84, 151, 254, 255, 313, 321, 486, 491, 493, 496, 511, 513, 515, 542, 615, 677, 732, 768, 777, 781, 790, 851, 856, 857, 858, 870, 883, 884, 885, 887, 889, 890, 896, 898, 900, 904, 905, 906, 910, 911, 921, 929, 932, 934, 940, 941, 942, 943, 966, 967, 969, 971, 972, 988, 1007, 1012, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1027, 1028, 1029, 1033, 1041, 1046, 1052, 1061, 1063, 1067, 1079, 1080, 1082, 1084, 1103, 1104, 1105, 1106, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1138, 1139, 1143, 1152, 1153, 1165, 1171, 1175, 1177, 1178, 1190, 1203, 1206, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1257, 1259, 1262, 1265, 1268, 1270, 1280, 1281, 1303, 1304, 1307, 1318, 1330, 1334, 1339, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1365, 1366, 1367, 1383, 1392, 1418, 1419, 1420, 1422, 1428, 1434, 1435, 1436, 1437, 1449, 1461, 1469, 1486, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1510, 1512, 1513, 1521, 1524, 1525, 1526, 1527, 1532, 1536, 1540, 1541, 1551, 1558, 1565, 1566, 1567, 1569, 1571, 1572, 1573, 1574, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1589, 1590, 1591, 1592, 1593, 1602, 1603, 1609, 1611, 1612, 1647, 1648, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1695, 1706, 1707, 1733, 1739, 1743, 1753, 1783, 1784, 1808, 1829, 1831, 1843, 1850, 1851, 1857, 1858, 1859, 1860, 1862, 1863, 1869, 1870, 1872, 1873, 1875, 1876, 1877, 1878, 1879, 1881, 1883, 1885, 1886, 1887, 1888, 1890, 1891, 1892, 1893, 1894, 1897, 1899, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1909, 1914, 1915, 1917, 1920, 1921, 1922, 1923, 1924, 1925, 1928, 1929], "robust": [0, 4, 1262, 1875, 1894], "document": [0, 9, 10, 11, 13, 17, 21, 23, 24, 28, 34, 38, 41, 63, 64, 71, 677, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 870, 871, 872, 873, 935, 966, 967, 969, 1020, 1063, 1135, 1138, 1139, 1171, 1178, 1190, 1303, 1304, 1319, 1330, 1365, 1366, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1422, 1611, 1620, 1629, 1649, 1706, 1733, 1750, 1843, 1857, 1860, 1862, 1863, 1875, 1876, 1877, 1879, 1882, 1888, 1890, 1894, 1898, 1899, 1901, 1904, 1905, 1908, 1909, 1910, 1913, 1917, 1921, 1925], "would": [0, 3, 4, 6, 9, 10, 12, 13, 15, 16, 17, 20, 23, 24, 28, 29, 30, 32, 38, 41, 47, 49, 51, 58, 59, 63, 65, 68, 71, 151, 444, 445, 446, 447, 448, 695, 757, 791, 851, 890, 894, 904, 940, 1064, 1066, 1084, 1124, 1125, 1188, 1190, 1191, 1195, 1197, 1205, 1206, 1303, 1304, 1335, 1336, 1337, 1338, 1339, 1374, 1388, 1392, 1415, 1416, 1417, 1422, 1432, 1437, 1521, 1532, 1593, 1602, 1603, 1635, 1647, 1678, 1716, 1720, 1722, 1733, 1743, 1822, 1823, 1828, 1860, 1862, 1863, 1876, 1877, 1878, 1879, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1899, 1901, 1904, 1905, 1906, 1908, 1913, 1914, 1915, 1917], "amiss": 0, "graph_break": [0, 12, 18, 1858], "mark_dynam": [0, 15, 1858], "t": [0, 1, 2, 3, 4, 5, 8, 9, 10, 15, 16, 18, 20, 21, 22, 29, 30, 38, 39, 41, 43, 47, 48, 51, 55, 57, 58, 64, 66, 68, 69, 70, 71, 151, 313, 315, 321, 457, 534, 568, 684, 685, 694, 757, 778, 782, 792, 820, 823, 874, 875, 876, 877, 886, 888, 890, 891, 894, 896, 899, 904, 941, 942, 943, 948, 962, 964, 967, 988, 1006, 1007, 1037, 1061, 1079, 1084, 1085, 1086, 1087, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1102, 1114, 1115, 1116, 1119, 1120, 1121, 1131, 1132, 1143, 1153, 1187, 1188, 1190, 1191, 1193, 1196, 1197, 1201, 1203, 1205, 1208, 1210, 1219, 1220, 1226, 1228, 1229, 1232, 1239, 1247, 1248, 1253, 1261, 1262, 1270, 1283, 1296, 1297, 1310, 1319, 1339, 1343, 1345, 1350, 1351, 1352, 1359, 1365, 1366, 1374, 1383, 1385, 1386, 1387, 1388, 1392, 1409, 1422, 1437, 1453, 1455, 1465, 1473, 1474, 1492, 1496, 1497, 1498, 1505, 1512, 1513, 1533, 1538, 1557, 1577, 1590, 1593, 1596, 1597, 1602, 1603, 1609, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1636, 1638, 1639, 1650, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1681, 1691, 1697, 1703, 1707, 1724, 1749, 1750, 1759, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1782, 1785, 1804, 1808, 1809, 1819, 1822, 1828, 1831, 1850, 1851, 1857, 1859, 1860, 1861, 1862, 1864, 1873, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1891, 1893, 1894, 1896, 1899, 1900, 1901, 1903, 1904, 1905, 1906, 1908, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1928], "index": [0, 4, 16, 29, 33, 38, 39, 43, 47, 56, 71, 192, 209, 281, 312, 313, 314, 315, 316, 317, 319, 321, 322, 470, 471, 510, 511, 512, 513, 514, 515, 516, 517, 692, 693, 814, 851, 874, 889, 934, 982, 985, 1042, 1043, 1083, 1123, 1124, 1125, 1129, 1131, 1132, 1161, 1162, 1163, 1164, 1188, 1206, 1211, 1219, 1237, 1255, 1269, 1277, 1279, 1283, 1287, 1290, 1291, 1292, 1295, 1312, 1318, 1321, 1322, 1330, 1345, 1358, 1365, 1366, 1423, 1424, 1429, 1432, 1433, 1471, 1473, 1512, 1513, 1558, 1620, 1622, 1629, 1630, 1635, 1648, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1692, 1693, 1708, 1740, 1741, 1742, 1743, 1745, 1746, 1747, 1777, 1787, 1788, 1790, 1791, 1792, 1794, 1795, 1804, 1818, 1839, 1842, 1843, 1850, 1858, 1859, 1860, 1861, 1863, 1870, 1875, 1876, 1877, 1878, 1883, 1886, 1887, 1889, 1892, 1898, 1903, 1915, 1917, 1920, 1921, 1922, 1923, 1924], "mark": [0, 17, 18, 43, 58, 70, 71, 823, 894, 895, 1303, 1304, 1602, 1659, 1860, 1862, 1883, 1887, 1888, 1894, 1905, 1907, 1914, 1923], "tensor": [0, 1, 3, 6, 8, 9, 12, 13, 14, 15, 17, 19, 20, 21, 22, 27, 28, 29, 32, 34, 35, 38, 39, 41, 42, 43, 45, 47, 48, 63, 66, 67, 68, 69, 70, 71, 89, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 717, 729, 731, 732, 735, 736, 737, 738, 739, 740, 741, 742, 743, 745, 747, 752, 753, 754, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 781, 782, 783, 784, 785, 786, 787, 791, 795, 796, 797, 798, 799, 816, 817, 818, 819, 821, 822, 824, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 908, 910, 911, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 976, 977, 978, 979, 980, 987, 995, 996, 1002, 1006, 1009, 1012, 1016, 1027, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1165, 1167, 1168, 1169, 1170, 1172, 1175, 1177, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1191, 1193, 1194, 1196, 1197, 1200, 1201, 1203, 1205, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1301, 1310, 1311, 1312, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1330, 1334, 1335, 1338, 1339, 1343, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1368, 1369, 1374, 1375, 1376, 1382, 1388, 1389, 1392, 1393, 1409, 1412, 1413, 1414, 1415, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1432, 1433, 1434, 1435, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1454, 1455, 1456, 1457, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1593, 1598, 1599, 1602, 1603, 1604, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1632, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1656, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1673, 1674, 1675, 1676, 1677, 1678, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1745, 1746, 1747, 1748, 1749, 1752, 1753, 1756, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1779, 1780, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1817, 1818, 1819, 1820, 1821, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1858, 1859, 1860, 1862, 1863, 1867, 1870, 1879, 1881, 1882, 1884, 1885, 1886, 1887, 1889, 1890, 1892, 1894, 1895, 1896, 1897, 1898, 1900, 1903, 1904, 1905, 1906, 1907, 1909, 1912, 1913, 1914, 1918, 1919, 1922, 1924, 1926, 1927, 1928], "dynam": [0, 1, 14, 17, 19, 22, 25, 26, 29, 32, 33, 38, 677, 726, 730, 757, 758, 759, 760, 761, 762, 791, 812, 823, 826, 841, 847, 848, 849, 850, 855, 856, 950, 965, 1197, 1203, 1205, 1261, 1609, 1858, 1862, 1863, 1864, 1881, 1886, 1894, 1897, 1901, 1904, 1905, 1909], "dim": [0, 15, 41, 46, 47, 68, 69, 71, 113, 115, 116, 117, 119, 135, 136, 137, 185, 205, 208, 211, 212, 213, 214, 215, 216, 230, 260, 264, 281, 312, 313, 314, 315, 316, 317, 321, 322, 354, 380, 392, 407, 409, 410, 411, 414, 428, 429, 430, 431, 435, 436, 452, 461, 469, 478, 489, 490, 492, 503, 504, 510, 511, 512, 513, 514, 515, 516, 517, 534, 535, 538, 539, 541, 544, 549, 550, 552, 557, 562, 570, 575, 580, 581, 582, 584, 585, 587, 602, 603, 606, 607, 608, 609, 612, 614, 690, 692, 693, 694, 696, 871, 872, 873, 900, 901, 903, 937, 944, 953, 961, 963, 978, 980, 1042, 1043, 1044, 1045, 1046, 1055, 1061, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1102, 1103, 1121, 1131, 1132, 1143, 1153, 1161, 1162, 1163, 1164, 1167, 1211, 1221, 1222, 1242, 1246, 1256, 1258, 1259, 1269, 1277, 1287, 1289, 1290, 1292, 1295, 1297, 1310, 1317, 1318, 1319, 1320, 1321, 1322, 1330, 1357, 1358, 1359, 1362, 1366, 1368, 1373, 1388, 1393, 1412, 1428, 1429, 1430, 1455, 1457, 1469, 1471, 1472, 1503, 1504, 1520, 1523, 1532, 1540, 1545, 1546, 1547, 1556, 1557, 1559, 1561, 1565, 1571, 1577, 1578, 1586, 1602, 1610, 1616, 1620, 1622, 1629, 1630, 1643, 1646, 1649, 1698, 1705, 1708, 1728, 1729, 1734, 1735, 1740, 1741, 1742, 1745, 1746, 1777, 1780, 1781, 1784, 1787, 1789, 1796, 1799, 1801, 1802, 1803, 1804, 1807, 1819, 1823, 1824, 1825, 1826, 1829, 1830, 1838, 1839, 1840, 1841, 1842, 1845, 1846, 1850, 1851, 1858, 1859, 1860, 1861, 1877, 1878, 1889, 1890, 1899, 1901, 1903, 1917, 1918, 1920, 1926], "note": [0, 2, 3, 4, 6, 9, 15, 17, 18, 20, 23, 28, 29, 30, 32, 33, 35, 37, 38, 39, 41, 43, 45, 46, 47, 48, 49, 56, 58, 60, 63, 67, 69, 70, 71, 151, 222, 377, 497, 498, 511, 513, 515, 732, 738, 739, 740, 788, 790, 791, 792, 796, 838, 858, 862, 881, 890, 896, 898, 899, 900, 901, 902, 903, 904, 906, 940, 963, 1038, 1046, 1051, 1063, 1084, 1114, 1116, 1131, 1132, 1143, 1165, 1177, 1187, 1188, 1190, 1191, 1196, 1262, 1284, 1303, 1304, 1338, 1339, 1345, 1353, 1354, 1355, 1356, 1358, 1365, 1366, 1374, 1376, 1382, 1388, 1389, 1392, 1413, 1414, 1422, 1423, 1425, 1426, 1427, 1428, 1429, 1432, 1433, 1436, 1437, 1453, 1454, 1461, 1465, 1470, 1474, 1493, 1494, 1504, 1512, 1513, 1521, 1532, 1533, 1556, 1559, 1564, 1565, 1578, 1593, 1602, 1603, 1649, 1657, 1658, 1675, 1681, 1683, 1689, 1691, 1707, 1714, 1789, 1790, 1791, 1792, 1794, 1795, 1800, 1804, 1808, 1829, 1843, 1850, 1857, 1860, 1861, 1864, 1870, 1875, 1878, 1879, 1883, 1884, 1885, 1887, 1888, 1889, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1901, 1902, 1904, 1905, 1907, 1909, 1911, 1912, 1914, 1915, 1917, 1921, 1922, 1929], "state": [0, 1, 2, 3, 6, 10, 12, 14, 15, 16, 17, 24, 27, 38, 41, 43, 45, 47, 49, 51, 58, 61, 63, 71, 89, 745, 757, 833, 995, 996, 1000, 1005, 1009, 1019, 1034, 1035, 1120, 1129, 1142, 1190, 1193, 1205, 1262, 1301, 1308, 1374, 1375, 1392, 1393, 1422, 1437, 1439, 1593, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1714, 1757, 1783, 1871, 1882, 1883, 1886, 1887, 1888, 1892, 1896, 1899, 1901, 1904, 1912, 1926], "The": [0, 1, 2, 3, 4, 6, 8, 9, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 25, 28, 29, 30, 32, 33, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 67, 68, 69, 70, 73, 74, 75, 83, 84, 89, 151, 192, 197, 209, 210, 222, 255, 290, 311, 313, 315, 319, 321, 398, 400, 401, 402, 447, 457, 482, 485, 486, 491, 493, 496, 497, 511, 513, 515, 534, 541, 580, 600, 614, 615, 677, 681, 684, 685, 686, 687, 691, 692, 693, 694, 732, 745, 754, 757, 763, 764, 765, 766, 769, 770, 771, 776, 777, 779, 780, 782, 783, 784, 789, 790, 791, 792, 796, 799, 812, 814, 816, 817, 818, 819, 822, 824, 834, 835, 851, 856, 861, 874, 875, 877, 881, 882, 886, 887, 889, 890, 891, 892, 893, 898, 899, 901, 902, 903, 904, 905, 906, 910, 911, 913, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 935, 936, 942, 949, 952, 958, 962, 965, 966, 972, 979, 995, 1006, 1007, 1009, 1010, 1011, 1020, 1033, 1034, 1035, 1046, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1063, 1064, 1068, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1111, 1113, 1114, 1115, 1116, 1117, 1120, 1123, 1126, 1129, 1130, 1131, 1134, 1135, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1156, 1160, 1164, 1167, 1187, 1190, 1193, 1195, 1197, 1200, 1201, 1203, 1205, 1206, 1209, 1210, 1214, 1215, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1235, 1236, 1237, 1239, 1242, 1244, 1245, 1246, 1247, 1248, 1249, 1252, 1253, 1254, 1256, 1259, 1261, 1262, 1277, 1278, 1279, 1280, 1282, 1283, 1284, 1290, 1298, 1299, 1302, 1303, 1304, 1307, 1308, 1312, 1318, 1321, 1323, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1365, 1366, 1367, 1369, 1370, 1371, 1374, 1375, 1376, 1377, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1422, 1425, 1427, 1429, 1436, 1437, 1439, 1440, 1450, 1451, 1453, 1461, 1464, 1465, 1470, 1471, 1473, 1474, 1486, 1489, 1490, 1504, 1505, 1512, 1513, 1514, 1516, 1517, 1520, 1521, 1523, 1532, 1533, 1545, 1546, 1547, 1556, 1559, 1571, 1574, 1590, 1593, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1626, 1628, 1629, 1632, 1638, 1642, 1643, 1646, 1648, 1649, 1650, 1656, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1697, 1698, 1701, 1704, 1707, 1712, 1713, 1714, 1716, 1718, 1720, 1725, 1727, 1729, 1731, 1732, 1734, 1739, 1746, 1747, 1748, 1749, 1756, 1757, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1777, 1783, 1785, 1786, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1802, 1803, 1804, 1808, 1809, 1818, 1824, 1825, 1826, 1828, 1829, 1832, 1833, 1834, 1835, 1842, 1843, 1844, 1845, 1846, 1848, 1850, 1853, 1857, 1860, 1861, 1862, 1864, 1865, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1911, 1912, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1929], "behavior": [0, 2, 3, 8, 16, 18, 21, 29, 32, 37, 39, 41, 42, 43, 45, 47, 48, 51, 56, 59, 63, 67, 68, 70, 71, 254, 319, 470, 511, 541, 614, 684, 782, 790, 823, 875, 889, 932, 936, 949, 1058, 1063, 1066, 1108, 1115, 1116, 1120, 1190, 1200, 1203, 1205, 1235, 1242, 1246, 1259, 1260, 1261, 1276, 1284, 1291, 1359, 1362, 1383, 1392, 1422, 1437, 1461, 1474, 1486, 1521, 1589, 1590, 1593, 1594, 1602, 1603, 1648, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1701, 1707, 1723, 1730, 1772, 1808, 1829, 1843, 1857, 1860, 1864, 1865, 1867, 1869, 1876, 1878, 1884, 1886, 1888, 1889, 1897, 1898, 1899, 1901, 1904, 1905, 1906, 1909, 1910, 1913, 1918, 1921], "dimens": [0, 2, 15, 30, 38, 41, 46, 47, 63, 68, 69, 71, 219, 233, 254, 260, 313, 315, 317, 321, 432, 433, 471, 472, 473, 491, 511, 513, 515, 534, 540, 542, 543, 557, 580, 581, 582, 584, 585, 604, 614, 683, 689, 690, 692, 693, 694, 696, 732, 755, 776, 778, 782, 871, 872, 873, 874, 883, 884, 885, 889, 904, 929, 937, 940, 941, 942, 943, 944, 963, 978, 980, 1042, 1043, 1044, 1045, 1046, 1051, 1052, 1053, 1054, 1055, 1061, 1063, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1102, 1131, 1132, 1143, 1152, 1153, 1164, 1167, 1187, 1210, 1211, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1269, 1270, 1277, 1280, 1284, 1287, 1289, 1290, 1291, 1292, 1295, 1297, 1310, 1317, 1318, 1319, 1320, 1321, 1322, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1351, 1352, 1354, 1355, 1356, 1357, 1358, 1359, 1362, 1364, 1365, 1366, 1368, 1369, 1372, 1373, 1376, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1391, 1392, 1394, 1402, 1403, 1408, 1409, 1410, 1411, 1412, 1413, 1416, 1417, 1421, 1428, 1429, 1430, 1431, 1434, 1435, 1436, 1440, 1441, 1442, 1449, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1467, 1469, 1470, 1471, 1472, 1473, 1486, 1492, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1520, 1521, 1522, 1523, 1532, 1535, 1538, 1539, 1540, 1557, 1558, 1559, 1571, 1577, 1578, 1590, 1609, 1610, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1636, 1637, 1639, 1641, 1643, 1646, 1648, 1649, 1695, 1698, 1705, 1707, 1708, 1709, 1714, 1728, 1729, 1730, 1734, 1743, 1745, 1746, 1756, 1777, 1781, 1784, 1787, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1799, 1801, 1802, 1803, 1804, 1807, 1808, 1817, 1819, 1823, 1824, 1825, 1826, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1838, 1839, 1840, 1841, 1842, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1858, 1859, 1861, 1862, 1863, 1878, 1881, 1884, 1886, 1889, 1890, 1891, 1897, 1906, 1908, 1917, 1918, 1920, 1922, 1923], "govern": [0, 8, 9, 1858, 1908], "few": [0, 2, 8, 9, 15, 17, 20, 21, 22, 23, 29, 39, 43, 49, 1063, 1120, 1366, 1602, 1857, 1863, 1883, 1886, 1888, 1890, 1892, 1897, 1900, 1901, 1904, 1906, 1908, 1911, 1921, 1923, 1925], "factor": [0, 1, 4, 17, 39, 47, 71, 686, 687, 688, 796, 816, 918, 941, 942, 943, 1232, 1233, 1234, 1237, 1239, 1279, 1280, 1281, 1360, 1383, 1410, 1434, 1435, 1562, 1563, 1571, 1675, 1676, 1677, 1679, 1680, 1682, 1684, 1685, 1686, 1687, 1688, 1691, 1692, 1693, 1707, 1765, 1786, 1808, 1881, 1882, 1908], "config": [0, 14, 15, 17, 19, 20, 21, 23, 24, 29, 39, 63, 71, 789, 790, 791, 792, 856, 858, 950, 1887, 1900, 1911], "dynamic_shap": [0, 14, 15, 25, 1655], "true": [0, 1, 2, 3, 4, 6, 14, 15, 17, 19, 20, 21, 22, 24, 28, 29, 32, 38, 39, 41, 42, 43, 45, 46, 47, 49, 60, 63, 68, 69, 70, 71, 151, 197, 210, 260, 319, 321, 328, 329, 330, 331, 332, 333, 335, 336, 337, 338, 339, 340, 341, 342, 343, 351, 396, 400, 402, 447, 457, 459, 470, 476, 486, 493, 494, 502, 514, 515, 553, 564, 577, 578, 587, 591, 600, 606, 614, 677, 684, 689, 690, 691, 692, 693, 694, 696, 715, 716, 717, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 735, 736, 737, 738, 739, 740, 743, 746, 751, 753, 757, 758, 761, 762, 765, 766, 776, 782, 783, 794, 811, 823, 856, 870, 872, 873, 877, 886, 889, 890, 891, 894, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 908, 910, 911, 917, 919, 922, 925, 927, 928, 934, 935, 941, 942, 943, 949, 950, 955, 966, 1004, 1058, 1067, 1068, 1069, 1085, 1086, 1092, 1093, 1116, 1119, 1120, 1121, 1122, 1124, 1125, 1126, 1130, 1131, 1132, 1134, 1146, 1147, 1148, 1151, 1152, 1163, 1165, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1190, 1194, 1195, 1196, 1199, 1205, 1206, 1207, 1209, 1211, 1214, 1219, 1220, 1231, 1232, 1233, 1236, 1237, 1238, 1239, 1242, 1244, 1246, 1247, 1248, 1250, 1251, 1252, 1253, 1255, 1256, 1259, 1261, 1262, 1271, 1272, 1273, 1274, 1277, 1278, 1279, 1281, 1283, 1287, 1289, 1290, 1291, 1292, 1295, 1312, 1317, 1320, 1323, 1326, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1370, 1371, 1374, 1375, 1376, 1377, 1382, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1431, 1436, 1437, 1438, 1439, 1453, 1454, 1461, 1465, 1467, 1468, 1469, 1470, 1471, 1474, 1475, 1486, 1488, 1489, 1490, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1516, 1517, 1521, 1523, 1525, 1531, 1532, 1533, 1545, 1546, 1547, 1556, 1564, 1571, 1590, 1591, 1593, 1602, 1603, 1605, 1606, 1609, 1610, 1613, 1614, 1615, 1627, 1635, 1636, 1637, 1638, 1639, 1641, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1695, 1697, 1705, 1707, 1708, 1712, 1713, 1714, 1731, 1732, 1739, 1742, 1743, 1751, 1752, 1753, 1756, 1758, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1781, 1783, 1785, 1802, 1803, 1804, 1807, 1808, 1822, 1826, 1831, 1840, 1841, 1843, 1844, 1845, 1846, 1850, 1853, 1857, 1859, 1861, 1862, 1863, 1870, 1872, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1897, 1898, 1899, 1901, 1905, 1906, 1907, 1908, 1909, 1910, 1912, 1913, 1914, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1928], "fals": [0, 1, 2, 4, 6, 12, 15, 17, 18, 19, 21, 24, 28, 29, 32, 38, 39, 41, 42, 43, 45, 46, 47, 49, 63, 66, 71, 113, 114, 115, 116, 117, 119, 135, 136, 137, 151, 182, 183, 184, 197, 210, 260, 301, 318, 319, 321, 328, 332, 335, 336, 338, 342, 343, 344, 351, 354, 392, 396, 407, 409, 410, 411, 414, 420, 428, 429, 430, 431, 444, 445, 446, 447, 448, 452, 457, 459, 469, 470, 478, 493, 494, 502, 515, 539, 552, 553, 562, 577, 591, 600, 606, 607, 612, 614, 677, 690, 691, 692, 693, 694, 696, 709, 710, 711, 712, 713, 714, 731, 732, 742, 743, 748, 749, 750, 752, 755, 757, 765, 766, 773, 775, 776, 777, 779, 780, 782, 794, 811, 816, 817, 818, 819, 821, 822, 823, 835, 836, 854, 855, 860, 862, 871, 872, 873, 877, 890, 891, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 914, 917, 919, 922, 925, 927, 928, 934, 935, 941, 942, 943, 949, 950, 955, 966, 1004, 1009, 1021, 1063, 1064, 1065, 1066, 1068, 1069, 1076, 1080, 1081, 1082, 1083, 1088, 1089, 1094, 1095, 1096, 1098, 1099, 1100, 1116, 1117, 1118, 1119, 1121, 1122, 1124, 1125, 1126, 1128, 1130, 1132, 1134, 1146, 1147, 1148, 1151, 1152, 1165, 1175, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1190, 1195, 1196, 1197, 1205, 1206, 1207, 1209, 1211, 1214, 1219, 1220, 1231, 1232, 1233, 1234, 1236, 1237, 1238, 1239, 1242, 1244, 1246, 1247, 1250, 1251, 1252, 1253, 1254, 1259, 1260, 1261, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1281, 1283, 1287, 1289, 1290, 1292, 1295, 1303, 1304, 1312, 1317, 1318, 1319, 1320, 1323, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1356, 1358, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1370, 1371, 1374, 1375, 1376, 1377, 1379, 1380, 1381, 1382, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1407, 1408, 1409, 1413, 1414, 1415, 1416, 1417, 1421, 1422, 1425, 1426, 1427, 1428, 1429, 1431, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1449, 1451, 1453, 1454, 1461, 1464, 1465, 1466, 1467, 1469, 1470, 1471, 1474, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1493, 1494, 1495, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1512, 1513, 1514, 1516, 1517, 1518, 1521, 1523, 1525, 1526, 1527, 1532, 1533, 1536, 1542, 1543, 1545, 1546, 1547, 1551, 1556, 1560, 1564, 1566, 1567, 1569, 1570, 1571, 1572, 1574, 1584, 1587, 1588, 1590, 1602, 1604, 1606, 1609, 1611, 1614, 1615, 1627, 1636, 1637, 1638, 1639, 1641, 1644, 1647, 1648, 1649, 1653, 1654, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1705, 1707, 1708, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1731, 1732, 1739, 1743, 1751, 1752, 1753, 1756, 1758, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1781, 1790, 1791, 1792, 1793, 1794, 1795, 1802, 1803, 1804, 1807, 1808, 1822, 1826, 1831, 1840, 1843, 1844, 1845, 1846, 1853, 1855, 1856, 1857, 1859, 1860, 1861, 1862, 1863, 1869, 1870, 1871, 1872, 1875, 1877, 1878, 1882, 1883, 1886, 1887, 1888, 1890, 1894, 1897, 1898, 1901, 1902, 1905, 1906, 1907, 1909, 1912, 1913, 1917, 1918, 1919, 1921, 1922, 1924, 1925, 1927, 1928], "must": [0, 1, 4, 6, 7, 10, 12, 13, 15, 18, 21, 28, 29, 32, 38, 41, 43, 45, 47, 48, 49, 56, 59, 60, 63, 66, 68, 70, 71, 89, 98, 140, 154, 155, 197, 260, 313, 315, 321, 398, 400, 402, 511, 541, 542, 563, 580, 581, 582, 584, 585, 614, 683, 684, 685, 686, 687, 688, 694, 745, 754, 769, 770, 771, 790, 812, 814, 856, 857, 875, 881, 886, 887, 888, 889, 891, 897, 899, 901, 902, 903, 905, 906, 918, 920, 922, 923, 924, 925, 926, 927, 930, 934, 937, 952, 962, 965, 966, 976, 977, 978, 980, 1006, 1007, 1009, 1051, 1053, 1054, 1055, 1057, 1060, 1061, 1063, 1084, 1085, 1086, 1091, 1093, 1094, 1095, 1096, 1097, 1104, 1105, 1114, 1116, 1119, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1132, 1133, 1143, 1152, 1153, 1156, 1167, 1187, 1190, 1200, 1205, 1212, 1215, 1244, 1245, 1246, 1247, 1253, 1255, 1256, 1259, 1262, 1280, 1282, 1283, 1284, 1290, 1297, 1312, 1318, 1321, 1322, 1326, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1365, 1366, 1369, 1376, 1377, 1383, 1415, 1422, 1425, 1428, 1453, 1459, 1474, 1494, 1503, 1505, 1513, 1532, 1545, 1546, 1547, 1565, 1602, 1625, 1635, 1636, 1642, 1644, 1649, 1657, 1687, 1689, 1696, 1697, 1700, 1701, 1704, 1712, 1713, 1734, 1743, 1746, 1755, 1771, 1782, 1785, 1786, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1804, 1809, 1819, 1823, 1824, 1828, 1833, 1835, 1839, 1843, 1847, 1848, 1850, 1851, 1853, 1860, 1861, 1862, 1863, 1870, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1892, 1896, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1924, 1928], "work": [0, 1, 2, 3, 4, 6, 8, 9, 10, 13, 15, 17, 18, 20, 21, 22, 24, 25, 29, 30, 32, 33, 34, 41, 42, 43, 45, 46, 47, 48, 49, 58, 59, 60, 61, 63, 64, 68, 71, 120, 151, 352, 444, 445, 446, 447, 448, 485, 584, 585, 818, 858, 859, 890, 904, 964, 966, 967, 969, 998, 1009, 1010, 1030, 1064, 1066, 1083, 1103, 1104, 1105, 1120, 1190, 1194, 1201, 1202, 1225, 1226, 1253, 1254, 1262, 1359, 1419, 1422, 1438, 1455, 1559, 1577, 1602, 1659, 1689, 1716, 1720, 1722, 1748, 1754, 1819, 1822, 1857, 1860, 1863, 1864, 1875, 1876, 1877, 1878, 1881, 1883, 1885, 1886, 1887, 1888, 1889, 1891, 1892, 1894, 1896, 1899, 1900, 1901, 1905, 1906, 1908, 1911, 1913, 1914, 1923, 1925, 1928], "rais": [0, 1, 2, 6, 8, 16, 21, 27, 28, 29, 32, 41, 45, 47, 49, 51, 58, 63, 68, 70, 71, 89, 313, 315, 321, 694, 896, 898, 899, 900, 901, 902, 903, 904, 905, 906, 931, 940, 968, 1033, 1106, 1111, 1188, 1190, 1195, 1197, 1205, 1207, 1219, 1221, 1229, 1230, 1233, 1237, 1238, 1243, 1250, 1251, 1255, 1256, 1261, 1282, 1307, 1422, 1571, 1614, 1615, 1620, 1622, 1625, 1635, 1658, 1659, 1745, 1843, 1857, 1864, 1870, 1875, 1883, 1886, 1888, 1890, 1897, 1901, 1905, 1906, 1912, 1913, 1924, 1928], "except": [0, 4, 6, 8, 10, 13, 16, 28, 32, 41, 42, 46, 47, 49, 50, 51, 55, 59, 63, 70, 71, 580, 584, 585, 614, 681, 690, 692, 693, 696, 757, 882, 905, 906, 937, 944, 948, 968, 978, 980, 1008, 1021, 1055, 1061, 1063, 1109, 1110, 1129, 1131, 1153, 1197, 1205, 1207, 1211, 1245, 1261, 1277, 1287, 1289, 1290, 1292, 1295, 1317, 1320, 1322, 1374, 1392, 1437, 1474, 1558, 1602, 1610, 1635, 1642, 1643, 1647, 1649, 1705, 1729, 1745, 1782, 1800, 1802, 1803, 1807, 1829, 1845, 1846, 1850, 1851, 1858, 1860, 1862, 1863, 1864, 1865, 1870, 1875, 1878, 1886, 1888, 1894, 1897, 1900, 1905, 1906, 1913, 1915, 1917, 1919, 1920, 1924], "when": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 14, 15, 16, 18, 19, 21, 23, 24, 28, 29, 32, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 56, 57, 58, 59, 60, 61, 63, 66, 68, 69, 70, 71, 83, 85, 98, 151, 192, 209, 260, 313, 321, 447, 486, 495, 496, 511, 513, 515, 541, 557, 577, 614, 683, 686, 732, 765, 766, 776, 782, 788, 790, 821, 837, 855, 862, 874, 877, 890, 898, 899, 900, 901, 902, 903, 904, 905, 906, 910, 911, 918, 921, 930, 938, 941, 949, 950, 955, 956, 960, 966, 968, 978, 980, 1002, 1008, 1009, 1021, 1046, 1063, 1102, 1106, 1111, 1116, 1120, 1121, 1126, 1129, 1130, 1131, 1143, 1165, 1179, 1180, 1182, 1183, 1186, 1190, 1191, 1193, 1201, 1202, 1203, 1205, 1206, 1210, 1211, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1235, 1236, 1237, 1238, 1239, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1250, 1251, 1253, 1254, 1255, 1259, 1260, 1261, 1262, 1270, 1276, 1279, 1284, 1290, 1291, 1294, 1312, 1317, 1318, 1319, 1330, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1365, 1366, 1369, 1372, 1374, 1375, 1377, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1409, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1436, 1437, 1449, 1450, 1453, 1454, 1455, 1456, 1458, 1461, 1467, 1468, 1469, 1470, 1472, 1473, 1474, 1475, 1476, 1486, 1488, 1489, 1490, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1513, 1519, 1521, 1532, 1533, 1556, 1559, 1561, 1564, 1565, 1571, 1579, 1590, 1591, 1592, 1593, 1598, 1599, 1602, 1603, 1604, 1605, 1609, 1610, 1611, 1612, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1638, 1643, 1647, 1648, 1649, 1650, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1695, 1697, 1704, 1707, 1708, 1730, 1736, 1743, 1748, 1751, 1758, 1776, 1782, 1785, 1787, 1788, 1789, 1799, 1804, 1808, 1817, 1822, 1824, 1829, 1833, 1835, 1840, 1843, 1850, 1853, 1857, 1858, 1860, 1862, 1869, 1871, 1873, 1875, 1876, 1877, 1881, 1884, 1885, 1886, 1887, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1904, 1905, 1906, 1907, 1912, 1913, 1914, 1915, 1918, 1920, 1921, 1922, 1923, 1924], "conjunct": [0, 4, 38, 41, 45, 63, 821, 1486, 1521, 1602, 1911, 1913], "mark_dyam": 0, "eventu": [0, 2, 8, 15, 16, 58, 63, 1857, 1906], "support": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 18, 19, 20, 21, 22, 26, 27, 28, 29, 30, 32, 33, 34, 35, 38, 39, 41, 43, 45, 46, 47, 48, 50, 51, 58, 59, 63, 66, 67, 68, 70, 71, 83, 84, 311, 321, 457, 580, 614, 682, 683, 684, 686, 690, 692, 693, 696, 726, 735, 736, 737, 769, 770, 771, 776, 782, 783, 784, 789, 790, 791, 792, 798, 814, 830, 856, 858, 859, 889, 891, 896, 905, 906, 918, 919, 923, 926, 928, 930, 942, 943, 950, 957, 963, 965, 1006, 1007, 1009, 1026, 1058, 1060, 1063, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1108, 1109, 1110, 1111, 1113, 1114, 1115, 1126, 1130, 1147, 1148, 1160, 1187, 1194, 1201, 1205, 1209, 1210, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1280, 1284, 1288, 1293, 1294, 1311, 1350, 1351, 1352, 1353, 1354, 1355, 1362, 1365, 1366, 1369, 1389, 1409, 1427, 1428, 1461, 1471, 1473, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1513, 1515, 1521, 1532, 1538, 1571, 1589, 1590, 1592, 1602, 1649, 1654, 1656, 1664, 1665, 1667, 1695, 1707, 1726, 1727, 1748, 1751, 1752, 1782, 1785, 1788, 1805, 1808, 1831, 1833, 1835, 1847, 1848, 1849, 1856, 1857, 1858, 1860, 1862, 1864, 1865, 1867, 1871, 1873, 1875, 1879, 1883, 1884, 1885, 1886, 1887, 1888, 1892, 1894, 1896, 1897, 1899, 1900, 1902, 1904, 1905, 1906, 1907, 1911, 1912, 1913, 1918, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1928], "2": [0, 1, 2, 4, 12, 13, 14, 15, 16, 17, 20, 21, 22, 23, 28, 30, 32, 35, 36, 37, 38, 39, 41, 42, 45, 47, 48, 49, 51, 56, 58, 63, 67, 68, 69, 70, 71, 174, 192, 209, 226, 234, 254, 260, 313, 315, 317, 321, 335, 377, 401, 402, 444, 445, 446, 447, 448, 480, 486, 491, 494, 497, 511, 513, 515, 541, 555, 557, 577, 578, 580, 581, 582, 584, 585, 586, 604, 614, 677, 678, 680, 681, 682, 683, 686, 687, 688, 689, 690, 692, 694, 695, 696, 731, 735, 736, 737, 738, 739, 740, 742, 743, 752, 755, 757, 759, 790, 793, 817, 862, 871, 872, 873, 874, 875, 876, 877, 881, 883, 884, 885, 887, 896, 898, 899, 900, 901, 902, 903, 910, 911, 919, 921, 922, 923, 924, 925, 926, 927, 928, 929, 931, 932, 933, 934, 936, 937, 938, 940, 941, 942, 943, 944, 948, 949, 952, 955, 956, 957, 958, 961, 962, 963, 1037, 1042, 1045, 1046, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1073, 1076, 1077, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1119, 1120, 1121, 1124, 1125, 1126, 1130, 1131, 1132, 1133, 1134, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1155, 1156, 1164, 1165, 1167, 1177, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1193, 1194, 1199, 1201, 1203, 1205, 1209, 1210, 1211, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1266, 1267, 1268, 1269, 1276, 1278, 1279, 1280, 1281, 1283, 1284, 1287, 1288, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1307, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1326, 1329, 1334, 1335, 1336, 1337, 1338, 1339, 1344, 1345, 1346, 1347, 1348, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1372, 1373, 1374, 1376, 1378, 1379, 1380, 1381, 1383, 1390, 1391, 1392, 1393, 1394, 1408, 1410, 1411, 1412, 1413, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1424, 1425, 1427, 1428, 1430, 1431, 1433, 1434, 1435, 1436, 1437, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1451, 1452, 1453, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1470, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1486, 1488, 1493, 1494, 1505, 1512, 1513, 1519, 1521, 1523, 1525, 1532, 1538, 1545, 1546, 1547, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1571, 1587, 1593, 1602, 1606, 1609, 1610, 1614, 1626, 1627, 1628, 1629, 1631, 1632, 1635, 1637, 1638, 1640, 1641, 1642, 1643, 1644, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1656, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1686, 1690, 1691, 1692, 1696, 1697, 1698, 1700, 1701, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1718, 1720, 1722, 1723, 1724, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1739, 1743, 1745, 1746, 1747, 1748, 1749, 1750, 1753, 1756, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1777, 1781, 1782, 1783, 1785, 1786, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1802, 1803, 1804, 1805, 1807, 1808, 1809, 1810, 1811, 1817, 1818, 1820, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1855, 1856, 1858, 1859, 1861, 1862, 1863, 1864, 1870, 1871, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1885, 1887, 1888, 1891, 1892, 1894, 1895, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1910, 1911, 1913, 1914, 1915, 1917, 1918, 1920, 1921, 1922, 1923, 1924, 1925, 1927], "fulli": [0, 15, 21, 30, 32, 38, 41, 45, 46, 67, 71, 677, 1026, 1190, 1418, 1419, 1420, 1422, 1859, 1863, 1869, 1888, 1905, 1908], "constrain": [0, 47, 1458, 1863, 1894], "doe": [0, 1, 2, 4, 5, 6, 8, 9, 10, 12, 20, 21, 27, 29, 32, 41, 45, 47, 49, 51, 55, 57, 58, 60, 63, 66, 67, 68, 70, 71, 151, 254, 335, 434, 457, 580, 614, 677, 692, 693, 745, 754, 757, 787, 791, 858, 877, 917, 930, 1000, 1004, 1054, 1063, 1067, 1116, 1119, 1131, 1164, 1189, 1191, 1194, 1200, 1205, 1215, 1220, 1232, 1233, 1237, 1238, 1245, 1251, 1253, 1259, 1262, 1279, 1283, 1284, 1290, 1294, 1298, 1314, 1340, 1341, 1342, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1362, 1365, 1366, 1369, 1374, 1375, 1385, 1386, 1387, 1392, 1393, 1395, 1396, 1397, 1404, 1405, 1406, 1416, 1417, 1423, 1429, 1432, 1437, 1439, 1461, 1473, 1504, 1556, 1602, 1603, 1611, 1614, 1618, 1644, 1647, 1649, 1654, 1658, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1692, 1696, 1701, 1743, 1746, 1747, 1751, 1753, 1777, 1782, 1808, 1828, 1831, 1843, 1850, 1856, 1857, 1858, 1860, 1862, 1863, 1865, 1871, 1875, 1876, 1877, 1878, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1894, 1896, 1897, 1898, 1901, 1905, 1906, 1908, 1913, 1915, 1917, 1920, 1924], "allow": [0, 1, 2, 3, 4, 6, 8, 9, 10, 14, 15, 16, 17, 20, 21, 24, 28, 29, 30, 32, 33, 38, 39, 41, 42, 47, 49, 50, 58, 59, 63, 64, 66, 67, 68, 69, 71, 151, 511, 677, 732, 790, 794, 796, 821, 890, 892, 904, 905, 935, 949, 1006, 1009, 1033, 1063, 1124, 1190, 1195, 1207, 1245, 1267, 1307, 1321, 1335, 1336, 1337, 1358, 1359, 1376, 1415, 1416, 1417, 1422, 1425, 1428, 1450, 1465, 1602, 1607, 1648, 1656, 1660, 1676, 1785, 1843, 1857, 1862, 1863, 1870, 1876, 1877, 1878, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1892, 1893, 1894, 1896, 1897, 1899, 1901, 1904, 1905, 1906, 1907, 1908, 1910, 1913, 1917, 1920, 1921, 1922, 1924], "than": [0, 1, 4, 5, 6, 7, 9, 10, 12, 13, 16, 17, 20, 23, 24, 29, 30, 32, 38, 39, 41, 42, 43, 47, 48, 49, 51, 55, 58, 59, 60, 63, 68, 71, 151, 254, 497, 542, 614, 677, 690, 696, 776, 782, 890, 899, 900, 914, 921, 932, 939, 940, 944, 945, 978, 1016, 1020, 1033, 1051, 1052, 1103, 1104, 1105, 1107, 1111, 1116, 1127, 1134, 1146, 1150, 1164, 1175, 1187, 1188, 1191, 1201, 1210, 1211, 1214, 1219, 1220, 1226, 1230, 1235, 1243, 1244, 1246, 1247, 1250, 1255, 1265, 1278, 1281, 1287, 1290, 1292, 1295, 1307, 1312, 1322, 1338, 1339, 1350, 1351, 1352, 1359, 1365, 1366, 1383, 1414, 1428, 1436, 1453, 1459, 1469, 1470, 1471, 1486, 1496, 1497, 1498, 1512, 1513, 1521, 1532, 1558, 1571, 1589, 1590, 1593, 1602, 1609, 1610, 1611, 1612, 1638, 1643, 1649, 1664, 1665, 1689, 1691, 1705, 1706, 1727, 1728, 1756, 1789, 1790, 1791, 1792, 1794, 1795, 1825, 1833, 1835, 1843, 1857, 1859, 1860, 1862, 1863, 1865, 1877, 1878, 1879, 1881, 1883, 1884, 1886, 1888, 1889, 1890, 1891, 1894, 1896, 1897, 1898, 1899, 1901, 1904, 1905, 1906, 1908, 1909, 1913, 1917, 1918, 1920, 1922, 1923, 1924], "valu": [0, 1, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 17, 21, 23, 28, 29, 30, 32, 35, 38, 39, 42, 43, 45, 47, 49, 50, 52, 55, 56, 58, 59, 63, 65, 68, 70, 71, 89, 102, 103, 104, 105, 120, 151, 155, 222, 235, 236, 237, 238, 254, 259, 260, 272, 273, 299, 311, 313, 315, 316, 317, 318, 319, 321, 323, 326, 352, 399, 400, 418, 419, 421, 422, 470, 480, 482, 511, 513, 515, 534, 541, 557, 580, 581, 582, 584, 585, 596, 597, 677, 678, 681, 684, 685, 688, 692, 693, 694, 732, 753, 761, 767, 768, 776, 781, 782, 784, 790, 792, 793, 796, 799, 816, 817, 818, 819, 822, 823, 824, 851, 856, 862, 871, 872, 873, 877, 882, 886, 888, 890, 892, 893, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 919, 920, 921, 928, 934, 938, 943, 945, 957, 958, 961, 967, 997, 1006, 1007, 1020, 1033, 1042, 1043, 1046, 1054, 1055, 1068, 1077, 1078, 1080, 1082, 1084, 1085, 1086, 1091, 1093, 1094, 1095, 1096, 1097, 1106, 1111, 1117, 1119, 1120, 1121, 1122, 1126, 1127, 1129, 1130, 1132, 1134, 1138, 1139, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1160, 1175, 1180, 1181, 1182, 1183, 1186, 1187, 1188, 1190, 1191, 1193, 1196, 1197, 1205, 1208, 1210, 1211, 1214, 1218, 1219, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1232, 1233, 1234, 1235, 1239, 1242, 1244, 1246, 1247, 1249, 1253, 1254, 1259, 1260, 1261, 1262, 1265, 1270, 1276, 1278, 1279, 1282, 1287, 1289, 1290, 1292, 1295, 1307, 1310, 1312, 1316, 1317, 1318, 1319, 1322, 1323, 1326, 1330, 1335, 1336, 1337, 1338, 1340, 1341, 1342, 1343, 1344, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1364, 1365, 1366, 1367, 1369, 1376, 1377, 1378, 1381, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1407, 1408, 1409, 1412, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1436, 1450, 1453, 1455, 1456, 1457, 1458, 1459, 1461, 1464, 1465, 1467, 1469, 1470, 1471, 1473, 1474, 1493, 1494, 1496, 1497, 1498, 1503, 1504, 1513, 1514, 1518, 1521, 1523, 1532, 1533, 1534, 1545, 1546, 1547, 1556, 1557, 1558, 1559, 1561, 1564, 1571, 1584, 1585, 1590, 1592, 1593, 1595, 1597, 1600, 1601, 1602, 1607, 1609, 1610, 1611, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1628, 1629, 1635, 1638, 1639, 1642, 1644, 1648, 1649, 1653, 1654, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1683, 1689, 1697, 1701, 1704, 1708, 1710, 1711, 1723, 1725, 1727, 1728, 1729, 1734, 1735, 1736, 1743, 1746, 1756, 1759, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1777, 1781, 1785, 1786, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1804, 1808, 1809, 1819, 1823, 1826, 1829, 1832, 1833, 1834, 1835, 1837, 1840, 1841, 1842, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1864, 1870, 1872, 1873, 1875, 1878, 1881, 1882, 1883, 1885, 1886, 1888, 1889, 1890, 1891, 1892, 1894, 1898, 1899, 1901, 1903, 1904, 1905, 1907, 1908, 1911, 1912, 1913, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1927], "both": [0, 2, 3, 4, 12, 14, 15, 16, 17, 18, 20, 21, 22, 25, 26, 29, 32, 38, 39, 41, 42, 43, 46, 47, 51, 56, 57, 58, 59, 63, 70, 71, 98, 339, 726, 765, 766, 769, 770, 771, 790, 848, 889, 893, 899, 900, 901, 902, 903, 918, 962, 987, 1058, 1079, 1109, 1110, 1111, 1119, 1133, 1135, 1143, 1150, 1167, 1180, 1181, 1187, 1190, 1203, 1211, 1212, 1260, 1276, 1284, 1290, 1303, 1304, 1335, 1336, 1340, 1341, 1342, 1347, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1377, 1383, 1385, 1386, 1387, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1415, 1416, 1417, 1422, 1428, 1461, 1473, 1474, 1477, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1545, 1546, 1547, 1571, 1602, 1614, 1644, 1664, 1665, 1689, 1712, 1713, 1782, 1783, 1785, 1804, 1808, 1828, 1829, 1860, 1862, 1863, 1870, 1876, 1877, 1879, 1882, 1883, 1884, 1888, 1889, 1891, 1894, 1897, 1898, 1899, 1901, 1905, 1906, 1908, 1911, 1913, 1915, 1917, 1918, 1924, 1926, 1927], "eager": [0, 2, 9, 12, 15, 17, 18, 20, 25, 29, 1038, 1188, 1191, 1201, 1755, 1863, 1886, 1907, 1909, 1911], "compil": [0, 12, 13, 14, 15, 16, 18, 20, 23, 24, 25, 26, 32, 33, 63, 64, 71, 677, 965, 990, 994, 1006, 1007, 1120, 1188, 1190, 1191, 1194, 1195, 1201, 1202, 1203, 1205, 1206, 1207, 1422, 1859, 1860, 1862, 1863, 1864, 1865, 1869, 1882, 1885, 1887, 1893, 1900, 1901, 1925], "mode": [0, 5, 9, 14, 15, 16, 17, 18, 19, 20, 22, 29, 38, 39, 41, 43, 47, 58, 60, 68, 69, 71, 222, 223, 743, 744, 769, 770, 771, 776, 782, 783, 784, 812, 814, 820, 823, 856, 857, 886, 888, 891, 892, 893, 898, 899, 900, 901, 905, 917, 950, 964, 997, 1037, 1038, 1067, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1120, 1123, 1124, 1125, 1126, 1129, 1130, 1138, 1165, 1173, 1174, 1188, 1190, 1191, 1194, 1205, 1207, 1248, 1261, 1291, 1303, 1304, 1340, 1341, 1342, 1350, 1351, 1352, 1366, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1438, 1461, 1474, 1475, 1496, 1497, 1498, 1513, 1521, 1532, 1559, 1590, 1591, 1592, 1603, 1610, 1614, 1647, 1683, 1691, 1707, 1750, 1752, 1753, 1843, 1858, 1861, 1871, 1876, 1881, 1886, 1887, 1889, 1890, 1894, 1903, 1907, 1909, 1910, 1911, 1913, 1925, 1928], "export": [0, 15, 22, 28, 33, 35, 41, 48, 61, 88, 913, 966, 1193, 1195, 1201, 1207, 1636, 1637, 1655, 1656, 1657, 1659, 1660, 1858, 1860, 1862, 1863, 1888, 1902, 1903, 1907, 1908, 1913], "error": [0, 1, 2, 6, 9, 12, 16, 20, 27, 32, 34, 35, 38, 39, 41, 42, 44, 47, 56, 58, 59, 63, 66, 68, 70, 71, 83, 84, 191, 222, 313, 315, 321, 323, 328, 542, 553, 611, 614, 677, 816, 862, 875, 877, 896, 898, 899, 900, 901, 902, 903, 904, 974, 1009, 1020, 1033, 1037, 1061, 1119, 1123, 1124, 1126, 1131, 1153, 1190, 1195, 1204, 1219, 1220, 1229, 1231, 1233, 1236, 1237, 1238, 1248, 1251, 1261, 1279, 1307, 1312, 1338, 1339, 1372, 1383, 1389, 1413, 1422, 1451, 1453, 1519, 1530, 1552, 1571, 1574, 1575, 1602, 1604, 1605, 1606, 1644, 1649, 1659, 1660, 1703, 1743, 1750, 1799, 1804, 1843, 1850, 1851, 1857, 1858, 1860, 1862, 1863, 1869, 1870, 1875, 1876, 1877, 1878, 1882, 1883, 1886, 1888, 1889, 1891, 1892, 1898, 1901, 1905, 1911, 1913, 1918, 1923, 1924, 1926, 1927], "3": [0, 1, 2, 4, 5, 7, 10, 12, 14, 17, 20, 21, 23, 25, 27, 28, 29, 30, 35, 36, 38, 39, 41, 43, 45, 47, 48, 49, 51, 56, 58, 63, 65, 67, 68, 69, 70, 71, 192, 209, 254, 260, 289, 313, 315, 317, 321, 401, 402, 444, 445, 446, 447, 448, 470, 486, 491, 494, 497, 511, 513, 515, 534, 541, 555, 557, 578, 580, 581, 582, 584, 585, 604, 614, 677, 678, 682, 683, 684, 685, 686, 687, 688, 689, 690, 694, 695, 696, 731, 735, 736, 737, 738, 739, 740, 743, 745, 754, 757, 758, 759, 760, 762, 769, 770, 771, 782, 790, 821, 858, 859, 862, 872, 873, 875, 876, 877, 884, 885, 898, 899, 900, 901, 902, 903, 918, 920, 921, 922, 923, 924, 925, 926, 927, 929, 930, 931, 932, 933, 934, 936, 937, 938, 940, 941, 942, 943, 944, 948, 949, 952, 955, 956, 961, 962, 963, 1006, 1007, 1009, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1076, 1079, 1084, 1087, 1091, 1097, 1102, 1103, 1104, 1105, 1106, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1119, 1121, 1126, 1127, 1129, 1131, 1132, 1133, 1134, 1143, 1146, 1149, 1150, 1151, 1152, 1153, 1155, 1156, 1164, 1165, 1167, 1175, 1177, 1179, 1181, 1190, 1194, 1196, 1199, 1201, 1205, 1206, 1210, 1211, 1212, 1213, 1214, 1215, 1219, 1221, 1222, 1223, 1225, 1226, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1267, 1270, 1272, 1276, 1277, 1278, 1279, 1280, 1281, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1296, 1297, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1320, 1321, 1322, 1323, 1335, 1336, 1337, 1338, 1339, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1354, 1355, 1358, 1365, 1366, 1369, 1370, 1371, 1372, 1374, 1375, 1377, 1379, 1380, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1425, 1427, 1429, 1434, 1435, 1437, 1439, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1455, 1456, 1457, 1461, 1469, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1486, 1488, 1493, 1494, 1497, 1498, 1500, 1501, 1504, 1512, 1513, 1516, 1517, 1519, 1521, 1525, 1526, 1532, 1540, 1556, 1558, 1559, 1562, 1563, 1569, 1570, 1577, 1578, 1590, 1602, 1610, 1624, 1626, 1628, 1629, 1630, 1631, 1635, 1637, 1638, 1639, 1640, 1643, 1648, 1649, 1650, 1652, 1653, 1654, 1656, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1686, 1689, 1690, 1692, 1696, 1698, 1700, 1704, 1705, 1707, 1708, 1711, 1712, 1713, 1714, 1715, 1716, 1718, 1720, 1722, 1723, 1724, 1727, 1728, 1729, 1730, 1731, 1732, 1734, 1735, 1736, 1739, 1743, 1747, 1748, 1749, 1756, 1759, 1761, 1763, 1765, 1766, 1767, 1771, 1772, 1773, 1781, 1783, 1785, 1786, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1799, 1807, 1808, 1810, 1811, 1817, 1818, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1847, 1850, 1851, 1852, 1853, 1855, 1856, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1870, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1891, 1894, 1895, 1899, 1900, 1901, 1904, 1905, 1908, 1910, 1913, 1914, 1915, 1917, 1918, 1920, 1921, 1922, 1923, 1924, 1925], "partial": [0, 20, 24, 47, 49, 58, 63, 66, 71, 838, 1009, 1053, 1130, 1143, 1236, 1237, 1238, 1280, 1418, 1419, 1420, 1548, 1549, 1550, 1602, 1621, 1788, 1863, 1864, 1877, 1883, 1888, 1891, 1901, 1915, 1924], "least": [0, 2, 6, 7, 9, 17, 29, 39, 43, 47, 57, 58, 63, 260, 402, 694, 921, 1051, 1053, 1054, 1063, 1104, 1105, 1143, 1151, 1152, 1187, 1212, 1235, 1262, 1284, 1316, 1330, 1602, 1636, 1857, 1863, 1877, 1881, 1883, 1884, 1886, 1890, 1906, 1909, 1915, 1917, 1918, 1919, 1924], "full": [0, 4, 8, 9, 14, 17, 19, 21, 22, 23, 29, 33, 38, 39, 41, 45, 47, 58, 61, 63, 64, 68, 71, 511, 897, 919, 928, 950, 1091, 1092, 1093, 1097, 1098, 1100, 1118, 1130, 1131, 1147, 1148, 1194, 1227, 1228, 1235, 1236, 1237, 1248, 1253, 1254, 1262, 1279, 1339, 1345, 1376, 1436, 1465, 1496, 1497, 1498, 1505, 1518, 1564, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1756, 1808, 1809, 1850, 1857, 1859, 1860, 1861, 1862, 1863, 1865, 1877, 1882, 1886, 1887, 1888, 1891, 1894, 1897, 1898, 1903, 1905, 1908, 1911, 1914, 1921, 1924], "unbound": 0, "rang": [0, 1, 2, 4, 13, 15, 21, 29, 38, 41, 42, 45, 47, 58, 59, 61, 67, 71, 89, 301, 480, 681, 758, 760, 762, 792, 816, 817, 818, 819, 820, 822, 823, 824, 882, 920, 945, 1024, 1025, 1033, 1063, 1113, 1129, 1150, 1151, 1152, 1256, 1267, 1282, 1291, 1307, 1319, 1330, 1358, 1368, 1370, 1371, 1375, 1381, 1393, 1412, 1424, 1429, 1433, 1439, 1455, 1456, 1457, 1461, 1516, 1517, 1521, 1577, 1602, 1607, 1679, 1680, 1682, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1708, 1787, 1842, 1860, 1861, 1863, 1883, 1885, 1886, 1890, 1894, 1896, 1897, 1901, 1903, 1904, 1907, 1908, 1911, 1912, 1918, 1920, 1922, 1923, 1924, 1925], "shape": [0, 2, 9, 14, 17, 19, 22, 28, 29, 30, 39, 41, 47, 63, 65, 67, 69, 71, 98, 172, 192, 209, 219, 400, 402, 444, 446, 448, 470, 495, 496, 511, 513, 515, 541, 563, 614, 677, 682, 684, 685, 694, 732, 742, 743, 753, 755, 757, 761, 763, 764, 765, 766, 769, 770, 771, 778, 793, 875, 881, 895, 899, 901, 902, 903, 914, 920, 921, 923, 926, 931, 933, 937, 938, 950, 957, 979, 1053, 1054, 1055, 1057, 1058, 1063, 1064, 1066, 1068, 1083, 1084, 1085, 1086, 1094, 1095, 1096, 1102, 1108, 1109, 1110, 1111, 1117, 1124, 1125, 1129, 1130, 1131, 1132, 1134, 1146, 1151, 1152, 1156, 1164, 1167, 1181, 1187, 1203, 1205, 1206, 1209, 1214, 1215, 1219, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1278, 1279, 1283, 1291, 1296, 1297, 1311, 1312, 1323, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1488, 1489, 1490, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1512, 1513, 1517, 1521, 1523, 1532, 1533, 1538, 1545, 1546, 1547, 1557, 1558, 1561, 1562, 1563, 1565, 1571, 1590, 1593, 1602, 1604, 1605, 1609, 1611, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1650, 1653, 1658, 1660, 1695, 1704, 1708, 1712, 1713, 1716, 1718, 1719, 1720, 1727, 1729, 1730, 1734, 1743, 1746, 1771, 1785, 1786, 1788, 1791, 1793, 1799, 1804, 1805, 1808, 1818, 1825, 1829, 1839, 1840, 1841, 1850, 1853, 1855, 1858, 1859, 1860, 1861, 1863, 1876, 1877, 1878, 1883, 1884, 1886, 1888, 1889, 1890, 1902, 1903, 1907, 1910, 1913, 1917, 1918, 1922, 1923, 1924, 1925], "pass": [0, 1, 2, 4, 6, 7, 8, 13, 16, 17, 19, 21, 22, 25, 29, 32, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 51, 55, 56, 57, 58, 59, 60, 61, 63, 65, 67, 68, 70, 71, 151, 254, 447, 511, 513, 515, 541, 557, 790, 791, 820, 823, 856, 858, 877, 886, 887, 888, 889, 890, 896, 904, 934, 950, 964, 998, 1009, 1053, 1084, 1085, 1086, 1094, 1095, 1096, 1102, 1116, 1119, 1120, 1124, 1125, 1126, 1129, 1130, 1152, 1188, 1190, 1191, 1194, 1199, 1201, 1205, 1206, 1234, 1250, 1252, 1261, 1307, 1330, 1331, 1332, 1333, 1341, 1359, 1365, 1366, 1370, 1371, 1422, 1427, 1428, 1450, 1466, 1467, 1468, 1469, 1474, 1486, 1516, 1517, 1521, 1532, 1533, 1559, 1571, 1593, 1596, 1597, 1598, 1599, 1602, 1612, 1614, 1616, 1621, 1635, 1638, 1642, 1644, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1739, 1743, 1747, 1808, 1857, 1860, 1864, 1867, 1871, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1885, 1887, 1888, 1889, 1891, 1893, 1894, 1897, 1901, 1902, 1904, 1905, 1906, 1913, 1915, 1917, 1918, 1920, 1922, 1923, 1924, 1927, 1928], "through": [0, 1, 6, 8, 10, 12, 13, 15, 16, 17, 18, 21, 26, 28, 29, 33, 38, 41, 43, 47, 51, 63, 68, 70, 71, 494, 789, 837, 851, 858, 859, 896, 905, 906, 971, 1009, 1090, 1123, 1131, 1188, 1191, 1193, 1205, 1206, 1208, 1225, 1226, 1247, 1253, 1270, 1429, 1466, 1467, 1468, 1469, 1523, 1593, 1602, 1614, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1707, 1850, 1857, 1858, 1862, 1863, 1867, 1869, 1873, 1875, 1876, 1877, 1883, 1886, 1888, 1890, 1891, 1893, 1894, 1900, 1901, 1905, 1906, 1908, 1911, 1913, 1914, 1915, 1917, 1921, 1925, 1927, 1929], "4": [0, 2, 4, 12, 14, 15, 17, 21, 29, 30, 35, 36, 38, 39, 41, 43, 45, 47, 48, 49, 56, 58, 68, 71, 192, 209, 242, 254, 289, 311, 313, 315, 317, 321, 401, 402, 444, 445, 470, 482, 486, 491, 494, 497, 511, 515, 534, 541, 553, 555, 557, 581, 582, 604, 614, 680, 681, 682, 683, 686, 688, 689, 690, 692, 693, 694, 696, 736, 738, 739, 740, 743, 745, 754, 757, 770, 771, 821, 862, 871, 872, 873, 877, 878, 879, 880, 881, 882, 884, 885, 896, 898, 901, 902, 903, 918, 921, 924, 928, 929, 930, 934, 936, 939, 940, 943, 944, 945, 948, 952, 957, 958, 959, 960, 963, 1043, 1046, 1053, 1055, 1057, 1058, 1061, 1062, 1063, 1066, 1068, 1078, 1079, 1081, 1083, 1091, 1097, 1099, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1111, 1113, 1114, 1116, 1119, 1121, 1129, 1130, 1131, 1132, 1133, 1134, 1143, 1146, 1150, 1151, 1152, 1153, 1155, 1156, 1160, 1164, 1167, 1179, 1181, 1187, 1196, 1201, 1203, 1210, 1211, 1212, 1213, 1214, 1215, 1219, 1221, 1222, 1228, 1230, 1232, 1233, 1234, 1237, 1239, 1242, 1244, 1246, 1248, 1250, 1252, 1255, 1256, 1257, 1259, 1260, 1263, 1265, 1266, 1271, 1273, 1274, 1276, 1278, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1310, 1311, 1312, 1320, 1321, 1322, 1323, 1330, 1335, 1346, 1347, 1348, 1351, 1352, 1354, 1355, 1363, 1365, 1366, 1367, 1369, 1373, 1374, 1392, 1393, 1418, 1419, 1425, 1427, 1429, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1447, 1461, 1473, 1474, 1475, 1476, 1477, 1478, 1486, 1488, 1497, 1500, 1512, 1513, 1521, 1532, 1556, 1559, 1562, 1563, 1589, 1590, 1591, 1592, 1593, 1602, 1609, 1614, 1625, 1637, 1638, 1640, 1642, 1648, 1649, 1650, 1652, 1654, 1656, 1661, 1674, 1679, 1680, 1686, 1690, 1691, 1692, 1696, 1700, 1701, 1704, 1705, 1707, 1708, 1710, 1714, 1716, 1718, 1720, 1722, 1723, 1724, 1725, 1726, 1727, 1729, 1730, 1734, 1735, 1736, 1738, 1739, 1743, 1756, 1763, 1765, 1766, 1771, 1772, 1774, 1776, 1781, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1804, 1807, 1810, 1811, 1818, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1829, 1832, 1833, 1834, 1835, 1837, 1838, 1839, 1841, 1842, 1843, 1844, 1847, 1848, 1849, 1850, 1851, 1852, 1856, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1870, 1875, 1877, 1878, 1881, 1883, 1884, 1886, 1887, 1888, 1894, 1896, 1899, 1900, 1901, 1905, 1906, 1908, 1910, 1913, 1917, 1918, 1920, 1921, 1922, 1923, 1924], "attempt": [0, 1, 2, 9, 15, 16, 17, 29, 32, 41, 58, 59, 68, 944, 958, 1194, 1200, 1279, 1571, 1604, 1605, 1664, 1665, 1843, 1860, 1863, 1876, 1877, 1882, 1886, 1888, 1900, 1904, 1905, 1913], "explicitli": [0, 1, 9, 15, 32, 41, 46, 51, 63, 1000, 1051, 1053, 1063, 1152, 1230, 1243, 1247, 1255, 1297, 1532, 1590, 1689, 1804, 1860, 1862, 1863, 1864, 1869, 1886, 1888, 1891, 1893, 1899, 1901, 1905, 1906, 1912, 1913, 1917], "As": [0, 1, 2, 9, 13, 18, 21, 27, 29, 39, 41, 43, 47, 63, 66, 67, 71, 254, 932, 1063, 1194, 1221, 1225, 1226, 1236, 1237, 1248, 1253, 1361, 1362, 1363, 1367, 1388, 1422, 1453, 1589, 1648, 1654, 1856, 1860, 1862, 1863, 1870, 1878, 1883, 1886, 1888, 1890, 1894, 1897, 1900, 1901, 1905, 1906, 1912, 1913, 1914, 1915, 1917, 1925], "all": [0, 1, 2, 3, 4, 6, 7, 8, 10, 12, 13, 15, 16, 17, 18, 20, 21, 24, 25, 27, 28, 29, 30, 32, 33, 35, 38, 39, 41, 42, 43, 45, 47, 49, 51, 55, 56, 57, 58, 59, 60, 61, 63, 66, 68, 69, 70, 71, 76, 89, 151, 260, 313, 315, 321, 335, 485, 511, 513, 515, 543, 557, 604, 607, 614, 677, 683, 684, 689, 691, 695, 696, 732, 757, 788, 790, 791, 811, 837, 851, 855, 858, 871, 874, 886, 887, 888, 890, 891, 894, 895, 896, 898, 899, 900, 901, 902, 903, 904, 905, 906, 914, 915, 916, 920, 929, 931, 936, 937, 941, 944, 945, 949, 961, 966, 967, 969, 970, 978, 979, 988, 996, 1000, 1006, 1010, 1011, 1019, 1020, 1027, 1028, 1030, 1031, 1035, 1037, 1039, 1080, 1081, 1082, 1083, 1086, 1089, 1090, 1093, 1096, 1098, 1100, 1116, 1119, 1120, 1126, 1127, 1129, 1130, 1132, 1152, 1155, 1186, 1187, 1190, 1197, 1200, 1201, 1204, 1205, 1225, 1252, 1261, 1277, 1279, 1287, 1289, 1292, 1300, 1309, 1317, 1318, 1319, 1320, 1330, 1337, 1339, 1343, 1345, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1365, 1366, 1369, 1374, 1375, 1376, 1377, 1382, 1388, 1389, 1392, 1393, 1409, 1413, 1417, 1418, 1419, 1420, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1432, 1433, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1461, 1465, 1467, 1469, 1470, 1473, 1478, 1479, 1486, 1492, 1494, 1512, 1513, 1518, 1523, 1542, 1543, 1571, 1577, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1606, 1609, 1614, 1621, 1625, 1635, 1639, 1647, 1648, 1649, 1650, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1683, 1686, 1687, 1690, 1691, 1692, 1693, 1705, 1783, 1787, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1801, 1802, 1803, 1804, 1807, 1823, 1825, 1832, 1833, 1834, 1835, 1838, 1841, 1845, 1846, 1848, 1852, 1857, 1860, 1861, 1862, 1863, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1894, 1896, 1897, 1898, 1899, 1900, 1902, 1903, 1905, 1906, 1907, 1908, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1922, 1924, 1925, 1926, 1927, 1928], "call": [0, 1, 2, 3, 4, 9, 13, 15, 16, 17, 18, 19, 21, 23, 24, 28, 29, 30, 32, 33, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 58, 60, 63, 64, 65, 67, 68, 69, 70, 71, 76, 151, 290, 323, 335, 457, 485, 486, 553, 577, 611, 614, 694, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 778, 787, 794, 821, 854, 858, 859, 890, 894, 895, 896, 897, 898, 900, 901, 904, 910, 911, 933, 950, 964, 967, 969, 998, 1000, 1010, 1011, 1020, 1027, 1028, 1030, 1031, 1061, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1119, 1120, 1131, 1135, 1153, 1165, 1175, 1190, 1193, 1195, 1200, 1201, 1202, 1209, 1245, 1253, 1257, 1259, 1261, 1262, 1291, 1334, 1340, 1341, 1342, 1359, 1360, 1361, 1362, 1363, 1365, 1367, 1369, 1407, 1418, 1419, 1420, 1422, 1429, 1430, 1450, 1461, 1473, 1499, 1500, 1501, 1507, 1508, 1509, 1514, 1532, 1571, 1590, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1611, 1614, 1621, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1637, 1643, 1644, 1646, 1647, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1720, 1747, 1754, 1755, 1783, 1802, 1803, 1804, 1824, 1843, 1845, 1846, 1850, 1851, 1857, 1860, 1864, 1867, 1873, 1875, 1877, 1878, 1879, 1882, 1883, 1885, 1886, 1887, 1888, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1900, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1926, 1928, 1929], "made": [0, 10, 12, 15, 21, 29, 43, 45, 46, 59, 71, 896, 906, 1190, 1422, 1467, 1469, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1724, 1862, 1870, 1883, 1900, 1905, 1922, 1924, 1928], "befor": [0, 1, 2, 4, 7, 8, 12, 13, 15, 16, 18, 21, 24, 26, 29, 32, 35, 38, 39, 41, 42, 43, 45, 46, 47, 50, 55, 57, 58, 59, 60, 63, 71, 98, 151, 744, 757, 785, 786, 787, 890, 894, 896, 948, 966, 1044, 1045, 1046, 1055, 1063, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1104, 1105, 1108, 1116, 1119, 1190, 1201, 1203, 1242, 1246, 1259, 1289, 1317, 1320, 1359, 1365, 1366, 1369, 1374, 1422, 1423, 1424, 1461, 1465, 1473, 1521, 1540, 1577, 1578, 1593, 1596, 1597, 1598, 1599, 1602, 1610, 1643, 1646, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1691, 1705, 1708, 1734, 1743, 1754, 1755, 1784, 1787, 1790, 1791, 1792, 1794, 1795, 1804, 1807, 1829, 1840, 1860, 1862, 1863, 1875, 1882, 1883, 1886, 1887, 1888, 1891, 1893, 1894, 1897, 1899, 1900, 1904, 1905, 1906, 1908, 1913, 1914, 1915, 1917, 1918, 1922, 1924], "mark_stat": [0, 1858], "none": [0, 1, 2, 3, 4, 6, 13, 19, 21, 29, 32, 35, 38, 39, 41, 42, 43, 45, 46, 47, 49, 51, 55, 56, 58, 60, 63, 67, 68, 69, 70, 71, 113, 115, 116, 117, 119, 135, 136, 139, 151, 154, 155, 157, 174, 186, 187, 188, 189, 205, 206, 208, 210, 213, 214, 215, 216, 230, 235, 236, 237, 238, 258, 286, 290, 301, 335, 351, 354, 377, 407, 409, 410, 411, 414, 420, 426, 427, 428, 429, 430, 431, 444, 445, 446, 447, 448, 452, 453, 469, 478, 480, 486, 492, 501, 511, 518, 534, 535, 549, 550, 552, 553, 562, 577, 578, 580, 585, 587, 600, 605, 606, 607, 612, 623, 625, 627, 629, 631, 633, 635, 637, 639, 641, 643, 645, 647, 649, 652, 654, 656, 657, 659, 661, 663, 665, 667, 669, 671, 673, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 692, 693, 694, 695, 696, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 746, 747, 748, 749, 750, 751, 752, 763, 764, 765, 766, 776, 777, 778, 779, 780, 782, 783, 784, 785, 786, 790, 791, 792, 794, 796, 811, 814, 816, 817, 818, 819, 822, 823, 835, 836, 837, 854, 855, 856, 857, 858, 859, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 875, 876, 877, 878, 879, 880, 881, 882, 886, 887, 888, 889, 890, 891, 892, 893, 896, 897, 899, 901, 902, 903, 904, 905, 906, 910, 911, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 934, 937, 939, 940, 941, 942, 943, 945, 946, 948, 950, 952, 953, 954, 956, 957, 959, 960, 961, 962, 963, 964, 966, 967, 969, 970, 971, 975, 976, 978, 979, 980, 983, 984, 985, 991, 992, 998, 1008, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1033, 1036, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1055, 1056, 1058, 1059, 1060, 1062, 1064, 1065, 1066, 1068, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1117, 1118, 1119, 1120, 1121, 1125, 1128, 1129, 1131, 1132, 1133, 1134, 1135, 1136, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1161, 1162, 1163, 1164, 1167, 1168, 1184, 1185, 1187, 1189, 1190, 1194, 1197, 1199, 1200, 1201, 1203, 1205, 1206, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1283, 1284, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1325, 1326, 1328, 1329, 1330, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1365, 1366, 1368, 1370, 1371, 1372, 1375, 1376, 1377, 1381, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1432, 1433, 1436, 1438, 1439, 1453, 1454, 1455, 1456, 1457, 1461, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1474, 1475, 1476, 1481, 1482, 1486, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1504, 1505, 1512, 1513, 1516, 1517, 1518, 1519, 1521, 1522, 1529, 1531, 1532, 1533, 1534, 1535, 1538, 1540, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1552, 1553, 1554, 1555, 1556, 1557, 1559, 1561, 1564, 1571, 1575, 1576, 1577, 1578, 1586, 1587, 1588, 1590, 1591, 1592, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1604, 1605, 1606, 1607, 1609, 1610, 1613, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1635, 1637, 1638, 1639, 1640, 1643, 1644, 1646, 1648, 1649, 1650, 1651, 1653, 1654, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1695, 1696, 1697, 1700, 1701, 1702, 1704, 1705, 1707, 1708, 1711, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1726, 1727, 1728, 1729, 1734, 1736, 1737, 1738, 1743, 1756, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1780, 1781, 1784, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1819, 1820, 1821, 1822, 1824, 1826, 1829, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1840, 1841, 1844, 1845, 1846, 1847, 1850, 1852, 1853, 1854, 1855, 1856, 1857, 1859, 1860, 1861, 1862, 1863, 1864, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1881, 1883, 1886, 1888, 1889, 1894, 1896, 1899, 1901, 1905, 1906, 1907, 1908, 1910, 1912, 1913, 1918, 1919, 1920, 1922, 1924, 1926, 1927, 1928], "static": [0, 2, 4, 9, 12, 14, 15, 21, 32, 42, 47, 49, 63, 791, 812, 814, 823, 829, 854, 856, 858, 886, 887, 888, 889, 1203, 1465, 1602, 1783, 1860, 1861, 1862, 1863, 1886, 1893, 1902, 1906, 1909, 1913, 1919], "prevent": [0, 1, 8, 9, 12, 16, 18, 21, 38, 39, 41, 42, 49, 63, 71, 732, 896, 966, 1044, 1045, 1187, 1289, 1317, 1320, 1360, 1428, 1453, 1540, 1577, 1578, 1593, 1602, 1705, 1784, 1787, 1807, 1833, 1835, 1843, 1875, 1882, 1883, 1886, 1887, 1890, 1894, 1905, 1907, 1915, 1917, 1918], "u": [0, 8, 9, 15, 17, 21, 23, 29, 64, 69, 71, 757, 898, 941, 942, 943, 1226, 1228, 1232, 1236, 1237, 1253, 1279, 1281, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1374, 1375, 1392, 1393, 1407, 1409, 1437, 1439, 1440, 1461, 1472, 1614, 1697, 1808, 1809, 1859, 1860, 1861, 1870, 1877, 1881, 1883, 1886, 1887, 1888, 1889, 1894, 1905, 1907, 1917, 1921, 1922], "from": [0, 1, 2, 4, 6, 7, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 21, 22, 25, 27, 28, 29, 32, 33, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 55, 56, 58, 60, 61, 63, 64, 66, 68, 69, 70, 89, 154, 155, 174, 197, 222, 223, 258, 286, 313, 315, 319, 321, 377, 402, 447, 453, 470, 472, 473, 480, 485, 486, 491, 511, 513, 515, 541, 543, 557, 577, 604, 605, 607, 614, 677, 709, 710, 711, 712, 713, 714, 717, 725, 726, 729, 732, 735, 736, 737, 738, 739, 740, 742, 743, 753, 757, 761, 769, 770, 771, 778, 785, 786, 789, 790, 791, 794, 797, 812, 813, 814, 821, 823, 837, 851, 855, 857, 858, 859, 861, 862, 876, 877, 888, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 905, 906, 910, 911, 919, 920, 928, 929, 934, 935, 947, 965, 966, 969, 978, 979, 980, 998, 1002, 1020, 1047, 1063, 1083, 1085, 1086, 1091, 1092, 1093, 1097, 1098, 1099, 1100, 1103, 1104, 1105, 1114, 1115, 1116, 1117, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1147, 1148, 1152, 1167, 1187, 1188, 1190, 1191, 1193, 1195, 1196, 1197, 1200, 1201, 1213, 1229, 1233, 1242, 1245, 1246, 1259, 1260, 1261, 1262, 1276, 1280, 1281, 1294, 1299, 1303, 1304, 1305, 1307, 1312, 1321, 1322, 1330, 1334, 1340, 1341, 1342, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1359, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1374, 1375, 1376, 1377, 1383, 1385, 1386, 1387, 1388, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1422, 1423, 1424, 1428, 1432, 1433, 1437, 1439, 1440, 1461, 1466, 1467, 1471, 1473, 1474, 1486, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1518, 1521, 1523, 1532, 1545, 1546, 1547, 1559, 1589, 1593, 1602, 1606, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1627, 1629, 1632, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1646, 1650, 1656, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1697, 1700, 1708, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1729, 1730, 1733, 1735, 1736, 1743, 1756, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1804, 1805, 1809, 1819, 1822, 1831, 1833, 1835, 1840, 1841, 1843, 1844, 1853, 1858, 1860, 1861, 1862, 1863, 1865, 1867, 1869, 1870, 1871, 1872, 1873, 1875, 1877, 1878, 1879, 1881, 1883, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1904, 1906, 1907, 1908, 1909, 1913, 1914, 1915, 1917, 1918, 1920, 1922, 1923, 1924, 1925, 1926, 1927, 1928], "can": [0, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 26, 28, 29, 30, 32, 33, 34, 35, 36, 37, 38, 39, 41, 43, 45, 46, 47, 49, 50, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 67, 68, 69, 70, 71, 83, 84, 151, 155, 254, 323, 335, 457, 486, 511, 513, 542, 611, 614, 677, 684, 726, 738, 739, 740, 745, 754, 755, 757, 765, 766, 769, 770, 771, 782, 788, 789, 790, 791, 794, 796, 811, 817, 820, 821, 823, 834, 838, 851, 855, 856, 858, 859, 860, 876, 877, 886, 887, 888, 890, 891, 892, 893, 896, 898, 899, 900, 901, 902, 903, 904, 905, 906, 910, 911, 913, 917, 920, 937, 943, 950, 955, 964, 966, 976, 978, 980, 987, 988, 1006, 1008, 1012, 1014, 1016, 1020, 1021, 1046, 1063, 1064, 1067, 1068, 1081, 1083, 1084, 1085, 1086, 1099, 1102, 1119, 1120, 1121, 1122, 1124, 1125, 1126, 1129, 1130, 1131, 1134, 1135, 1143, 1146, 1151, 1152, 1165, 1181, 1187, 1188, 1190, 1191, 1193, 1194, 1196, 1200, 1201, 1203, 1205, 1206, 1211, 1214, 1221, 1229, 1232, 1236, 1237, 1242, 1245, 1248, 1249, 1253, 1259, 1261, 1278, 1279, 1281, 1291, 1300, 1319, 1321, 1322, 1323, 1328, 1329, 1330, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1359, 1360, 1364, 1365, 1366, 1367, 1370, 1371, 1374, 1379, 1380, 1381, 1383, 1389, 1391, 1392, 1395, 1396, 1397, 1408, 1412, 1413, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1424, 1427, 1428, 1429, 1431, 1432, 1433, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1449, 1450, 1453, 1458, 1461, 1464, 1465, 1466, 1467, 1468, 1469, 1471, 1472, 1474, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1516, 1517, 1532, 1545, 1546, 1547, 1565, 1571, 1590, 1593, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1604, 1605, 1606, 1614, 1635, 1636, 1642, 1647, 1649, 1653, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1686, 1687, 1689, 1693, 1695, 1704, 1708, 1716, 1720, 1730, 1736, 1739, 1751, 1753, 1754, 1756, 1781, 1783, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1802, 1803, 1804, 1808, 1822, 1826, 1829, 1831, 1839, 1842, 1845, 1846, 1850, 1855, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1867, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1878, 1879, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1911, 1913, 1914, 1915, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929], "improv": [0, 1, 2, 4, 10, 23, 24, 29, 32, 36, 39, 41, 63, 71, 757, 801, 802, 803, 898, 900, 904, 958, 1143, 1360, 1374, 1392, 1437, 1468, 1571, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1691, 1858, 1860, 1882, 1887, 1888, 1889, 1897, 1898, 1902, 1908, 1909, 1913], "time": [0, 2, 4, 5, 8, 9, 10, 12, 13, 14, 15, 16, 17, 21, 24, 25, 26, 28, 29, 32, 38, 39, 41, 42, 43, 45, 47, 48, 49, 55, 58, 59, 60, 68, 70, 71, 89, 290, 313, 486, 491, 614, 677, 682, 683, 684, 685, 686, 687, 688, 691, 742, 743, 753, 757, 761, 765, 766, 796, 798, 821, 838, 874, 904, 910, 911, 915, 918, 930, 938, 940, 955, 962, 966, 967, 969, 1009, 1022, 1041, 1044, 1055, 1084, 1085, 1086, 1092, 1103, 1104, 1105, 1113, 1116, 1125, 1126, 1127, 1130, 1131, 1179, 1187, 1190, 1197, 1202, 1205, 1206, 1210, 1215, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1234, 1235, 1236, 1239, 1241, 1245, 1248, 1250, 1252, 1253, 1261, 1262, 1284, 1294, 1311, 1312, 1314, 1324, 1332, 1333, 1335, 1336, 1337, 1339, 1340, 1341, 1342, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1366, 1369, 1370, 1371, 1374, 1385, 1386, 1387, 1392, 1394, 1408, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1434, 1435, 1437, 1458, 1461, 1473, 1474, 1475, 1476, 1486, 1489, 1490, 1516, 1517, 1561, 1562, 1563, 1579, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1609, 1610, 1612, 1614, 1648, 1664, 1665, 1685, 1695, 1696, 1707, 1729, 1735, 1785, 1799, 1804, 1805, 1824, 1850, 1858, 1862, 1863, 1864, 1869, 1871, 1875, 1881, 1883, 1885, 1887, 1888, 1890, 1891, 1893, 1894, 1896, 1898, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1913, 1914, 1915, 1917, 1922, 1927], "perform": [0, 1, 2, 3, 4, 5, 6, 13, 15, 17, 18, 19, 20, 21, 22, 23, 24, 26, 30, 32, 36, 37, 38, 39, 41, 42, 43, 45, 46, 47, 49, 58, 59, 63, 67, 70, 71, 120, 207, 210, 457, 577, 600, 614, 683, 684, 685, 686, 687, 688, 757, 778, 801, 802, 803, 844, 855, 858, 891, 896, 898, 900, 901, 904, 905, 918, 930, 950, 955, 956, 965, 971, 1020, 1044, 1045, 1058, 1083, 1106, 1108, 1119, 1120, 1123, 1154, 1165, 1190, 1199, 1200, 1205, 1233, 1235, 1238, 1242, 1245, 1246, 1250, 1251, 1259, 1260, 1262, 1267, 1276, 1289, 1294, 1303, 1304, 1314, 1317, 1320, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1362, 1365, 1366, 1374, 1392, 1422, 1428, 1430, 1437, 1450, 1465, 1468, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1540, 1557, 1571, 1577, 1578, 1593, 1602, 1604, 1605, 1610, 1614, 1635, 1642, 1644, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1697, 1705, 1733, 1747, 1751, 1779, 1784, 1785, 1786, 1787, 1807, 1809, 1843, 1858, 1860, 1863, 1873, 1875, 1876, 1877, 1879, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1891, 1892, 1895, 1897, 1898, 1901, 1904, 1905, 1907, 1908, 1909, 1911, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1921, 1922, 1924, 1928], "ha": [0, 1, 2, 6, 7, 8, 9, 10, 12, 13, 14, 16, 17, 18, 20, 21, 22, 23, 24, 29, 30, 32, 33, 34, 36, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 55, 57, 58, 59, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 89, 151, 197, 210, 255, 260, 335, 444, 445, 446, 447, 448, 472, 473, 494, 496, 541, 577, 578, 600, 601, 615, 677, 686, 690, 692, 693, 694, 696, 732, 757, 776, 778, 782, 784, 788, 794, 835, 837, 844, 855, 861, 871, 872, 874, 886, 889, 890, 892, 894, 900, 905, 906, 920, 938, 941, 942, 955, 956, 957, 963, 966, 967, 969, 974, 1002, 1005, 1006, 1051, 1053, 1067, 1099, 1111, 1119, 1120, 1123, 1124, 1127, 1131, 1143, 1152, 1153, 1164, 1187, 1190, 1194, 1197, 1200, 1201, 1202, 1205, 1210, 1211, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1241, 1243, 1244, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1256, 1257, 1261, 1270, 1277, 1279, 1284, 1287, 1289, 1290, 1291, 1292, 1294, 1295, 1317, 1318, 1319, 1320, 1338, 1339, 1340, 1341, 1342, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1359, 1360, 1366, 1369, 1370, 1371, 1374, 1377, 1382, 1385, 1386, 1387, 1392, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1426, 1427, 1428, 1429, 1430, 1437, 1453, 1455, 1461, 1469, 1473, 1474, 1486, 1496, 1497, 1498, 1504, 1513, 1516, 1517, 1521, 1532, 1556, 1558, 1559, 1561, 1565, 1571, 1577, 1590, 1592, 1593, 1596, 1597, 1602, 1609, 1611, 1613, 1616, 1620, 1622, 1625, 1635, 1636, 1643, 1644, 1648, 1650, 1656, 1659, 1661, 1664, 1665, 1681, 1682, 1683, 1685, 1689, 1691, 1695, 1705, 1707, 1708, 1709, 1710, 1727, 1729, 1739, 1751, 1773, 1786, 1787, 1788, 1799, 1801, 1802, 1803, 1804, 1807, 1808, 1825, 1831, 1845, 1846, 1850, 1860, 1862, 1863, 1869, 1870, 1873, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1892, 1893, 1894, 1896, 1897, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1912, 1913, 1914, 1915, 1917, 1919, 1920, 1922, 1923, 1924, 1925], "lower": [0, 1, 2, 9, 17, 29, 39, 41, 47, 63, 790, 792, 856, 929, 934, 941, 942, 943, 945, 1077, 1078, 1150, 1151, 1219, 1226, 1228, 1236, 1237, 1244, 1247, 1252, 1290, 1312, 1319, 1330, 1440, 1496, 1497, 1498, 1569, 1570, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1683, 1689, 1691, 1706, 1708, 1728, 1743, 1751, 1788, 1831, 1832, 1833, 1859, 1860, 1861, 1863, 1879, 1881, 1883, 1894, 1903, 1908, 1918, 1924], "preced": [0, 45, 49, 63, 677, 1597, 1689, 1828, 1864, 1885, 1904, 1908], "backend": [0, 2, 14, 17, 18, 19, 21, 22, 23, 25, 26, 32, 57, 61, 63, 738, 739, 740, 789, 790, 830, 852, 853, 856, 858, 859, 898, 904, 950, 989, 1020, 1063, 1120, 1203, 1233, 1235, 1253, 1303, 1304, 1305, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1521, 1559, 1571, 1602, 1659, 1660, 1751, 1858, 1859, 1861, 1862, 1867, 1871, 1874, 1885, 1886, 1897, 1898, 1901, 1909, 1911, 1917], "inductor": [0, 12, 13, 15, 19, 20, 22, 23, 25, 29, 677, 950, 1869], "nopython": [0, 17, 20, 21, 29], "guard_export_fn": 0, "guard_fail_fn": 0, "disabl": [0, 1, 3, 6, 14, 16, 17, 19, 23, 25, 29, 42, 47, 63, 71, 807, 808, 917, 950, 1009, 1063, 1067, 1119, 1165, 1190, 1192, 1205, 1206, 1422, 1428, 1461, 1469, 1571, 1602, 1603, 1644, 1647, 1752, 1753, 1756, 1783, 1858, 1862, 1869, 1882, 1885, 1886, 1887, 1888, 1892, 1897, 1898, 1901, 1906, 1912, 1917, 1924], "main": [0, 4, 8, 13, 17, 21, 28, 38, 39, 41, 42, 47, 49, 50, 51, 56, 58, 59, 60, 61, 71, 260, 494, 1050, 1051, 1052, 1053, 1054, 1252, 1523, 1788, 1832, 1833, 1834, 1835, 1857, 1860, 1873, 1875, 1877, 1878, 1882, 1883, 1886, 1887, 1888, 1889, 1894, 1900, 1913, 1914, 1922, 1923], "entrypoint": [0, 43, 46, 49, 51, 56, 59, 1875], "do": [0, 1, 2, 5, 8, 9, 10, 12, 15, 16, 18, 21, 22, 24, 25, 27, 28, 29, 30, 32, 33, 38, 39, 41, 45, 46, 48, 49, 51, 58, 59, 60, 63, 64, 65, 68, 69, 70, 71, 493, 511, 513, 515, 755, 820, 823, 860, 889, 891, 896, 905, 936, 949, 1009, 1042, 1043, 1044, 1045, 1114, 1116, 1125, 1132, 1152, 1165, 1177, 1187, 1193, 1201, 1205, 1235, 1253, 1262, 1269, 1279, 1281, 1290, 1312, 1322, 1334, 1344, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1379, 1380, 1381, 1408, 1440, 1441, 1442, 1449, 1464, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1523, 1525, 1540, 1593, 1602, 1650, 1658, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1695, 1701, 1843, 1857, 1858, 1860, 1861, 1863, 1865, 1867, 1875, 1876, 1877, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1907, 1908, 1909, 1913, 1915, 1918, 1919, 1920, 1921, 1922, 1924], "extract": [0, 13, 18, 26, 27, 35, 71, 833, 1365, 1369, 1473, 1512, 1589, 1907, 1913, 1927], "paramet": [0, 1, 2, 3, 4, 6, 14, 17, 19, 22, 27, 28, 30, 32, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 52, 56, 58, 60, 63, 65, 67, 70, 71, 89, 151, 156, 171, 173, 176, 179, 180, 181, 196, 197, 207, 210, 240, 254, 255, 260, 267, 297, 313, 315, 317, 319, 321, 325, 331, 393, 400, 402, 444, 445, 446, 447, 448, 457, 470, 491, 494, 495, 496, 497, 498, 511, 513, 515, 518, 522, 534, 541, 542, 543, 557, 563, 580, 581, 582, 584, 585, 600, 601, 604, 614, 615, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 692, 693, 694, 695, 696, 732, 735, 736, 737, 738, 739, 740, 741, 742, 743, 747, 752, 753, 755, 756, 757, 761, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 774, 776, 777, 778, 779, 780, 782, 783, 784, 785, 786, 788, 790, 792, 794, 796, 797, 798, 811, 816, 817, 818, 819, 820, 821, 822, 823, 824, 835, 836, 837, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 862, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 890, 898, 899, 900, 901, 902, 903, 904, 905, 906, 912, 913, 914, 917, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 947, 948, 949, 950, 952, 955, 956, 957, 958, 959, 960, 961, 962, 963, 964, 965, 966, 967, 969, 970, 971, 972, 974, 975, 976, 977, 978, 979, 980, 983, 984, 985, 987, 991, 992, 993, 995, 998, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1023, 1025, 1026, 1027, 1028, 1029, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1073, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1160, 1164, 1165, 1167, 1169, 1170, 1172, 1175, 1176, 1177, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1189, 1190, 1191, 1192, 1193, 1194, 1196, 1197, 1200, 1201, 1202, 1203, 1205, 1206, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1297, 1302, 1303, 1304, 1307, 1308, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1453, 1454, 1455, 1457, 1458, 1459, 1461, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1488, 1489, 1490, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1516, 1517, 1518, 1520, 1521, 1523, 1525, 1532, 1533, 1540, 1545, 1546, 1547, 1556, 1557, 1558, 1559, 1561, 1562, 1563, 1564, 1565, 1571, 1577, 1578, 1586, 1590, 1591, 1592, 1593, 1601, 1602, 1604, 1605, 1606, 1607, 1608, 1609, 1610, 1611, 1612, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1696, 1697, 1698, 1700, 1701, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1733, 1734, 1735, 1736, 1738, 1739, 1743, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1753, 1756, 1757, 1758, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1779, 1781, 1782, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1807, 1808, 1812, 1813, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1855, 1856, 1857, 1858, 1860, 1863, 1865, 1867, 1871, 1872, 1875, 1877, 1878, 1879, 1881, 1882, 1883, 1886, 1887, 1888, 1892, 1893, 1894, 1896, 1898, 1899, 1901, 1905, 1906, 1907, 1908, 1912, 1913, 1914, 1917, 1918, 1919, 1922, 1924, 1926, 1927, 1928], "One": [0, 4, 9, 13, 15, 16, 23, 32, 41, 43, 63, 66, 68, 71, 580, 929, 1120, 1131, 1181, 1474, 1558, 1609, 1612, 1678, 1683, 1691, 1718, 1719, 1839, 1850, 1860, 1862, 1863, 1877, 1878, 1884, 1885, 1886, 1888, 1893, 1906, 1915, 1922], "thing": [0, 2, 4, 8, 9, 12, 16, 17, 21, 23, 27, 29, 41, 68, 71, 1120, 1199, 1291, 1338, 1523, 1782, 1862, 1883, 1886, 1888, 1889, 1890, 1891, 1896, 1901, 1905, 1908, 1909, 1915], "either": [0, 2, 9, 10, 15, 17, 18, 19, 20, 22, 32, 35, 38, 39, 41, 45, 46, 47, 49, 51, 56, 58, 59, 60, 63, 68, 70, 71, 155, 222, 313, 321, 511, 513, 614, 677, 729, 735, 736, 737, 742, 743, 753, 761, 776, 782, 788, 855, 887, 889, 896, 905, 906, 937, 950, 977, 1063, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1116, 1120, 1143, 1167, 1183, 1190, 1205, 1245, 1260, 1261, 1276, 1291, 1328, 1329, 1332, 1333, 1336, 1337, 1338, 1339, 1350, 1351, 1352, 1354, 1355, 1356, 1358, 1366, 1376, 1382, 1389, 1391, 1413, 1414, 1416, 1417, 1422, 1425, 1426, 1427, 1428, 1429, 1436, 1437, 1439, 1453, 1454, 1469, 1470, 1472, 1474, 1475, 1476, 1493, 1494, 1504, 1532, 1533, 1556, 1564, 1590, 1597, 1602, 1627, 1649, 1664, 1665, 1667, 1689, 1704, 1706, 1748, 1804, 1808, 1853, 1857, 1860, 1862, 1863, 1865, 1869, 1877, 1881, 1883, 1884, 1886, 1888, 1889, 1890, 1891, 1893, 1894, 1896, 1898, 1901, 1904, 1905, 1906, 1908, 1914, 1915, 1917, 1918, 1921, 1924, 1929], "callabl": [0, 4, 6, 13, 18, 19, 21, 28, 38, 39, 41, 45, 47, 49, 51, 56, 58, 60, 63, 70, 71, 73, 74, 75, 120, 398, 838, 950, 1006, 1007, 1009, 1120, 1121, 1122, 1127, 1130, 1131, 1190, 1193, 1201, 1205, 1261, 1262, 1422, 1465, 1467, 1469, 1471, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1672, 1674, 1675, 1676, 1677, 1678, 1685, 1688, 1850, 1857, 1860, 1862, 1863, 1864, 1873, 1886, 1894, 1901, 1905, 1906, 1907, 1913, 1924, 1926, 1927, 1928], "take": [0, 1, 2, 3, 4, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 21, 23, 28, 32, 38, 39, 41, 43, 45, 47, 49, 57, 58, 59, 60, 63, 65, 66, 68, 69, 70, 71, 757, 790, 795, 811, 817, 823, 859, 898, 899, 900, 901, 902, 903, 905, 906, 943, 963, 1000, 1051, 1053, 1054, 1079, 1081, 1084, 1087, 1091, 1092, 1094, 1097, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1222, 1244, 1247, 1330, 1339, 1366, 1370, 1371, 1374, 1392, 1416, 1417, 1418, 1419, 1420, 1422, 1430, 1437, 1465, 1475, 1476, 1516, 1517, 1534, 1558, 1571, 1602, 1647, 1675, 1679, 1704, 1831, 1850, 1857, 1860, 1861, 1863, 1870, 1871, 1875, 1876, 1877, 1878, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1892, 1894, 1898, 1900, 1901, 1903, 1905, 1907, 1908, 1913, 1914, 1915, 1917, 1920, 1921, 1922, 1926], "graphmodul": [0, 13, 16, 21, 28, 29, 73, 74, 75, 76, 856, 857, 858, 859, 1927], "example_input": [0, 13, 16, 21, 814, 815, 858, 859, 1201, 1205, 1908, 1927], "python": [0, 1, 2, 4, 5, 10, 13, 14, 15, 16, 17, 18, 19, 20, 23, 24, 25, 26, 27, 29, 32, 33, 35, 38, 41, 45, 47, 48, 49, 51, 52, 55, 56, 58, 59, 63, 71, 352, 586, 621, 677, 778, 877, 898, 899, 900, 901, 902, 903, 905, 906, 936, 937, 949, 950, 1000, 1006, 1007, 1009, 1058, 1063, 1081, 1083, 1111, 1116, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1166, 1188, 1190, 1191, 1193, 1194, 1195, 1200, 1201, 1205, 1261, 1423, 1424, 1432, 1433, 1571, 1602, 1701, 1723, 1727, 1747, 1748, 1783, 1850, 1857, 1867, 1869, 1874, 1875, 1877, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1893, 1896, 1899, 1900, 1905, 1908, 1912, 1913, 1914, 1915, 1920, 1923, 1924], "run": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 24, 28, 29, 32, 33, 35, 38, 39, 41, 42, 45, 47, 49, 50, 51, 56, 57, 58, 59, 60, 61, 63, 64, 65, 66, 68, 69, 70, 71, 151, 789, 795, 814, 816, 817, 818, 819, 822, 854, 858, 859, 860, 890, 904, 905, 906, 1008, 1009, 1120, 1125, 1131, 1165, 1190, 1191, 1193, 1194, 1197, 1199, 1201, 1203, 1205, 1206, 1235, 1261, 1262, 1290, 1340, 1341, 1342, 1359, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1450, 1461, 1571, 1593, 1602, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1751, 1755, 1787, 1833, 1835, 1843, 1850, 1858, 1860, 1863, 1871, 1873, 1875, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1893, 1894, 1895, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1911, 1912, 1913, 1914, 1915, 1917, 1922, 1925, 1926, 1927], "faster": [0, 1, 3, 9, 17, 20, 24, 26, 30, 38, 39, 41, 63, 899, 905, 906, 1119, 1219, 1220, 1225, 1226, 1230, 1235, 1243, 1245, 1247, 1250, 1253, 1255, 1259, 1262, 1438, 1455, 1561, 1577, 1602, 1606, 1607, 1609, 1664, 1665, 1676, 1790, 1791, 1792, 1794, 1795, 1871, 1883, 1886, 1891, 1904, 1908, 1917, 1922], "also": [0, 1, 2, 3, 4, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 19, 23, 24, 25, 28, 29, 30, 32, 33, 35, 38, 39, 41, 45, 46, 47, 48, 55, 58, 63, 67, 68, 69, 70, 71, 155, 219, 222, 223, 254, 323, 511, 513, 515, 540, 611, 738, 739, 740, 757, 797, 811, 858, 877, 886, 887, 896, 919, 928, 942, 950, 963, 1006, 1009, 1020, 1044, 1045, 1063, 1067, 1083, 1114, 1120, 1126, 1130, 1131, 1132, 1135, 1137, 1147, 1148, 1152, 1165, 1190, 1193, 1194, 1196, 1199, 1203, 1205, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1257, 1258, 1291, 1297, 1310, 1318, 1330, 1338, 1340, 1341, 1342, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1366, 1369, 1374, 1388, 1392, 1422, 1429, 1437, 1451, 1453, 1461, 1470, 1471, 1473, 1499, 1500, 1501, 1521, 1558, 1574, 1593, 1602, 1612, 1614, 1624, 1626, 1628, 1629, 1630, 1631, 1647, 1679, 1685, 1689, 1692, 1695, 1720, 1727, 1739, 1749, 1764, 1765, 1782, 1785, 1799, 1808, 1817, 1819, 1822, 1828, 1829, 1840, 1841, 1850, 1853, 1857, 1858, 1860, 1862, 1863, 1867, 1869, 1870, 1871, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1913, 1914, 1917, 1918, 1920, 1921, 1922, 1923, 1924, 1925, 1927, 1928], "provid": [0, 1, 2, 4, 8, 9, 10, 12, 13, 15, 17, 18, 21, 22, 26, 28, 29, 30, 32, 33, 38, 39, 41, 42, 43, 45, 46, 47, 49, 51, 56, 58, 59, 60, 61, 63, 67, 70, 71, 151, 600, 677, 686, 732, 735, 736, 737, 742, 743, 745, 753, 754, 757, 761, 785, 786, 796, 797, 811, 821, 838, 855, 890, 899, 901, 902, 903, 929, 934, 937, 942, 943, 962, 974, 1020, 1063, 1083, 1119, 1131, 1143, 1151, 1152, 1187, 1190, 1196, 1197, 1201, 1203, 1205, 1220, 1237, 1262, 1294, 1353, 1354, 1355, 1358, 1374, 1375, 1383, 1388, 1392, 1393, 1418, 1419, 1420, 1422, 1428, 1429, 1432, 1437, 1439, 1450, 1465, 1466, 1467, 1468, 1469, 1493, 1494, 1571, 1602, 1616, 1636, 1644, 1659, 1660, 1689, 1692, 1697, 1733, 1743, 1790, 1791, 1792, 1793, 1794, 1795, 1833, 1835, 1850, 1857, 1860, 1862, 1863, 1867, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1886, 1887, 1888, 1889, 1891, 1894, 1895, 1897, 1901, 1904, 1905, 1906, 1908, 1909, 1911, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1929], "addit": [0, 1, 2, 4, 6, 8, 10, 12, 15, 17, 18, 24, 25, 29, 32, 33, 38, 41, 42, 43, 47, 52, 58, 59, 63, 70, 71, 335, 511, 604, 746, 748, 749, 750, 751, 755, 757, 778, 792, 811, 856, 1020, 1187, 1190, 1194, 1199, 1204, 1330, 1341, 1342, 1343, 1353, 1354, 1355, 1366, 1373, 1374, 1376, 1383, 1386, 1387, 1401, 1402, 1403, 1407, 1408, 1409, 1410, 1412, 1418, 1419, 1420, 1422, 1428, 1430, 1455, 1457, 1461, 1465, 1469, 1471, 1492, 1499, 1500, 1501, 1538, 1602, 1667, 1840, 1841, 1848, 1860, 1862, 1863, 1869, 1873, 1876, 1877, 1878, 1883, 1885, 1886, 1888, 1889, 1893, 1896, 1897, 1900, 1901, 1902, 1907, 1908, 1909, 1911, 1913, 1914, 1915, 1917, 1921, 1924], "context": [0, 1, 3, 6, 15, 16, 21, 38, 45, 49, 58, 59, 63, 71, 151, 789, 886, 887, 888, 890, 891, 904, 905, 917, 970, 985, 987, 998, 1004, 1009, 1016, 1036, 1038, 1067, 1121, 1125, 1130, 1165, 1190, 1303, 1422, 1571, 1593, 1602, 1603, 1612, 1614, 1647, 1656, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1753, 1783, 1858, 1863, 1864, 1875, 1882, 1883, 1886, 1888, 1892, 1893, 1896, 1901, 1905, 1907, 1912, 1913, 1915, 1917, 1920, 1925], "like": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 21, 22, 23, 25, 27, 28, 29, 30, 32, 33, 38, 39, 41, 46, 47, 56, 58, 59, 63, 64, 65, 66, 67, 68, 69, 71, 336, 586, 614, 757, 790, 838, 857, 875, 896, 905, 906, 919, 928, 1006, 1007, 1016, 1058, 1063, 1064, 1084, 1106, 1109, 1110, 1116, 1120, 1123, 1124, 1125, 1131, 1147, 1148, 1188, 1190, 1191, 1197, 1200, 1205, 1209, 1236, 1237, 1248, 1261, 1330, 1338, 1366, 1369, 1385, 1386, 1387, 1422, 1423, 1424, 1432, 1433, 1450, 1473, 1515, 1533, 1589, 1593, 1602, 1603, 1604, 1605, 1610, 1635, 1653, 1678, 1701, 1716, 1720, 1739, 1748, 1751, 1808, 1819, 1850, 1855, 1857, 1858, 1860, 1862, 1863, 1870, 1875, 1876, 1877, 1882, 1883, 1886, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1899, 1900, 1901, 1904, 1906, 1907, 1908, 1911, 1913, 1914, 1917, 1919, 1920, 1924, 1925, 1927, 1928], "jit": [0, 1, 13, 15, 20, 26, 27, 30, 32, 1006, 1007, 1038, 1140, 1188, 1189, 1190, 1204, 1658, 1659, 1754, 1755, 1858, 1862, 1865, 1871, 1877, 1885, 1893, 1899, 1901, 1908, 1913, 1922], "fuser": [0, 790, 1203, 1860], "fuser2": 0, "set": [0, 1, 2, 3, 4, 6, 9, 10, 14, 15, 16, 17, 18, 19, 21, 22, 24, 25, 28, 29, 31, 32, 37, 38, 39, 41, 42, 43, 45, 47, 49, 51, 56, 58, 59, 60, 61, 63, 66, 67, 70, 71, 89, 151, 155, 254, 330, 444, 445, 446, 447, 448, 457, 494, 518, 577, 578, 677, 732, 738, 740, 757, 776, 782, 789, 790, 791, 794, 812, 813, 814, 817, 818, 819, 822, 823, 838, 851, 855, 856, 858, 859, 862, 875, 887, 889, 890, 897, 898, 899, 900, 901, 902, 903, 904, 917, 929, 934, 945, 949, 950, 956, 974, 989, 998, 1010, 1011, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1064, 1066, 1119, 1128, 1137, 1152, 1170, 1171, 1190, 1194, 1197, 1199, 1201, 1203, 1205, 1206, 1225, 1226, 1229, 1235, 1242, 1244, 1246, 1247, 1259, 1260, 1261, 1262, 1276, 1279, 1282, 1302, 1306, 1307, 1308, 1330, 1334, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1367, 1374, 1377, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1407, 1409, 1413, 1414, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1432, 1436, 1437, 1453, 1454, 1461, 1470, 1471, 1486, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1506, 1507, 1508, 1509, 1514, 1521, 1525, 1532, 1533, 1542, 1543, 1556, 1558, 1564, 1571, 1590, 1602, 1604, 1605, 1610, 1615, 1644, 1656, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1693, 1707, 1714, 1716, 1720, 1722, 1723, 1731, 1732, 1743, 1744, 1747, 1748, 1749, 1750, 1751, 1753, 1754, 1755, 1756, 1757, 1758, 1773, 1788, 1802, 1803, 1822, 1832, 1833, 1834, 1835, 1843, 1845, 1846, 1857, 1859, 1860, 1862, 1863, 1864, 1867, 1869, 1871, 1872, 1873, 1875, 1878, 1881, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1900, 1903, 1904, 1905, 1906, 1907, 1908, 1909, 1911, 1912, 1913, 1922, 1924, 1926, 1927, 1928], "backend_ctx_ctor": 0, "attribut": [0, 1, 2, 21, 28, 30, 38, 39, 41, 42, 48, 71, 151, 290, 493, 494, 724, 735, 736, 737, 738, 739, 740, 742, 743, 753, 761, 788, 799, 812, 813, 814, 835, 836, 837, 855, 856, 886, 890, 892, 896, 1114, 1189, 1190, 1191, 1193, 1194, 1200, 1201, 1262, 1359, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1422, 1465, 1602, 1603, 1613, 1614, 1615, 1636, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1858, 1861, 1864, 1878, 1882, 1883, 1886, 1888, 1889, 1894, 1899, 1901, 1905, 1908, 1913, 1923, 1924, 1928, 1929], "see": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 15, 18, 19, 20, 21, 23, 27, 28, 29, 32, 33, 34, 37, 38, 41, 42, 47, 50, 58, 59, 61, 63, 68, 69, 70, 71, 90, 94, 96, 98, 100, 102, 104, 106, 108, 110, 113, 114, 115, 116, 117, 118, 119, 121, 123, 125, 127, 129, 130, 133, 135, 136, 137, 138, 139, 141, 143, 145, 146, 149, 151, 152, 154, 155, 156, 157, 158, 160, 162, 164, 166, 168, 170, 171, 172, 173, 176, 177, 179, 180, 181, 182, 183, 184, 185, 186, 190, 193, 194, 198, 200, 201, 203, 205, 206, 208, 211, 212, 213, 215, 218, 219, 221, 225, 226, 227, 228, 229, 230, 231, 234, 235, 237, 239, 240, 241, 243, 245, 246, 248, 250, 252, 255, 256, 261, 263, 264, 265, 266, 267, 268, 270, 272, 274, 275, 276, 278, 280, 281, 282, 284, 287, 288, 291, 293, 295, 297, 298, 299, 300, 301, 302, 303, 305, 307, 309, 313, 321, 322, 323, 324, 325, 327, 328, 334, 344, 345, 346, 347, 348, 349, 350, 351, 352, 354, 355, 357, 359, 361, 363, 365, 367, 369, 370, 372, 374, 378, 379, 380, 381, 382, 384, 386, 388, 390, 392, 393, 394, 396, 397, 403, 404, 405, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 420, 421, 423, 424, 426, 428, 429, 430, 431, 432, 433, 437, 439, 441, 449, 451, 452, 454, 456, 458, 459, 460, 461, 463, 464, 466, 467, 469, 476, 478, 479, 481, 483, 486, 487, 489, 491, 492, 493, 495, 496, 497, 499, 500, 503, 504, 505, 508, 513, 515, 516, 517, 519, 522, 523, 525, 527, 528, 530, 532, 535, 536, 537, 539, 540, 544, 545, 547, 549, 551, 552, 553, 558, 560, 562, 564, 565, 566, 567, 569, 570, 571, 573, 575, 576, 587, 588, 589, 591, 592, 594, 596, 598, 602, 603, 606, 607, 608, 611, 612, 613, 615, 616, 617, 618, 677, 690, 692, 693, 696, 727, 728, 729, 730, 731, 732, 735, 736, 737, 738, 739, 740, 742, 743, 745, 753, 754, 757, 758, 759, 760, 761, 762, 763, 764, 765, 768, 769, 770, 771, 776, 777, 778, 779, 780, 781, 782, 790, 837, 856, 857, 858, 859, 862, 871, 872, 873, 876, 887, 889, 890, 891, 892, 893, 895, 896, 900, 904, 905, 910, 911, 914, 919, 921, 928, 930, 933, 947, 950, 960, 964, 965, 966, 967, 969, 971, 972, 974, 988, 989, 998, 999, 1009, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1027, 1028, 1029, 1058, 1061, 1063, 1064, 1066, 1067, 1076, 1081, 1099, 1102, 1117, 1122, 1123, 1124, 1126, 1135, 1143, 1147, 1148, 1152, 1153, 1161, 1162, 1163, 1165, 1190, 1194, 1201, 1205, 1206, 1208, 1209, 1211, 1221, 1229, 1232, 1235, 1237, 1244, 1246, 1247, 1255, 1259, 1260, 1262, 1268, 1270, 1276, 1277, 1279, 1287, 1289, 1290, 1291, 1292, 1294, 1295, 1303, 1304, 1310, 1317, 1319, 1320, 1330, 1338, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1365, 1366, 1368, 1374, 1376, 1382, 1383, 1388, 1389, 1392, 1413, 1414, 1418, 1419, 1420, 1421, 1422, 1425, 1426, 1427, 1428, 1429, 1434, 1435, 1436, 1437, 1440, 1449, 1451, 1453, 1454, 1466, 1467, 1468, 1469, 1470, 1471, 1474, 1480, 1481, 1482, 1483, 1484, 1485, 1487, 1488, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1512, 1513, 1514, 1515, 1518, 1519, 1520, 1521, 1522, 1524, 1525, 1526, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1558, 1559, 1560, 1562, 1563, 1564, 1565, 1566, 1567, 1569, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1587, 1588, 1589, 1590, 1591, 1592, 1602, 1603, 1609, 1610, 1611, 1614, 1620, 1629, 1638, 1643, 1646, 1647, 1648, 1649, 1653, 1695, 1705, 1706, 1716, 1718, 1720, 1722, 1723, 1727, 1730, 1733, 1739, 1748, 1751, 1753, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1776, 1783, 1784, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1802, 1803, 1804, 1807, 1817, 1819, 1822, 1828, 1829, 1833, 1835, 1843, 1845, 1846, 1851, 1853, 1855, 1857, 1858, 1860, 1861, 1862, 1863, 1864, 1868, 1869, 1870, 1872, 1875, 1876, 1877, 1878, 1879, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1906, 1907, 1908, 1909, 1912, 1913, 1914, 1917, 1918, 1920, 1921, 1923, 1924, 1925, 1928, 1929], "aotautogradmemoryefficientfusionwithcontext": 0, "usag": [0, 1, 2, 5, 8, 10, 15, 16, 17, 18, 29, 33, 38, 41, 45, 47, 48, 49, 52, 55, 56, 58, 60, 63, 71, 745, 754, 789, 790, 791, 807, 808, 809, 810, 812, 813, 814, 851, 855, 887, 1012, 1032, 1036, 1063, 1114, 1119, 1123, 1124, 1125, 1203, 1262, 1602, 1657, 1860, 1863, 1873, 1877, 1882, 1883, 1888, 1890, 1901, 1907, 1915, 1922, 1923, 1925, 1926, 1927], "Or": [0, 8, 21, 49, 71, 945, 1892, 1895, 1901, 1917], "string": [0, 3, 4, 13, 17, 21, 29, 31, 32, 38, 41, 49, 55, 56, 58, 71, 600, 811, 851, 989, 1006, 1007, 1063, 1120, 1190, 1197, 1200, 1261, 1350, 1351, 1352, 1422, 1423, 1432, 1465, 1467, 1469, 1496, 1497, 1498, 1625, 1707, 1739, 1747, 1749, 1857, 1861, 1862, 1863, 1864, 1877, 1883, 1888, 1893, 1894, 1901, 1905, 1907, 1913, 1919, 1920, 1922, 1927, 1928], "name": [0, 2, 3, 4, 13, 14, 17, 21, 23, 25, 28, 29, 32, 39, 41, 46, 47, 49, 51, 52, 55, 56, 58, 60, 63, 71, 677, 694, 744, 745, 754, 789, 811, 812, 813, 814, 821, 837, 851, 855, 914, 965, 992, 1119, 1129, 1188, 1190, 1191, 1197, 1200, 1205, 1206, 1220, 1225, 1226, 1232, 1233, 1235, 1236, 1237, 1238, 1248, 1249, 1251, 1253, 1254, 1261, 1422, 1472, 1595, 1600, 1601, 1602, 1609, 1610, 1611, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1643, 1644, 1646, 1658, 1659, 1739, 1749, 1844, 1857, 1858, 1860, 1861, 1863, 1864, 1867, 1869, 1872, 1873, 1875, 1881, 1883, 1886, 1887, 1888, 1891, 1893, 1894, 1901, 1903, 1905, 1906, 1907, 1913, 1914, 1919, 1922, 1924, 1925, 1926, 1927, 1928, 1929], "list_backend": [0, 13, 19, 20, 22, 950, 1858], "whole": [0, 16, 21, 24, 25, 38, 41, 43, 1131, 1190, 1422, 1450, 1461, 1602, 1850, 1883, 1887, 1896, 1897, 1905], "program": [0, 2, 4, 5, 9, 12, 15, 16, 17, 20, 22, 24, 26, 29, 35, 38, 41, 50, 59, 61, 63, 71, 614, 955, 956, 1012, 1014, 1120, 1751, 1860, 1862, 1864, 1883, 1886, 1890, 1893, 1895, 1896, 1899, 1900, 1922], "turn": [0, 16, 19, 20, 21, 32, 38, 68, 71, 677, 870, 950, 1178, 1205, 1466, 1468, 1790, 1791, 1792, 1793, 1794, 1795, 1870, 1883, 1886, 1897, 1898, 1901, 1907, 1908, 1914, 1917], "decor": [0, 1, 2, 13, 18, 26, 47, 51, 55, 59, 71, 896, 1067, 1165, 1195, 1201, 1207, 1647, 1783, 1860, 1862, 1863, 1867, 1882, 1883, 1888, 1906, 1913, 1928], "exampl": [0, 1, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 28, 29, 32, 35, 38, 39, 41, 42, 43, 44, 45, 46, 47, 48, 49, 51, 52, 55, 56, 57, 58, 59, 60, 61, 63, 64, 65, 67, 68, 69, 70, 88, 89, 192, 209, 242, 254, 260, 289, 311, 313, 315, 317, 321, 335, 352, 401, 402, 444, 445, 446, 447, 448, 470, 480, 482, 486, 491, 494, 497, 511, 513, 515, 534, 541, 555, 557, 577, 578, 580, 581, 582, 583, 584, 585, 586, 604, 614, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 717, 725, 726, 731, 735, 736, 737, 738, 739, 740, 742, 743, 745, 753, 754, 755, 757, 758, 759, 760, 761, 762, 769, 770, 771, 782, 789, 790, 791, 793, 794, 807, 808, 809, 810, 811, 812, 813, 814, 821, 835, 851, 856, 857, 858, 859, 862, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 891, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 908, 910, 911, 918, 920, 921, 922, 923, 924, 925, 926, 927, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 948, 949, 950, 952, 955, 956, 957, 958, 959, 960, 961, 962, 963, 1006, 1007, 1012, 1014, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1067, 1068, 1069, 1073, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1119, 1120, 1121, 1122, 1127, 1129, 1131, 1132, 1133, 1134, 1137, 1143, 1146, 1149, 1150, 1151, 1152, 1153, 1155, 1156, 1160, 1164, 1165, 1167, 1175, 1177, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1188, 1190, 1191, 1193, 1194, 1195, 1196, 1197, 1199, 1200, 1201, 1203, 1204, 1205, 1206, 1207, 1208, 1210, 1211, 1212, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1263, 1264, 1265, 1266, 1267, 1269, 1270, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1486, 1488, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1512, 1513, 1516, 1517, 1521, 1523, 1556, 1558, 1559, 1562, 1563, 1571, 1590, 1593, 1602, 1609, 1610, 1612, 1614, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1646, 1647, 1648, 1649, 1650, 1652, 1653, 1654, 1656, 1657, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1682, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1696, 1698, 1700, 1701, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1715, 1716, 1718, 1720, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1739, 1743, 1745, 1746, 1747, 1748, 1749, 1752, 1753, 1756, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1781, 1783, 1785, 1786, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1802, 1803, 1805, 1807, 1808, 1810, 1811, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1855, 1856, 1857, 1858, 1860, 1862, 1863, 1864, 1867, 1869, 1870, 1872, 1873, 1876, 1877, 1878, 1881, 1883, 1884, 1885, 1886, 1890, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1904, 1905, 1906, 1907, 1908, 1909, 1913, 1915, 1917, 1918, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1928], "toy_exampl": [0, 13, 14, 17, 21, 29], "b": [0, 1, 2, 4, 13, 14, 17, 20, 21, 28, 29, 30, 38, 41, 43, 47, 56, 71, 260, 335, 398, 614, 682, 683, 745, 754, 778, 821, 877, 894, 896, 897, 908, 910, 911, 918, 929, 930, 932, 936, 938, 940, 943, 948, 957, 963, 1006, 1007, 1055, 1058, 1062, 1063, 1108, 1109, 1110, 1111, 1116, 1120, 1133, 1155, 1167, 1187, 1193, 1200, 1201, 1209, 1210, 1212, 1221, 1222, 1230, 1234, 1235, 1239, 1242, 1243, 1244, 1245, 1246, 1247, 1250, 1251, 1252, 1255, 1256, 1259, 1262, 1271, 1273, 1274, 1280, 1288, 1293, 1295, 1311, 1339, 1343, 1365, 1366, 1373, 1409, 1492, 1494, 1513, 1520, 1538, 1609, 1636, 1637, 1638, 1639, 1640, 1641, 1649, 1656, 1675, 1677, 1708, 1714, 1727, 1730, 1746, 1758, 1777, 1785, 1790, 1791, 1792, 1794, 1795, 1799, 1804, 1805, 1807, 1814, 1815, 1824, 1831, 1832, 1834, 1847, 1852, 1859, 1860, 1861, 1862, 1863, 1876, 1877, 1878, 1881, 1882, 1884, 1886, 1890, 1891, 1892, 1897, 1899, 1907, 1908, 1914, 1915, 1917, 1918, 1921, 1922, 1927], "optimize_assert": [0, 1858], "hook": [0, 2, 16, 17, 18, 21, 26, 42, 45, 63, 486, 745, 754, 896, 910, 911, 1009, 1190, 1359, 1422, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1643, 1646, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1858, 1879, 1887, 1888, 1893, 1905, 1908], "export_constraint": 0, "same": [0, 1, 2, 4, 8, 12, 13, 15, 16, 17, 21, 24, 28, 29, 32, 33, 34, 35, 38, 39, 41, 42, 43, 45, 47, 49, 55, 56, 58, 59, 60, 61, 63, 66, 68, 70, 71, 140, 154, 196, 222, 255, 311, 313, 315, 319, 321, 339, 444, 445, 446, 447, 448, 470, 482, 495, 496, 498, 511, 513, 515, 518, 541, 577, 614, 615, 683, 686, 690, 692, 693, 694, 696, 717, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 742, 743, 753, 755, 758, 759, 760, 761, 762, 776, 782, 785, 786, 790, 791, 793, 797, 799, 811, 816, 819, 821, 822, 856, 858, 875, 876, 877, 889, 892, 895, 898, 899, 900, 901, 902, 903, 905, 906, 918, 920, 921, 930, 932, 934, 937, 942, 944, 952, 963, 964, 966, 977, 979, 998, 1009, 1046, 1051, 1053, 1054, 1060, 1063, 1065, 1066, 1069, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1111, 1115, 1116, 1118, 1119, 1120, 1123, 1124, 1125, 1126, 1129, 1130, 1131, 1132, 1135, 1143, 1151, 1152, 1160, 1164, 1181, 1187, 1190, 1200, 1201, 1205, 1206, 1210, 1211, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1257, 1277, 1281, 1283, 1284, 1287, 1289, 1290, 1291, 1292, 1295, 1317, 1320, 1321, 1322, 1328, 1329, 1332, 1333, 1334, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1369, 1372, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1391, 1394, 1404, 1405, 1406, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1425, 1426, 1427, 1428, 1430, 1431, 1436, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1473, 1474, 1477, 1478, 1479, 1486, 1492, 1493, 1494, 1496, 1497, 1498, 1504, 1513, 1521, 1523, 1532, 1533, 1571, 1590, 1602, 1609, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1635, 1639, 1644, 1649, 1650, 1654, 1656, 1660, 1674, 1695, 1700, 1701, 1704, 1705, 1717, 1719, 1721, 1725, 1727, 1729, 1730, 1734, 1743, 1746, 1759, 1782, 1790, 1791, 1792, 1794, 1795, 1801, 1802, 1803, 1807, 1808, 1818, 1829, 1840, 1841, 1842, 1843, 1845, 1846, 1847, 1850, 1856, 1857, 1860, 1862, 1863, 1873, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1896, 1897, 1898, 1899, 1901, 1904, 1905, 1906, 1908, 1911, 1913, 1914, 1915, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1926, 1927, 1928], "f": [0, 2, 11, 13, 15, 21, 27, 28, 39, 41, 47, 49, 50, 55, 56, 64, 65, 68, 69, 70, 71, 174, 258, 286, 335, 377, 892, 893, 1081, 1083, 1090, 1099, 1120, 1121, 1123, 1124, 1125, 1126, 1130, 1131, 1143, 1190, 1197, 1200, 1201, 1261, 1388, 1390, 1391, 1393, 1422, 1471, 1488, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1512, 1513, 1516, 1517, 1523, 1556, 1558, 1559, 1571, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1739, 1850, 1860, 1862, 1863, 1876, 1877, 1883, 1886, 1888, 1890, 1891, 1892, 1894, 1900, 1901, 1905, 1906, 1917, 1922, 1924, 1928], "arg": [0, 1, 2, 4, 5, 6, 13, 14, 16, 21, 28, 29, 32, 38, 39, 41, 45, 46, 47, 49, 50, 56, 57, 59, 60, 61, 63, 70, 71, 88, 577, 600, 677, 729, 744, 746, 748, 749, 750, 751, 757, 759, 760, 821, 858, 887, 889, 894, 895, 1009, 1119, 1123, 1124, 1125, 1131, 1190, 1193, 1279, 1338, 1339, 1356, 1358, 1374, 1382, 1384, 1389, 1392, 1411, 1413, 1414, 1422, 1425, 1426, 1427, 1429, 1436, 1437, 1450, 1452, 1453, 1454, 1456, 1460, 1461, 1462, 1463, 1470, 1493, 1494, 1504, 1533, 1556, 1564, 1593, 1602, 1616, 1621, 1635, 1642, 1644, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1809, 1841, 1847, 1850, 1857, 1861, 1863, 1864, 1875, 1877, 1883, 1886, 1887, 1888, 1889, 1896, 1901, 1902, 1905, 1906, 1913, 1914, 1915, 1919, 1927, 1928], "aten_graph": 0, "pre_autograd": 0, "decomposition_t": 0, "tracing_mod": 0, "symbol": [0, 15, 16, 27, 32, 37, 84, 621, 814, 1204, 1258, 1392, 1437, 1831, 1847, 1858, 1863, 1902], "constraint": [0, 12, 15, 41, 46, 791, 792, 899, 998, 1009, 1125, 1602, 1610, 1635, 1678, 1858, 1863, 1878, 1889, 1891, 1894, 1917], "assume_static_by_default": [0, 15], "kwarg": [0, 1, 2, 6, 13, 14, 28, 29, 32, 38, 41, 42, 45, 58, 63, 71, 577, 600, 744, 757, 759, 760, 818, 819, 821, 824, 887, 967, 969, 1006, 1007, 1119, 1130, 1131, 1190, 1193, 1195, 1253, 1279, 1374, 1384, 1392, 1411, 1422, 1437, 1452, 1456, 1460, 1462, 1463, 1593, 1598, 1602, 1616, 1621, 1625, 1635, 1642, 1644, 1647, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1739, 1841, 1850, 1857, 1863, 1864, 1888, 1889, 1894, 1902, 1904, 1913, 1919, 1927, 1928], "input": [0, 2, 3, 4, 6, 10, 12, 15, 16, 27, 28, 29, 30, 33, 36, 38, 39, 41, 42, 45, 46, 47, 48, 51, 63, 64, 65, 66, 67, 68, 69, 71, 83, 89, 151, 260, 280, 301, 401, 482, 515, 606, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 692, 693, 694, 695, 696, 717, 725, 726, 731, 732, 735, 736, 737, 738, 739, 740, 742, 743, 753, 755, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 787, 788, 789, 790, 791, 793, 794, 795, 796, 797, 799, 811, 814, 816, 834, 835, 836, 837, 854, 855, 858, 859, 860, 861, 862, 863, 864, 865, 866, 867, 868, 869, 871, 872, 873, 874, 875, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 890, 894, 896, 898, 899, 900, 901, 902, 903, 904, 905, 906, 914, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 933, 934, 936, 938, 939, 941, 942, 943, 944, 945, 946, 947, 949, 952, 955, 956, 957, 958, 959, 960, 961, 962, 963, 979, 1006, 1007, 1009, 1042, 1043, 1044, 1045, 1047, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1063, 1065, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1131, 1132, 1133, 1134, 1135, 1136, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1167, 1168, 1169, 1170, 1172, 1175, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1190, 1193, 1194, 1196, 1197, 1201, 1203, 1205, 1206, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1277, 1278, 1280, 1282, 1283, 1284, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1589, 1590, 1591, 1592, 1593, 1595, 1596, 1597, 1598, 1600, 1601, 1602, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1630, 1631, 1635, 1636, 1637, 1639, 1644, 1647, 1648, 1649, 1651, 1652, 1654, 1656, 1659, 1660, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1682, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1717, 1719, 1721, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1738, 1740, 1741, 1742, 1745, 1746, 1748, 1759, 1760, 1761, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1784, 1785, 1786, 1787, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1797, 1798, 1799, 1800, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1817, 1818, 1819, 1820, 1821, 1823, 1825, 1826, 1827, 1828, 1831, 1832, 1834, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1853, 1854, 1856, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1867, 1870, 1871, 1877, 1878, 1879, 1881, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1893, 1894, 1897, 1898, 1899, 1901, 1904, 1906, 1907, 1908, 1909, 1911, 1912, 1913, 1914, 1917, 1918, 1920, 1921, 1924, 1926, 1927, 1928], "format": [0, 2, 29, 36, 39, 41, 43, 51, 60, 71, 156, 171, 173, 176, 179, 180, 181, 196, 207, 210, 240, 267, 297, 325, 331, 393, 497, 498, 522, 577, 580, 581, 582, 583, 584, 585, 677, 732, 757, 789, 790, 947, 1009, 1063, 1064, 1065, 1118, 1187, 1190, 1203, 1232, 1345, 1366, 1374, 1392, 1422, 1437, 1602, 1636, 1638, 1654, 1656, 1657, 1659, 1717, 1719, 1721, 1739, 1782, 1785, 1790, 1791, 1792, 1793, 1794, 1795, 1804, 1856, 1857, 1860, 1863, 1864, 1869, 1886, 1888, 1894, 1899, 1901, 1902, 1903, 1907, 1908, 1913, 1914, 1917, 1920, 1922, 1924], "execut": [0, 1, 2, 3, 4, 5, 6, 8, 14, 15, 16, 17, 18, 21, 23, 24, 26, 28, 29, 32, 33, 38, 41, 43, 45, 49, 50, 52, 59, 63, 68, 70, 71, 486, 910, 911, 969, 980, 1041, 1120, 1190, 1191, 1193, 1205, 1206, 1261, 1303, 1304, 1359, 1422, 1428, 1466, 1467, 1468, 1469, 1596, 1598, 1602, 1754, 1858, 1860, 1862, 1864, 1871, 1882, 1884, 1885, 1890, 1893, 1894, 1896, 1898, 1900, 1901, 1907, 1908, 1913, 1914, 1917], "outsid": [0, 1, 6, 10, 24, 27, 38, 51, 63, 68, 681, 792, 882, 1119, 1121, 1125, 1130, 1191, 1521, 1602, 1680, 1681, 1686, 1687, 1693, 1862, 1863, 1881, 1883, 1886, 1889, 1890, 1924], "pytorch": [0, 1, 2, 3, 4, 5, 6, 13, 15, 16, 17, 19, 21, 22, 26, 27, 28, 30, 31, 32, 34, 35, 38, 39, 43, 44, 45, 46, 47, 48, 49, 51, 58, 59, 63, 64, 67, 69, 71, 83, 84, 86, 87, 151, 511, 580, 677, 695, 727, 728, 729, 730, 742, 743, 753, 757, 758, 759, 760, 761, 762, 789, 790, 807, 808, 809, 810, 877, 890, 935, 940, 941, 950, 951, 963, 988, 989, 1000, 1005, 1063, 1108, 1114, 1120, 1121, 1125, 1130, 1131, 1136, 1176, 1177, 1200, 1220, 1231, 1233, 1234, 1235, 1238, 1251, 1260, 1276, 1279, 1280, 1291, 1338, 1339, 1345, 1374, 1388, 1418, 1419, 1420, 1465, 1494, 1571, 1602, 1635, 1643, 1644, 1649, 1656, 1660, 1707, 1739, 1747, 1748, 1758, 1804, 1808, 1831, 1843, 1850, 1857, 1859, 1862, 1863, 1867, 1869, 1870, 1872, 1873, 1877, 1878, 1879, 1884, 1885, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1900, 1904, 1905, 1907, 1908, 1909, 1910, 1913, 1914, 1917, 1918, 1920, 1921, 1922, 1928, 1929], "A": [0, 2, 3, 4, 6, 8, 9, 10, 12, 13, 16, 17, 19, 20, 21, 22, 27, 28, 29, 32, 35, 38, 39, 41, 42, 43, 45, 46, 47, 49, 55, 58, 59, 60, 63, 64, 69, 70, 76, 89, 557, 577, 580, 581, 582, 591, 621, 677, 689, 694, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 742, 743, 753, 758, 759, 760, 761, 762, 787, 789, 811, 855, 856, 858, 859, 916, 919, 928, 929, 931, 936, 941, 942, 949, 950, 958, 962, 966, 967, 969, 977, 979, 980, 1048, 1063, 1068, 1076, 1077, 1078, 1090, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1134, 1143, 1146, 1147, 1148, 1152, 1180, 1181, 1182, 1183, 1186, 1188, 1190, 1193, 1197, 1200, 1202, 1205, 1206, 1210, 1214, 1219, 1220, 1221, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1259, 1262, 1270, 1278, 1279, 1280, 1281, 1285, 1323, 1339, 1343, 1345, 1358, 1365, 1366, 1375, 1376, 1384, 1393, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1412, 1421, 1422, 1428, 1450, 1455, 1457, 1465, 1470, 1471, 1486, 1492, 1504, 1512, 1523, 1533, 1540, 1551, 1571, 1577, 1578, 1593, 1602, 1603, 1604, 1605, 1609, 1611, 1614, 1636, 1637, 1640, 1656, 1657, 1658, 1659, 1664, 1666, 1667, 1672, 1676, 1678, 1682, 1683, 1685, 1688, 1689, 1691, 1697, 1707, 1709, 1710, 1711, 1712, 1713, 1724, 1730, 1736, 1739, 1772, 1781, 1783, 1784, 1787, 1799, 1803, 1804, 1808, 1809, 1826, 1831, 1832, 1833, 1834, 1835, 1839, 1840, 1841, 1842, 1843, 1846, 1850, 1853, 1857, 1859, 1860, 1861, 1862, 1863, 1867, 1870, 1871, 1876, 1877, 1881, 1882, 1885, 1886, 1888, 1889, 1890, 1896, 1897, 1899, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1913, 1914, 1915, 1917, 1918, 1919, 1920, 1922, 1923, 1927, 1928, 1929], "variabl": [0, 3, 4, 6, 15, 17, 20, 29, 32, 35, 37, 39, 47, 49, 51, 56, 61, 63, 68, 71, 447, 677, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 725, 726, 727, 728, 729, 731, 735, 736, 737, 738, 739, 740, 742, 743, 753, 757, 761, 796, 894, 958, 962, 1032, 1064, 1131, 1203, 1205, 1262, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1365, 1366, 1374, 1375, 1392, 1393, 1394, 1407, 1409, 1422, 1425, 1430, 1437, 1439, 1602, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1653, 1660, 1662, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1716, 1718, 1720, 1843, 1850, 1855, 1857, 1858, 1869, 1870, 1877, 1878, 1883, 1885, 1887, 1890, 1891, 1897, 1898, 1900, 1901, 1904, 1908, 1913, 1919, 1922], "length": [0, 15, 17, 29, 38, 39, 41, 43, 47, 260, 313, 315, 321, 351, 432, 433, 580, 581, 582, 732, 757, 811, 890, 904, 949, 980, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1116, 1131, 1164, 1187, 1205, 1209, 1321, 1322, 1340, 1345, 1350, 1359, 1366, 1369, 1374, 1390, 1392, 1428, 1437, 1465, 1473, 1496, 1497, 1498, 1505, 1513, 1532, 1571, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1714, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1788, 1790, 1791, 1792, 1794, 1795, 1804, 1829, 1850, 1859, 1861, 1863, 1870, 1877, 1878, 1884, 1890, 1917, 1924], "argument": [0, 1, 2, 4, 5, 6, 9, 10, 12, 16, 23, 28, 32, 35, 38, 41, 42, 43, 45, 47, 49, 56, 59, 61, 63, 67, 68, 70, 71, 89, 151, 197, 210, 313, 321, 444, 445, 446, 447, 448, 486, 511, 515, 557, 577, 578, 580, 581, 582, 584, 585, 600, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 692, 693, 694, 695, 696, 731, 735, 736, 737, 738, 739, 740, 790, 791, 796, 816, 817, 818, 821, 822, 823, 838, 854, 855, 858, 860, 862, 877, 878, 879, 880, 881, 882, 886, 887, 888, 889, 890, 894, 895, 896, 899, 901, 902, 903, 904, 905, 910, 911, 917, 918, 919, 920, 922, 923, 924, 925, 926, 927, 928, 930, 934, 937, 939, 940, 941, 942, 943, 945, 947, 948, 952, 956, 957, 959, 960, 962, 963, 985, 987, 991, 992, 998, 1006, 1007, 1009, 1032, 1036, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1058, 1060, 1061, 1062, 1064, 1065, 1066, 1068, 1073, 1076, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1132, 1133, 1134, 1135, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1164, 1167, 1184, 1185, 1187, 1190, 1193, 1201, 1205, 1206, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1280, 1281, 1283, 1284, 1287, 1288, 1289, 1290, 1292, 1293, 1294, 1295, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1326, 1340, 1341, 1342, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1366, 1369, 1372, 1374, 1381, 1384, 1385, 1386, 1387, 1388, 1392, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1418, 1419, 1420, 1422, 1423, 1428, 1429, 1430, 1437, 1461, 1469, 1473, 1475, 1476, 1519, 1521, 1557, 1593, 1596, 1597, 1598, 1599, 1602, 1613, 1614, 1616, 1620, 1621, 1625, 1629, 1635, 1644, 1648, 1650, 1653, 1654, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1683, 1695, 1696, 1700, 1701, 1704, 1705, 1707, 1708, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1726, 1727, 1728, 1729, 1736, 1738, 1743, 1747, 1753, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1781, 1783, 1785, 1786, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1797, 1798, 1800, 1801, 1802, 1803, 1804, 1805, 1807, 1808, 1819, 1820, 1821, 1822, 1824, 1825, 1826, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1837, 1840, 1843, 1845, 1846, 1850, 1851, 1852, 1853, 1855, 1856, 1857, 1861, 1862, 1863, 1865, 1867, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1898, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1911, 1912, 1913, 1917, 1918, 1919, 1920, 1922, 1924, 1928, 1929], "list": [0, 1, 2, 4, 6, 7, 8, 10, 13, 15, 16, 19, 20, 21, 22, 23, 28, 29, 32, 33, 35, 38, 39, 41, 42, 43, 45, 47, 49, 58, 60, 63, 68, 70, 71, 84, 185, 241, 302, 444, 446, 448, 575, 580, 581, 582, 586, 616, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 789, 790, 795, 811, 812, 813, 814, 835, 851, 858, 876, 883, 884, 885, 932, 933, 936, 940, 944, 949, 950, 990, 996, 1048, 1061, 1063, 1064, 1103, 1117, 1129, 1143, 1153, 1190, 1194, 1196, 1201, 1203, 1205, 1206, 1289, 1291, 1320, 1359, 1365, 1394, 1422, 1424, 1433, 1450, 1461, 1472, 1512, 1586, 1602, 1603, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1649, 1653, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1683, 1685, 1687, 1688, 1689, 1691, 1692, 1710, 1712, 1713, 1716, 1720, 1735, 1772, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1802, 1803, 1807, 1822, 1823, 1824, 1840, 1841, 1843, 1845, 1846, 1851, 1855, 1857, 1860, 1861, 1864, 1865, 1869, 1871, 1873, 1876, 1877, 1878, 1888, 1892, 1894, 1897, 1898, 1899, 1903, 1904, 1905, 1906, 1907, 1908, 1913, 1914, 1917, 1919, 1920, 1921, 1922, 1923, 1925, 1926, 1927, 1928], "bool": [0, 1, 2, 3, 4, 6, 15, 19, 28, 32, 38, 39, 41, 42, 43, 45, 46, 47, 49, 52, 58, 60, 63, 70, 71, 151, 197, 210, 245, 260, 319, 321, 328, 329, 330, 331, 333, 334, 339, 341, 444, 445, 446, 447, 448, 457, 470, 494, 515, 578, 600, 677, 690, 691, 692, 693, 694, 696, 732, 755, 776, 777, 782, 791, 811, 862, 871, 872, 873, 877, 890, 898, 899, 900, 901, 902, 903, 904, 905, 906, 917, 919, 922, 924, 925, 927, 928, 934, 935, 941, 942, 943, 949, 950, 966, 973, 1003, 1009, 1021, 1064, 1065, 1066, 1069, 1076, 1081, 1099, 1115, 1116, 1117, 1118, 1119, 1121, 1122, 1124, 1125, 1126, 1130, 1132, 1147, 1148, 1151, 1152, 1165, 1175, 1179, 1181, 1187, 1190, 1194, 1196, 1197, 1205, 1206, 1209, 1211, 1219, 1220, 1231, 1232, 1233, 1234, 1236, 1237, 1238, 1239, 1242, 1244, 1246, 1247, 1250, 1251, 1252, 1253, 1259, 1260, 1261, 1262, 1271, 1272, 1273, 1274, 1276, 1277, 1279, 1281, 1287, 1289, 1290, 1292, 1295, 1303, 1304, 1312, 1317, 1318, 1319, 1320, 1321, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1370, 1371, 1375, 1376, 1377, 1379, 1380, 1381, 1382, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1409, 1413, 1414, 1415, 1416, 1417, 1422, 1425, 1426, 1427, 1428, 1429, 1431, 1436, 1439, 1440, 1441, 1442, 1449, 1453, 1454, 1461, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1474, 1486, 1493, 1494, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1518, 1521, 1523, 1525, 1532, 1533, 1556, 1564, 1571, 1590, 1602, 1603, 1606, 1607, 1609, 1611, 1613, 1614, 1615, 1636, 1637, 1638, 1639, 1641, 1644, 1649, 1653, 1654, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1697, 1703, 1705, 1707, 1708, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1743, 1748, 1752, 1753, 1758, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1781, 1790, 1791, 1792, 1793, 1794, 1795, 1802, 1803, 1804, 1807, 1808, 1816, 1822, 1826, 1831, 1840, 1841, 1843, 1844, 1845, 1846, 1855, 1856, 1857, 1859, 1860, 1861, 1862, 1863, 1872, 1873, 1875, 1876, 1877, 1878, 1892, 1899, 1901, 1903, 1905, 1906, 1907, 1912, 1913, 1919, 1920, 1922, 1923, 1924, 1925, 1927, 1928], "aten": [0, 2, 3, 4, 13, 18, 22, 23, 29, 32, 35, 83, 1006, 1120, 1312, 1658, 1659, 1783, 1858, 1860, 1861, 1867, 1885, 1900, 1903, 1907, 1908], "oper": [0, 1, 3, 5, 6, 8, 9, 12, 14, 15, 17, 18, 20, 21, 26, 27, 28, 29, 30, 33, 35, 38, 43, 47, 48, 55, 56, 58, 59, 64, 69, 70, 71, 83, 84, 85, 86, 87, 254, 313, 321, 335, 352, 402, 444, 445, 446, 447, 448, 491, 494, 511, 513, 515, 586, 683, 686, 738, 739, 740, 744, 745, 754, 755, 765, 766, 776, 782, 789, 790, 792, 793, 796, 820, 823, 856, 858, 859, 862, 886, 888, 894, 896, 918, 919, 921, 923, 926, 928, 930, 932, 937, 940, 943, 947, 956, 967, 969, 997, 1006, 1037, 1042, 1043, 1044, 1045, 1058, 1063, 1064, 1065, 1066, 1076, 1081, 1099, 1111, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1131, 1138, 1141, 1147, 1148, 1165, 1190, 1200, 1201, 1205, 1206, 1209, 1219, 1232, 1242, 1245, 1246, 1259, 1260, 1269, 1276, 1284, 1289, 1294, 1303, 1304, 1317, 1320, 1334, 1339, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1369, 1370, 1371, 1379, 1380, 1381, 1382, 1384, 1389, 1408, 1413, 1418, 1419, 1420, 1422, 1435, 1440, 1441, 1442, 1449, 1464, 1465, 1467, 1469, 1473, 1489, 1490, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1506, 1507, 1508, 1509, 1513, 1514, 1516, 1517, 1521, 1525, 1532, 1538, 1540, 1546, 1547, 1557, 1559, 1563, 1571, 1577, 1578, 1589, 1590, 1591, 1592, 1602, 1604, 1605, 1638, 1644, 1649, 1653, 1654, 1675, 1681, 1691, 1695, 1704, 1705, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1727, 1733, 1750, 1751, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1784, 1785, 1786, 1787, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1807, 1822, 1843, 1850, 1853, 1855, 1856, 1858, 1859, 1860, 1864, 1867, 1882, 1884, 1885, 1886, 1887, 1889, 1890, 1894, 1895, 1896, 1897, 1898, 1902, 1904, 1907, 1909, 1911, 1912, 1913, 1914, 1918, 1920, 1921, 1924], "default": [0, 1, 3, 4, 6, 10, 13, 15, 16, 17, 19, 22, 23, 24, 25, 28, 29, 30, 32, 35, 41, 42, 43, 45, 46, 47, 49, 50, 55, 56, 57, 58, 59, 61, 63, 66, 67, 68, 69, 71, 151, 156, 171, 173, 176, 179, 180, 181, 196, 207, 210, 240, 267, 290, 297, 325, 331, 393, 444, 445, 446, 447, 448, 457, 494, 497, 498, 518, 522, 577, 578, 580, 677, 691, 694, 709, 710, 711, 712, 713, 714, 717, 727, 728, 729, 730, 732, 752, 755, 757, 765, 766, 767, 769, 770, 771, 776, 782, 790, 795, 800, 805, 806, 811, 814, 816, 817, 818, 819, 822, 825, 826, 827, 828, 829, 830, 831, 832, 838, 839, 840, 841, 842, 843, 845, 846, 851, 852, 853, 855, 862, 876, 877, 890, 891, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 919, 928, 934, 938, 941, 942, 943, 947, 950, 962, 963, 966, 969, 971, 975, 978, 979, 980, 983, 984, 991, 992, 995, 1006, 1008, 1009, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1033, 1034, 1037, 1039, 1040, 1041, 1044, 1045, 1046, 1051, 1052, 1053, 1054, 1055, 1058, 1063, 1064, 1065, 1066, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1130, 1131, 1135, 1137, 1143, 1147, 1148, 1151, 1152, 1179, 1181, 1187, 1190, 1191, 1194, 1201, 1205, 1206, 1209, 1210, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1276, 1279, 1281, 1287, 1289, 1290, 1291, 1295, 1316, 1317, 1319, 1320, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1436, 1437, 1439, 1440, 1441, 1442, 1449, 1453, 1454, 1458, 1459, 1461, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1473, 1474, 1483, 1484, 1485, 1486, 1488, 1489, 1490, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1518, 1520, 1521, 1523, 1525, 1532, 1533, 1540, 1545, 1546, 1547, 1556, 1557, 1559, 1564, 1571, 1577, 1578, 1586, 1590, 1602, 1603, 1604, 1605, 1606, 1607, 1609, 1610, 1611, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1636, 1637, 1639, 1641, 1642, 1643, 1644, 1646, 1648, 1649, 1653, 1654, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1695, 1697, 1705, 1707, 1708, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1726, 1729, 1735, 1736, 1739, 1743, 1747, 1748, 1749, 1750, 1751, 1756, 1758, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1802, 1803, 1804, 1807, 1808, 1809, 1822, 1823, 1829, 1831, 1833, 1835, 1840, 1841, 1843, 1844, 1845, 1846, 1850, 1855, 1856, 1857, 1858, 1860, 1863, 1867, 1869, 1871, 1872, 1875, 1878, 1881, 1882, 1885, 1887, 1888, 1889, 1890, 1892, 1894, 1897, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1912, 1913, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1929], "tranform": 0, "autograd": [0, 1, 5, 6, 8, 9, 17, 18, 24, 29, 41, 45, 47, 63, 64, 67, 140, 335, 444, 445, 446, 447, 448, 494, 686, 862, 876, 877, 891, 917, 919, 928, 947, 1009, 1064, 1065, 1066, 1076, 1081, 1099, 1116, 1117, 1118, 1119, 1120, 1129, 1131, 1147, 1148, 1165, 1190, 1209, 1229, 1260, 1276, 1284, 1294, 1376, 1422, 1428, 1469, 1523, 1538, 1602, 1653, 1654, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1755, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1850, 1855, 1856, 1858, 1861, 1865, 1870, 1878, 1881, 1886, 1887, 1890, 1891, 1893, 1894, 1907, 1923, 1924, 1925, 1928], "appli": [0, 1, 2, 4, 6, 9, 12, 14, 18, 28, 39, 43, 45, 46, 47, 49, 51, 58, 63, 67, 68, 69, 71, 83, 84, 120, 321, 398, 471, 511, 515, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 732, 735, 736, 737, 738, 739, 740, 755, 757, 763, 764, 765, 766, 767, 768, 769, 770, 771, 777, 778, 779, 780, 781, 807, 808, 809, 810, 837, 855, 894, 896, 897, 905, 917, 923, 926, 957, 1051, 1053, 1058, 1067, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1111, 1119, 1120, 1127, 1130, 1131, 1190, 1194, 1239, 1262, 1279, 1327, 1328, 1329, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1364, 1370, 1371, 1372, 1373, 1374, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1394, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1421, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1436, 1437, 1440, 1441, 1442, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1475, 1476, 1480, 1481, 1482, 1483, 1484, 1485, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1514, 1516, 1517, 1518, 1519, 1522, 1524, 1525, 1526, 1527, 1531, 1532, 1533, 1535, 1536, 1538, 1539, 1540, 1541, 1542, 1543, 1545, 1546, 1547, 1551, 1556, 1564, 1565, 1566, 1567, 1571, 1572, 1573, 1574, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1593, 1598, 1599, 1602, 1609, 1610, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1635, 1636, 1643, 1644, 1646, 1647, 1649, 1662, 1674, 1678, 1691, 1704, 1709, 1710, 1711, 1712, 1713, 1753, 1784, 1785, 1787, 1804, 1840, 1841, 1842, 1850, 1860, 1863, 1870, 1875, 1877, 1882, 1883, 1886, 1887, 1888, 1889, 1891, 1894, 1897, 1901, 1904, 1905, 1906, 1908, 1911, 1914, 1917, 1918], "further": [0, 1, 2, 5, 10, 15, 29, 32, 39, 41, 63, 70, 1135, 1194, 1229, 1330, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1602, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1695, 1859, 1863, 1870, 1894, 1896, 1905, 1907, 1915, 1922, 1927], "flag": [0, 2, 3, 17, 18, 19, 28, 29, 32, 41, 42, 48, 59, 61, 63, 66, 68, 71, 732, 870, 898, 900, 917, 919, 928, 941, 942, 950, 994, 1114, 1119, 1121, 1122, 1124, 1125, 1126, 1130, 1131, 1147, 1148, 1165, 1171, 1178, 1281, 1428, 1532, 1533, 1602, 1611, 1614, 1644, 1664, 1665, 1751, 1753, 1758, 1783, 1831, 1843, 1850, 1858, 1860, 1863, 1875, 1883, 1886, 1888, 1897, 1898, 1901, 1905, 1908, 1922, 1923], "onli": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 20, 21, 23, 24, 27, 28, 29, 32, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 56, 58, 59, 63, 67, 68, 70, 71, 83, 84, 120, 254, 311, 321, 323, 335, 352, 444, 445, 446, 447, 448, 457, 480, 485, 511, 513, 515, 554, 580, 581, 582, 584, 585, 611, 614, 692, 693, 732, 735, 736, 737, 738, 740, 769, 770, 771, 776, 782, 783, 784, 788, 790, 798, 811, 814, 817, 818, 821, 825, 839, 846, 855, 875, 891, 894, 895, 896, 897, 898, 900, 905, 919, 920, 928, 965, 966, 967, 969, 976, 978, 980, 1006, 1007, 1009, 1030, 1060, 1064, 1066, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1109, 1110, 1114, 1115, 1120, 1131, 1143, 1147, 1148, 1152, 1160, 1171, 1179, 1188, 1190, 1193, 1194, 1201, 1205, 1206, 1209, 1220, 1225, 1226, 1228, 1229, 1230, 1231, 1233, 1235, 1236, 1237, 1238, 1248, 1250, 1251, 1253, 1254, 1261, 1262, 1279, 1284, 1330, 1353, 1354, 1355, 1358, 1359, 1365, 1366, 1369, 1392, 1422, 1425, 1427, 1428, 1430, 1438, 1461, 1473, 1474, 1504, 1513, 1515, 1521, 1532, 1559, 1589, 1590, 1593, 1596, 1597, 1598, 1599, 1602, 1604, 1605, 1615, 1635, 1636, 1637, 1649, 1656, 1660, 1664, 1665, 1667, 1678, 1681, 1685, 1688, 1689, 1691, 1695, 1707, 1716, 1720, 1722, 1724, 1747, 1751, 1752, 1754, 1758, 1785, 1789, 1799, 1804, 1808, 1822, 1833, 1835, 1840, 1841, 1843, 1847, 1848, 1849, 1850, 1857, 1861, 1862, 1863, 1867, 1869, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1911, 1913, 1914, 1915, 1917, 1918, 1920, 1921, 1922, 1923, 1924, 1925], "valid": [0, 2, 15, 21, 24, 29, 41, 47, 56, 58, 71, 85, 744, 745, 754, 788, 941, 1006, 1063, 1188, 1190, 1191, 1211, 1225, 1226, 1235, 1236, 1237, 1248, 1253, 1284, 1350, 1351, 1352, 1496, 1497, 1498, 1521, 1593, 1620, 1625, 1629, 1658, 1659, 1679, 1680, 1685, 1686, 1687, 1688, 1690, 1691, 1692, 1693, 1707, 1860, 1861, 1862, 1863, 1877, 1878, 1883, 1886, 1888, 1892, 1901, 1904, 1907, 1913, 1914], "dict": [0, 1, 4, 6, 19, 24, 28, 38, 39, 41, 42, 43, 45, 46, 47, 49, 52, 56, 60, 63, 65, 67, 71, 677, 789, 790, 791, 812, 813, 814, 833, 851, 907, 950, 1006, 1007, 1020, 1029, 1119, 1129, 1131, 1188, 1189, 1190, 1191, 1196, 1201, 1205, 1206, 1261, 1262, 1359, 1369, 1422, 1423, 1432, 1473, 1593, 1602, 1625, 1644, 1656, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1850, 1857, 1860, 1861, 1863, 1864, 1872, 1873, 1888, 1894, 1899, 1901, 1903, 1904, 1913, 1914, 1922, 1926, 1927, 1928], "dictionari": [0, 4, 19, 24, 32, 38, 39, 47, 67, 71, 677, 789, 790, 791, 794, 812, 813, 814, 835, 836, 837, 851, 855, 861, 950, 1020, 1119, 1129, 1190, 1191, 1197, 1201, 1205, 1206, 1261, 1262, 1365, 1366, 1422, 1423, 1432, 1512, 1625, 1862, 1864, 1888, 1894, 1901, 1904, 1913, 1922, 1926, 1928], "map": [0, 4, 16, 21, 28, 32, 41, 47, 49, 55, 56, 58, 59, 63, 68, 69, 71, 681, 732, 789, 790, 794, 796, 811, 812, 814, 836, 837, 851, 852, 853, 854, 855, 861, 882, 931, 1120, 1131, 1143, 1152, 1197, 1200, 1261, 1262, 1353, 1354, 1355, 1361, 1362, 1363, 1367, 1369, 1418, 1419, 1420, 1423, 1432, 1507, 1508, 1509, 1514, 1609, 1625, 1708, 1710, 1840, 1841, 1850, 1864, 1877, 1879, 1883, 1887, 1888, 1889, 1895, 1900, 1905, 1908, 1911, 1913, 1914, 1915, 1919, 1924, 1928], "decomposit": [0, 15, 16, 28, 47, 71, 941, 1135, 1219, 1220, 1225, 1226, 1227, 1228, 1229, 1231, 1236, 1237, 1238, 1239, 1244, 1248, 1249, 1253, 1254, 1279, 1281, 1609, 1695, 1697, 1701, 1707, 1808, 1809, 1858, 1897], "requir": [0, 1, 2, 6, 9, 10, 12, 13, 14, 16, 17, 19, 20, 24, 32, 33, 38, 39, 41, 42, 43, 45, 47, 49, 57, 58, 63, 66, 68, 70, 71, 120, 151, 222, 335, 457, 494, 511, 513, 515, 557, 790, 792, 820, 823, 877, 886, 890, 895, 898, 899, 900, 901, 902, 903, 904, 950, 963, 964, 1019, 1063, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1104, 1105, 1131, 1132, 1203, 1229, 1260, 1262, 1276, 1358, 1365, 1366, 1465, 1466, 1467, 1468, 1469, 1471, 1513, 1571, 1593, 1602, 1603, 1612, 1614, 1616, 1656, 1667, 1677, 1695, 1792, 1804, 1843, 1850, 1857, 1860, 1863, 1865, 1870, 1871, 1875, 1877, 1878, 1882, 1883, 1885, 1886, 1887, 1888, 1890, 1891, 1892, 1893, 1894, 1896, 1899, 1901, 1905, 1906, 1908, 1909, 1913, 1914, 1915, 1917, 1922, 1924, 1925, 1927, 1928], "specifi": [0, 2, 3, 4, 6, 9, 13, 15, 19, 28, 32, 38, 39, 41, 45, 46, 47, 49, 51, 56, 57, 58, 59, 63, 71, 98, 151, 196, 259, 319, 331, 470, 480, 491, 495, 497, 498, 511, 513, 515, 534, 542, 543, 557, 577, 580, 581, 582, 584, 585, 600, 677, 732, 738, 739, 740, 765, 766, 790, 791, 792, 796, 811, 820, 823, 837, 851, 855, 856, 858, 875, 877, 889, 890, 904, 921, 944, 950, 961, 962, 963, 966, 967, 976, 977, 978, 980, 995, 998, 1009, 1034, 1044, 1045, 1046, 1050, 1051, 1053, 1063, 1066, 1077, 1080, 1082, 1083, 1085, 1086, 1088, 1089, 1090, 1092, 1093, 1094, 1095, 1096, 1098, 1100, 1121, 1122, 1125, 1131, 1132, 1143, 1151, 1152, 1190, 1194, 1205, 1206, 1232, 1242, 1244, 1246, 1247, 1256, 1259, 1261, 1262, 1272, 1289, 1291, 1297, 1316, 1317, 1320, 1336, 1337, 1338, 1339, 1345, 1354, 1356, 1358, 1359, 1365, 1366, 1369, 1376, 1382, 1383, 1388, 1389, 1392, 1413, 1414, 1419, 1422, 1425, 1426, 1427, 1428, 1429, 1436, 1453, 1454, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1475, 1476, 1489, 1490, 1493, 1494, 1504, 1505, 1512, 1513, 1518, 1521, 1533, 1540, 1556, 1557, 1564, 1571, 1577, 1578, 1602, 1607, 1609, 1610, 1613, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1646, 1649, 1656, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1672, 1674, 1675, 1676, 1677, 1678, 1683, 1688, 1689, 1697, 1705, 1714, 1730, 1735, 1736, 1739, 1756, 1784, 1786, 1787, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1802, 1803, 1807, 1823, 1825, 1829, 1839, 1840, 1841, 1842, 1844, 1845, 1846, 1850, 1857, 1860, 1862, 1863, 1867, 1869, 1870, 1872, 1873, 1876, 1877, 1883, 1886, 1888, 1892, 1894, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1912, 1913, 1917, 1918, 1919, 1920, 1922, 1924], "str": [0, 1, 2, 3, 4, 17, 19, 21, 28, 29, 32, 38, 39, 41, 43, 45, 46, 47, 49, 52, 56, 58, 60, 63, 71, 321, 511, 515, 600, 776, 782, 789, 790, 791, 812, 813, 814, 851, 898, 900, 908, 912, 913, 938, 950, 965, 976, 977, 978, 980, 989, 990, 992, 993, 994, 1006, 1007, 1008, 1020, 1021, 1023, 1025, 1037, 1058, 1063, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1119, 1120, 1124, 1129, 1131, 1139, 1188, 1189, 1190, 1191, 1193, 1194, 1196, 1199, 1235, 1248, 1253, 1254, 1261, 1262, 1291, 1303, 1304, 1319, 1338, 1339, 1345, 1350, 1351, 1352, 1356, 1358, 1366, 1372, 1376, 1382, 1383, 1388, 1389, 1398, 1399, 1400, 1413, 1414, 1422, 1423, 1425, 1426, 1427, 1429, 1432, 1436, 1439, 1450, 1453, 1454, 1465, 1467, 1469, 1470, 1471, 1472, 1474, 1493, 1494, 1504, 1505, 1513, 1518, 1521, 1532, 1533, 1556, 1564, 1590, 1602, 1609, 1610, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1643, 1644, 1646, 1656, 1659, 1667, 1683, 1689, 1691, 1708, 1739, 1743, 1750, 1751, 1785, 1804, 1850, 1857, 1859, 1860, 1861, 1862, 1863, 1864, 1871, 1872, 1873, 1875, 1877, 1881, 1883, 1901, 1903, 1905, 1906, 1907, 1912, 1913, 1919, 1922, 1924, 1926, 1927, 1928], "result": [0, 2, 4, 5, 6, 8, 9, 10, 13, 16, 21, 22, 25, 28, 29, 32, 35, 38, 39, 41, 43, 47, 49, 51, 56, 59, 63, 68, 69, 70, 71, 154, 222, 223, 254, 255, 315, 335, 398, 494, 496, 553, 580, 581, 582, 584, 585, 615, 683, 684, 685, 686, 687, 690, 692, 693, 694, 696, 757, 790, 874, 876, 892, 893, 898, 899, 900, 901, 902, 903, 905, 906, 918, 921, 932, 936, 941, 947, 949, 958, 960, 976, 978, 980, 1006, 1007, 1020, 1042, 1043, 1044, 1045, 1046, 1058, 1063, 1081, 1084, 1090, 1099, 1106, 1108, 1111, 1115, 1116, 1119, 1120, 1121, 1124, 1125, 1130, 1131, 1135, 1151, 1152, 1154, 1167, 1181, 1190, 1193, 1194, 1201, 1205, 1206, 1208, 1210, 1211, 1215, 1229, 1231, 1233, 1234, 1242, 1246, 1248, 1250, 1251, 1252, 1259, 1269, 1270, 1277, 1287, 1289, 1290, 1291, 1292, 1294, 1295, 1317, 1320, 1359, 1361, 1362, 1363, 1367, 1369, 1374, 1388, 1392, 1422, 1428, 1437, 1466, 1467, 1468, 1469, 1473, 1503, 1521, 1532, 1586, 1589, 1590, 1602, 1609, 1611, 1644, 1647, 1648, 1649, 1650, 1659, 1689, 1695, 1697, 1704, 1705, 1708, 1714, 1727, 1733, 1748, 1776, 1786, 1788, 1789, 1800, 1802, 1803, 1804, 1807, 1808, 1809, 1818, 1822, 1823, 1828, 1829, 1831, 1832, 1834, 1845, 1846, 1850, 1860, 1861, 1862, 1863, 1870, 1871, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1894, 1897, 1898, 1901, 1902, 1904, 1906, 1907, 1909, 1910, 1913, 1914, 1917, 1920, 1922, 1923, 1924, 1927, 1928], "need": [0, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 21, 24, 29, 32, 33, 38, 39, 41, 42, 43, 45, 46, 47, 50, 51, 56, 58, 59, 61, 63, 65, 66, 68, 71, 151, 254, 470, 493, 497, 580, 677, 731, 732, 816, 817, 818, 821, 822, 823, 838, 855, 886, 890, 894, 895, 904, 931, 932, 940, 1000, 1009, 1016, 1051, 1053, 1063, 1084, 1086, 1106, 1119, 1190, 1283, 1312, 1358, 1365, 1418, 1419, 1420, 1422, 1428, 1465, 1467, 1469, 1496, 1497, 1498, 1589, 1602, 1614, 1616, 1620, 1622, 1650, 1678, 1724, 1729, 1743, 1801, 1829, 1858, 1860, 1862, 1863, 1870, 1871, 1875, 1877, 1878, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1893, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1911, 1913, 1914, 1915, 1917, 1919, 1920, 1924, 1925, 1927, 1928], "effect": [0, 1, 4, 8, 12, 32, 38, 39, 41, 47, 60, 68, 71, 197, 210, 600, 732, 776, 782, 998, 1046, 1131, 1190, 1232, 1233, 1234, 1235, 1291, 1330, 1345, 1353, 1354, 1355, 1360, 1361, 1362, 1363, 1367, 1422, 1428, 1474, 1532, 1559, 1590, 1596, 1602, 1603, 1621, 1675, 1683, 1783, 1788, 1808, 1829, 1850, 1857, 1860, 1871, 1881, 1882, 1883, 1886, 1888, 1908, 1911, 1919, 1920, 1922], "By": [0, 2, 3, 4, 6, 14, 17, 23, 24, 27, 29, 32, 38, 41, 50, 55, 71, 444, 445, 446, 447, 448, 877, 962, 969, 1012, 1014, 1046, 1058, 1081, 1083, 1084, 1085, 1086, 1094, 1095, 1096, 1121, 1122, 1124, 1125, 1131, 1143, 1151, 1152, 1194, 1242, 1253, 1261, 1290, 1295, 1316, 1338, 1339, 1340, 1341, 1342, 1356, 1358, 1376, 1382, 1385, 1386, 1387, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1461, 1470, 1493, 1494, 1504, 1533, 1556, 1564, 1646, 1697, 1708, 1729, 1783, 1829, 1850, 1857, 1862, 1867, 1870, 1883, 1886, 1888, 1890, 1894, 1897, 1899, 1901, 1904, 1912, 1913, 1917, 1924], "arbitrari": [0, 2, 4, 17, 24, 29, 41, 45, 254, 887, 1046, 1253, 1261, 1359, 1365, 1389, 1413, 1473, 1493, 1494, 1512, 1533, 1559, 1635, 1808, 1829, 1863, 1869, 1883, 1889, 1893, 1894, 1904, 1906, 1908, 1917, 1925, 1928], "keyword": [0, 1, 2, 6, 38, 41, 42, 45, 63, 68, 71, 89, 313, 321, 444, 445, 446, 447, 448, 578, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 692, 693, 694, 695, 696, 858, 862, 877, 878, 879, 880, 881, 882, 918, 919, 920, 922, 923, 924, 925, 926, 927, 928, 930, 934, 937, 939, 941, 942, 943, 945, 947, 948, 952, 956, 957, 959, 960, 962, 963, 976, 978, 980, 1006, 1007, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1055, 1058, 1060, 1062, 1064, 1065, 1066, 1068, 1073, 1076, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1116, 1117, 1118, 1119, 1132, 1133, 1134, 1135, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1164, 1167, 1184, 1185, 1190, 1193, 1205, 1206, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1280, 1281, 1283, 1284, 1287, 1288, 1289, 1290, 1292, 1293, 1294, 1295, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1326, 1359, 1381, 1384, 1422, 1596, 1597, 1602, 1614, 1616, 1621, 1625, 1644, 1648, 1650, 1653, 1654, 1656, 1695, 1696, 1700, 1701, 1704, 1705, 1707, 1708, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1726, 1727, 1728, 1729, 1736, 1738, 1743, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1781, 1783, 1786, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1797, 1798, 1800, 1801, 1802, 1803, 1805, 1807, 1808, 1819, 1820, 1821, 1822, 1826, 1829, 1831, 1832, 1833, 1834, 1835, 1837, 1843, 1845, 1846, 1847, 1852, 1853, 1855, 1856, 1857, 1863, 1864, 1877, 1878, 1888, 1897, 1901, 1904, 1913, 1917, 1918, 1922, 1925, 1928], "tupl": [0, 4, 6, 21, 28, 32, 38, 43, 49, 55, 56, 58, 63, 71, 319, 444, 446, 448, 495, 518, 534, 557, 580, 581, 582, 692, 693, 694, 732, 763, 764, 765, 766, 769, 770, 771, 776, 782, 783, 784, 790, 814, 815, 851, 858, 859, 875, 876, 883, 884, 885, 886, 887, 889, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 911, 933, 961, 976, 977, 980, 991, 1009, 1015, 1042, 1043, 1061, 1064, 1066, 1080, 1082, 1083, 1085, 1086, 1088, 1089, 1090, 1092, 1093, 1095, 1096, 1098, 1100, 1103, 1113, 1117, 1119, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1135, 1151, 1153, 1190, 1196, 1201, 1205, 1206, 1211, 1220, 1225, 1226, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1242, 1246, 1248, 1249, 1251, 1253, 1256, 1259, 1277, 1279, 1281, 1287, 1289, 1291, 1292, 1295, 1297, 1317, 1320, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1369, 1370, 1371, 1390, 1391, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1423, 1428, 1432, 1443, 1444, 1445, 1446, 1447, 1448, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1481, 1482, 1484, 1485, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1516, 1517, 1532, 1545, 1546, 1547, 1557, 1559, 1590, 1591, 1592, 1597, 1598, 1599, 1602, 1614, 1625, 1638, 1644, 1648, 1649, 1653, 1656, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1697, 1698, 1707, 1716, 1718, 1720, 1730, 1734, 1735, 1781, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1799, 1802, 1803, 1807, 1808, 1809, 1822, 1823, 1824, 1825, 1826, 1831, 1838, 1839, 1840, 1841, 1845, 1846, 1850, 1851, 1853, 1855, 1860, 1861, 1864, 1875, 1878, 1883, 1886, 1888, 1889, 1894, 1899, 1901, 1904, 1905, 1908, 1913, 1917, 1922, 1924, 1927, 1928], "guard": [0, 17, 24, 26, 29, 49, 677, 1858, 1869, 1896, 1903, 1905, 1925, 1928], "repres": [0, 2, 9, 15, 16, 21, 30, 38, 39, 47, 48, 49, 51, 52, 58, 60, 63, 71, 83, 757, 789, 790, 793, 886, 958, 962, 964, 996, 999, 1063, 1084, 1086, 1091, 1093, 1094, 1095, 1096, 1120, 1143, 1150, 1179, 1180, 1183, 1186, 1189, 1205, 1206, 1237, 1279, 1330, 1345, 1422, 1428, 1469, 1471, 1473, 1602, 1608, 1611, 1616, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1635, 1645, 1657, 1659, 1683, 1689, 1695, 1697, 1708, 1790, 1791, 1792, 1794, 1795, 1804, 1808, 1840, 1841, 1848, 1849, 1860, 1862, 1863, 1870, 1873, 1878, 1883, 1888, 1889, 1891, 1893, 1894, 1897, 1901, 1902, 1906, 1908, 1909, 1911, 1913, 1917, 1920, 1929], "option": [0, 1, 2, 4, 6, 14, 17, 18, 19, 20, 21, 22, 25, 28, 29, 32, 38, 41, 45, 46, 47, 49, 52, 56, 57, 58, 60, 61, 63, 71, 84, 89, 151, 156, 171, 173, 176, 179, 180, 181, 196, 207, 210, 240, 267, 297, 325, 331, 393, 444, 445, 446, 447, 448, 486, 497, 498, 511, 518, 522, 534, 557, 577, 578, 580, 581, 582, 584, 585, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 691, 692, 693, 694, 695, 696, 732, 755, 776, 777, 782, 789, 791, 796, 815, 851, 856, 859, 862, 873, 875, 876, 877, 878, 879, 880, 881, 882, 889, 890, 898, 899, 900, 901, 902, 903, 904, 905, 906, 909, 910, 911, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 930, 934, 937, 939, 940, 941, 942, 943, 945, 947, 948, 949, 950, 956, 957, 959, 960, 961, 962, 963, 964, 966, 967, 969, 971, 975, 976, 978, 979, 980, 983, 984, 991, 992, 995, 998, 1006, 1007, 1008, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1033, 1034, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1060, 1062, 1063, 1064, 1065, 1066, 1068, 1073, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1116, 1117, 1118, 1119, 1120, 1123, 1124, 1125, 1132, 1133, 1134, 1135, 1143, 1146, 1147, 1148, 1149, 1150, 1151, 1154, 1155, 1156, 1164, 1167, 1179, 1181, 1184, 1185, 1187, 1188, 1190, 1191, 1194, 1196, 1203, 1205, 1206, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1303, 1304, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1326, 1328, 1329, 1330, 1332, 1333, 1334, 1336, 1337, 1338, 1339, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1369, 1370, 1371, 1372, 1376, 1379, 1380, 1381, 1382, 1383, 1388, 1389, 1394, 1398, 1399, 1400, 1401, 1402, 1403, 1408, 1413, 1414, 1418, 1419, 1420, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1431, 1432, 1433, 1436, 1440, 1441, 1442, 1449, 1453, 1454, 1461, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1473, 1474, 1475, 1476, 1486, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1512, 1513, 1516, 1517, 1518, 1521, 1523, 1532, 1533, 1540, 1545, 1546, 1547, 1556, 1557, 1564, 1571, 1577, 1578, 1590, 1598, 1599, 1602, 1603, 1609, 1610, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1633, 1634, 1635, 1636, 1637, 1638, 1639, 1641, 1643, 1644, 1646, 1648, 1649, 1650, 1653, 1654, 1655, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1672, 1674, 1675, 1676, 1677, 1678, 1682, 1695, 1696, 1697, 1700, 1704, 1705, 1707, 1708, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1726, 1727, 1728, 1729, 1736, 1738, 1743, 1756, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1781, 1782, 1783, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1807, 1808, 1809, 1819, 1820, 1821, 1822, 1823, 1826, 1828, 1831, 1832, 1833, 1834, 1835, 1837, 1840, 1841, 1843, 1844, 1845, 1846, 1847, 1852, 1853, 1855, 1856, 1857, 1860, 1861, 1863, 1865, 1867, 1869, 1871, 1872, 1873, 1878, 1881, 1886, 1888, 1889, 1890, 1893, 1894, 1898, 1901, 1905, 1907, 1908, 1913, 1917, 1918, 1920, 1922, 1924, 1927], "accumul": [0, 1, 2, 3, 15, 17, 29, 63, 151, 290, 313, 318, 319, 321, 470, 683, 890, 904, 1259, 1602, 1662, 1663, 1843, 1860, 1861, 1873, 1883, 1886, 1887, 1890, 1897, 1904, 1909, 1913, 1914, 1917], "dure": [0, 1, 2, 6, 12, 13, 17, 20, 21, 25, 28, 29, 32, 35, 39, 41, 43, 49, 50, 52, 58, 63, 70, 71, 84, 335, 501, 502, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 790, 824, 886, 887, 896, 1008, 1009, 1021, 1022, 1041, 1200, 1202, 1203, 1205, 1261, 1334, 1340, 1341, 1342, 1359, 1360, 1365, 1366, 1385, 1386, 1387, 1440, 1461, 1467, 1469, 1506, 1512, 1513, 1593, 1602, 1604, 1605, 1642, 1656, 1659, 1692, 1789, 1833, 1835, 1862, 1870, 1871, 1873, 1876, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1891, 1893, 1894, 1897, 1898, 1901, 1905, 1907, 1908, 1911, 1913, 1915, 1924], "abov": [0, 1, 2, 4, 13, 14, 15, 17, 18, 20, 21, 22, 23, 29, 33, 41, 47, 51, 58, 60, 63, 64, 69, 71, 83, 614, 677, 789, 790, 877, 919, 928, 943, 1020, 1046, 1050, 1051, 1052, 1053, 1054, 1063, 1135, 1147, 1148, 1190, 1191, 1210, 1221, 1225, 1226, 1244, 1246, 1247, 1250, 1253, 1256, 1259, 1262, 1338, 1369, 1422, 1450, 1458, 1473, 1571, 1593, 1650, 1683, 1707, 1718, 1719, 1751, 1756, 1769, 1788, 1829, 1832, 1833, 1834, 1835, 1857, 1860, 1862, 1863, 1870, 1883, 1884, 1885, 1886, 1888, 1889, 1891, 1894, 1898, 1899, 1901, 1905, 1908, 1913, 1914, 1915, 1917, 1918, 1924], "assertionerror": [0, 29, 71, 731, 1659, 1924], "without": [0, 1, 2, 4, 6, 8, 9, 10, 12, 15, 16, 17, 20, 29, 32, 35, 38, 39, 41, 42, 43, 45, 47, 51, 58, 63, 64, 69, 70, 71, 254, 614, 947, 967, 969, 1004, 1084, 1085, 1086, 1094, 1095, 1096, 1187, 1188, 1190, 1191, 1236, 1237, 1252, 1259, 1312, 1340, 1341, 1342, 1362, 1366, 1385, 1386, 1387, 1419, 1422, 1430, 1461, 1469, 1513, 1593, 1602, 1626, 1642, 1683, 1714, 1730, 1747, 1748, 1838, 1857, 1862, 1863, 1870, 1871, 1873, 1875, 1877, 1882, 1883, 1884, 1886, 1887, 1888, 1891, 1892, 1894, 1896, 1898, 1899, 1901, 1905, 1906, 1908, 1912, 1913, 1917, 1922, 1927, 1929], "dynamo": [0, 13, 15, 16, 18, 19, 20, 21, 23, 24, 25, 29, 71, 677, 950, 1869, 1902], "output": [0, 1, 2, 5, 6, 8, 12, 13, 14, 15, 16, 17, 20, 21, 23, 27, 28, 29, 35, 38, 39, 41, 45, 46, 47, 49, 55, 56, 67, 68, 69, 71, 140, 313, 321, 444, 445, 446, 448, 511, 515, 563, 614, 677, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 692, 693, 694, 695, 696, 717, 725, 726, 731, 732, 735, 736, 737, 738, 739, 740, 741, 742, 743, 746, 747, 748, 749, 750, 751, 752, 753, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 769, 770, 771, 772, 774, 776, 777, 778, 779, 780, 782, 783, 784, 789, 790, 791, 793, 796, 799, 811, 814, 855, 858, 859, 860, 862, 871, 872, 875, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 918, 920, 921, 922, 923, 924, 925, 926, 927, 930, 934, 937, 938, 939, 940, 941, 942, 943, 945, 948, 956, 957, 959, 960, 963, 976, 978, 979, 980, 1006, 1007, 1009, 1019, 1020, 1042, 1043, 1044, 1045, 1047, 1050, 1051, 1053, 1055, 1058, 1060, 1062, 1063, 1064, 1065, 1066, 1068, 1073, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1106, 1107, 1108, 1109, 1110, 1111, 1113, 1117, 1118, 1120, 1121, 1122, 1124, 1125, 1126, 1127, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1143, 1146, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1164, 1167, 1184, 1185, 1187, 1190, 1194, 1201, 1205, 1206, 1210, 1211, 1212, 1213, 1214, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1280, 1281, 1283, 1284, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1322, 1323, 1324, 1326, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1488, 1489, 1490, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1512, 1513, 1515, 1516, 1517, 1518, 1521, 1523, 1532, 1533, 1538, 1540, 1545, 1546, 1547, 1556, 1557, 1561, 1562, 1563, 1564, 1571, 1586, 1590, 1591, 1592, 1596, 1598, 1599, 1602, 1610, 1611, 1612, 1615, 1636, 1638, 1639, 1643, 1646, 1648, 1649, 1650, 1653, 1654, 1656, 1659, 1660, 1678, 1682, 1695, 1696, 1704, 1705, 1708, 1711, 1712, 1713, 1714, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1726, 1727, 1728, 1729, 1731, 1732, 1736, 1738, 1743, 1751, 1756, 1759, 1761, 1773, 1774, 1776, 1781, 1785, 1786, 1788, 1789, 1797, 1798, 1800, 1801, 1802, 1803, 1804, 1805, 1807, 1808, 1819, 1820, 1821, 1826, 1829, 1831, 1832, 1834, 1837, 1839, 1840, 1841, 1843, 1844, 1845, 1846, 1847, 1850, 1852, 1853, 1855, 1856, 1857, 1860, 1861, 1863, 1869, 1871, 1876, 1877, 1878, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1894, 1897, 1901, 1904, 1905, 1906, 1907, 1908, 1910, 1914, 1917, 1918, 1920, 1921, 1922, 1924, 1926, 1927], "consist": [0, 13, 17, 23, 29, 38, 41, 43, 46, 47, 58, 59, 71, 905, 941, 942, 1190, 1219, 1225, 1226, 1228, 1230, 1231, 1232, 1233, 1257, 1259, 1422, 1469, 1611, 1614, 1660, 1707, 1808, 1860, 1863, 1870, 1877, 1878, 1889, 1894, 1898, 1901, 1904, 1907, 1917], "type": [0, 2, 3, 4, 6, 13, 14, 15, 19, 20, 21, 28, 32, 33, 34, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 52, 56, 58, 59, 60, 63, 68, 70, 71, 89, 151, 192, 197, 209, 326, 329, 333, 341, 444, 445, 446, 447, 448, 480, 556, 601, 677, 682, 683, 684, 685, 686, 687, 731, 732, 735, 736, 737, 746, 748, 749, 750, 751, 753, 761, 763, 764, 767, 768, 769, 770, 771, 772, 773, 774, 775, 778, 781, 789, 790, 791, 794, 812, 813, 814, 816, 817, 818, 819, 820, 822, 824, 837, 851, 852, 853, 854, 855, 856, 857, 858, 859, 862, 876, 886, 887, 888, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 910, 911, 918, 919, 921, 922, 923, 924, 925, 926, 927, 928, 929, 931, 932, 934, 935, 936, 937, 938, 940, 949, 950, 973, 975, 982, 983, 984, 986, 989, 990, 991, 992, 993, 994, 995, 996, 997, 1001, 1003, 1006, 1007, 1008, 1009, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1022, 1026, 1038, 1040, 1041, 1044, 1045, 1058, 1063, 1064, 1065, 1066, 1076, 1077, 1078, 1081, 1099, 1106, 1108, 1109, 1110, 1111, 1114, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1124, 1127, 1128, 1129, 1131, 1133, 1137, 1138, 1139, 1142, 1147, 1148, 1150, 1151, 1152, 1166, 1169, 1172, 1175, 1186, 1187, 1188, 1190, 1191, 1193, 1196, 1199, 1201, 1203, 1205, 1206, 1208, 1209, 1212, 1221, 1225, 1242, 1246, 1253, 1259, 1260, 1261, 1262, 1276, 1279, 1282, 1289, 1291, 1298, 1299, 1301, 1311, 1317, 1320, 1330, 1334, 1350, 1351, 1352, 1359, 1366, 1412, 1422, 1423, 1424, 1428, 1432, 1433, 1450, 1455, 1456, 1457, 1465, 1466, 1467, 1468, 1469, 1481, 1482, 1486, 1487, 1491, 1493, 1494, 1495, 1496, 1497, 1498, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1512, 1513, 1514, 1515, 1518, 1520, 1521, 1522, 1523, 1525, 1526, 1527, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1539, 1540, 1542, 1543, 1544, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1564, 1566, 1567, 1569, 1571, 1572, 1574, 1575, 1576, 1577, 1578, 1584, 1587, 1588, 1589, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1606, 1607, 1608, 1609, 1610, 1611, 1613, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1633, 1634, 1636, 1637, 1638, 1639, 1640, 1641, 1643, 1644, 1646, 1648, 1649, 1653, 1654, 1656, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1697, 1705, 1706, 1707, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1726, 1727, 1729, 1732, 1733, 1743, 1744, 1747, 1748, 1749, 1751, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1784, 1787, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1804, 1805, 1807, 1808, 1809, 1822, 1831, 1833, 1835, 1840, 1841, 1843, 1844, 1850, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1864, 1871, 1872, 1873, 1876, 1878, 1881, 1882, 1883, 1885, 1886, 1891, 1892, 1893, 1894, 1897, 1900, 1902, 1903, 1906, 1907, 1908, 1910, 1911, 1912, 1913, 1917, 1918, 1919, 1920, 1922, 1924, 1925, 1926, 1927, 1928], "headerdoc": 0, "wa": [0, 1, 2, 4, 8, 16, 18, 21, 22, 28, 35, 39, 41, 46, 56, 57, 58, 59, 63, 70, 71, 335, 485, 494, 677, 782, 789, 851, 940, 951, 966, 967, 990, 994, 1009, 1022, 1041, 1083, 1131, 1187, 1196, 1205, 1220, 1231, 1233, 1237, 1261, 1279, 1312, 1392, 1418, 1419, 1420, 1451, 1474, 1486, 1521, 1574, 1590, 1602, 1603, 1638, 1683, 1689, 1802, 1803, 1840, 1841, 1845, 1846, 1850, 1857, 1860, 1862, 1863, 1864, 1867, 1869, 1870, 1873, 1875, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1893, 1895, 1901, 1904, 1906, 1908, 1912, 1913, 1924], "author": [0, 14, 17, 20, 24, 25, 29, 39, 58, 59, 63, 1131, 1674, 1714, 1850, 1882], "chatgpt": 0, "slight": [0, 1747, 1917, 1920], "modif": [0, 17, 20, 33, 63, 71, 222, 777, 894, 1115, 1116, 1190, 1422, 1602, 1883, 1888, 1894, 1905, 1908], "don": [0, 1, 2, 5, 8, 10, 15, 16, 17, 18, 21, 22, 30, 41, 57, 64, 66, 68, 71, 151, 782, 792, 890, 891, 904, 1037, 1119, 1205, 1283, 1385, 1386, 1387, 1474, 1590, 1593, 1602, 1650, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1750, 1857, 1860, 1864, 1875, 1876, 1877, 1883, 1886, 1888, 1890, 1894, 1896, 1900, 1901, 1904, 1905, 1906, 1908, 1913, 1914, 1917, 1928], "ani": [0, 1, 2, 3, 4, 5, 6, 8, 10, 12, 13, 14, 15, 16, 17, 20, 21, 24, 27, 28, 29, 30, 32, 35, 38, 39, 41, 42, 43, 45, 47, 49, 51, 52, 56, 57, 58, 59, 61, 63, 68, 70, 71, 151, 254, 497, 542, 614, 694, 755, 778, 789, 790, 791, 797, 807, 808, 809, 810, 812, 813, 814, 815, 820, 821, 823, 851, 862, 886, 887, 888, 890, 896, 898, 904, 905, 906, 932, 936, 937, 955, 966, 1002, 1009, 1020, 1079, 1080, 1082, 1083, 1084, 1086, 1090, 1094, 1095, 1096, 1111, 1119, 1120, 1127, 1128, 1129, 1131, 1152, 1189, 1190, 1194, 1196, 1200, 1201, 1203, 1205, 1211, 1219, 1221, 1225, 1226, 1230, 1235, 1236, 1237, 1242, 1243, 1246, 1250, 1253, 1259, 1261, 1327, 1328, 1329, 1331, 1332, 1333, 1334, 1338, 1339, 1343, 1344, 1350, 1351, 1352, 1359, 1360, 1364, 1368, 1369, 1372, 1373, 1376, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1388, 1389, 1408, 1409, 1411, 1412, 1413, 1421, 1422, 1430, 1432, 1433, 1436, 1440, 1441, 1442, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1471, 1472, 1473, 1492, 1496, 1497, 1498, 1538, 1557, 1558, 1571, 1593, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1626, 1636, 1637, 1639, 1642, 1644, 1649, 1656, 1659, 1678, 1683, 1723, 1739, 1754, 1756, 1808, 1850, 1857, 1860, 1861, 1862, 1870, 1871, 1872, 1873, 1875, 1876, 1877, 1878, 1882, 1883, 1885, 1886, 1888, 1889, 1891, 1892, 1893, 1894, 1895, 1896, 1898, 1901, 1903, 1904, 1905, 1906, 1908, 1913, 1914, 1915, 1917, 1919, 1922, 1924, 1926, 1927, 1928], "just": [0, 2, 3, 8, 12, 13, 14, 15, 16, 17, 18, 21, 26, 28, 32, 39, 41, 46, 47, 49, 56, 71, 586, 684, 694, 787, 820, 823, 886, 888, 914, 955, 956, 1205, 1206, 1244, 1247, 1252, 1253, 1279, 1361, 1362, 1363, 1367, 1602, 1614, 1615, 1679, 1747, 1832, 1833, 1834, 1835, 1857, 1860, 1875, 1882, 1883, 1888, 1889, 1891, 1893, 1894, 1895, 1899, 1905, 1906, 1913, 1914, 1920, 1921, 1923, 1927], "prior": [0, 10, 12, 17, 39, 41, 43, 49, 897, 1262, 1467, 1469, 1571, 1625, 1884, 1886, 1888, 1904, 1908], "recurs": [0, 2, 14, 18, 21, 47, 63, 71, 1055, 1190, 1201, 1203, 1422, 1681, 1862, 1888, 1894, 1905, 1913], "manag": [0, 1, 2, 3, 6, 8, 15, 16, 17, 21, 41, 45, 47, 49, 56, 58, 59, 60, 63, 71, 89, 485, 891, 917, 964, 965, 967, 970, 971, 972, 974, 985, 987, 988, 989, 998, 999, 1009, 1012, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1027, 1028, 1029, 1036, 1038, 1067, 1121, 1125, 1130, 1165, 1303, 1571, 1602, 1611, 1612, 1614, 1647, 1753, 1783, 1858, 1863, 1864, 1883, 1890, 1893, 1901, 1906, 1907, 1912, 1913, 1914, 1917, 1920, 1925], "complet": [0, 8, 18, 21, 25, 27, 32, 38, 41, 43, 49, 50, 56, 58, 60, 68, 70, 485, 677, 858, 966, 967, 969, 1039, 1119, 1120, 1193, 1201, 1203, 1208, 1220, 1248, 1303, 1304, 1309, 1486, 1602, 1611, 1644, 1707, 1858, 1862, 1863, 1864, 1869, 1875, 1882, 1883, 1886, 1889, 1892, 1898, 1905, 1906, 1913, 1914], "skip": [0, 1, 15, 18, 21, 58, 856, 1063, 1116, 1219, 1220, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1777, 1860, 1882, 1883, 1886, 1887, 1888, 1894, 1904, 1907], "frame": [0, 9, 14, 15, 17, 18, 26, 29, 71, 1187, 1804, 1890, 1922], "well": [0, 2, 4, 8, 10, 13, 16, 18, 22, 24, 32, 39, 41, 58, 63, 68, 69, 71, 614, 788, 819, 822, 858, 1006, 1124, 1125, 1190, 1194, 1200, 1205, 1225, 1226, 1227, 1229, 1235, 1248, 1253, 1299, 1340, 1341, 1342, 1358, 1392, 1422, 1461, 1542, 1543, 1602, 1659, 1707, 1860, 1863, 1870, 1876, 1878, 1882, 1883, 1886, 1888, 1889, 1891, 1894, 1896, 1898, 1901, 1905, 1908, 1911, 1913, 1915, 1917, 1921, 1922, 1925], "invok": [0, 1, 3, 9, 12, 16, 18, 21, 27, 33, 35, 38, 41, 56, 58, 59, 70, 71, 898, 900, 1006, 1007, 1190, 1193, 1199, 1359, 1422, 1595, 1597, 1600, 1601, 1683, 1689, 1860, 1863, 1864, 1871, 1882, 1885, 1886, 1887, 1888, 1889, 1893, 1894, 1905, 1913, 1914], "associ": [0, 2, 9, 10, 16, 17, 21, 29, 41, 43, 52, 892, 972, 1023, 1025, 1151, 1152, 1190, 1239, 1250, 1252, 1261, 1345, 1422, 1432, 1505, 1602, 1610, 1656, 1765, 1767, 1860, 1863, 1869, 1876, 1877, 1883, 1891, 1894, 1897, 1905, 1906, 1907, 1913, 1914, 1920, 1923], "code": [0, 2, 4, 5, 9, 10, 12, 13, 14, 15, 16, 18, 21, 22, 23, 24, 26, 27, 28, 29, 30, 32, 33, 38, 39, 41, 47, 49, 59, 60, 68, 69, 70, 120, 677, 1006, 1007, 1020, 1120, 1165, 1190, 1194, 1195, 1200, 1201, 1202, 1205, 1206, 1207, 1220, 1231, 1233, 1261, 1438, 1450, 1602, 1755, 1857, 1858, 1862, 1863, 1869, 1877, 1883, 1884, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1899, 1900, 1901, 1904, 1912, 1913, 1914, 1915, 1920, 1921, 1925, 1928], "still": [0, 1, 2, 3, 8, 9, 16, 20, 21, 22, 24, 29, 38, 41, 46, 47, 49, 58, 70, 71, 791, 796, 895, 900, 1194, 1199, 1207, 1389, 1413, 1602, 1603, 1604, 1605, 1691, 1739, 1859, 1860, 1863, 1875, 1876, 1877, 1878, 1882, 1883, 1886, 1887, 1888, 1890, 1892, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1913, 1914, 1915, 1917], "process": [0, 1, 2, 4, 15, 17, 21, 29, 30, 32, 39, 41, 42, 43, 47, 49, 50, 51, 52, 58, 59, 60, 61, 63, 71, 966, 1002, 1008, 1033, 1190, 1200, 1262, 1299, 1307, 1338, 1339, 1356, 1358, 1365, 1366, 1382, 1389, 1413, 1414, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1461, 1465, 1467, 1469, 1470, 1493, 1494, 1504, 1533, 1556, 1564, 1602, 1686, 1692, 1758, 1772, 1857, 1858, 1860, 1873, 1875, 1876, 1877, 1883, 1885, 1886, 1887, 1888, 1893, 1894, 1896, 1898, 1900, 1901, 1905, 1906, 1907, 1908, 1911, 1913, 1915, 1917, 1919, 1926], "reset": [0, 2, 757, 817, 822, 890, 964, 1012, 1014, 1027, 1028, 1029, 1190, 1374, 1422, 1438, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1697, 1714, 1809, 1858, 1873, 1901, 1912], "clear": [0, 2, 3, 9, 10, 60, 71, 1190, 1422, 1423, 1432, 1659, 1857, 1883, 1886, 1894, 1899, 1903, 1904], "cach": [0, 1, 3, 4, 12, 17, 23, 29, 47, 71, 485, 988, 989, 1006, 1009, 1014, 1016, 1018, 1020, 1028, 1033, 1298, 1299, 1300, 1603, 1614, 1875, 1890], "restor": [0, 3, 6, 14, 45, 71, 89, 1108, 1260, 1276, 1734, 1756, 1894, 1899], "initi": [0, 2, 4, 5, 9, 12, 21, 28, 34, 35, 38, 39, 43, 45, 49, 51, 58, 59, 61, 63, 89, 494, 577, 709, 710, 711, 712, 713, 714, 717, 727, 728, 729, 730, 742, 743, 753, 757, 761, 858, 859, 876, 966, 974, 995, 1000, 1001, 1004, 1005, 1030, 1137, 1166, 1188, 1190, 1202, 1203, 1261, 1262, 1279, 1340, 1341, 1342, 1343, 1345, 1353, 1354, 1355, 1359, 1365, 1366, 1374, 1375, 1377, 1385, 1386, 1387, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1422, 1430, 1437, 1439, 1461, 1471, 1512, 1593, 1602, 1604, 1605, 1609, 1611, 1614, 1642, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1693, 1747, 1748, 1749, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1858, 1861, 1862, 1863, 1873, 1878, 1881, 1883, 1886, 1887, 1888, 1893, 1900, 1901, 1904, 1905, 1906, 1912, 1913, 1914], "class": [0, 1, 2, 3, 4, 13, 14, 15, 21, 24, 28, 29, 33, 38, 39, 41, 42, 43, 45, 46, 47, 49, 50, 52, 55, 56, 58, 60, 63, 68, 70, 89, 554, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 833, 834, 835, 836, 837, 838, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 891, 894, 895, 896, 897, 917, 964, 965, 966, 967, 969, 970, 985, 987, 998, 1038, 1067, 1129, 1165, 1188, 1189, 1190, 1193, 1195, 1196, 1200, 1201, 1204, 1205, 1206, 1207, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1494, 1504, 1512, 1556, 1558, 1593, 1602, 1603, 1604, 1605, 1611, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1635, 1642, 1647, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1714, 1753, 1783, 1858, 1861, 1864, 1867, 1870, 1873, 1875, 1877, 1882, 1883, 1886, 1888, 1889, 1890, 1894, 1896, 1899, 1902, 1906, 1907, 1908, 1910, 1911, 1913, 1914, 1917, 1919, 1920, 1922, 1924, 1925, 1926, 1927, 1928, 1929], "optimizedmodul": [0, 1858], "mod": [0, 13, 29, 71, 718, 719, 729, 735, 736, 737, 742, 743, 753, 761, 807, 808, 809, 810, 833, 834, 861, 1119, 1193, 1194, 1199, 1206, 1644, 1862, 1863, 1905, 1926], "dynamo_ctx": 0, "origin": [0, 2, 13, 14, 16, 17, 18, 21, 23, 28, 29, 30, 35, 38, 39, 41, 43, 51, 63, 66, 70, 71, 207, 210, 222, 485, 542, 600, 604, 614, 677, 757, 794, 835, 836, 851, 854, 855, 935, 940, 967, 1083, 1084, 1086, 1090, 1094, 1095, 1096, 1102, 1119, 1129, 1164, 1187, 1197, 1201, 1202, 1205, 1206, 1283, 1297, 1330, 1334, 1346, 1358, 1359, 1374, 1451, 1461, 1504, 1574, 1609, 1610, 1611, 1614, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1635, 1638, 1641, 1643, 1644, 1646, 1659, 1689, 1698, 1734, 1745, 1781, 1796, 1829, 1840, 1841, 1860, 1863, 1869, 1875, 1877, 1883, 1886, 1888, 1890, 1893, 1896, 1897, 1899, 1901, 1905, 1906, 1908, 1909, 1919, 1926, 1927, 1928], "nn": [0, 1, 4, 6, 13, 16, 21, 27, 28, 29, 33, 38, 39, 41, 42, 45, 46, 59, 63, 64, 71, 298, 538, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 789, 790, 811, 851, 856, 857, 858, 859, 861, 1006, 1009, 1063, 1119, 1128, 1129, 1188, 1190, 1191, 1193, 1194, 1195, 1196, 1199, 1200, 1201, 1205, 1206, 1207, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1593, 1602, 1603, 1604, 1605, 1611, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1635, 1647, 1678, 1780, 1804, 1843, 1857, 1858, 1860, 1861, 1865, 1877, 1878, 1882, 1887, 1890, 1894, 1896, 1897, 1898, 1901, 1904, 1905, 1906, 1908, 1910, 1913, 1922, 1924, 1927], "object": [0, 1, 2, 4, 6, 7, 9, 13, 14, 16, 21, 24, 28, 32, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 58, 60, 63, 70, 71, 76, 89, 207, 210, 600, 790, 791, 851, 858, 877, 887, 888, 889, 914, 916, 987, 998, 1038, 1063, 1102, 1114, 1116, 1121, 1122, 1124, 1125, 1126, 1130, 1176, 1177, 1190, 1196, 1197, 1200, 1201, 1205, 1206, 1221, 1242, 1246, 1259, 1261, 1262, 1282, 1359, 1361, 1362, 1363, 1367, 1385, 1386, 1387, 1422, 1432, 1461, 1602, 1612, 1627, 1636, 1637, 1640, 1641, 1642, 1658, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1739, 1812, 1813, 1816, 1857, 1862, 1863, 1864, 1867, 1871, 1872, 1875, 1879, 1883, 1885, 1886, 1888, 1889, 1890, 1891, 1893, 1896, 1898, 1899, 1900, 1901, 1904, 1908, 1910, 1911, 1912, 1913, 1915, 1919, 1920, 1922, 1924, 1928, 1929], "later": [0, 1, 2, 4, 8, 21, 24, 37, 39, 41, 63, 70, 71, 742, 743, 753, 761, 913, 998, 1261, 1392, 1415, 1416, 1417, 1437, 1451, 1545, 1546, 1547, 1574, 1602, 1808, 1860, 1883, 1885, 1886, 1887, 1894, 1899, 1914, 1915], "patch": [0, 8, 18, 65, 1369, 1473], "its": [0, 1, 2, 5, 6, 8, 9, 10, 12, 14, 15, 16, 17, 20, 21, 23, 24, 32, 33, 35, 38, 39, 40, 41, 42, 43, 45, 46, 47, 49, 50, 58, 59, 60, 63, 70, 71, 83, 84, 151, 457, 486, 502, 511, 513, 515, 580, 581, 582, 614, 677, 820, 823, 871, 872, 873, 875, 876, 877, 890, 893, 905, 910, 911, 917, 942, 943, 952, 958, 962, 970, 998, 1000, 1009, 1046, 1050, 1053, 1063, 1066, 1111, 1116, 1120, 1121, 1122, 1125, 1130, 1151, 1152, 1156, 1170, 1190, 1200, 1225, 1226, 1230, 1235, 1242, 1244, 1247, 1248, 1253, 1259, 1284, 1310, 1338, 1340, 1341, 1342, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1385, 1386, 1387, 1422, 1423, 1432, 1453, 1461, 1521, 1532, 1559, 1565, 1593, 1598, 1599, 1603, 1604, 1605, 1610, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1636, 1642, 1646, 1650, 1659, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1698, 1723, 1727, 1731, 1732, 1748, 1749, 1753, 1773, 1809, 1828, 1829, 1831, 1839, 1848, 1860, 1862, 1863, 1867, 1871, 1873, 1875, 1882, 1883, 1884, 1886, 1887, 1888, 1890, 1891, 1894, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1913, 1914, 1915, 1917, 1920, 1921, 1923, 1926, 1927], "forward": [0, 1, 6, 8, 9, 12, 13, 17, 21, 23, 24, 28, 29, 32, 39, 41, 42, 45, 47, 63, 64, 65, 67, 69, 71, 151, 222, 223, 677, 732, 745, 754, 757, 797, 812, 813, 814, 817, 821, 858, 859, 886, 888, 889, 890, 891, 892, 893, 894, 895, 896, 897, 898, 900, 901, 904, 905, 917, 1009, 1055, 1067, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1120, 1122, 1123, 1124, 1126, 1129, 1165, 1190, 1193, 1194, 1195, 1196, 1200, 1201, 1205, 1206, 1207, 1334, 1338, 1341, 1359, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1374, 1392, 1407, 1418, 1419, 1420, 1422, 1423, 1424, 1428, 1429, 1432, 1433, 1437, 1450, 1465, 1466, 1467, 1468, 1469, 1507, 1508, 1509, 1514, 1559, 1593, 1596, 1597, 1598, 1599, 1602, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1643, 1646, 1647, 1714, 1753, 1782, 1843, 1858, 1859, 1860, 1862, 1863, 1869, 1871, 1875, 1877, 1881, 1882, 1883, 1885, 1886, 1887, 1889, 1890, 1891, 1893, 1894, 1897, 1899, 1901, 1904, 1905, 1906, 1907, 1908, 1913, 1925, 1926, 1927], "method": [0, 1, 4, 8, 10, 13, 14, 20, 21, 29, 32, 33, 35, 38, 41, 42, 43, 45, 47, 48, 49, 50, 56, 58, 63, 70, 71, 222, 223, 323, 485, 486, 495, 496, 497, 518, 611, 790, 794, 796, 812, 813, 814, 835, 838, 851, 871, 872, 873, 890, 894, 895, 896, 897, 910, 911, 1000, 1114, 1143, 1188, 1190, 1191, 1193, 1194, 1195, 1200, 1201, 1205, 1206, 1207, 1235, 1253, 1254, 1261, 1262, 1319, 1322, 1330, 1338, 1365, 1422, 1423, 1424, 1432, 1433, 1450, 1521, 1593, 1602, 1610, 1611, 1614, 1616, 1618, 1621, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1632, 1638, 1643, 1656, 1657, 1662, 1663, 1664, 1666, 1676, 1708, 1789, 1804, 1808, 1857, 1858, 1860, 1863, 1864, 1871, 1873, 1875, 1876, 1877, 1881, 1882, 1883, 1886, 1888, 1889, 1890, 1891, 1894, 1896, 1899, 1902, 1904, 1905, 1908, 1910, 1913, 1915, 1919, 1920, 1922, 1923, 1925, 1928], "self": [0, 1, 2, 10, 13, 21, 28, 29, 35, 38, 39, 41, 43, 46, 49, 50, 55, 60, 63, 68, 71, 98, 140, 151, 154, 155, 156, 171, 173, 176, 179, 180, 181, 191, 192, 196, 197, 209, 217, 219, 233, 240, 254, 255, 258, 259, 267, 286, 290, 297, 311, 313, 315, 317, 319, 321, 323, 325, 326, 328, 329, 330, 331, 333, 341, 377, 393, 398, 400, 401, 402, 453, 470, 480, 482, 495, 496, 497, 498, 511, 513, 515, 518, 522, 534, 540, 541, 542, 543, 555, 557, 577, 578, 580, 581, 582, 584, 585, 601, 604, 605, 611, 614, 615, 617, 620, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 858, 859, 915, 1119, 1120, 1129, 1160, 1188, 1189, 1190, 1193, 1194, 1195, 1196, 1200, 1201, 1205, 1206, 1207, 1330, 1334, 1367, 1421, 1422, 1423, 1424, 1428, 1432, 1433, 1449, 1451, 1461, 1467, 1469, 1551, 1574, 1593, 1611, 1612, 1614, 1620, 1622, 1635, 1644, 1657, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1704, 1725, 1859, 1860, 1861, 1862, 1863, 1867, 1873, 1876, 1877, 1881, 1883, 1884, 1885, 1888, 1890, 1894, 1899, 1901, 1905, 1906, 1908, 1913, 1919], "register_backend": [0, 13, 41, 1858, 1913], "compiler_fn": [0, 21], "tag": [0, 2, 4, 8, 41, 1261, 1857, 1858, 1893, 1905, 1922], "given": [0, 1, 2, 3, 4, 8, 10, 16, 17, 19, 21, 28, 29, 32, 38, 39, 41, 42, 43, 45, 46, 47, 49, 56, 58, 60, 63, 69, 70, 71, 76, 151, 220, 313, 315, 317, 321, 326, 377, 398, 402, 471, 472, 473, 474, 475, 477, 511, 513, 515, 581, 582, 601, 604, 677, 690, 692, 693, 695, 696, 732, 757, 776, 782, 789, 790, 791, 792, 796, 797, 799, 817, 821, 834, 837, 851, 855, 862, 873, 886, 888, 890, 892, 894, 896, 898, 899, 900, 901, 902, 903, 906, 920, 921, 924, 932, 936, 937, 943, 944, 949, 950, 956, 958, 961, 962, 963, 966, 967, 969, 970, 971, 975, 983, 984, 987, 991, 992, 1008, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1038, 1039, 1040, 1041, 1048, 1050, 1055, 1063, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1103, 1119, 1129, 1130, 1156, 1187, 1190, 1197, 1205, 1206, 1211, 1215, 1225, 1227, 1228, 1237, 1239, 1245, 1253, 1262, 1269, 1271, 1272, 1273, 1274, 1277, 1287, 1289, 1291, 1292, 1295, 1320, 1330, 1338, 1339, 1345, 1350, 1351, 1352, 1354, 1355, 1356, 1358, 1359, 1365, 1366, 1370, 1371, 1374, 1382, 1392, 1414, 1418, 1419, 1420, 1422, 1424, 1426, 1427, 1429, 1431, 1433, 1437, 1450, 1456, 1470, 1471, 1474, 1475, 1476, 1486, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1512, 1513, 1516, 1517, 1521, 1532, 1556, 1571, 1586, 1590, 1591, 1592, 1596, 1597, 1598, 1610, 1635, 1642, 1643, 1646, 1649, 1650, 1659, 1685, 1688, 1690, 1692, 1695, 1700, 1705, 1708, 1709, 1710, 1723, 1729, 1734, 1745, 1746, 1777, 1781, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1799, 1804, 1807, 1809, 1818, 1819, 1824, 1826, 1828, 1838, 1843, 1857, 1858, 1860, 1863, 1867, 1869, 1870, 1872, 1875, 1878, 1879, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1891, 1893, 1894, 1898, 1899, 1901, 1904, 1907, 1908, 1913, 1914, 1917, 1918, 1919, 1922, 1924, 1927, 1928], "registri": [0, 38, 1858, 1901], "shorthand": [0, 457, 1209], "project": [0, 8, 28, 43, 1291, 1392, 1428, 1614, 1697, 1857, 1892], "import": [0, 2, 3, 4, 6, 8, 10, 12, 13, 14, 15, 17, 20, 21, 22, 27, 28, 29, 32, 34, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 50, 52, 55, 56, 60, 63, 66, 67, 68, 69, 70, 71, 222, 677, 731, 738, 739, 740, 769, 770, 771, 789, 857, 858, 859, 908, 910, 929, 936, 962, 1114, 1116, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1127, 1129, 1165, 1187, 1188, 1191, 1193, 1195, 1196, 1197, 1199, 1200, 1201, 1205, 1206, 1207, 1241, 1242, 1245, 1246, 1259, 1291, 1388, 1422, 1602, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1627, 1628, 1629, 1637, 1638, 1639, 1640, 1641, 1642, 1649, 1656, 1677, 1678, 1701, 1860, 1862, 1863, 1864, 1873, 1875, 1878, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1893, 1894, 1896, 1897, 1898, 1899, 1901, 1908, 1911, 1913, 1914, 1915, 1917, 1920, 1922, 1923, 1924, 1927, 1928], "might": [0, 2, 4, 5, 10, 12, 15, 16, 17, 18, 20, 21, 28, 29, 32, 33, 35, 41, 43, 45, 47, 58, 68, 70, 71, 151, 485, 541, 890, 963, 1205, 1206, 1521, 1602, 1603, 1857, 1860, 1873, 1878, 1883, 1885, 1886, 1887, 1888, 1891, 1893, 1898, 1901, 1905, 1906, 1908, 1913, 1914, 1915, 1917, 1921, 1923, 1924], "easier": [0, 3, 8, 17, 29, 38, 71, 1860, 1862, 1878, 1883, 1884, 1888, 1889], "directli": [0, 1, 2, 4, 8, 10, 15, 16, 17, 20, 23, 28, 29, 32, 33, 38, 39, 41, 43, 47, 48, 49, 57, 63, 67, 71, 554, 729, 744, 887, 896, 1046, 1114, 1120, 1127, 1129, 1135, 1220, 1428, 1455, 1474, 1532, 1577, 1636, 1829, 1860, 1862, 1863, 1873, 1883, 1886, 1887, 1888, 1889, 1891, 1893, 1894, 1895, 1896, 1899, 1905, 1907, 1908, 1913, 1917, 1922, 1924], "compiledfn": 0, "fake": [0, 71, 709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 790, 796, 797, 807, 809, 835, 858, 859, 1077, 1078, 1858, 1905, 1908, 1911], "__name__": [0, 38, 39, 41, 50, 51, 59, 1887, 1888, 1896, 1900, 1905, 1914], "sequenc": [0, 2, 12, 15, 17, 26, 28, 29, 38, 43, 45, 46, 47, 63, 151, 563, 732, 757, 811, 877, 890, 904, 934, 936, 937, 940, 948, 969, 976, 977, 980, 1048, 1062, 1064, 1131, 1151, 1152, 1155, 1205, 1245, 1291, 1330, 1340, 1345, 1350, 1359, 1366, 1374, 1392, 1428, 1437, 1450, 1465, 1466, 1467, 1468, 1469, 1513, 1571, 1611, 1614, 1621, 1635, 1636, 1637, 1638, 1639, 1640, 1641, 1650, 1653, 1656, 1660, 1675, 1714, 1716, 1720, 1743, 1801, 1804, 1850, 1852, 1855, 1860, 1861, 1862, 1878, 1886, 1890, 1901, 1905, 1906, 1913, 1923, 1924], "categor": [0, 8, 28, 51, 1523, 1858, 1864, 1909, 1913], "exclude_tag": 0, "debug": [0, 2, 3, 5, 9, 15, 17, 18, 19, 24, 38, 55, 677, 824, 825, 829, 840, 905, 906, 950, 964, 997, 1037, 1138, 1219, 1596, 1597, 1598, 1599, 1750, 1758, 1858, 1862, 1869, 1883, 1885, 1886, 1887, 1892, 1893, 1894, 1898, 1900, 1901, 1902, 1905, 1926], "experiment": [0, 2, 3, 15, 16, 19, 22, 29, 39, 41, 45, 46, 63, 71, 898, 900, 904, 950, 1037, 1120, 1220, 1231, 1233, 1234, 1238, 1251, 1602, 1656, 1678, 1858, 1860, 1862, 1876, 1877, 1887, 1898, 1900, 1901, 1905, 1906, 1907], "conveni": [1, 4, 8, 12, 15, 21, 23, 26, 32, 55, 58, 59, 69, 1131, 1247, 1593, 1850, 1857, 1862, 1867, 1882, 1883, 1886, 1888, 1893, 1894, 1905, 1912], "where": [1, 2, 3, 4, 5, 8, 9, 10, 15, 16, 17, 18, 20, 21, 29, 30, 32, 33, 38, 39, 41, 45, 46, 47, 49, 51, 58, 59, 60, 61, 63, 65, 66, 68, 71, 154, 224, 254, 400, 402, 485, 677, 690, 692, 693, 696, 732, 755, 757, 778, 817, 818, 830, 874, 893, 898, 900, 913, 919, 928, 934, 941, 942, 943, 958, 962, 967, 969, 978, 980, 1042, 1043, 1046, 1050, 1068, 1079, 1080, 1082, 1085, 1086, 1088, 1089, 1091, 1092, 1093, 1095, 1096, 1098, 1100, 1124, 1125, 1126, 1130, 1131, 1134, 1146, 1147, 1148, 1149, 1179, 1180, 1182, 1183, 1186, 1187, 1188, 1191, 1203, 1209, 1210, 1211, 1214, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1257, 1258, 1259, 1261, 1262, 1267, 1270, 1277, 1278, 1279, 1280, 1284, 1287, 1289, 1290, 1291, 1292, 1295, 1312, 1317, 1318, 1320, 1323, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1364, 1365, 1366, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1492, 1494, 1504, 1505, 1512, 1517, 1519, 1520, 1538, 1539, 1556, 1558, 1559, 1562, 1563, 1565, 1571, 1574, 1602, 1604, 1605, 1609, 1636, 1637, 1638, 1639, 1648, 1658, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1681, 1682, 1683, 1695, 1705, 1707, 1708, 1728, 1729, 1765, 1771, 1772, 1777, 1781, 1785, 1786, 1787, 1790, 1791, 1792, 1793, 1794, 1795, 1802, 1803, 1804, 1807, 1808, 1822, 1831, 1832, 1833, 1834, 1835, 1840, 1841, 1845, 1846, 1847, 1848, 1849, 1850, 1859, 1860, 1861, 1863, 1864, 1869, 1870, 1872, 1875, 1878, 1881, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1891, 1894, 1897, 1898, 1901, 1903, 1904, 1905, 1906, 1907, 1908, 1911, 1913, 1915, 1917, 1918, 1920, 1922, 1927, 1928], "float": [1, 2, 4, 15, 20, 28, 30, 38, 39, 41, 45, 47, 49, 52, 60, 63, 71, 154, 155, 220, 313, 315, 317, 321, 333, 400, 474, 480, 511, 682, 684, 689, 691, 695, 729, 732, 735, 736, 737, 741, 742, 743, 745, 752, 753, 758, 759, 760, 761, 762, 767, 768, 769, 770, 771, 772, 774, 776, 777, 778, 782, 789, 790, 791, 796, 814, 816, 827, 835, 836, 849, 854, 855, 858, 859, 862, 877, 905, 906, 919, 920, 928, 935, 938, 942, 952, 957, 958, 962, 963, 1033, 1046, 1057, 1058, 1068, 1081, 1099, 1108, 1109, 1110, 1111, 1113, 1134, 1137, 1146, 1147, 1148, 1151, 1152, 1172, 1179, 1180, 1182, 1183, 1184, 1185, 1188, 1190, 1205, 1206, 1209, 1213, 1215, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1262, 1267, 1276, 1278, 1280, 1307, 1311, 1312, 1316, 1318, 1319, 1320, 1323, 1326, 1330, 1334, 1340, 1341, 1342, 1344, 1356, 1357, 1358, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1370, 1371, 1376, 1377, 1378, 1381, 1382, 1383, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1408, 1410, 1414, 1422, 1427, 1428, 1430, 1431, 1436, 1440, 1443, 1444, 1445, 1446, 1447, 1453, 1459, 1461, 1464, 1465, 1467, 1469, 1470, 1471, 1474, 1475, 1476, 1503, 1504, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1518, 1523, 1532, 1557, 1564, 1571, 1590, 1602, 1606, 1607, 1610, 1619, 1620, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1638, 1639, 1643, 1649, 1650, 1656, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1686, 1687, 1689, 1691, 1693, 1695, 1701, 1704, 1708, 1709, 1710, 1711, 1723, 1727, 1728, 1748, 1749, 1752, 1756, 1765, 1766, 1768, 1769, 1771, 1805, 1808, 1812, 1829, 1831, 1843, 1859, 1860, 1861, 1862, 1863, 1864, 1870, 1873, 1875, 1876, 1878, 1879, 1881, 1882, 1886, 1888, 1890, 1894, 1897, 1901, 1903, 1905, 1907, 1908, 1909, 1913, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1929], "datatyp": [1, 71, 877, 1187, 1190, 1422, 1604, 1605, 1751, 1897, 1901], "other": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 17, 18, 20, 21, 22, 28, 29, 32, 33, 35, 38, 39, 42, 45, 47, 48, 49, 51, 55, 56, 58, 59, 63, 64, 66, 68, 69, 70, 71, 98, 99, 114, 130, 131, 134, 146, 147, 150, 151, 160, 161, 166, 167, 197, 198, 199, 208, 234, 239, 243, 244, 245, 255, 274, 275, 282, 283, 284, 285, 291, 292, 293, 294, 295, 296, 303, 304, 307, 308, 309, 310, 313, 315, 321, 324, 344, 352, 355, 356, 357, 358, 359, 360, 363, 364, 365, 366, 378, 379, 394, 395, 408, 412, 437, 438, 449, 450, 454, 455, 486, 496, 518, 558, 559, 560, 561, 577, 580, 613, 614, 615, 618, 619, 682, 691, 735, 736, 737, 738, 739, 740, 757, 811, 823, 858, 862, 868, 875, 876, 881, 887, 890, 891, 904, 905, 906, 910, 911, 917, 922, 923, 925, 926, 927, 929, 934, 957, 963, 964, 967, 969, 971, 978, 988, 1009, 1051, 1057, 1058, 1059, 1060, 1067, 1068, 1069, 1083, 1090, 1108, 1109, 1110, 1111, 1114, 1120, 1121, 1122, 1123, 1126, 1130, 1132, 1133, 1134, 1144, 1145, 1146, 1155, 1156, 1158, 1159, 1164, 1165, 1167, 1179, 1188, 1190, 1194, 1201, 1210, 1212, 1213, 1214, 1216, 1217, 1222, 1240, 1242, 1245, 1246, 1259, 1267, 1268, 1269, 1271, 1273, 1274, 1277, 1278, 1284, 1287, 1288, 1292, 1293, 1297, 1300, 1311, 1313, 1323, 1326, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1359, 1369, 1374, 1376, 1388, 1422, 1423, 1432, 1450, 1465, 1469, 1473, 1496, 1497, 1498, 1523, 1532, 1571, 1590, 1593, 1602, 1606, 1607, 1625, 1647, 1651, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1686, 1687, 1693, 1695, 1723, 1727, 1743, 1748, 1751, 1753, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1805, 1806, 1822, 1828, 1832, 1834, 1847, 1848, 1853, 1854, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1865, 1867, 1871, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1894, 1895, 1896, 1897, 1899, 1901, 1904, 1908, 1909, 1913, 1914, 1915, 1918, 1922, 1923, 1924, 1928], "point": [1, 2, 8, 9, 10, 13, 14, 17, 20, 21, 24, 28, 30, 38, 39, 42, 45, 49, 55, 58, 59, 63, 71, 89, 154, 155, 321, 333, 339, 480, 695, 735, 736, 737, 738, 739, 740, 741, 746, 747, 748, 749, 750, 751, 752, 753, 756, 758, 759, 760, 761, 762, 772, 774, 776, 777, 778, 782, 792, 796, 816, 817, 818, 819, 822, 827, 849, 858, 859, 862, 877, 899, 901, 902, 903, 905, 906, 919, 920, 928, 957, 958, 962, 1012, 1014, 1023, 1027, 1028, 1109, 1110, 1111, 1137, 1143, 1147, 1148, 1152, 1172, 1187, 1190, 1205, 1206, 1213, 1215, 1236, 1237, 1260, 1262, 1267, 1276, 1319, 1326, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1415, 1416, 1417, 1422, 1473, 1474, 1486, 1512, 1521, 1532, 1571, 1590, 1602, 1649, 1661, 1692, 1708, 1709, 1710, 1714, 1723, 1736, 1748, 1749, 1756, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1843, 1858, 1860, 1862, 1863, 1864, 1867, 1873, 1879, 1881, 1882, 1883, 1887, 1891, 1894, 1897, 1906, 1907, 1908, 1909, 1911, 1913, 1914, 1917, 1920, 1922, 1923, 1924, 1925, 1926, 1929], "lower_precision_fp": 1, "half": [1, 2, 11, 39, 47, 614, 952, 1077, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1190, 1252, 1258, 1350, 1351, 1352, 1353, 1354, 1355, 1370, 1371, 1373, 1422, 1516, 1517, 1520, 1658, 1683, 1736, 1804, 1876, 1894, 1897, 1919, 1920, 1923, 1925], "linear": [1, 3, 10, 29, 39, 41, 42, 45, 47, 63, 65, 67, 69, 71, 430, 471, 472, 473, 474, 475, 478, 708, 717, 725, 726, 762, 789, 790, 791, 793, 811, 851, 855, 856, 858, 859, 900, 943, 969, 1063, 1119, 1121, 1129, 1131, 1143, 1190, 1194, 1201, 1215, 1221, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1250, 1252, 1280, 1319, 1338, 1344, 1364, 1372, 1373, 1381, 1407, 1422, 1424, 1437, 1439, 1441, 1449, 1451, 1458, 1461, 1472, 1474, 1510, 1519, 1520, 1532, 1566, 1574, 1579, 1590, 1593, 1602, 1609, 1610, 1614, 1624, 1625, 1626, 1627, 1628, 1630, 1631, 1632, 1633, 1634, 1642, 1643, 1646, 1686, 1689, 1697, 1708, 1843, 1850, 1858, 1861, 1862, 1868, 1871, 1878, 1881, 1886, 1887, 1888, 1890, 1894, 1899, 1901, 1903, 1904, 1906, 1908, 1909, 1910, 1911, 1913], "layer": [1, 9, 17, 39, 41, 43, 45, 46, 63, 66, 731, 732, 757, 838, 855, 1335, 1336, 1337, 1339, 1340, 1341, 1342, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1361, 1362, 1363, 1367, 1374, 1375, 1377, 1385, 1386, 1387, 1392, 1393, 1394, 1407, 1409, 1415, 1416, 1417, 1428, 1429, 1437, 1439, 1450, 1461, 1465, 1466, 1467, 1468, 1469, 1535, 1602, 1609, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1858, 1881, 1886, 1888, 1890, 1893, 1894, 1899, 1901, 1904, 1906, 1908, 1909, 1911, 1927], "convolut": [1, 2, 3, 19, 735, 736, 737, 738, 739, 740, 769, 770, 771, 950, 1199, 1350, 1351, 1352, 1353, 1354, 1355, 1361, 1362, 1363, 1367, 1398, 1399, 1400, 1401, 1402, 1403, 1434, 1435, 1440, 1470, 1471, 1473, 1496, 1497, 1498, 1499, 1500, 1501, 1520, 1521, 1751, 1858, 1859, 1861, 1871, 1881, 1885, 1886, 1891, 1894, 1903, 1907, 1908, 1911], "much": [1, 5, 8, 10, 15, 17, 21, 22, 33, 38, 39, 151, 890, 899, 904, 1020, 1225, 1226, 1253, 1262, 1366, 1602, 1625, 1689, 1860, 1883, 1886, 1891, 1894, 1899, 1905, 1906, 1913, 1914, 1917], "reduct": [1, 3, 23, 29, 41, 63, 321, 511, 515, 1235, 1267, 1319, 1338, 1339, 1345, 1356, 1358, 1366, 1376, 1382, 1383, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1471, 1493, 1494, 1502, 1504, 1505, 1513, 1518, 1529, 1530, 1533, 1534, 1544, 1552, 1553, 1554, 1555, 1556, 1564, 1575, 1576, 1587, 1588, 1602, 1708, 1785, 1861, 1876, 1887, 1891, 1905, 1908], "often": [1, 3, 5, 8, 9, 16, 17, 22, 29, 32, 38, 41, 47, 59, 66, 71, 151, 890, 904, 1205, 1236, 1237, 1246, 1295, 1365, 1385, 1386, 1387, 1486, 1494, 1512, 1521, 1593, 1609, 1656, 1691, 1863, 1883, 1886, 1890, 1893, 1894, 1897, 1898, 1905, 1913, 1922], "tri": [1, 3, 4, 8, 16, 17, 38, 47, 51, 71, 577, 1190, 1422, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1862, 1863, 1875, 1890, 1901, 1905], "match": [1, 2, 4, 17, 21, 28, 41, 43, 45, 47, 58, 71, 151, 313, 315, 321, 472, 473, 497, 498, 577, 580, 690, 696, 776, 790, 791, 792, 851, 875, 890, 904, 905, 906, 963, 966, 978, 979, 980, 1009, 1055, 1063, 1119, 1131, 1167, 1190, 1203, 1205, 1222, 1261, 1283, 1357, 1366, 1422, 1428, 1474, 1493, 1494, 1532, 1558, 1565, 1571, 1590, 1602, 1614, 1644, 1650, 1709, 1743, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1824, 1850, 1860, 1863, 1870, 1876, 1878, 1883, 1884, 1886, 1888, 1894, 1899, 1901, 1904, 1905, 1906, 1908, 1909, 1910, 1913, 1920, 1924, 1926], "appropri": [1, 8, 9, 10, 17, 21, 24, 41, 42, 47, 63, 70, 71, 891, 1009, 1205, 1863, 1864, 1867, 1877, 1891, 1906, 1908, 1911, 1913, 1914, 1915, 1919, 1928], "ordinarili": [1, 1882], "train": [1, 2, 12, 13, 17, 20, 22, 23, 25, 26, 29, 33, 38, 39, 41, 42, 44, 45, 49, 56, 57, 58, 59, 63, 66, 67, 71, 709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 730, 796, 798, 835, 836, 852, 853, 854, 856, 858, 859, 860, 1008, 1009, 1012, 1014, 1021, 1129, 1165, 1190, 1195, 1201, 1204, 1205, 1330, 1334, 1340, 1341, 1342, 1358, 1359, 1360, 1365, 1366, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1428, 1429, 1440, 1461, 1469, 1487, 1491, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1569, 1570, 1602, 1610, 1612, 1614, 1643, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1857, 1859, 1860, 1861, 1871, 1873, 1881, 1883, 1886, 1887, 1890, 1895, 1897, 1899, 1901, 1904, 1905, 1906, 1907, 1911, 1913, 1915, 1922], "gradscal": [1, 1882, 1886], "togeth": [1, 4, 10, 13, 16, 17, 24, 38, 41, 46, 47, 64, 69, 71, 757, 1006, 1063, 1119, 1121, 1125, 1129, 1130, 1135, 1229, 1374, 1392, 1437, 1532, 1602, 1606, 1829, 1871, 1882, 1888, 1889, 1890, 1893, 1894, 1908, 1913, 1914, 1915, 1922], "shown": [1, 13, 18, 39, 50, 59, 1006, 1016, 1394, 1614, 1659, 1689, 1756, 1860, 1863, 1882, 1886, 1888, 1890, 1894, 1906, 1908, 1917], "recip": [1, 4, 16, 45, 1422, 1602, 1616, 1882, 1894], "howev": [1, 3, 4, 5, 6, 8, 10, 12, 15, 16, 17, 18, 32, 33, 38, 39, 41, 45, 47, 49, 55, 63, 64, 65, 67, 68, 70, 71, 480, 542, 891, 898, 966, 988, 1009, 1051, 1053, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1119, 1120, 1124, 1125, 1127, 1130, 1131, 1190, 1193, 1194, 1200, 1202, 1229, 1244, 1245, 1247, 1261, 1262, 1279, 1338, 1341, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1366, 1422, 1496, 1497, 1498, 1521, 1593, 1602, 1635, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1790, 1791, 1792, 1793, 1794, 1795, 1850, 1858, 1863, 1878, 1882, 1883, 1886, 1888, 1892, 1894, 1896, 1898, 1899, 1900, 1901, 1905, 1906, 1913, 1915, 1917], "modular": [1, 1882], "mai": [1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 21, 23, 27, 29, 32, 37, 38, 39, 41, 45, 47, 48, 49, 51, 55, 57, 58, 63, 64, 68, 70, 71, 197, 222, 254, 313, 321, 457, 513, 515, 553, 600, 614, 677, 686, 812, 813, 814, 858, 889, 896, 898, 900, 904, 905, 914, 921, 932, 944, 955, 956, 958, 960, 963, 964, 966, 967, 975, 988, 998, 999, 1000, 1006, 1007, 1009, 1020, 1022, 1026, 1040, 1041, 1063, 1102, 1106, 1111, 1114, 1116, 1123, 1124, 1126, 1152, 1187, 1190, 1193, 1194, 1199, 1200, 1202, 1203, 1205, 1211, 1220, 1221, 1225, 1226, 1227, 1229, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1245, 1247, 1248, 1251, 1252, 1253, 1259, 1261, 1262, 1267, 1284, 1294, 1307, 1330, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1388, 1392, 1418, 1419, 1420, 1422, 1429, 1437, 1467, 1469, 1474, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1513, 1521, 1523, 1532, 1538, 1559, 1571, 1589, 1590, 1591, 1592, 1593, 1602, 1609, 1611, 1612, 1614, 1649, 1678, 1683, 1707, 1727, 1730, 1748, 1751, 1758, 1776, 1788, 1804, 1808, 1831, 1843, 1857, 1858, 1860, 1862, 1863, 1867, 1869, 1870, 1871, 1873, 1877, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1894, 1897, 1898, 1899, 1900, 1901, 1905, 1907, 1908, 1909, 1911, 1913, 1915, 1917, 1919, 1925, 1928], "separ": [1, 2, 4, 10, 12, 29, 32, 38, 41, 45, 58, 59, 63, 64, 66, 69, 70, 71, 732, 757, 887, 1063, 1080, 1082, 1088, 1089, 1092, 1093, 1098, 1100, 1119, 1200, 1235, 1250, 1377, 1385, 1386, 1387, 1428, 1430, 1540, 1650, 1857, 1861, 1863, 1869, 1882, 1883, 1885, 1886, 1889, 1899, 1904, 1905, 1914, 1917, 1918, 1922], "desir": [1, 2, 4, 29, 38, 41, 47, 63, 71, 89, 156, 171, 173, 176, 179, 180, 181, 196, 207, 210, 240, 254, 267, 297, 325, 393, 444, 445, 446, 447, 448, 495, 497, 498, 518, 522, 541, 542, 543, 557, 577, 580, 600, 601, 614, 790, 862, 876, 919, 928, 947, 1010, 1011, 1034, 1035, 1044, 1045, 1064, 1065, 1066, 1076, 1081, 1099, 1116, 1117, 1118, 1147, 1148, 1190, 1209, 1260, 1276, 1282, 1289, 1302, 1308, 1317, 1319, 1320, 1338, 1339, 1422, 1472, 1494, 1540, 1577, 1578, 1593, 1635, 1649, 1653, 1654, 1698, 1705, 1708, 1709, 1710, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1757, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1784, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1807, 1822, 1833, 1835, 1855, 1856, 1876, 1877, 1878, 1882, 1883, 1886, 1889, 1892, 1894, 1899, 1906, 1912, 1913, 1918, 1919, 1920], "section": [1, 2, 8, 13, 21, 27, 29, 38, 47, 49, 50, 67, 71, 120, 1020, 1063, 1143, 1359, 1374, 1392, 1420, 1437, 1504, 1638, 1823, 1858, 1860, 1861, 1862, 1863, 1864, 1875, 1877, 1878, 1882, 1883, 1886, 1887, 1888, 1889, 1891, 1892, 1894, 1896, 1914, 1922], "infer": [1, 2, 3, 4, 6, 12, 15, 17, 20, 22, 25, 30, 33, 47, 58, 577, 614, 858, 859, 862, 876, 877, 980, 1116, 1117, 1152, 1165, 1174, 1188, 1191, 1199, 1204, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1428, 1474, 1532, 1558, 1593, 1647, 1678, 1689, 1723, 1730, 1748, 1749, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1839, 1858, 1860, 1862, 1863, 1867, 1876, 1878, 1894, 1901, 1902, 1907, 1908, 1909, 1911, 1917], "For": [1, 2, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19, 21, 23, 24, 25, 28, 29, 30, 32, 33, 35, 38, 39, 41, 42, 43, 47, 49, 55, 56, 58, 59, 61, 63, 64, 65, 67, 68, 69, 70, 71, 197, 222, 254, 289, 313, 315, 321, 335, 352, 470, 480, 491, 497, 511, 513, 515, 580, 586, 600, 614, 683, 684, 685, 686, 687, 690, 696, 731, 735, 736, 737, 738, 739, 740, 757, 789, 790, 791, 811, 855, 856, 889, 905, 918, 922, 924, 925, 927, 930, 939, 943, 950, 998, 1012, 1014, 1020, 1044, 1045, 1046, 1063, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1107, 1129, 1131, 1132, 1143, 1152, 1167, 1190, 1200, 1201, 1203, 1205, 1206, 1221, 1225, 1226, 1229, 1232, 1233, 1234, 1235, 1237, 1246, 1247, 1249, 1253, 1262, 1269, 1277, 1284, 1290, 1294, 1330, 1334, 1338, 1339, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1365, 1366, 1368, 1369, 1374, 1376, 1383, 1388, 1392, 1394, 1422, 1425, 1426, 1427, 1428, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1453, 1458, 1472, 1473, 1477, 1478, 1479, 1494, 1496, 1497, 1498, 1521, 1557, 1559, 1571, 1579, 1593, 1598, 1599, 1602, 1612, 1635, 1636, 1637, 1639, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1691, 1736, 1745, 1783, 1793, 1799, 1808, 1823, 1825, 1829, 1837, 1848, 1849, 1850, 1857, 1858, 1860, 1863, 1865, 1867, 1869, 1870, 1871, 1873, 1876, 1877, 1878, 1879, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1891, 1892, 1894, 1896, 1897, 1898, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1913, 1914, 1915, 1917, 1919, 1920, 1921, 1922, 1923, 1924, 1928], "api": [1, 3, 4, 6, 9, 10, 12, 22, 26, 39, 41, 42, 46, 49, 50, 51, 55, 56, 57, 58, 59, 63, 64, 67, 70, 797, 821, 858, 891, 892, 893, 901, 917, 939, 964, 998, 999, 1000, 1006, 1007, 1009, 1036, 1067, 1107, 1120, 1123, 1124, 1126, 1131, 1200, 1201, 1203, 1307, 1602, 1644, 1647, 1656, 1658, 1736, 1747, 1753, 1837, 1850, 1857, 1867, 1869, 1870, 1871, 1875, 1876, 1878, 1883, 1887, 1899, 1901, 1909, 1913, 1914, 1917, 1920, 1922, 1925, 1928], "equival": [1, 4, 6, 13, 21, 38, 39, 45, 46, 47, 51, 58, 59, 67, 68, 71, 83, 156, 171, 173, 176, 179, 180, 181, 240, 255, 267, 297, 319, 325, 393, 447, 457, 496, 498, 522, 601, 607, 614, 615, 617, 689, 741, 745, 752, 754, 756, 782, 783, 784, 873, 887, 931, 933, 936, 938, 941, 948, 949, 1051, 1055, 1058, 1061, 1062, 1063, 1065, 1080, 1082, 1085, 1088, 1089, 1092, 1093, 1095, 1098, 1100, 1118, 1120, 1123, 1125, 1131, 1153, 1155, 1167, 1189, 1190, 1200, 1205, 1206, 1209, 1221, 1242, 1246, 1254, 1259, 1291, 1296, 1310, 1317, 1330, 1340, 1341, 1342, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1365, 1366, 1377, 1383, 1385, 1386, 1387, 1388, 1392, 1394, 1422, 1453, 1461, 1473, 1475, 1540, 1561, 1571, 1590, 1591, 1592, 1602, 1654, 1678, 1714, 1717, 1721, 1745, 1751, 1759, 1781, 1787, 1800, 1810, 1811, 1817, 1822, 1841, 1850, 1851, 1852, 1856, 1860, 1862, 1863, 1883, 1901, 1905, 1909, 1917, 1918, 1920, 1923, 1924, 1928, 1929], "device_typ": [1, 41, 1882, 1912], "dtype": [1, 2, 14, 16, 29, 30, 35, 36, 38, 41, 43, 46, 63, 71, 154, 155, 192, 209, 213, 214, 215, 216, 242, 311, 313, 315, 317, 319, 321, 409, 428, 431, 444, 445, 446, 447, 448, 452, 457, 469, 480, 482, 511, 513, 562, 577, 578, 600, 614, 684, 686, 689, 690, 694, 696, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 742, 743, 746, 747, 748, 749, 750, 751, 752, 753, 755, 757, 758, 761, 762, 769, 770, 771, 791, 792, 796, 816, 817, 818, 819, 820, 821, 822, 823, 824, 838, 855, 856, 858, 859, 862, 876, 877, 894, 896, 898, 900, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 935, 942, 952, 955, 956, 962, 963, 979, 1044, 1045, 1064, 1065, 1066, 1076, 1080, 1081, 1082, 1088, 1089, 1099, 1106, 1111, 1113, 1115, 1116, 1117, 1118, 1137, 1147, 1148, 1160, 1190, 1194, 1203, 1209, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1271, 1272, 1273, 1274, 1276, 1279, 1280, 1284, 1288, 1289, 1290, 1293, 1294, 1312, 1316, 1317, 1318, 1320, 1330, 1339, 1340, 1341, 1342, 1343, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1365, 1366, 1369, 1374, 1375, 1377, 1385, 1386, 1387, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1422, 1428, 1429, 1430, 1437, 1438, 1439, 1443, 1444, 1445, 1446, 1447, 1461, 1465, 1467, 1469, 1473, 1474, 1475, 1476, 1488, 1504, 1505, 1538, 1540, 1571, 1577, 1578, 1593, 1604, 1605, 1611, 1614, 1615, 1635, 1649, 1653, 1654, 1658, 1660, 1695, 1701, 1705, 1706, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1725, 1733, 1736, 1748, 1749, 1751, 1752, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1780, 1784, 1787, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1807, 1808, 1819, 1822, 1833, 1835, 1840, 1843, 1848, 1849, 1853, 1855, 1856, 1858, 1859, 1860, 1861, 1862, 1863, 1865, 1870, 1877, 1878, 1886, 1888, 1894, 1897, 1901, 1903, 1908, 1909, 1910, 1917, 1918, 1919, 1922, 1923, 1924, 1929], "enabl": [1, 2, 3, 6, 9, 13, 15, 16, 17, 18, 19, 21, 22, 23, 29, 35, 36, 38, 39, 41, 42, 43, 45, 46, 47, 49, 59, 63, 501, 502, 677, 757, 809, 810, 891, 896, 917, 950, 964, 1009, 1063, 1067, 1165, 1173, 1174, 1192, 1198, 1303, 1304, 1374, 1392, 1437, 1438, 1468, 1571, 1602, 1611, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1647, 1677, 1752, 1753, 1756, 1783, 1843, 1863, 1869, 1870, 1871, 1874, 1878, 1882, 1883, 1884, 1885, 1886, 1893, 1895, 1897, 1898, 1901, 1906, 1907, 1912, 1913, 1914, 1917, 1925, 1927, 1928], "cache_en": [1, 1009], "instanc": [1, 4, 12, 21, 28, 38, 41, 42, 43, 45, 47, 48, 49, 55, 58, 59, 60, 63, 68, 71, 140, 614, 677, 731, 745, 754, 790, 793, 821, 823, 838, 855, 964, 1063, 1114, 1188, 1190, 1201, 1205, 1262, 1365, 1366, 1369, 1385, 1386, 1387, 1394, 1422, 1432, 1466, 1468, 1469, 1473, 1531, 1602, 1610, 1621, 1635, 1643, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1793, 1823, 1860, 1862, 1864, 1869, 1871, 1875, 1877, 1882, 1883, 1886, 1887, 1888, 1890, 1894, 1898, 1905, 1908, 1913, 1914, 1915, 1917, 1919, 1924, 1928], "serv": [1, 8, 9, 13, 17, 33, 41, 1859, 1870, 1902, 1904, 1913, 1914], "region": [1, 4, 6, 16, 17, 47, 55, 765, 766, 1335, 1336, 1337, 1370, 1371, 1381, 1383, 1415, 1416, 1417, 1489, 1490, 1516, 1517, 1546, 1547, 1860, 1875, 1882, 1886], "your": [1, 2, 3, 5, 8, 9, 10, 12, 13, 16, 17, 18, 19, 20, 22, 24, 25, 27, 29, 30, 32, 33, 34, 38, 41, 45, 46, 47, 50, 51, 55, 57, 58, 59, 60, 61, 63, 67, 68, 70, 71, 890, 896, 898, 899, 904, 950, 1165, 1190, 1194, 1195, 1199, 1202, 1205, 1206, 1207, 1422, 1429, 1602, 1611, 1614, 1647, 1678, 1752, 1840, 1860, 1862, 1863, 1867, 1869, 1875, 1876, 1877, 1879, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1892, 1893, 1894, 1895, 1897, 1898, 1900, 1901, 1904, 1906, 1909, 1912, 1914, 1917, 1922, 1923, 1925, 1928], "script": [1, 5, 13, 20, 23, 25, 29, 35, 38, 41, 44, 49, 51, 57, 59, 60, 1191, 1193, 1194, 1195, 1196, 1199, 1200, 1202, 1204, 1205, 1207, 1857, 1858, 1862, 1863, 1871, 1885, 1893, 1895, 1899, 1905, 1908, 1913], "In": [1, 3, 4, 5, 8, 10, 12, 13, 14, 15, 16, 17, 18, 21, 23, 25, 28, 29, 33, 35, 38, 41, 43, 45, 47, 51, 58, 59, 60, 63, 65, 66, 67, 68, 70, 71, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 122, 124, 126, 128, 131, 132, 134, 142, 144, 147, 148, 150, 153, 155, 159, 161, 163, 165, 167, 169, 178, 187, 195, 199, 202, 204, 214, 216, 222, 232, 236, 238, 244, 247, 249, 251, 253, 257, 262, 269, 271, 273, 277, 279, 283, 285, 292, 294, 296, 304, 306, 308, 310, 356, 358, 360, 362, 364, 366, 368, 371, 373, 375, 376, 383, 385, 387, 389, 391, 395, 419, 422, 425, 427, 438, 440, 442, 450, 455, 465, 468, 484, 488, 490, 506, 509, 520, 524, 526, 529, 531, 533, 546, 548, 550, 559, 561, 568, 572, 574, 590, 593, 595, 597, 599, 609, 619, 677, 757, 797, 821, 851, 896, 934, 955, 956, 963, 1009, 1020, 1032, 1033, 1037, 1038, 1063, 1084, 1086, 1094, 1095, 1096, 1111, 1121, 1125, 1128, 1130, 1188, 1190, 1199, 1202, 1203, 1205, 1221, 1230, 1235, 1236, 1237, 1245, 1248, 1253, 1258, 1262, 1267, 1270, 1279, 1284, 1290, 1291, 1317, 1335, 1336, 1337, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1361, 1362, 1363, 1367, 1369, 1374, 1383, 1392, 1407, 1415, 1416, 1417, 1422, 1428, 1465, 1467, 1469, 1473, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1511, 1521, 1528, 1537, 1565, 1568, 1570, 1571, 1585, 1602, 1609, 1614, 1615, 1647, 1678, 1689, 1691, 1727, 1743, 1745, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1808, 1809, 1831, 1843, 1847, 1848, 1857, 1858, 1859, 1860, 1862, 1863, 1869, 1870, 1875, 1876, 1877, 1878, 1881, 1882, 1885, 1886, 1888, 1889, 1890, 1891, 1893, 1894, 1896, 1897, 1898, 1899, 1901, 1904, 1905, 1907, 1908, 1909, 1910, 1913, 1914, 1915, 1917, 1922, 1924], "chosen": [1, 17, 29, 68, 1051, 1211, 1571, 1756, 1781, 1826, 1878, 1882, 1886, 1888, 1901, 1908], "maintain": [1, 8, 9, 15, 16, 21, 22, 38, 39, 41, 47, 63, 67, 71, 1334, 1362, 1367, 1514, 1602, 1635, 1649, 1858, 1878, 1882, 1883, 1886, 1888, 1894, 1908], "accuraci": [1, 17, 19, 39, 950, 1253, 1571, 1858, 1873, 1882, 1894, 1922, 1926], "detail": [1, 2, 3, 4, 8, 9, 21, 22, 25, 29, 30, 31, 32, 33, 34, 35, 38, 41, 42, 43, 47, 49, 59, 63, 69, 71, 151, 323, 493, 611, 732, 735, 736, 737, 738, 739, 740, 757, 763, 764, 765, 768, 769, 770, 771, 776, 777, 779, 780, 781, 782, 790, 856, 857, 858, 859, 870, 887, 889, 890, 891, 892, 893, 896, 905, 933, 960, 965, 969, 971, 972, 974, 988, 989, 998, 1009, 1012, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1027, 1028, 1029, 1046, 1063, 1102, 1124, 1135, 1138, 1139, 1143, 1171, 1178, 1190, 1194, 1205, 1229, 1247, 1254, 1262, 1268, 1270, 1290, 1330, 1334, 1344, 1353, 1354, 1355, 1359, 1365, 1366, 1367, 1368, 1370, 1371, 1374, 1392, 1422, 1428, 1434, 1435, 1437, 1449, 1470, 1480, 1481, 1482, 1483, 1484, 1485, 1487, 1488, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1522, 1524, 1525, 1526, 1527, 1529, 1530, 1531, 1533, 1534, 1535, 1536, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1560, 1562, 1563, 1564, 1565, 1566, 1567, 1569, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1587, 1588, 1589, 1593, 1602, 1603, 1638, 1648, 1659, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1678, 1683, 1695, 1707, 1739, 1750, 1776, 1784, 1829, 1843, 1857, 1860, 1861, 1862, 1863, 1870, 1872, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1893, 1894, 1897, 1898, 1899, 1901, 1905, 1906, 1908, 1910, 1912, 1913, 1914, 1915, 1917, 1921, 1922, 1924, 1925, 1928], "enter": [1, 41, 891, 1165], "should": [1, 2, 4, 5, 6, 10, 13, 16, 17, 18, 20, 21, 23, 24, 28, 29, 32, 33, 35, 38, 39, 41, 42, 43, 45, 47, 48, 49, 50, 51, 56, 57, 58, 59, 60, 63, 67, 68, 70, 71, 120, 151, 155, 313, 321, 398, 402, 444, 445, 446, 447, 448, 486, 494, 511, 513, 515, 580, 581, 582, 584, 585, 683, 686, 687, 732, 757, 769, 770, 771, 790, 793, 797, 814, 821, 835, 836, 851, 852, 853, 856, 862, 886, 887, 888, 889, 890, 894, 895, 896, 897, 898, 899, 900, 904, 910, 911, 918, 919, 920, 921, 928, 941, 962, 966, 969, 979, 980, 998, 1000, 1009, 1054, 1064, 1065, 1066, 1076, 1081, 1084, 1085, 1086, 1094, 1095, 1096, 1099, 1114, 1116, 1117, 1118, 1120, 1121, 1125, 1129, 1130, 1131, 1147, 1148, 1151, 1152, 1187, 1188, 1190, 1191, 1195, 1199, 1201, 1202, 1205, 1206, 1207, 1209, 1234, 1259, 1260, 1261, 1267, 1276, 1279, 1280, 1281, 1330, 1338, 1339, 1343, 1356, 1358, 1359, 1361, 1362, 1363, 1366, 1367, 1388, 1414, 1422, 1428, 1429, 1430, 1449, 1470, 1474, 1486, 1492, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1513, 1521, 1571, 1593, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1635, 1636, 1637, 1640, 1642, 1653, 1654, 1657, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1670, 1672, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1707, 1709, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1730, 1746, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1790, 1791, 1792, 1793, 1794, 1795, 1808, 1822, 1831, 1850, 1855, 1856, 1857, 1858, 1860, 1862, 1863, 1867, 1869, 1870, 1872, 1873, 1875, 1877, 1878, 1881, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1894, 1896, 1897, 1898, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1913, 1915, 1917, 1921, 1922, 1924, 1925, 1928], "model": [1, 2, 3, 4, 5, 6, 9, 10, 12, 13, 16, 17, 18, 19, 20, 21, 22, 24, 29, 39, 41, 42, 43, 45, 46, 47, 57, 59, 61, 63, 64, 65, 66, 67, 68, 69, 71, 83, 84, 88, 789, 790, 791, 794, 795, 807, 808, 809, 810, 811, 812, 813, 814, 816, 817, 818, 821, 822, 823, 833, 834, 835, 836, 851, 854, 855, 856, 857, 858, 859, 860, 950, 1010, 1030, 1119, 1120, 1121, 1129, 1131, 1165, 1190, 1194, 1195, 1199, 1201, 1205, 1207, 1261, 1330, 1359, 1376, 1387, 1388, 1422, 1428, 1450, 1461, 1465, 1467, 1468, 1469, 1520, 1602, 1603, 1608, 1610, 1612, 1625, 1644, 1645, 1656, 1657, 1659, 1660, 1667, 1672, 1677, 1678, 1683, 1689, 1691, 1804, 1850, 1858, 1860, 1862, 1863, 1864, 1871, 1872, 1878, 1883, 1885, 1886, 1887, 1888, 1892, 1894, 1895, 1896, 1897, 1898, 1899, 1901, 1902, 1907, 1909, 1913, 1914, 1916, 1917, 1918, 1922, 1926, 1927], "": [1, 2, 3, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17, 20, 21, 22, 23, 24, 27, 28, 29, 32, 33, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 51, 54, 55, 56, 58, 59, 63, 65, 67, 68, 70, 71, 462, 480, 491, 494, 511, 541, 555, 578, 621, 677, 686, 691, 692, 693, 732, 757, 790, 791, 792, 812, 813, 814, 817, 820, 823, 851, 858, 859, 872, 874, 875, 876, 877, 893, 894, 895, 899, 900, 902, 906, 934, 936, 949, 955, 956, 957, 962, 964, 966, 970, 985, 989, 998, 1000, 1005, 1006, 1009, 1010, 1011, 1030, 1031, 1032, 1038, 1055, 1058, 1060, 1061, 1063, 1077, 1078, 1080, 1081, 1082, 1085, 1086, 1088, 1089, 1092, 1093, 1095, 1096, 1097, 1098, 1100, 1102, 1103, 1104, 1105, 1106, 1109, 1110, 1111, 1116, 1117, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1129, 1131, 1135, 1143, 1151, 1152, 1153, 1177, 1179, 1187, 1188, 1190, 1194, 1200, 1201, 1205, 1220, 1221, 1231, 1232, 1233, 1235, 1238, 1242, 1244, 1246, 1247, 1251, 1252, 1253, 1254, 1259, 1261, 1262, 1277, 1284, 1289, 1291, 1294, 1296, 1297, 1303, 1304, 1307, 1316, 1317, 1320, 1322, 1328, 1329, 1330, 1338, 1339, 1340, 1341, 1342, 1345, 1359, 1365, 1376, 1422, 1423, 1428, 1432, 1438, 1450, 1453, 1455, 1461, 1465, 1467, 1469, 1475, 1476, 1493, 1494, 1505, 1518, 1521, 1532, 1533, 1538, 1571, 1577, 1590, 1593, 1598, 1599, 1602, 1603, 1614, 1625, 1638, 1642, 1649, 1650, 1658, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1673, 1674, 1675, 1676, 1677, 1678, 1683, 1695, 1697, 1701, 1708, 1723, 1726, 1727, 1730, 1731, 1732, 1734, 1736, 1743, 1750, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1802, 1803, 1804, 1807, 1808, 1809, 1810, 1811, 1819, 1823, 1825, 1831, 1845, 1846, 1847, 1850, 1851, 1857, 1859, 1860, 1861, 1862, 1863, 1864, 1867, 1869, 1870, 1872, 1873, 1875, 1876, 1877, 1882, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1896, 1897, 1899, 1900, 1901, 1903, 1904, 1906, 1907, 1908, 1910, 1911, 1913, 1914, 1915, 1916, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1927, 1928], "e": [1, 2, 3, 4, 6, 8, 12, 15, 16, 18, 21, 23, 29, 30, 32, 33, 38, 39, 41, 42, 45, 47, 48, 49, 50, 51, 52, 56, 57, 58, 59, 61, 63, 66, 68, 70, 71, 89, 151, 258, 335, 377, 577, 614, 732, 745, 754, 757, 790, 791, 812, 814, 851, 855, 856, 858, 859, 877, 886, 890, 895, 905, 906, 929, 931, 934, 995, 1009, 1034, 1063, 1073, 1114, 1120, 1125, 1129, 1140, 1165, 1169, 1170, 1172, 1175, 1187, 1190, 1196, 1197, 1205, 1225, 1226, 1241, 1253, 1261, 1262, 1263, 1265, 1267, 1284, 1295, 1338, 1339, 1340, 1341, 1342, 1345, 1350, 1351, 1352, 1358, 1359, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1374, 1377, 1382, 1385, 1386, 1387, 1388, 1389, 1392, 1394, 1395, 1396, 1397, 1413, 1422, 1423, 1428, 1429, 1431, 1432, 1436, 1437, 1453, 1461, 1465, 1469, 1470, 1471, 1473, 1496, 1497, 1498, 1505, 1507, 1508, 1509, 1512, 1513, 1514, 1521, 1532, 1564, 1571, 1590, 1592, 1593, 1598, 1602, 1603, 1604, 1605, 1610, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1635, 1636, 1642, 1646, 1649, 1656, 1657, 1664, 1665, 1700, 1711, 1729, 1736, 1743, 1747, 1754, 1759, 1804, 1808, 1857, 1860, 1862, 1863, 1864, 1867, 1870, 1871, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1892, 1893, 1894, 1897, 1899, 1901, 1904, 1905, 1907, 1908, 1913, 1914, 1915, 1917, 1918, 1920, 1921, 1922, 1924, 1928, 1929], "network": [1, 2, 8, 9, 15, 33, 45, 47, 58, 838, 1009, 1190, 1205, 1206, 1334, 1340, 1341, 1342, 1345, 1353, 1354, 1355, 1359, 1360, 1361, 1362, 1363, 1364, 1367, 1376, 1388, 1392, 1422, 1429, 1434, 1435, 1440, 1449, 1451, 1461, 1465, 1467, 1469, 1486, 1520, 1521, 1574, 1593, 1610, 1612, 1638, 1643, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1683, 1689, 1860, 1862, 1863, 1881, 1882, 1897, 1898, 1901, 1904, 1908, 1913, 1914, 1915], "loss": [1, 2, 39, 41, 42, 45, 47, 63, 1121, 1187, 1225, 1226, 1235, 1253, 1330, 1338, 1339, 1345, 1356, 1358, 1365, 1376, 1382, 1383, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1471, 1493, 1494, 1504, 1505, 1518, 1533, 1556, 1564, 1602, 1636, 1667, 1672, 1678, 1682, 1691, 1751, 1857, 1858, 1873, 1877, 1883, 1886, 1887, 1890, 1891, 1894, 1904, 1908, 1909, 1913, 1914, 1922], "comput": [1, 4, 6, 8, 9, 12, 15, 16, 17, 20, 28, 30, 32, 34, 38, 39, 41, 43, 47, 49, 51, 63, 64, 65, 67, 151, 290, 486, 493, 678, 680, 694, 695, 757, 765, 766, 797, 799, 816, 817, 818, 819, 821, 822, 886, 890, 891, 892, 894, 895, 898, 899, 900, 901, 902, 903, 904, 905, 906, 910, 911, 917, 922, 923, 924, 925, 926, 927, 938, 940, 941, 942, 949, 956, 958, 963, 1006, 1009, 1046, 1055, 1057, 1060, 1063, 1067, 1068, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1106, 1108, 1109, 1110, 1112, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1133, 1134, 1135, 1143, 1146, 1149, 1150, 1151, 1152, 1165, 1167, 1190, 1193, 1201, 1209, 1210, 1212, 1214, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1258, 1259, 1260, 1262, 1270, 1271, 1272, 1273, 1274, 1276, 1277, 1278, 1279, 1288, 1289, 1290, 1293, 1317, 1319, 1323, 1330, 1334, 1335, 1336, 1337, 1340, 1341, 1342, 1353, 1354, 1355, 1357, 1358, 1360, 1365, 1366, 1374, 1377, 1385, 1386, 1387, 1388, 1390, 1391, 1392, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1412, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1428, 1429, 1431, 1436, 1437, 1455, 1457, 1461, 1470, 1471, 1474, 1488, 1489, 1490, 1503, 1504, 1512, 1513, 1520, 1521, 1523, 1532, 1540, 1545, 1546, 1547, 1548, 1549, 1550, 1561, 1564, 1571, 1577, 1578, 1593, 1596, 1598, 1599, 1602, 1603, 1606, 1609, 1612, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1628, 1629, 1636, 1642, 1646, 1647, 1649, 1662, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1695, 1701, 1707, 1708, 1712, 1713, 1727, 1728, 1751, 1753, 1759, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1782, 1784, 1785, 1786, 1787, 1804, 1808, 1809, 1824, 1829, 1847, 1850, 1858, 1860, 1863, 1870, 1873, 1876, 1877, 1879, 1882, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1894, 1895, 1901, 1904, 1908, 1911, 1913, 1917, 1918, 1923, 1926], "backward": [1, 2, 6, 10, 12, 13, 17, 23, 24, 28, 29, 41, 42, 43, 45, 47, 63, 67, 68, 71, 290, 335, 486, 494, 501, 502, 511, 513, 515, 578, 677, 683, 686, 757, 812, 813, 814, 887, 892, 893, 894, 895, 896, 897, 899, 901, 904, 905, 910, 911, 917, 918, 930, 1009, 1067, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1119, 1120, 1190, 1262, 1270, 1284, 1294, 1338, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1359, 1365, 1374, 1375, 1376, 1389, 1392, 1393, 1409, 1413, 1414, 1422, 1428, 1429, 1436, 1437, 1466, 1467, 1468, 1469, 1470, 1471, 1493, 1494, 1504, 1505, 1521, 1532, 1556, 1559, 1594, 1598, 1599, 1602, 1614, 1647, 1656, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1682, 1695, 1707, 1782, 1785, 1789, 1808, 1843, 1857, 1858, 1861, 1863, 1869, 1877, 1878, 1881, 1882, 1887, 1888, 1889, 1890, 1893, 1894, 1896, 1897, 1904, 1905, 1907, 1908, 1913, 1917, 1918, 1923], "under": [1, 2, 4, 5, 6, 10, 15, 16, 17, 21, 29, 38, 41, 58, 63, 64, 66, 68, 70, 85, 905, 913, 935, 1165, 1190, 1345, 1422, 1486, 1512, 1513, 1609, 1611, 1614, 1659, 1728, 1859, 1875, 1882, 1883, 1886, 1887, 1889, 1891, 1896, 1901, 1905, 1906, 1908, 1911, 1912, 1915, 1918, 1922, 1925, 1927], "recommend": [1, 2, 6, 17, 38, 39, 41, 43, 47, 49, 58, 59, 63, 67, 70, 71, 89, 447, 890, 955, 956, 963, 1084, 1085, 1086, 1094, 1095, 1096, 1177, 1193, 1235, 1262, 1307, 1330, 1359, 1533, 1602, 1714, 1840, 1857, 1860, 1872, 1875, 1877, 1881, 1882, 1883, 1885, 1886, 1888, 1889, 1894, 1896, 1897, 1899, 1901, 1905, 1908], "correspond": [1, 2, 8, 18, 25, 29, 35, 38, 39, 41, 45, 46, 47, 58, 63, 71, 83, 472, 473, 511, 513, 515, 541, 542, 677, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 732, 790, 794, 833, 835, 854, 855, 856, 861, 877, 886, 888, 889, 890, 895, 898, 900, 905, 942, 957, 1009, 1029, 1058, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1143, 1152, 1179, 1190, 1206, 1220, 1225, 1226, 1231, 1234, 1253, 1260, 1262, 1276, 1291, 1312, 1359, 1365, 1392, 1422, 1428, 1468, 1512, 1521, 1558, 1598, 1602, 1610, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1643, 1649, 1678, 1683, 1700, 1701, 1711, 1734, 1743, 1759, 1802, 1803, 1808, 1839, 1842, 1845, 1846, 1857, 1860, 1861, 1863, 1867, 1873, 1876, 1877, 1882, 1883, 1886, 1887, 1888, 1889, 1891, 1893, 1894, 1898, 1901, 1905, 1907, 1908, 1913, 1914, 1917, 1918, 1919, 1922, 1924, 1926, 1927], "devic": [1, 2, 3, 6, 9, 12, 14, 16, 20, 25, 29, 32, 35, 38, 39, 41, 42, 43, 46, 59, 60, 63, 67, 70, 71, 89, 197, 207, 210, 289, 313, 321, 335, 444, 445, 446, 447, 448, 513, 515, 577, 683, 686, 720, 721, 722, 723, 724, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 746, 747, 748, 749, 750, 751, 752, 862, 874, 876, 877, 898, 900, 918, 919, 921, 928, 930, 965, 966, 967, 969, 970, 971, 972, 973, 975, 976, 977, 978, 979, 980, 982, 983, 984, 987, 991, 992, 993, 995, 996, 1004, 1006, 1007, 1008, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1032, 1033, 1034, 1035, 1039, 1040, 1041, 1064, 1065, 1066, 1076, 1081, 1099, 1117, 1118, 1147, 1148, 1190, 1194, 1197, 1200, 1203, 1209, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1230, 1231, 1232, 1233, 1236, 1237, 1238, 1244, 1247, 1248, 1250, 1251, 1253, 1254, 1260, 1261, 1276, 1279, 1284, 1290, 1294, 1307, 1309, 1330, 1340, 1341, 1342, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1365, 1366, 1375, 1377, 1385, 1386, 1387, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1422, 1428, 1430, 1438, 1439, 1461, 1465, 1467, 1469, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1513, 1532, 1538, 1571, 1586, 1590, 1591, 1592, 1593, 1602, 1604, 1605, 1606, 1607, 1635, 1642, 1648, 1650, 1653, 1654, 1667, 1707, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1747, 1751, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1785, 1786, 1790, 1791, 1792, 1793, 1794, 1795, 1808, 1822, 1824, 1833, 1835, 1843, 1855, 1856, 1858, 1859, 1860, 1861, 1862, 1863, 1865, 1871, 1876, 1878, 1882, 1887, 1889, 1890, 1892, 1894, 1895, 1898, 1901, 1903, 1904, 1905, 1906, 1907, 1908, 1912, 1913, 1917, 1919, 1923, 1924], "creat": [1, 2, 4, 6, 7, 8, 10, 12, 13, 15, 16, 17, 21, 26, 28, 29, 32, 38, 39, 41, 43, 45, 47, 49, 50, 56, 58, 59, 60, 61, 63, 70, 71, 89, 151, 223, 254, 335, 577, 578, 580, 581, 582, 584, 585, 729, 735, 736, 737, 742, 743, 753, 761, 789, 790, 791, 811, 812, 813, 814, 816, 821, 851, 875, 876, 877, 890, 892, 904, 929, 931, 947, 948, 957, 965, 974, 1006, 1007, 1016, 1051, 1066, 1115, 1116, 1117, 1187, 1190, 1193, 1202, 1208, 1213, 1219, 1220, 1226, 1228, 1247, 1260, 1276, 1291, 1312, 1338, 1356, 1365, 1366, 1369, 1383, 1389, 1413, 1414, 1422, 1425, 1426, 1427, 1450, 1453, 1454, 1461, 1470, 1471, 1473, 1602, 1614, 1635, 1642, 1647, 1658, 1659, 1678, 1746, 1777, 1788, 1793, 1822, 1829, 1858, 1863, 1864, 1867, 1871, 1875, 1882, 1883, 1886, 1887, 1888, 1889, 1891, 1894, 1895, 1896, 1899, 1901, 1904, 1905, 1907, 1908, 1913, 1914, 1915, 1917, 1919, 1921, 1922, 1923, 1924, 1925, 1926, 1927, 1929], "net": [1, 7, 33, 49, 66, 71, 1190, 1205, 1206, 1359, 1422, 1602, 1625, 1682, 1862, 1863, 1882, 1883, 1886, 1894, 1922], "sgd": [1, 38, 39, 45, 1365, 1593, 1602, 1683, 1689, 1691, 1882, 1886, 1887, 1894, 1904, 1913, 1914], "target": [1, 13, 14, 15, 21, 28, 29, 32, 45, 63, 67, 69, 70, 71, 497, 732, 763, 764, 789, 794, 856, 858, 859, 935, 1121, 1190, 1199, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1338, 1339, 1345, 1356, 1358, 1370, 1371, 1376, 1382, 1383, 1388, 1389, 1413, 1414, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1436, 1453, 1454, 1465, 1474, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1493, 1494, 1502, 1504, 1505, 1516, 1517, 1518, 1529, 1530, 1533, 1534, 1544, 1552, 1553, 1554, 1555, 1556, 1564, 1571, 1575, 1576, 1602, 1677, 1843, 1861, 1863, 1882, 1883, 1886, 1896, 1901, 1904, 1905, 1908, 1909, 1913, 1922, 1926], "data": [1, 2, 3, 4, 8, 15, 16, 17, 20, 21, 27, 30, 35, 36, 39, 41, 43, 45, 47, 48, 49, 52, 55, 58, 60, 63, 67, 71, 140, 151, 196, 197, 326, 329, 333, 336, 341, 444, 447, 480, 491, 495, 497, 614, 735, 736, 737, 757, 769, 770, 771, 778, 789, 790, 791, 795, 816, 817, 818, 819, 820, 822, 824, 862, 876, 877, 887, 890, 919, 928, 934, 967, 1044, 1045, 1064, 1065, 1066, 1076, 1077, 1078, 1081, 1083, 1084, 1086, 1094, 1095, 1096, 1099, 1102, 1103, 1104, 1105, 1114, 1116, 1117, 1118, 1120, 1129, 1147, 1148, 1150, 1169, 1172, 1197, 1201, 1205, 1209, 1260, 1261, 1262, 1276, 1281, 1289, 1291, 1303, 1304, 1317, 1319, 1320, 1343, 1345, 1350, 1351, 1352, 1359, 1374, 1377, 1385, 1386, 1387, 1392, 1394, 1409, 1429, 1437, 1438, 1474, 1486, 1491, 1492, 1496, 1497, 1498, 1531, 1538, 1540, 1577, 1578, 1602, 1603, 1604, 1605, 1635, 1636, 1637, 1638, 1640, 1649, 1653, 1654, 1658, 1659, 1683, 1689, 1697, 1705, 1708, 1709, 1710, 1714, 1716, 1717, 1719, 1720, 1721, 1722, 1723, 1730, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1784, 1787, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1807, 1808, 1822, 1831, 1833, 1835, 1842, 1843, 1855, 1856, 1858, 1860, 1861, 1864, 1870, 1871, 1873, 1875, 1878, 1882, 1883, 1884, 1886, 1888, 1889, 1893, 1896, 1898, 1899, 1900, 1903, 1904, 1905, 1906, 1908, 1911, 1913, 1915, 1917, 1918, 1919, 1920, 1921, 1922, 1924, 1925, 1926, 1927], "zero_grad": [1, 2, 45, 1190, 1422, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1682, 1882, 1886, 1890, 1894, 1896, 1904], "loss_fn": [1, 45, 1677, 1882, 1886, 1887, 1896, 1904], "exit": [1, 2, 3, 5, 21, 35, 41, 49, 58, 63, 70, 71, 891, 1602, 1863, 1875, 1883, 1896, 1901, 1915], "step": [1, 2, 3, 5, 10, 17, 21, 23, 29, 32, 38, 39, 41, 42, 43, 45, 47, 59, 63, 67, 71, 535, 604, 683, 765, 766, 854, 862, 891, 892, 893, 921, 945, 1149, 1237, 1260, 1262, 1276, 1279, 1291, 1370, 1371, 1392, 1489, 1490, 1516, 1517, 1602, 1635, 1656, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1714, 1723, 1777, 1859, 1860, 1861, 1877, 1882, 1883, 1886, 1887, 1888, 1890, 1894, 1896, 1898, 1900, 1901, 1905, 1907, 1908, 1913, 1914, 1917, 1922], "along": [1, 32, 35, 38, 41, 47, 51, 58, 313, 315, 317, 321, 491, 511, 513, 515, 683, 694, 816, 872, 873, 944, 961, 963, 978, 980, 1046, 1054, 1055, 1062, 1063, 1079, 1084, 1087, 1091, 1094, 1097, 1103, 1131, 1132, 1155, 1164, 1167, 1211, 1222, 1258, 1310, 1317, 1321, 1322, 1331, 1332, 1333, 1339, 1357, 1370, 1371, 1412, 1415, 1416, 1417, 1455, 1457, 1486, 1494, 1503, 1516, 1517, 1520, 1523, 1540, 1545, 1546, 1547, 1557, 1577, 1578, 1620, 1622, 1629, 1630, 1639, 1648, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1689, 1708, 1728, 1729, 1734, 1745, 1781, 1784, 1787, 1788, 1796, 1801, 1819, 1823, 1826, 1829, 1838, 1847, 1850, 1852, 1857, 1862, 1867, 1878, 1884, 1888, 1890, 1893, 1894, 1905, 1908, 1918], "complex": [1, 2, 4, 8, 9, 18, 20, 38, 39, 41, 71, 311, 329, 482, 682, 689, 905, 906, 943, 955, 956, 1058, 1084, 1106, 1111, 1143, 1160, 1169, 1180, 1182, 1183, 1186, 1187, 1190, 1210, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1232, 1239, 1242, 1244, 1246, 1247, 1248, 1249, 1253, 1254, 1258, 1259, 1260, 1262, 1270, 1276, 1288, 1293, 1311, 1350, 1351, 1352, 1389, 1422, 1496, 1497, 1498, 1609, 1649, 1701, 1714, 1727, 1748, 1759, 1804, 1805, 1808, 1843, 1847, 1848, 1849, 1857, 1858, 1861, 1863, 1864, 1872, 1896, 1903, 1919, 1920, 1923, 1924, 1925], "scenario": [1, 17, 18, 38, 41, 58, 1657, 1658, 1886, 1891, 1901, 1907, 1913], "g": [1, 2, 3, 4, 6, 8, 13, 15, 16, 23, 27, 29, 30, 32, 33, 38, 39, 41, 45, 47, 48, 49, 50, 51, 52, 56, 57, 58, 59, 61, 63, 66, 68, 70, 71, 577, 614, 745, 754, 757, 790, 791, 812, 814, 851, 856, 858, 859, 886, 895, 905, 906, 931, 1009, 1063, 1114, 1120, 1124, 1125, 1140, 1143, 1165, 1187, 1190, 1196, 1197, 1205, 1261, 1345, 1346, 1359, 1361, 1362, 1363, 1367, 1369, 1374, 1382, 1388, 1392, 1393, 1422, 1423, 1432, 1437, 1453, 1505, 1507, 1508, 1509, 1514, 1521, 1602, 1603, 1604, 1605, 1646, 1649, 1656, 1657, 1662, 1663, 1664, 1665, 1668, 1674, 1675, 1676, 1677, 1729, 1736, 1747, 1754, 1772, 1804, 1857, 1860, 1862, 1863, 1864, 1867, 1870, 1875, 1882, 1883, 1886, 1888, 1889, 1890, 1891, 1893, 1894, 1897, 1898, 1901, 1904, 1905, 1907, 1908, 1913, 1917, 1920, 1921, 1922, 1928], "penalti": [1, 24, 778, 1020, 1661, 1662, 1663, 1664, 1666, 1668, 1674, 1675, 1677, 1909], "multipl": [1, 2, 3, 4, 6, 12, 16, 17, 19, 28, 38, 39, 41, 42, 43, 47, 48, 51, 58, 59, 60, 63, 68, 70, 71, 192, 209, 315, 511, 683, 685, 686, 692, 693, 757, 838, 871, 872, 875, 904, 938, 940, 950, 958, 962, 978, 979, 980, 1006, 1061, 1063, 1066, 1116, 1124, 1125, 1126, 1127, 1130, 1131, 1135, 1139, 1153, 1154, 1203, 1206, 1211, 1212, 1227, 1228, 1229, 1245, 1250, 1255, 1256, 1284, 1287, 1292, 1294, 1338, 1339, 1353, 1354, 1355, 1356, 1358, 1366, 1369, 1374, 1382, 1388, 1389, 1410, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1473, 1493, 1494, 1504, 1513, 1533, 1556, 1564, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1676, 1684, 1685, 1686, 1687, 1688, 1693, 1695, 1751, 1779, 1785, 1786, 1790, 1791, 1792, 1794, 1795, 1823, 1824, 1831, 1839, 1843, 1850, 1851, 1857, 1858, 1862, 1863, 1875, 1876, 1877, 1878, 1883, 1885, 1887, 1889, 1891, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1907, 1908, 1909, 1913, 1914, 1915, 1917, 1927], "autocastmodel": 1, "produc": [1, 8, 13, 15, 17, 20, 21, 24, 29, 32, 38, 41, 43, 48, 50, 52, 55, 60, 68, 69, 70, 71, 89, 729, 735, 736, 737, 742, 743, 753, 761, 789, 790, 921, 941, 1002, 1094, 1095, 1096, 1114, 1124, 1125, 1131, 1143, 1201, 1205, 1206, 1209, 1225, 1226, 1229, 1236, 1237, 1248, 1253, 1287, 1290, 1291, 1292, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1398, 1399, 1400, 1401, 1402, 1403, 1428, 1505, 1513, 1521, 1532, 1590, 1591, 1592, 1649, 1678, 1707, 1714, 1723, 1808, 1843, 1850, 1860, 1862, 1863, 1875, 1876, 1882, 1883, 1884, 1886, 1888, 1892, 1893, 1894, 1897, 1898, 1899, 1900, 1901, 1917, 1921], "after": [1, 2, 8, 10, 12, 14, 17, 18, 19, 21, 24, 28, 29, 32, 38, 39, 41, 42, 43, 45, 46, 58, 60, 63, 70, 71, 260, 757, 787, 854, 856, 858, 859, 890, 891, 894, 950, 964, 966, 1002, 1009, 1062, 1120, 1175, 1190, 1194, 1245, 1284, 1326, 1359, 1374, 1407, 1422, 1425, 1465, 1467, 1469, 1486, 1521, 1593, 1596, 1602, 1614, 1616, 1620, 1622, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1682, 1683, 1689, 1691, 1747, 1804, 1829, 1852, 1857, 1862, 1863, 1873, 1875, 1881, 1882, 1883, 1886, 1887, 1888, 1890, 1891, 1893, 1894, 1896, 1897, 1901, 1904, 1905, 1907, 1908, 1913, 1914, 1915, 1916, 1918, 1920, 1922], "them": [1, 2, 4, 6, 8, 9, 10, 15, 16, 17, 20, 21, 24, 25, 28, 29, 30, 32, 33, 38, 41, 43, 49, 50, 55, 58, 60, 63, 67, 68, 70, 71, 151, 222, 254, 731, 890, 896, 900, 932, 1009, 1048, 1051, 1063, 1211, 1220, 1231, 1245, 1257, 1261, 1289, 1320, 1346, 1365, 1422, 1455, 1457, 1577, 1621, 1636, 1639, 1679, 1787, 1789, 1807, 1857, 1862, 1863, 1870, 1871, 1873, 1875, 1876, 1877, 1878, 1882, 1883, 1884, 1886, 1888, 1889, 1890, 1892, 1893, 1894, 1898, 1900, 1904, 1906, 1907, 1908, 1909, 1913, 1914, 1915, 1917, 1918, 1922, 1923, 1926], "differ": [1, 2, 4, 6, 9, 16, 17, 18, 20, 21, 23, 24, 25, 26, 29, 32, 35, 38, 41, 43, 45, 46, 47, 49, 50, 51, 55, 56, 58, 59, 61, 63, 64, 67, 68, 69, 71, 197, 485, 491, 614, 677, 683, 686, 692, 693, 732, 757, 790, 793, 794, 819, 821, 822, 858, 859, 862, 876, 877, 905, 906, 918, 930, 931, 962, 1046, 1051, 1053, 1055, 1063, 1103, 1104, 1105, 1109, 1110, 1116, 1119, 1124, 1125, 1131, 1143, 1164, 1190, 1200, 1205, 1219, 1225, 1226, 1236, 1237, 1245, 1248, 1253, 1257, 1284, 1294, 1330, 1339, 1340, 1341, 1342, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1374, 1375, 1383, 1385, 1386, 1387, 1388, 1392, 1393, 1409, 1422, 1425, 1428, 1443, 1444, 1446, 1447, 1448, 1450, 1453, 1461, 1467, 1469, 1471, 1474, 1477, 1478, 1479, 1486, 1494, 1512, 1521, 1532, 1534, 1545, 1546, 1547, 1571, 1593, 1602, 1604, 1605, 1609, 1644, 1649, 1656, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1673, 1674, 1675, 1676, 1677, 1678, 1683, 1691, 1697, 1707, 1729, 1802, 1803, 1808, 1829, 1840, 1841, 1843, 1845, 1846, 1850, 1857, 1860, 1862, 1863, 1865, 1869, 1870, 1875, 1876, 1878, 1882, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1894, 1896, 1897, 1898, 1900, 1904, 1905, 1906, 1907, 1908, 1909, 1913, 1915, 1917, 1920, 1922, 1923, 1924, 1927], "caus": [1, 2, 3, 4, 6, 16, 18, 32, 35, 38, 41, 45, 51, 57, 58, 59, 68, 71, 553, 614, 874, 877, 890, 1116, 1201, 1205, 1225, 1226, 1253, 1307, 1532, 1533, 1590, 1593, 1602, 1648, 1660, 1747, 1758, 1804, 1843, 1860, 1863, 1875, 1884, 1886, 1888, 1890, 1896, 1898, 1900, 1901, 1905, 1908, 1909, 1915, 1917, 1920], "mismatch": [1, 41, 71, 877, 1191, 1659, 1660, 1862, 1882, 1887, 1888, 1890, 1901, 1924], "so": [1, 2, 3, 4, 8, 10, 12, 15, 16, 17, 18, 20, 21, 22, 23, 24, 27, 28, 29, 32, 34, 38, 39, 41, 42, 43, 45, 46, 47, 48, 50, 51, 58, 59, 61, 63, 66, 67, 68, 70, 71, 335, 457, 494, 677, 856, 891, 896, 898, 899, 904, 947, 965, 988, 1051, 1053, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1088, 1089, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1114, 1116, 1119, 1123, 1124, 1126, 1127, 1177, 1187, 1190, 1193, 1194, 1199, 1201, 1203, 1245, 1247, 1257, 1262, 1267, 1279, 1300, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1366, 1369, 1376, 1422, 1438, 1455, 1457, 1473, 1486, 1496, 1497, 1498, 1521, 1577, 1578, 1593, 1602, 1648, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1773, 1787, 1799, 1804, 1808, 1828, 1840, 1844, 1860, 1862, 1863, 1869, 1871, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1886, 1887, 1888, 1889, 1891, 1892, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1908, 1912, 1913, 1917, 1918, 1920, 1922, 1923, 1925], "cast": [1, 7, 39, 56, 63, 335, 600, 601, 935, 1044, 1045, 1190, 1242, 1246, 1259, 1289, 1317, 1320, 1422, 1540, 1577, 1578, 1649, 1705, 1784, 1787, 1793, 1807, 1812, 1813, 1860, 1882, 1897, 1901, 1918, 1919, 1920], "back": [1, 2, 3, 12, 18, 20, 21, 32, 38, 39, 41, 43, 47, 58, 63, 68, 71, 732, 834, 905, 947, 1083, 1120, 1191, 1203, 1255, 1261, 1468, 1606, 1607, 1789, 1857, 1860, 1863, 1883, 1888, 1889, 1896, 1897, 1898, 1901, 1904, 1905, 1908, 1913, 1917, 1928], "alreadi": [1, 2, 12, 16, 30, 38, 39, 41, 42, 58, 59, 63, 70, 71, 196, 207, 210, 462, 485, 521, 577, 600, 601, 789, 837, 851, 855, 876, 974, 1000, 1190, 1199, 1261, 1422, 1597, 1602, 1635, 1678, 1838, 1840, 1857, 1860, 1870, 1872, 1876, 1877, 1882, 1883, 1886, 1888, 1891, 1896, 1901, 1904, 1905, 1908, 1914, 1915, 1919, 1921], "incur": [1, 6, 39, 41, 63, 940, 1896, 1913], "overhead": [1, 2, 4, 5, 9, 12, 16, 17, 19, 20, 21, 23, 39, 41, 63, 778, 950, 1020, 1201, 1602, 1885, 1886, 1887, 1892, 1893, 1906, 1907, 1914, 1917, 1923], "here": [1, 2, 8, 9, 10, 12, 15, 16, 17, 18, 20, 21, 22, 23, 25, 27, 29, 33, 35, 38, 39, 41, 42, 47, 57, 59, 65, 66, 67, 68, 70, 71, 577, 790, 791, 960, 972, 1063, 1080, 1082, 1083, 1088, 1089, 1090, 1092, 1093, 1098, 1100, 1119, 1129, 1188, 1201, 1340, 1341, 1342, 1353, 1354, 1355, 1385, 1386, 1387, 1430, 1461, 1521, 1523, 1611, 1675, 1678, 1689, 1776, 1857, 1860, 1862, 1863, 1865, 1876, 1877, 1878, 1882, 1883, 1886, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1900, 1901, 1904, 1905, 1906, 1908, 1911, 1917, 1921, 1922, 1924], "assum": [1, 14, 15, 24, 30, 38, 41, 46, 47, 49, 51, 58, 59, 63, 66, 69, 71, 814, 1046, 1081, 1084, 1086, 1094, 1095, 1096, 1099, 1181, 1187, 1188, 1191, 1205, 1225, 1226, 1228, 1235, 1244, 1247, 1250, 1252, 1262, 1345, 1414, 1474, 1505, 1571, 1602, 1611, 1614, 1639, 1679, 1680, 1685, 1686, 1687, 1690, 1692, 1693, 1697, 1809, 1829, 1831, 1857, 1860, 1862, 1863, 1876, 1883, 1886, 1888, 1889, 1891, 1893, 1897, 1901, 1904, 1905, 1906, 1913, 1914, 1915, 1917], "a_float32": 1, "rand": [1, 2, 35, 47, 71, 335, 690, 696, 898, 899, 900, 901, 902, 903, 962, 1006, 1007, 1080, 1082, 1085, 1086, 1088, 1089, 1092, 1093, 1095, 1096, 1098, 1100, 1121, 1196, 1201, 1205, 1206, 1207, 1263, 1264, 1266, 1338, 1388, 1465, 1466, 1467, 1468, 1469, 1493, 1512, 1513, 1571, 1602, 1614, 1647, 1700, 1711, 1712, 1713, 1717, 1859, 1860, 1861, 1862, 1863, 1865, 1876, 1877, 1901, 1903, 1906, 1908, 1913, 1914, 1918, 1921, 1922, 1925], "8": [1, 2, 14, 21, 29, 32, 37, 38, 39, 41, 47, 49, 313, 315, 317, 321, 401, 402, 470, 511, 515, 557, 604, 614, 682, 683, 694, 695, 742, 743, 758, 760, 762, 770, 771, 817, 818, 819, 822, 901, 921, 929, 940, 943, 944, 948, 1006, 1007, 1042, 1046, 1061, 1066, 1079, 1095, 1096, 1102, 1103, 1106, 1113, 1143, 1152, 1153, 1213, 1242, 1245, 1246, 1247, 1255, 1257, 1260, 1261, 1321, 1322, 1327, 1328, 1329, 1331, 1332, 1333, 1346, 1357, 1392, 1418, 1419, 1425, 1427, 1429, 1436, 1437, 1440, 1443, 1444, 1445, 1446, 1447, 1448, 1461, 1465, 1466, 1467, 1468, 1469, 1473, 1497, 1500, 1503, 1559, 1564, 1569, 1570, 1571, 1649, 1650, 1656, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1683, 1691, 1696, 1700, 1704, 1724, 1734, 1735, 1736, 1743, 1756, 1763, 1766, 1771, 1777, 1781, 1788, 1790, 1791, 1796, 1804, 1808, 1818, 1823, 1824, 1825, 1827, 1829, 1838, 1843, 1844, 1851, 1860, 1864, 1870, 1886, 1888, 1899, 1901, 1903, 1905, 1906, 1907, 1908, 1911, 1913, 1917, 1918, 1920, 1921, 1923], "b_float32": 1, "c_float32": 1, "d_float32": 1, "mm": [1, 23, 942, 943, 1194, 1245, 1284, 1432, 1433, 1707, 1808, 1843, 1859, 1861, 1862, 1876, 1882, 1885, 1888, 1897, 1903, 1917], "No": [1, 10, 12, 61, 70, 897, 1602, 1647, 1862, 1886, 1901, 1911, 1921, 1924], "manual": [1, 12, 15, 25, 38, 41, 56, 58, 59, 61, 63, 71, 794, 835, 875, 904, 1152, 1194, 1338, 1339, 1358, 1426, 1427, 1429, 1450, 1469, 1493, 1494, 1504, 1556, 1614, 1635, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1860, 1863, 1875, 1882, 1886, 1888, 1889, 1890, 1891, 1894, 1900, 1901, 1908, 1909, 1922], "e_float16": 1, "handl": [1, 2, 6, 10, 12, 16, 17, 18, 20, 21, 24, 30, 32, 38, 39, 41, 42, 43, 45, 49, 50, 51, 58, 59, 63, 70, 71, 486, 837, 887, 897, 910, 911, 957, 966, 981, 1008, 1021, 1063, 1109, 1110, 1131, 1190, 1220, 1359, 1422, 1471, 1521, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1727, 1773, 1809, 1850, 1857, 1873, 1875, 1877, 1886, 1888, 1889, 1890, 1891, 1896, 1901, 1905, 1908, 1913, 1915, 1924, 1925], "f_float16": 1, "g_float32": 1, "epoch": [1, 38, 51, 61, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1873, 1882, 1904, 1922], "eval": [1, 71, 811, 857, 858, 1129, 1190, 1194, 1199, 1205, 1340, 1341, 1342, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1428, 1461, 1469, 1610, 1863, 1871, 1894, 1901, 1908, 1927, 1928], "testmodel": 1, "__init__": [1, 2, 13, 15, 28, 29, 38, 39, 41, 47, 63, 71, 858, 859, 1129, 1188, 1191, 1193, 1196, 1201, 1205, 1206, 1207, 1422, 1423, 1424, 1432, 1433, 1593, 1860, 1862, 1863, 1873, 1883, 1888, 1890, 1894, 1899, 1901, 1905, 1908, 1922], "input_s": [1, 731, 757, 758, 762, 1374, 1375, 1392, 1393, 1437, 1438, 1439, 1861], "num_class": [1, 20, 1558, 1861], "super": [1, 10, 13, 18, 28, 29, 38, 39, 41, 43, 71, 858, 859, 1129, 1188, 1193, 1196, 1201, 1205, 1206, 1207, 1422, 1423, 1424, 1432, 1433, 1434, 1435, 1593, 1689, 1860, 1862, 1863, 1864, 1883, 1888, 1894, 1899, 1901, 1905, 1908], "fc1": [1, 39, 1593, 1906], "suggest": [1, 10, 23, 29, 39, 64, 83, 84, 1356, 1857, 1865, 1882, 1883, 1890, 1917], "issu": [1, 3, 4, 6, 10, 11, 12, 17, 18, 19, 22, 27, 30, 32, 37, 38, 41, 48, 63, 64, 66, 68, 71, 898, 904, 950, 1114, 1125, 1127, 1131, 1235, 1279, 1291, 1388, 1392, 1418, 1419, 1420, 1437, 1474, 1532, 1533, 1747, 1850, 1857, 1858, 1863, 1865, 1870, 1875, 1876, 1877, 1878, 1882, 1883, 1886, 1888, 1896, 1897, 1898, 1900, 1901, 1905, 1908, 1909, 1913, 1917, 1918, 1920], "http": [1, 3, 4, 5, 8, 10, 19, 20, 23, 27, 28, 32, 33, 39, 40, 41, 46, 47, 58, 59, 63, 151, 677, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 789, 790, 890, 950, 1063, 1120, 1262, 1291, 1345, 1392, 1418, 1419, 1420, 1440, 1441, 1465, 1468, 1471, 1646, 1697, 1714, 1747, 1772, 1843, 1857, 1864, 1872, 1883, 1884, 1891, 1892, 1894, 1898, 1900, 1901, 1905, 1907, 1920, 1922, 1929], "github": [1, 8, 10, 17, 23, 27, 28, 29, 32, 40, 41, 54, 63, 64, 68, 151, 789, 790, 890, 904, 1120, 1291, 1418, 1419, 1420, 1465, 1683, 1747, 1857, 1865, 1870, 1888, 1891, 1898, 1901, 1907, 1908, 1917, 1918, 1920], "com": [1, 8, 23, 27, 28, 32, 40, 41, 57, 59, 63, 151, 789, 790, 890, 1120, 1291, 1418, 1419, 1420, 1465, 1747, 1843, 1857, 1872, 1891, 1892, 1898, 1900, 1901, 1907, 1920], "75956": 1, "_c": [1, 38, 39, 41, 70, 898, 904, 1189, 1201, 1658, 1861, 1863, 1873, 1886, 1893, 1897, 1900, 1901], "_jit_set_autocast_mod": 1, "randn": [1, 2, 12, 13, 17, 20, 21, 22, 27, 29, 30, 41, 47, 65, 67, 68, 69, 71, 289, 311, 482, 541, 577, 581, 582, 583, 584, 585, 586, 614, 680, 681, 682, 683, 684, 685, 686, 687, 692, 693, 696, 717, 725, 726, 731, 735, 736, 737, 738, 739, 740, 753, 755, 757, 758, 759, 760, 761, 762, 769, 770, 771, 858, 859, 871, 872, 873, 875, 878, 879, 880, 881, 882, 918, 930, 937, 939, 940, 941, 942, 943, 945, 957, 958, 959, 960, 961, 963, 1042, 1043, 1044, 1045, 1050, 1051, 1052, 1053, 1057, 1063, 1077, 1078, 1107, 1119, 1120, 1121, 1123, 1124, 1125, 1126, 1129, 1130, 1131, 1160, 1164, 1167, 1201, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1243, 1244, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1258, 1265, 1269, 1270, 1277, 1279, 1280, 1281, 1283, 1284, 1287, 1289, 1290, 1292, 1294, 1295, 1296, 1297, 1310, 1311, 1314, 1324, 1327, 1328, 1329, 1331, 1332, 1333, 1334, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1354, 1355, 1357, 1358, 1360, 1361, 1362, 1363, 1364, 1365, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1420, 1421, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1448, 1449, 1451, 1452, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1470, 1472, 1473, 1477, 1478, 1479, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1505, 1516, 1517, 1523, 1556, 1562, 1563, 1652, 1656, 1698, 1703, 1704, 1705, 1707, 1708, 1721, 1725, 1726, 1738, 1774, 1776, 1781, 1786, 1789, 1797, 1798, 1807, 1808, 1817, 1820, 1821, 1824, 1828, 1831, 1832, 1834, 1837, 1839, 1843, 1848, 1849, 1850, 1853, 1859, 1861, 1862, 1863, 1865, 1876, 1877, 1878, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1892, 1894, 1898, 1899, 1901, 1903, 1905, 1908, 1913, 1917, 1918, 1920, 1922, 1925, 1927], "freez": [1, 1190, 1199, 1365, 1366, 1422, 1883], "_": [1, 2, 4, 13, 21, 29, 38, 39, 41, 42, 45, 51, 69, 71, 678, 680, 681, 695, 862, 878, 879, 880, 881, 882, 891, 897, 920, 939, 956, 957, 959, 960, 962, 1107, 1112, 1126, 1130, 1156, 1210, 1218, 1269, 1277, 1340, 1341, 1342, 1385, 1386, 1387, 1461, 1602, 1610, 1643, 1675, 1677, 1697, 1720, 1723, 1726, 1738, 1753, 1759, 1761, 1767, 1774, 1776, 1797, 1808, 1820, 1821, 1883, 1886, 1889, 1890, 1894, 1900, 1904, 1905, 1907, 1918], "bug": [1, 17, 29, 32, 35, 41, 71, 1123, 1124, 1126, 1279, 1882, 1896, 1917], "what": [1, 2, 4, 6, 8, 9, 10, 12, 13, 15, 16, 17, 18, 21, 22, 27, 29, 41, 46, 47, 51, 55, 56, 63, 65, 67, 68, 71, 889, 1124, 1205, 1206, 1279, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1416, 1417, 1450, 1473, 1545, 1546, 1547, 1571, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1708, 1857, 1858, 1860, 1862, 1863, 1876, 1888, 1889, 1891, 1894, 1901, 1904, 1907, 1908, 1913, 1914, 1917], "observ": [1, 12, 17, 29, 39, 49, 58, 753, 786, 787, 789, 790, 791, 792, 793, 794, 796, 797, 798, 799, 805, 806, 808, 810, 812, 814, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 838, 856, 858, 859, 861, 958, 962, 1203, 1291, 1338, 1339, 1340, 1341, 1342, 1356, 1358, 1382, 1385, 1386, 1387, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1461, 1470, 1493, 1494, 1504, 1533, 1556, 1564, 1882, 1883, 1886, 1887, 1893, 1909, 1927], "pleas": [1, 2, 5, 6, 7, 8, 9, 10, 13, 16, 22, 25, 27, 29, 30, 33, 39, 41, 47, 50, 53, 54, 58, 59, 63, 64, 65, 66, 67, 68, 69, 71, 254, 255, 496, 511, 615, 686, 727, 728, 729, 730, 731, 732, 738, 739, 740, 742, 743, 753, 758, 759, 760, 761, 762, 858, 859, 889, 891, 892, 893, 898, 900, 901, 904, 932, 1046, 1119, 1123, 1124, 1125, 1126, 1127, 1131, 1190, 1253, 1284, 1294, 1345, 1353, 1388, 1422, 1521, 1533, 1538, 1559, 1571, 1589, 1602, 1643, 1644, 1685, 1747, 1850, 1865, 1870, 1876, 1877, 1878, 1879, 1882, 1883, 1888, 1889, 1892, 1897, 1898, 1900, 1901, 1904, 1905, 1908, 1911, 1913, 1914, 1917, 1918, 1920, 1921, 1922, 1924], "file": [1, 2, 4, 7, 8, 10, 13, 15, 17, 18, 23, 25, 30, 32, 35, 38, 43, 49, 51, 56, 58, 60, 66, 68, 71, 898, 904, 912, 913, 965, 1002, 1123, 1124, 1126, 1127, 1165, 1197, 1200, 1261, 1659, 1739, 1783, 1857, 1860, 1863, 1864, 1865, 1872, 1876, 1877, 1878, 1883, 1886, 1888, 1893, 1898, 1899, 1900, 1901, 1907, 1911, 1914, 1917, 1919, 1922], "subregion": 1, "nest": [1, 2, 6, 32, 43, 63, 71, 586, 790, 812, 814, 891, 900, 1024, 1025, 1121, 1131, 1190, 1193, 1205, 1422, 1428, 1468, 1656, 1660, 1850, 1858, 1889, 1901, 1907, 1913], "local": [1, 14, 17, 21, 29, 41, 43, 45, 46, 49, 56, 58, 59, 60, 61, 63, 71, 917, 1006, 1067, 1120, 1165, 1190, 1262, 1361, 1362, 1363, 1367, 1369, 1410, 1422, 1473, 1515, 1539, 1589, 1602, 1603, 1647, 1753, 1783, 1857, 1858, 1862, 1875, 1882, 1886, 1887, 1890, 1901, 1905, 1906, 1910, 1913, 1914, 1915, 1922], "particular": [1, 4, 8, 12, 16, 17, 18, 29, 38, 43, 49, 55, 58, 59, 63, 71, 557, 677, 858, 859, 1037, 1131, 1190, 1284, 1359, 1422, 1656, 1850, 1860, 1862, 1870, 1878, 1886, 1888, 1890, 1893, 1894, 1897, 1901, 1904, 1917, 1919, 1925, 1928], "explicit": [1, 9, 41, 63, 67, 71, 998, 1143, 1177, 1533, 1747, 1824, 1857, 1858, 1859, 1863, 1864, 1876, 1882, 1886, 1888, 1905, 1920, 1921], "control": [1, 2, 3, 12, 13, 15, 20, 21, 32, 38, 39, 41, 42, 43, 47, 49, 54, 57, 58, 752, 796, 855, 858, 873, 877, 891, 919, 928, 1050, 1051, 1052, 1053, 1054, 1147, 1148, 1201, 1202, 1203, 1205, 1220, 1226, 1228, 1231, 1233, 1236, 1238, 1242, 1248, 1251, 1253, 1259, 1279, 1330, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1408, 1416, 1417, 1473, 1571, 1602, 1695, 1751, 1752, 1766, 1781, 1783, 1788, 1804, 1808, 1826, 1832, 1833, 1834, 1835, 1858, 1860, 1869, 1883, 1885, 1886, 1887, 1894, 1896, 1897, 1899, 1901, 1904, 1908, 1915, 1917], "surround": [1, 71, 787, 1862, 1882, 1886], "ensur": [1, 2, 5, 7, 8, 10, 12, 16, 17, 29, 38, 41, 42, 43, 45, 49, 58, 59, 61, 63, 70, 71, 480, 485, 732, 816, 894, 896, 1120, 1190, 1334, 1415, 1422, 1425, 1426, 1465, 1521, 1545, 1546, 1547, 1571, 1602, 1755, 1857, 1860, 1862, 1870, 1872, 1875, 1882, 1883, 1886, 1888, 1889, 1891, 1896, 1898, 1905, 1908, 1909, 1913, 1914], "necessari": [1, 2, 4, 10, 17, 29, 32, 38, 43, 49, 58, 59, 63, 70, 89, 192, 209, 557, 586, 897, 1120, 1164, 1201, 1428, 1636, 1637, 1860, 1863, 1877, 1881, 1883, 1884, 1886, 1887, 1892, 1894, 1897, 1900, 1905, 1908, 1913, 1914, 1915, 1920], "becaus": [1, 2, 4, 5, 6, 8, 9, 12, 15, 16, 17, 18, 20, 21, 27, 29, 32, 38, 39, 41, 45, 47, 51, 63, 67, 68, 70, 71, 494, 900, 905, 906, 1084, 1085, 1086, 1094, 1095, 1096, 1121, 1125, 1130, 1131, 1187, 1191, 1194, 1197, 1236, 1237, 1261, 1279, 1340, 1341, 1342, 1359, 1461, 1593, 1602, 1603, 1681, 1723, 1804, 1850, 1858, 1860, 1863, 1865, 1875, 1876, 1877, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1897, 1901, 1905, 1908, 1909, 1913, 1915, 1917, 1922, 1924, 1927, 1928], "f_float32": 1, "re": [1, 2, 5, 6, 8, 12, 15, 16, 17, 20, 22, 28, 29, 32, 38, 41, 45, 48, 55, 58, 63, 64, 65, 66, 67, 68, 70, 71, 930, 1114, 1190, 1194, 1422, 1577, 1603, 1638, 1734, 1787, 1860, 1863, 1870, 1875, 1882, 1883, 1886, 1888, 1889, 1891, 1896, 1908, 1914, 1915, 1918, 1928], "again": [1, 12, 15, 16, 21, 23, 35, 38, 41, 45, 49, 66, 1312, 1883, 1889, 1894], "regardless": [1, 17, 38, 57, 63, 956, 1194, 1199, 1840, 1882, 1886, 1899, 1913, 1924], "g_float16": 1, "thread": [1, 2, 4, 14, 38, 41, 43, 49, 60, 63, 70, 917, 966, 1067, 1140, 1141, 1165, 1359, 1647, 1753, 1754, 1755, 1858, 1860, 1873, 1882, 1886, 1893, 1896, 1913, 1915, 1925], "new": [1, 2, 6, 9, 12, 14, 15, 17, 21, 28, 29, 32, 35, 38, 40, 41, 43, 47, 49, 58, 59, 63, 64, 67, 68, 69, 70, 71, 222, 254, 311, 447, 482, 486, 494, 497, 541, 577, 580, 614, 677, 681, 757, 788, 811, 816, 851, 876, 878, 879, 880, 881, 882, 892, 910, 911, 933, 934, 939, 948, 957, 959, 960, 967, 969, 1047, 1051, 1073, 1077, 1078, 1104, 1105, 1107, 1120, 1129, 1131, 1160, 1164, 1165, 1179, 1180, 1183, 1186, 1190, 1196, 1201, 1203, 1263, 1264, 1265, 1266, 1283, 1321, 1324, 1340, 1341, 1342, 1374, 1385, 1386, 1387, 1422, 1423, 1428, 1432, 1461, 1472, 1474, 1532, 1595, 1598, 1599, 1600, 1601, 1602, 1610, 1614, 1616, 1620, 1621, 1622, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1639, 1643, 1647, 1664, 1665, 1691, 1715, 1725, 1726, 1730, 1731, 1732, 1738, 1739, 1743, 1748, 1749, 1759, 1761, 1772, 1774, 1776, 1797, 1798, 1801, 1818, 1820, 1821, 1837, 1839, 1842, 1848, 1849, 1850, 1857, 1860, 1862, 1863, 1867, 1870, 1871, 1875, 1876, 1877, 1878, 1879, 1883, 1886, 1888, 1889, 1892, 1893, 1894, 1895, 1896, 1898, 1899, 1900, 1901, 1902, 1904, 1905, 1907, 1908, 1911, 1915, 1917, 1918, 1919, 1921, 1922, 1923, 1924, 1927], "affect": [1, 2, 3, 8, 10, 24, 35, 37, 48, 63, 222, 223, 782, 917, 967, 969, 1067, 1114, 1137, 1165, 1190, 1303, 1304, 1392, 1422, 1437, 1474, 1590, 1603, 1647, 1747, 1750, 1751, 1753, 1882, 1883, 1886, 1891, 1894, 1897, 1898, 1919], "dataparallel": [1, 41, 1586, 1602, 1638, 1858, 1883, 1890, 1896, 1913], "parallel": [1, 17, 31, 32, 38, 39, 41, 42, 43, 45, 58, 59, 63, 1140, 1141, 1193, 1359, 1428, 1461, 1521, 1602, 1754, 1755, 1858, 1863, 1882, 1883, 1885, 1896, 1900, 1913, 1915], "distributeddataparallel": [1, 38, 39, 41, 42, 45, 59, 63, 1359, 1461, 1896, 1906, 1913], "one": [1, 2, 3, 4, 5, 6, 7, 8, 9, 12, 13, 15, 16, 17, 18, 20, 21, 23, 25, 26, 28, 29, 30, 32, 33, 35, 38, 39, 41, 42, 43, 45, 46, 47, 49, 51, 55, 58, 60, 61, 63, 67, 68, 69, 70, 71, 73, 75, 83, 84, 151, 222, 254, 352, 402, 485, 511, 518, 542, 557, 694, 745, 754, 790, 851, 852, 853, 877, 883, 889, 890, 891, 892, 894, 900, 921, 932, 934, 944, 948, 967, 969, 974, 976, 980, 1007, 1030, 1041, 1052, 1063, 1067, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1093, 1094, 1095, 1096, 1097, 1099, 1102, 1106, 1109, 1110, 1111, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1130, 1131, 1143, 1152, 1153, 1165, 1169, 1172, 1175, 1194, 1199, 1203, 1209, 1210, 1220, 1221, 1231, 1232, 1233, 1234, 1235, 1237, 1242, 1246, 1248, 1250, 1253, 1259, 1260, 1276, 1284, 1288, 1293, 1312, 1318, 1330, 1335, 1338, 1339, 1340, 1341, 1342, 1345, 1350, 1353, 1354, 1355, 1366, 1370, 1371, 1376, 1385, 1386, 1387, 1389, 1390, 1391, 1401, 1402, 1403, 1413, 1422, 1426, 1428, 1461, 1469, 1474, 1486, 1496, 1499, 1500, 1501, 1516, 1517, 1518, 1523, 1558, 1571, 1589, 1593, 1602, 1603, 1608, 1610, 1611, 1615, 1625, 1636, 1645, 1646, 1647, 1648, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1685, 1687, 1688, 1689, 1709, 1710, 1727, 1743, 1751, 1753, 1756, 1759, 1799, 1808, 1823, 1828, 1829, 1831, 1839, 1842, 1843, 1850, 1858, 1860, 1863, 1867, 1869, 1871, 1873, 1875, 1876, 1877, 1878, 1883, 1884, 1885, 1886, 1887, 1888, 1889, 1891, 1893, 1894, 1896, 1898, 1900, 1901, 1904, 1905, 1906, 1908, 1909, 1913, 1915, 1917, 1918, 1919, 1920, 1922, 1923, 1924], "gpu": [1, 2, 3, 4, 5, 8, 12, 16, 17, 19, 20, 22, 25, 26, 29, 32, 34, 36, 38, 39, 43, 49, 59, 60, 63, 70, 197, 210, 289, 332, 600, 757, 950, 971, 972, 975, 976, 977, 978, 979, 980, 986, 987, 988, 995, 1001, 1002, 1008, 1010, 1011, 1012, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1026, 1027, 1028, 1029, 1030, 1031, 1034, 1040, 1041, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1111, 1190, 1199, 1236, 1261, 1290, 1298, 1299, 1300, 1303, 1304, 1330, 1359, 1374, 1392, 1422, 1437, 1438, 1461, 1586, 1602, 1635, 1808, 1858, 1860, 1871, 1886, 1892, 1894, 1895, 1897, 1898, 1900, 1908, 1913, 1917, 1919, 1923, 1925], "per": [1, 15, 32, 38, 39, 41, 42, 43, 45, 46, 48, 49, 51, 57, 59, 60, 63, 64, 69, 471, 472, 473, 731, 732, 798, 805, 816, 819, 822, 830, 842, 850, 889, 898, 900, 970, 1046, 1077, 1121, 1131, 1262, 1338, 1339, 1340, 1341, 1342, 1356, 1358, 1359, 1366, 1377, 1382, 1385, 1386, 1387, 1388, 1389, 1394, 1413, 1414, 1422, 1425, 1426, 1427, 1428, 1429, 1436, 1453, 1454, 1461, 1465, 1466, 1467, 1468, 1469, 1470, 1493, 1494, 1504, 1533, 1556, 1564, 1602, 1646, 1650, 1667, 1683, 1689, 1697, 1709, 1756, 1758, 1809, 1825, 1829, 1850, 1873, 1877, 1879, 1885, 1886, 1887, 1889, 1893, 1906, 1908, 1909, 1911, 1914, 1917, 1922], "whether": [1, 2, 3, 8, 17, 19, 21, 29, 32, 38, 39, 41, 42, 43, 46, 47, 49, 57, 58, 63, 71, 319, 321, 470, 515, 614, 677, 690, 692, 693, 696, 871, 872, 877, 886, 894, 897, 898, 900, 905, 906, 917, 919, 928, 941, 942, 943, 949, 950, 951, 1005, 1021, 1119, 1131, 1147, 1148, 1165, 1187, 1190, 1197, 1198, 1206, 1211, 1219, 1220, 1226, 1228, 1231, 1232, 1233, 1234, 1236, 1237, 1238, 1239, 1244, 1246, 1247, 1250, 1251, 1252, 1253, 1261, 1277, 1279, 1287, 1289, 1290, 1292, 1295, 1312, 1317, 1318, 1319, 1320, 1345, 1356, 1382, 1388, 1422, 1431, 1436, 1471, 1483, 1484, 1485, 1505, 1533, 1564, 1602, 1609, 1611, 1614, 1627, 1641, 1644, 1649, 1658, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1683, 1695, 1705, 1708, 1752, 1753, 1802, 1803, 1804, 1807, 1808, 1826, 1831, 1840, 1841, 1843, 1845, 1846, 1850, 1857, 1863, 1869, 1870, 1872, 1878, 1882, 1886, 1888, 1892, 1901, 1906, 1908, 1913, 1917, 1919, 1921, 1922, 1927], "torch_dtyp": 1, "weight": [1, 17, 38, 41, 47, 63, 69, 71, 157, 301, 361, 362, 494, 709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 730, 731, 732, 735, 736, 737, 738, 739, 740, 742, 743, 746, 748, 749, 750, 751, 753, 757, 758, 760, 761, 762, 769, 770, 771, 778, 789, 790, 791, 805, 806, 830, 832, 838, 842, 846, 847, 848, 849, 850, 855, 856, 858, 859, 921, 962, 1119, 1121, 1129, 1131, 1151, 1152, 1190, 1194, 1199, 1201, 1206, 1215, 1312, 1338, 1339, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1365, 1366, 1374, 1375, 1377, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1422, 1426, 1427, 1428, 1429, 1430, 1437, 1439, 1451, 1465, 1491, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1512, 1513, 1522, 1531, 1535, 1538, 1553, 1555, 1556, 1565, 1574, 1593, 1602, 1609, 1610, 1612, 1614, 1625, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1642, 1643, 1644, 1646, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1677, 1711, 1850, 1857, 1858, 1859, 1861, 1862, 1863, 1871, 1872, 1877, 1878, 1881, 1888, 1890, 1894, 1899, 1908, 1909, 1910, 1911, 1917, 1922, 1926, 1927], "insid": [1, 2, 8, 16, 18, 21, 29, 38, 58, 63, 68, 70, 71, 894, 895, 896, 897, 972, 1009, 1121, 1125, 1130, 1201, 1602, 1860, 1862, 1863, 1871, 1882, 1886, 1888, 1889, 1893, 1901, 1926], "custom_fwd": [1, 1882], "fwd": [1, 23], "cast_input": [1, 1882], "helper": [1, 4, 6, 28, 41, 67, 71, 1461, 1857, 1858, 1862, 1886, 1887, 1901, 1905, 1913, 1928], "subclass": [1, 2, 14, 21, 32, 38, 43, 47, 51, 68, 71, 140, 534, 886, 887, 888, 1188, 1191, 1200, 1422, 1603, 1616, 1621, 1642, 1860, 1863, 1864, 1870, 1882, 1894, 1901, 1902, 1913, 1928], "page": [1, 7, 8, 10, 25, 38, 42, 59, 61, 1262, 1465, 1467, 1469, 1886, 1887, 1894, 1903, 1913], "incom": [1, 41, 60, 778, 816, 817, 818, 819, 822, 1343, 1409, 1492, 1538, 1875, 1883], "non": [1, 2, 4, 6, 12, 15, 16, 17, 18, 19, 20, 28, 32, 37, 39, 41, 42, 43, 46, 47, 49, 51, 58, 60, 61, 63, 70, 89, 151, 335, 502, 511, 515, 542, 695, 731, 736, 737, 738, 739, 740, 742, 743, 753, 757, 761, 762, 769, 770, 771, 835, 862, 874, 886, 888, 890, 895, 897, 905, 906, 921, 934, 937, 950, 955, 956, 961, 1020, 1109, 1110, 1116, 1120, 1125, 1131, 1167, 1190, 1193, 1202, 1205, 1206, 1225, 1226, 1233, 1237, 1238, 1251, 1253, 1262, 1272, 1279, 1284, 1289, 1312, 1317, 1318, 1322, 1335, 1336, 1337, 1351, 1352, 1354, 1355, 1358, 1368, 1374, 1391, 1392, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1425, 1427, 1429, 1437, 1439, 1453, 1504, 1523, 1551, 1556, 1598, 1599, 1602, 1648, 1678, 1700, 1743, 1744, 1759, 1771, 1785, 1786, 1790, 1791, 1792, 1793, 1794, 1795, 1824, 1840, 1850, 1857, 1858, 1860, 1862, 1863, 1865, 1875, 1878, 1881, 1884, 1888, 1889, 1890, 1894, 1898, 1901, 1906, 1907, 1912, 1913, 1915, 1917, 1918, 1920, 1921, 1922, 1924, 1928], "intern": [1, 4, 9, 10, 17, 21, 22, 29, 32, 38, 39, 41, 43, 47, 49, 55, 63, 68, 71, 964, 998, 1019, 1120, 1190, 1226, 1228, 1244, 1247, 1270, 1340, 1341, 1342, 1376, 1461, 1496, 1497, 1498, 1521, 1611, 1658, 1751, 1793, 1843, 1864, 1882, 1883, 1885, 1886, 1891, 1897, 1898, 1914, 1915, 1919, 1921], "current": [1, 2, 3, 4, 6, 7, 8, 10, 15, 16, 17, 21, 24, 25, 29, 30, 32, 38, 41, 43, 45, 46, 47, 49, 51, 58, 59, 63, 64, 70, 71, 89, 151, 210, 222, 485, 495, 496, 497, 738, 740, 778, 790, 792, 814, 856, 858, 859, 862, 876, 887, 890, 891, 898, 899, 900, 905, 919, 928, 964, 965, 966, 967, 969, 974, 975, 978, 979, 981, 982, 983, 984, 987, 988, 989, 991, 992, 995, 997, 998, 1001, 1003, 1004, 1008, 1009, 1010, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1030, 1032, 1034, 1036, 1039, 1040, 1041, 1064, 1066, 1076, 1081, 1099, 1115, 1117, 1137, 1138, 1139, 1147, 1148, 1173, 1174, 1190, 1194, 1205, 1209, 1260, 1262, 1276, 1291, 1298, 1300, 1362, 1365, 1369, 1422, 1461, 1473, 1515, 1521, 1532, 1571, 1589, 1590, 1592, 1602, 1615, 1619, 1620, 1621, 1622, 1623, 1628, 1629, 1630, 1631, 1653, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1707, 1716, 1718, 1720, 1722, 1723, 1747, 1751, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1783, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1833, 1835, 1840, 1855, 1858, 1860, 1862, 1863, 1864, 1865, 1867, 1870, 1873, 1875, 1878, 1882, 1883, 1886, 1887, 1892, 1893, 1894, 1895, 1899, 1900, 1901, 1902, 1904, 1905, 1906, 1908, 1911, 1913, 1914, 1917, 1919, 1920, 1922, 1923, 1926, 1928], "custom_bwd": [1, 1882], "bwd": 1, "small": [1, 4, 8, 10, 12, 16, 18, 19, 23, 29, 38, 39, 41, 47, 58, 862, 905, 906, 950, 977, 1020, 1252, 1253, 1265, 1267, 1330, 1357, 1431, 1436, 1450, 1474, 1503, 1557, 1564, 1602, 1680, 1686, 1695, 1808, 1860, 1862, 1863, 1886, 1888, 1890, 1894, 1897, 1899, 1901, 1905, 1908, 1909, 1918, 1924], "magnitud": [1, 957, 1646, 1759, 1881, 1882, 1886], "represent": [1, 4, 15, 17, 29, 32, 38, 41, 43, 56, 71, 480, 755, 823, 967, 1079, 1080, 1082, 1106, 1135, 1190, 1229, 1232, 1234, 1237, 1316, 1422, 1428, 1656, 1695, 1858, 1860, 1863, 1878, 1888, 1897, 1901, 1905, 1908, 1917, 1924, 1929], "These": [1, 2, 3, 4, 9, 12, 15, 17, 21, 24, 29, 32, 33, 38, 41, 42, 47, 64, 66, 69, 71, 791, 877, 962, 1063, 1127, 1187, 1190, 1232, 1297, 1330, 1422, 1593, 1610, 1858, 1860, 1861, 1862, 1863, 1873, 1876, 1877, 1879, 1882, 1883, 1886, 1887, 1888, 1894, 1897, 1899, 1901, 1905, 1911, 1913, 1914, 1920, 1925, 1928], "flush": [1, 2, 43, 1020, 1200, 1739, 1752, 1897, 1922], "zero": [1, 2, 3, 16, 20, 39, 41, 42, 45, 47, 60, 63, 68, 71, 151, 260, 315, 511, 513, 541, 542, 581, 582, 584, 585, 620, 676, 688, 695, 709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 741, 746, 747, 748, 749, 750, 751, 752, 753, 756, 757, 761, 765, 766, 769, 770, 771, 772, 774, 777, 778, 792, 796, 816, 817, 818, 819, 822, 827, 874, 883, 884, 885, 890, 895, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 920, 921, 941, 942, 943, 948, 957, 961, 1009, 1020, 1024, 1025, 1054, 1058, 1076, 1077, 1078, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1102, 1111, 1116, 1119, 1127, 1149, 1150, 1153, 1175, 1187, 1190, 1201, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1257, 1262, 1270, 1271, 1272, 1273, 1274, 1279, 1280, 1312, 1316, 1320, 1334, 1335, 1336, 1337, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1374, 1375, 1377, 1390, 1391, 1392, 1393, 1394, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1428, 1431, 1434, 1435, 1436, 1437, 1439, 1459, 1473, 1474, 1477, 1478, 1479, 1488, 1489, 1490, 1499, 1500, 1501, 1503, 1505, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1521, 1542, 1543, 1557, 1558, 1559, 1619, 1620, 1621, 1622, 1637, 1644, 1648, 1652, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1695, 1707, 1709, 1710, 1711, 1727, 1736, 1746, 1773, 1777, 1786, 1790, 1791, 1792, 1793, 1794, 1795, 1799, 1808, 1822, 1823, 1825, 1831, 1856, 1860, 1861, 1863, 1865, 1873, 1875, 1876, 1877, 1878, 1881, 1883, 1886, 1888, 1894, 1897, 1900, 1901, 1903, 1905, 1907, 1908, 1911, 1917, 1918, 1920, 1922, 1923, 1924, 1925], "underflow": [1, 1388, 1882], "updat": [1, 10, 12, 28, 30, 38, 39, 43, 45, 49, 58, 63, 66, 67, 71, 222, 511, 513, 757, 796, 797, 821, 1119, 1128, 1190, 1340, 1341, 1342, 1359, 1365, 1366, 1374, 1385, 1386, 1387, 1422, 1423, 1432, 1461, 1512, 1513, 1610, 1614, 1644, 1661, 1667, 1672, 1674, 1677, 1678, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1857, 1860, 1871, 1882, 1883, 1886, 1887, 1888, 1894, 1896, 1899, 1900, 1901, 1903, 1904, 1906, 1908, 1913, 1914, 1915, 1922], "lost": [1, 49, 59, 61, 1359, 1418, 1419, 1420], "To": [1, 2, 3, 4, 5, 6, 7, 10, 12, 13, 15, 16, 17, 19, 21, 22, 27, 28, 29, 32, 33, 38, 39, 41, 42, 45, 46, 47, 49, 50, 56, 57, 59, 60, 63, 68, 71, 83, 84, 335, 497, 554, 731, 891, 904, 947, 950, 965, 1010, 1030, 1051, 1053, 1063, 1091, 1093, 1097, 1108, 1190, 1191, 1193, 1194, 1200, 1201, 1235, 1257, 1262, 1290, 1330, 1339, 1362, 1388, 1418, 1419, 1420, 1422, 1475, 1476, 1494, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1646, 1689, 1697, 1708, 1747, 1755, 1809, 1857, 1860, 1862, 1863, 1867, 1875, 1876, 1877, 1879, 1882, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1894, 1895, 1899, 1901, 1904, 1905, 1906, 1907, 1908, 1913, 1914, 1915, 1917, 1920, 1921, 1922, 1923], "multipli": [1, 17, 41, 313, 321, 422, 511, 682, 683, 684, 685, 686, 687, 688, 757, 776, 782, 783, 784, 918, 930, 1033, 1046, 1063, 1143, 1154, 1213, 1225, 1226, 1230, 1243, 1245, 1247, 1253, 1255, 1284, 1294, 1307, 1311, 1314, 1338, 1350, 1351, 1352, 1355, 1374, 1392, 1474, 1475, 1476, 1532, 1590, 1591, 1592, 1614, 1680, 1686, 1688, 1695, 1779, 1782, 1785, 1786, 1800, 1804, 1805, 1808, 1829, 1861, 1876, 1886, 1891, 1894, 1897, 1903, 1917, 1918], "flow": [1, 12, 13, 15, 20, 21, 947, 1202, 1205, 1486, 1521, 1602, 1860, 1881, 1883, 1886, 1888, 1899, 1901, 1915], "word": [1, 2, 9, 41, 58, 59, 66, 70, 71, 934, 1330, 1350, 1351, 1352, 1365, 1366, 1465, 1512, 1513, 1532, 1590, 1602, 1609, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1862, 1883, 1890, 1905, 1914], "larger": [1, 10, 21, 23, 25, 28, 41, 47, 71, 254, 497, 906, 921, 1020, 1120, 1244, 1247, 1330, 1359, 1365, 1366, 1414, 1471, 1474, 1512, 1513, 1883, 1886, 1890, 1891, 1893, 1897, 1899, 1917, 1922], "thei": [1, 2, 4, 6, 8, 10, 12, 15, 16, 17, 18, 20, 24, 27, 29, 30, 34, 35, 38, 41, 43, 47, 48, 58, 63, 66, 67, 70, 71, 321, 335, 336, 683, 686, 687, 694, 797, 812, 813, 814, 821, 838, 851, 856, 887, 896, 906, 918, 1009, 1067, 1114, 1119, 1129, 1165, 1179, 1180, 1187, 1190, 1197, 1202, 1211, 1225, 1226, 1232, 1253, 1261, 1283, 1287, 1290, 1292, 1295, 1312, 1335, 1336, 1337, 1353, 1354, 1355, 1369, 1407, 1415, 1416, 1417, 1422, 1428, 1438, 1450, 1473, 1521, 1523, 1593, 1602, 1603, 1606, 1609, 1611, 1612, 1635, 1638, 1647, 1685, 1688, 1747, 1753, 1804, 1808, 1843, 1844, 1857, 1860, 1862, 1863, 1865, 1867, 1869, 1870, 1871, 1873, 1875, 1876, 1877, 1878, 1879, 1881, 1882, 1883, 1886, 1887, 1888, 1889, 1892, 1894, 1896, 1897, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1913, 1917, 1922, 1924, 1925, 1926, 1928], "grad": [1, 2, 6, 24, 27, 41, 47, 64, 67, 68, 71, 151, 335, 457, 486, 493, 494, 501, 502, 578, 877, 886, 890, 891, 897, 898, 900, 905, 906, 910, 911, 1009, 1067, 1119, 1120, 1122, 1126, 1130, 1131, 1165, 1173, 1190, 1262, 1422, 1602, 1647, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1672, 1673, 1674, 1675, 1676, 1677, 1678, 1753, 1785, 1843, 1850, 1858, 1860, 1861, 1876, 1877, 1878, 1882, 1887, 1888, 1889, 1891, 1894, 1896, 1903, 1913, 1914, 1917, 1923], "unscal": 1, "interfer": [1, 17, 1873, 1886, 1901], "learn": [1, 8, 9, 13, 15, 21, 33, 47, 57, 71, 1343, 1356, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1382, 1407, 1409, 1430, 1451, 1470, 1471, 1574, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1858, 1867, 1879, 1881, 1892, 1894, 1895, 1901, 1905, 1908, 1913, 1915], "rate": [1, 9, 25, 39, 47, 1361, 1362, 1363, 1367, 1468, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1700, 1858, 1893, 1922], "fp16": [1, 3, 726, 1602, 1908, 1909], "everi": [1, 2, 3, 9, 10, 15, 16, 17, 21, 25, 28, 29, 38, 39, 41, 43, 45, 47, 49, 63, 68, 71, 480, 486, 607, 677, 778, 816, 894, 910, 911, 1046, 1063, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1120, 1143, 1152, 1190, 1221, 1235, 1245, 1248, 1279, 1334, 1360, 1361, 1362, 1363, 1367, 1415, 1422, 1455, 1457, 1461, 1507, 1508, 1509, 1514, 1545, 1546, 1547, 1561, 1578, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1610, 1643, 1646, 1647, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1747, 1808, 1841, 1863, 1869, 1873, 1882, 1883, 1886, 1887, 1888, 1889, 1891, 1895, 1901, 1904, 1905, 1906, 1907, 1908, 1909, 1913, 1914, 1915, 1919, 1920, 1922, 1924], "most": [1, 2, 4, 5, 8, 9, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 28, 29, 33, 38, 41, 43, 45, 47, 48, 49, 50, 57, 58, 60, 61, 68, 69, 70, 71, 497, 790, 894, 895, 896, 901, 905, 914, 950, 1032, 1046, 1063, 1120, 1165, 1175, 1188, 1191, 1295, 1330, 1469, 1521, 1571, 1602, 1614, 1672, 1783, 1829, 1857, 1860, 1862, 1863, 1865, 1870, 1875, 1877, 1878, 1883, 1886, 1888, 1896, 1897, 1898, 1904, 1907, 1908, 1914, 1915, 1917, 1920, 1922, 1924], "bf16": [1, 3], "pretrain": [1, 20, 859, 1365, 1366, 1857, 1883, 1901], "cannot": [1, 4, 9, 10, 12, 20, 38, 39, 41, 47, 48, 51, 58, 63, 64, 68, 69, 70, 71, 86, 87, 223, 254, 521, 542, 877, 1084, 1086, 1094, 1095, 1096, 1102, 1119, 1187, 1195, 1312, 1345, 1365, 1474, 1505, 1571, 1602, 1658, 1809, 1857, 1860, 1861, 1862, 1863, 1864, 1865, 1873, 1877, 1878, 1883, 1887, 1888, 1899, 1900, 1901, 1908, 1913, 1915, 1917, 1919, 1920, 1928], "numer": [1, 17, 29, 38, 47, 64, 69, 684, 790, 905, 906, 934, 1194, 1205, 1206, 1221, 1225, 1226, 1230, 1235, 1243, 1244, 1247, 1250, 1253, 1255, 1277, 1279, 1339, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1455, 1458, 1461, 1512, 1533, 1540, 1571, 1577, 1579, 1610, 1643, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1711, 1743, 1808, 1858, 1863, 1864, 1868, 1871, 1886, 1888, 1889, 1901, 1908, 1918, 1923, 1929], "max": [1, 16, 19, 22, 23, 38, 41, 49, 51, 57, 58, 60, 63, 71, 117, 186, 187, 188, 189, 300, 692, 693, 694, 755, 767, 768, 777, 779, 780, 799, 816, 817, 818, 819, 822, 871, 921, 938, 945, 946, 950, 1042, 1077, 1078, 1150, 1201, 1221, 1235, 1242, 1244, 1246, 1247, 1259, 1331, 1332, 1333, 1344, 1345, 1356, 1357, 1366, 1370, 1371, 1376, 1381, 1382, 1390, 1391, 1408, 1410, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1425, 1426, 1427, 1430, 1441, 1442, 1449, 1470, 1471, 1473, 1483, 1484, 1485, 1495, 1503, 1513, 1516, 1517, 1532, 1536, 1545, 1546, 1547, 1557, 1561, 1565, 1567, 1572, 1590, 1606, 1638, 1664, 1665, 1666, 1676, 1681, 1682, 1691, 1712, 1713, 1785, 1814, 1815, 1843, 1859, 1860, 1861, 1870, 1873, 1878, 1884, 1886, 1890, 1903, 1908, 1911, 1929], "65504": 1, "overflow": [1, 1044, 1045, 1289, 1317, 1320, 1540, 1577, 1578, 1705, 1736, 1784, 1787, 1807, 1833, 1835, 1886, 1897, 1918], "case": [1, 2, 4, 5, 9, 10, 15, 16, 17, 18, 21, 24, 28, 29, 30, 32, 33, 38, 39, 41, 43, 45, 46, 47, 49, 50, 51, 58, 60, 61, 63, 64, 66, 67, 68, 69, 70, 71, 151, 155, 197, 352, 494, 497, 677, 757, 781, 788, 791, 817, 818, 820, 823, 855, 862, 890, 898, 900, 904, 919, 921, 957, 963, 988, 1010, 1011, 1030, 1031, 1032, 1063, 1084, 1086, 1094, 1095, 1096, 1111, 1121, 1125, 1130, 1149, 1175, 1188, 1191, 1199, 1202, 1203, 1205, 1219, 1221, 1225, 1226, 1230, 1235, 1236, 1237, 1239, 1245, 1248, 1253, 1255, 1259, 1261, 1262, 1267, 1270, 1279, 1290, 1312, 1330, 1335, 1336, 1337, 1338, 1339, 1350, 1351, 1352, 1354, 1355, 1356, 1358, 1361, 1362, 1363, 1364, 1366, 1367, 1369, 1378, 1379, 1380, 1381, 1382, 1383, 1389, 1390, 1391, 1408, 1413, 1415, 1416, 1417, 1428, 1429, 1430, 1440, 1453, 1459, 1464, 1469, 1471, 1473, 1486, 1504, 1513, 1521, 1525, 1526, 1556, 1558, 1565, 1602, 1604, 1605, 1609, 1611, 1614, 1615, 1648, 1649, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1689, 1727, 1730, 1743, 1745, 1759, 1762, 1808, 1809, 1839, 1843, 1853, 1857, 1863, 1868, 1875, 1876, 1877, 1881, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1891, 1894, 1896, 1897, 1899, 1901, 1904, 1905, 1906, 1908, 1909, 1911, 1912, 1913, 1914, 1915, 1917, 1918, 1919, 1921, 1922, 1923, 1924, 1928, 1929], "decreas": [1, 47, 1020, 1235, 1361, 1362, 1363, 1367, 1435, 1636, 1637, 1676, 1683, 1691, 1869, 1871, 1898, 1917, 1920], "bring": [1, 23, 25, 64, 71, 1084, 1486, 1521, 1906], "number": [1, 2, 3, 4, 5, 6, 8, 12, 15, 16, 17, 20, 25, 29, 32, 38, 39, 41, 45, 46, 47, 49, 56, 57, 58, 61, 63, 64, 66, 69, 71, 89, 155, 174, 219, 233, 254, 313, 352, 377, 398, 402, 434, 445, 470, 472, 473, 480, 491, 495, 497, 511, 513, 515, 540, 542, 543, 555, 580, 581, 582, 584, 585, 586, 605, 614, 682, 683, 684, 685, 686, 687, 688, 695, 755, 757, 765, 766, 769, 770, 771, 778, 816, 862, 874, 887, 905, 918, 920, 921, 930, 932, 936, 944, 945, 949, 957, 961, 962, 969, 971, 977, 986, 995, 996, 1007, 1009, 1010, 1011, 1020, 1030, 1031, 1034, 1035, 1055, 1058, 1060, 1063, 1064, 1068, 1076, 1106, 1108, 1111, 1116, 1118, 1132, 1134, 1140, 1141, 1142, 1146, 1150, 1151, 1152, 1164, 1166, 1187, 1188, 1190, 1203, 1210, 1213, 1214, 1221, 1235, 1244, 1253, 1257, 1262, 1267, 1278, 1282, 1290, 1301, 1302, 1306, 1308, 1311, 1312, 1316, 1320, 1323, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1343, 1344, 1345, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1364, 1365, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1388, 1389, 1392, 1393, 1398, 1399, 1400, 1401, 1402, 1403, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1421, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1436, 1437, 1439, 1440, 1441, 1442, 1449, 1451, 1452, 1453, 1454, 1455, 1457, 1458, 1459, 1460, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1488, 1489, 1490, 1492, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1512, 1513, 1516, 1517, 1522, 1532, 1533, 1535, 1538, 1545, 1546, 1547, 1556, 1558, 1564, 1565, 1571, 1593, 1602, 1610, 1614, 1619, 1620, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1635, 1636, 1637, 1639, 1643, 1648, 1649, 1650, 1652, 1653, 1659, 1667, 1680, 1681, 1682, 1683, 1686, 1687, 1689, 1690, 1691, 1697, 1700, 1704, 1714, 1716, 1717, 1718, 1720, 1721, 1722, 1727, 1729, 1730, 1733, 1734, 1735, 1736, 1744, 1748, 1752, 1754, 1755, 1756, 1757, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1782, 1786, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1800, 1801, 1802, 1803, 1804, 1805, 1809, 1823, 1824, 1825, 1833, 1835, 1840, 1841, 1844, 1845, 1846, 1847, 1848, 1849, 1855, 1858, 1861, 1862, 1863, 1864, 1865, 1870, 1873, 1875, 1878, 1881, 1884, 1886, 1888, 1891, 1894, 1897, 1899, 1901, 1904, 1905, 1906, 1907, 1909, 1912, 1913, 1914, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1929], "expect": [1, 2, 4, 6, 8, 10, 13, 16, 17, 23, 24, 29, 38, 39, 41, 43, 45, 49, 56, 58, 60, 63, 68, 69, 71, 677, 694, 757, 851, 898, 899, 900, 901, 902, 903, 1009, 1084, 1086, 1103, 1104, 1105, 1124, 1125, 1164, 1187, 1190, 1205, 1206, 1234, 1255, 1256, 1290, 1341, 1342, 1358, 1374, 1375, 1376, 1377, 1386, 1387, 1388, 1392, 1393, 1394, 1404, 1405, 1406, 1422, 1428, 1429, 1437, 1439, 1455, 1461, 1465, 1467, 1469, 1474, 1512, 1518, 1532, 1556, 1564, 1565, 1577, 1590, 1591, 1592, 1593, 1602, 1636, 1692, 1748, 1817, 1848, 1857, 1858, 1865, 1883, 1886, 1887, 1890, 1891, 1894, 1901, 1904, 1905, 1908, 1909, 1910, 1917, 1922, 1924], "alwai": [1, 6, 8, 12, 15, 16, 32, 34, 38, 39, 41, 56, 60, 63, 67, 71, 340, 447, 457, 791, 877, 895, 898, 904, 919, 928, 938, 944, 1009, 1020, 1050, 1058, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1094, 1095, 1096, 1097, 1099, 1102, 1106, 1147, 1148, 1190, 1200, 1205, 1220, 1225, 1226, 1227, 1228, 1230, 1231, 1243, 1246, 1247, 1248, 1249, 1253, 1255, 1318, 1338, 1340, 1341, 1342, 1359, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1458, 1461, 1593, 1602, 1635, 1731, 1732, 1758, 1804, 1808, 1840, 1843, 1863, 1864, 1875, 1878, 1883, 1884, 1885, 1886, 1887, 1888, 1891, 1893, 1894, 1905, 1906, 1912, 1913, 1915, 1917, 1920, 1923, 1924], "our": [1, 4, 8, 9, 12, 15, 16, 17, 20, 21, 22, 23, 28, 29, 41, 54, 57, 58, 59, 61, 67, 68, 69, 71, 894, 1083, 1120, 1338, 1883, 1888, 1891, 1896, 1901, 1904, 1908, 1914, 1917], "NOT": [1, 38, 41, 49, 58, 59, 60, 71, 924, 1272, 1362, 1602, 1603, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1647, 1656, 1658, 1664, 1665, 1678, 1883, 1915, 1917], "make": [1, 2, 3, 4, 5, 6, 9, 15, 16, 17, 18, 20, 22, 23, 24, 26, 28, 29, 32, 33, 38, 39, 41, 43, 44, 46, 47, 49, 50, 55, 58, 59, 60, 61, 63, 67, 68, 71, 140, 223, 494, 776, 782, 858, 859, 890, 941, 942, 943, 966, 967, 969, 1051, 1067, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1103, 1104, 1105, 1165, 1190, 1194, 1199, 1200, 1219, 1220, 1232, 1233, 1234, 1262, 1338, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1383, 1422, 1432, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1521, 1523, 1532, 1571, 1590, 1602, 1609, 1625, 1642, 1647, 1685, 1748, 1781, 1790, 1791, 1792, 1794, 1795, 1826, 1843, 1857, 1860, 1862, 1863, 1867, 1873, 1875, 1876, 1878, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1894, 1896, 1898, 1900, 1901, 1902, 1904, 1905, 1907, 1908, 1909, 1913, 1914, 1915, 1917, 1920, 1922, 1926, 1928], "guarante": [1, 2, 6, 10, 15, 38, 41, 43, 45, 47, 58, 60, 68, 70, 71, 873, 1190, 1199, 1359, 1422, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1781, 1843, 1883, 1885, 1886, 1897, 1898, 1905, 1907, 1909, 1913, 1915], "encount": [1, 6, 13, 17, 21, 24, 29, 41, 68, 70, 71, 1602, 1860, 1863, 1865, 1885, 1897, 1905, 1908], "nan": [1, 2, 47, 426, 427, 681, 683, 686, 687, 688, 691, 694, 695, 878, 882, 918, 934, 1109, 1110, 1111, 1150, 1179, 1180, 1182, 1183, 1229, 1236, 1249, 1252, 1265, 1270, 1288, 1289, 1293, 1316, 1317, 1318, 1319, 1320, 1521, 1606, 1701, 1738, 1743, 1797, 1831, 1861, 1870, 1882, 1883, 1889, 1897, 1918, 1924], "verifi": [1, 20, 27, 41, 71, 905, 1046, 1659, 1660, 1678, 1829, 1857, 1860, 1872, 1888, 1891, 1901, 1906], "compat": [1, 2, 32, 38, 43, 47, 49, 63, 67, 68, 71, 495, 496, 600, 614, 677, 812, 813, 814, 887, 931, 955, 956, 1190, 1195, 1207, 1220, 1231, 1244, 1247, 1422, 1428, 1466, 1467, 1468, 1469, 1532, 1656, 1658, 1730, 1857, 1858, 1862, 1863, 1869, 1875, 1876, 1882, 1888, 1899, 1905, 1907, 1908, 1911, 1913, 1919], "init_scal": 1, "65536": 1, "0": [1, 2, 4, 12, 13, 14, 15, 17, 20, 21, 22, 23, 28, 30, 32, 35, 38, 39, 41, 42, 43, 45, 46, 47, 48, 49, 50, 51, 52, 56, 58, 59, 60, 63, 66, 67, 68, 69, 70, 71, 89, 155, 157, 174, 185, 192, 209, 225, 226, 227, 228, 229, 254, 260, 263, 289, 298, 300, 311, 313, 315, 317, 321, 352, 401, 402, 426, 427, 444, 447, 448, 453, 480, 482, 486, 494, 505, 506, 511, 513, 515, 518, 535, 540, 541, 544, 553, 555, 557, 575, 577, 578, 580, 581, 582, 584, 585, 586, 592, 593, 594, 595, 602, 604, 605, 614, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 696, 709, 710, 711, 712, 713, 714, 715, 716, 720, 721, 722, 723, 724, 727, 728, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 745, 748, 749, 750, 752, 753, 754, 755, 757, 765, 766, 767, 769, 770, 771, 772, 775, 777, 779, 780, 782, 791, 793, 796, 799, 814, 817, 818, 819, 822, 851, 853, 862, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 895, 898, 899, 900, 902, 905, 906, 908, 910, 911, 914, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 931, 932, 934, 937, 938, 939, 940, 941, 942, 943, 944, 945, 948, 953, 954, 957, 958, 959, 960, 961, 962, 963, 969, 978, 980, 1006, 1007, 1033, 1037, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1051, 1052, 1053, 1054, 1055, 1057, 1058, 1061, 1063, 1065, 1066, 1073, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1097, 1098, 1099, 1100, 1102, 1103, 1104, 1105, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1119, 1121, 1122, 1123, 1124, 1125, 1129, 1130, 1131, 1132, 1133, 1143, 1147, 1149, 1150, 1151, 1152, 1153, 1156, 1160, 1164, 1167, 1175, 1186, 1187, 1188, 1190, 1194, 1196, 1197, 1201, 1209, 1210, 1211, 1212, 1213, 1215, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1231, 1232, 1233, 1234, 1235, 1236, 1241, 1242, 1243, 1244, 1246, 1247, 1248, 1249, 1251, 1256, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1269, 1270, 1271, 1272, 1273, 1274, 1276, 1279, 1283, 1287, 1288, 1289, 1290, 1292, 1293, 1294, 1295, 1296, 1297, 1307, 1310, 1311, 1312, 1314, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1324, 1326, 1328, 1329, 1330, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1344, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1374, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1408, 1410, 1412, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1436, 1437, 1438, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1449, 1453, 1455, 1456, 1457, 1459, 1461, 1464, 1465, 1467, 1469, 1470, 1471, 1473, 1474, 1477, 1478, 1479, 1486, 1487, 1488, 1489, 1490, 1491, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1512, 1513, 1514, 1515, 1516, 1517, 1519, 1521, 1524, 1525, 1526, 1529, 1530, 1531, 1532, 1536, 1537, 1539, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1556, 1557, 1558, 1559, 1560, 1561, 1564, 1565, 1567, 1571, 1572, 1575, 1577, 1580, 1586, 1587, 1588, 1589, 1590, 1593, 1602, 1606, 1609, 1610, 1614, 1619, 1620, 1622, 1623, 1624, 1625, 1627, 1628, 1629, 1630, 1631, 1632, 1635, 1636, 1638, 1639, 1641, 1642, 1643, 1644, 1646, 1648, 1649, 1650, 1654, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1698, 1700, 1701, 1703, 1704, 1705, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1725, 1726, 1727, 1728, 1729, 1730, 1733, 1734, 1735, 1736, 1738, 1739, 1743, 1745, 1746, 1747, 1750, 1752, 1756, 1759, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1776, 1777, 1781, 1783, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1801, 1802, 1803, 1804, 1805, 1807, 1808, 1810, 1811, 1817, 1818, 1820, 1821, 1822, 1823, 1824, 1828, 1829, 1831, 1832, 1833, 1834, 1835, 1837, 1838, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1848, 1849, 1850, 1851, 1853, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1863, 1870, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1910, 1911, 1913, 1914, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1926, 1928, 1929], "growth_factor": 1, "backoff_factor": 1, "5": [1, 2, 11, 14, 17, 28, 29, 30, 32, 35, 36, 38, 39, 41, 47, 56, 67, 68, 69, 70, 71, 155, 192, 209, 260, 289, 298, 313, 315, 317, 321, 401, 402, 444, 470, 497, 511, 513, 515, 534, 541, 555, 557, 581, 582, 583, 584, 585, 604, 682, 683, 687, 694, 731, 736, 737, 738, 739, 740, 742, 743, 757, 759, 770, 771, 858, 859, 862, 877, 883, 884, 885, 898, 901, 903, 918, 921, 928, 929, 930, 934, 936, 940, 943, 944, 945, 948, 957, 961, 1042, 1044, 1046, 1053, 1055, 1057, 1058, 1061, 1062, 1063, 1066, 1079, 1081, 1083, 1084, 1090, 1091, 1094, 1099, 1102, 1103, 1106, 1109, 1111, 1112, 1113, 1121, 1123, 1124, 1125, 1126, 1129, 1130, 1131, 1133, 1143, 1149, 1151, 1153, 1155, 1156, 1167, 1175, 1179, 1196, 1200, 1201, 1210, 1211, 1212, 1215, 1218, 1219, 1236, 1239, 1242, 1245, 1246, 1247, 1248, 1253, 1254, 1257, 1259, 1260, 1262, 1263, 1264, 1265, 1266, 1272, 1276, 1283, 1284, 1290, 1291, 1295, 1319, 1321, 1322, 1324, 1327, 1328, 1329, 1331, 1332, 1333, 1334, 1335, 1339, 1340, 1341, 1342, 1346, 1347, 1348, 1349, 1351, 1352, 1354, 1355, 1356, 1358, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1374, 1376, 1377, 1378, 1383, 1385, 1386, 1387, 1388, 1389, 1392, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1410, 1413, 1418, 1419, 1422, 1429, 1432, 1436, 1437, 1443, 1444, 1445, 1446, 1447, 1450, 1453, 1459, 1461, 1465, 1467, 1469, 1471, 1472, 1473, 1474, 1475, 1476, 1487, 1488, 1496, 1497, 1499, 1500, 1504, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1516, 1517, 1519, 1521, 1524, 1532, 1556, 1558, 1564, 1580, 1590, 1591, 1592, 1602, 1614, 1624, 1627, 1629, 1630, 1632, 1637, 1638, 1640, 1642, 1648, 1649, 1650, 1652, 1653, 1656, 1659, 1674, 1676, 1678, 1680, 1686, 1690, 1696, 1698, 1700, 1701, 1703, 1704, 1707, 1708, 1711, 1712, 1713, 1714, 1718, 1723, 1724, 1727, 1728, 1734, 1735, 1736, 1743, 1756, 1763, 1765, 1766, 1767, 1768, 1771, 1772, 1781, 1786, 1788, 1789, 1790, 1791, 1793, 1796, 1804, 1807, 1808, 1809, 1810, 1811, 1818, 1820, 1822, 1823, 1824, 1826, 1827, 1829, 1838, 1839, 1843, 1844, 1850, 1851, 1852, 1855, 1858, 1860, 1861, 1862, 1863, 1864, 1870, 1877, 1878, 1881, 1882, 1883, 1884, 1886, 1888, 1890, 1891, 1894, 1895, 1899, 1900, 1901, 1904, 1906, 1908, 1913, 1917, 1918, 1920, 1922, 1923, 1924], "growth_interv": 1, "2000": [1, 41, 45, 1081, 1083, 1090, 1099, 1112, 1267, 1474, 1683, 1711, 1761, 1762, 1822], "get_backoff_factor": 1, "backoff": [1, 1913], "get_growth_factor": 1, "growth": [1, 9], "get_growth_interv": 1, "int": [1, 3, 4, 15, 21, 28, 35, 38, 39, 41, 43, 45, 46, 47, 49, 52, 55, 56, 58, 59, 61, 63, 71, 89, 217, 219, 233, 242, 254, 313, 315, 317, 321, 436, 443, 444, 446, 448, 456, 471, 475, 491, 495, 497, 511, 513, 515, 518, 534, 540, 542, 543, 555, 557, 563, 580, 581, 582, 584, 585, 604, 614, 677, 690, 692, 693, 694, 696, 752, 753, 772, 774, 776, 777, 782, 783, 784, 816, 871, 872, 873, 875, 889, 896, 909, 919, 921, 928, 935, 937, 944, 949, 961, 962, 963, 965, 967, 969, 971, 972, 975, 976, 977, 978, 979, 980, 982, 983, 984, 985, 986, 991, 992, 993, 995, 997, 1001, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1032, 1033, 1034, 1037, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1050, 1051, 1052, 1053, 1054, 1055, 1061, 1064, 1066, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1102, 1116, 1117, 1121, 1122, 1123, 1124, 1125, 1131, 1132, 1138, 1140, 1141, 1143, 1147, 1148, 1150, 1151, 1152, 1153, 1164, 1166, 1187, 1188, 1190, 1191, 1193, 1196, 1201, 1209, 1211, 1221, 1222, 1242, 1243, 1246, 1255, 1256, 1257, 1258, 1259, 1260, 1262, 1269, 1276, 1277, 1282, 1287, 1289, 1290, 1292, 1295, 1297, 1298, 1299, 1302, 1312, 1317, 1318, 1319, 1320, 1321, 1322, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1340, 1341, 1342, 1343, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1358, 1359, 1365, 1366, 1368, 1369, 1370, 1371, 1373, 1375, 1377, 1385, 1386, 1387, 1390, 1391, 1393, 1394, 1398, 1399, 1400, 1401, 1402, 1403, 1407, 1409, 1410, 1412, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1424, 1427, 1429, 1430, 1433, 1434, 1435, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1455, 1457, 1458, 1461, 1465, 1467, 1469, 1470, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1503, 1504, 1505, 1512, 1513, 1520, 1523, 1532, 1540, 1556, 1557, 1558, 1562, 1563, 1577, 1578, 1586, 1590, 1591, 1592, 1602, 1610, 1619, 1620, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1636, 1638, 1643, 1646, 1649, 1650, 1652, 1653, 1656, 1658, 1659, 1660, 1667, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1697, 1698, 1705, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1718, 1719, 1720, 1722, 1728, 1729, 1730, 1733, 1734, 1735, 1736, 1739, 1744, 1745, 1746, 1750, 1754, 1755, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1777, 1781, 1784, 1787, 1788, 1789, 1796, 1799, 1801, 1802, 1803, 1804, 1807, 1809, 1813, 1819, 1823, 1824, 1826, 1828, 1829, 1832, 1833, 1834, 1835, 1838, 1839, 1840, 1841, 1842, 1844, 1845, 1846, 1850, 1851, 1855, 1859, 1860, 1861, 1862, 1863, 1864, 1873, 1875, 1876, 1878, 1881, 1886, 1889, 1901, 1903, 1906, 1907, 1908, 1912, 1913, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1929], "interv": [1, 47, 60, 862, 958, 1113, 1303, 1304, 1692, 1716, 1717, 1765, 1873, 1886, 1907], "get_scal": [1, 1882], "sync": [1, 12, 16, 41, 45, 63, 70, 71, 1602, 1886, 1887, 1906], "is_en": [1, 1783, 1790, 1791, 1792, 1793, 1794, 1795], "indic": [1, 2, 3, 4, 18, 21, 29, 38, 39, 41, 42, 46, 47, 58, 84, 192, 209, 222, 313, 315, 317, 318, 319, 321, 470, 511, 513, 515, 541, 569, 570, 580, 611, 692, 693, 732, 742, 743, 871, 872, 873, 874, 875, 895, 905, 906, 934, 941, 942, 964, 966, 967, 969, 1003, 1042, 1043, 1066, 1121, 1122, 1124, 1125, 1126, 1130, 1131, 1132, 1143, 1164, 1188, 1190, 1195, 1203, 1206, 1207, 1211, 1220, 1231, 1233, 1244, 1247, 1261, 1269, 1277, 1279, 1281, 1287, 1290, 1292, 1295, 1312, 1318, 1322, 1330, 1331, 1332, 1333, 1358, 1365, 1366, 1370, 1371, 1416, 1417, 1418, 1419, 1420, 1425, 1427, 1428, 1483, 1484, 1485, 1504, 1512, 1513, 1516, 1517, 1533, 1548, 1549, 1550, 1558, 1571, 1586, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1628, 1629, 1648, 1649, 1687, 1689, 1708, 1743, 1781, 1785, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1818, 1819, 1823, 1826, 1832, 1833, 1834, 1835, 1840, 1841, 1843, 1850, 1853, 1859, 1860, 1861, 1863, 1867, 1876, 1877, 1888, 1901, 1903, 1913, 1917, 1921, 1922, 1924], "load_state_dict": [1, 39, 43, 45, 63, 1190, 1261, 1422, 1593, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1857, 1858, 1894, 1899, 1908], "state_dict": [1, 39, 43, 45, 63, 833, 834, 1190, 1422, 1593, 1628, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1857, 1872, 1887, 1894, 1896, 1899, 1901, 1908, 1926], "load": [1, 2, 19, 20, 23, 29, 30, 32, 33, 39, 43, 45, 63, 834, 859, 913, 950, 965, 1194, 1200, 1205, 1366, 1593, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1670, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1739, 1858, 1860, 1871, 1872, 1877, 1883, 1886, 1893, 1894, 1898, 1900, 1901, 1922], "scaler": [1, 1882, 1886], "unmodifi": [1, 26, 41], "iter": [1, 2, 3, 4, 8, 17, 21, 28, 29, 39, 41, 42, 43, 45, 47, 59, 61, 63, 71, 976, 977, 978, 979, 980, 1009, 1012, 1014, 1035, 1190, 1262, 1422, 1423, 1424, 1432, 1433, 1602, 1603, 1606, 1607, 1608, 1610, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1643, 1645, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1681, 1682, 1683, 1686, 1697, 1767, 1809, 1861, 1863, 1864, 1875, 1877, 1882, 1883, 1884, 1886, 1887, 1888, 1891, 1894, 1904, 1907, 1912, 1922, 1928], "set_backoff_factor": 1, "new_factor": 1, "new_scal": 1, "set_growth_factor": 1, "set_growth_interv": 1, "new_interv": 1, "It": [1, 2, 4, 5, 6, 8, 9, 12, 13, 15, 16, 17, 20, 21, 23, 26, 28, 29, 34, 35, 38, 39, 41, 42, 43, 46, 47, 49, 51, 55, 56, 57, 58, 59, 60, 63, 65, 67, 68, 69, 70, 71, 89, 151, 197, 472, 473, 511, 513, 515, 541, 554, 886, 887, 888, 889, 890, 894, 917, 955, 956, 980, 985, 991, 992, 1010, 1011, 1030, 1031, 1039, 1086, 1115, 1120, 1123, 1131, 1132, 1151, 1187, 1190, 1191, 1196, 1200, 1222, 1226, 1230, 1233, 1235, 1237, 1238, 1243, 1247, 1248, 1250, 1251, 1253, 1255, 1258, 1259, 1261, 1262, 1270, 1330, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1359, 1369, 1416, 1417, 1418, 1419, 1420, 1422, 1429, 1450, 1453, 1473, 1475, 1523, 1533, 1577, 1595, 1596, 1597, 1600, 1601, 1602, 1610, 1611, 1614, 1635, 1638, 1639, 1647, 1656, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1695, 1714, 1727, 1743, 1753, 1759, 1766, 1787, 1839, 1850, 1857, 1862, 1863, 1873, 1875, 1877, 1883, 1885, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1894, 1895, 1896, 1897, 1898, 1900, 1901, 1902, 1904, 1905, 1906, 1908, 1913, 1914, 1915, 1918, 1919, 1921, 1925], "five": [1, 1863, 1899], "entri": [1, 4, 13, 15, 21, 41, 42, 45, 47, 56, 58, 59, 315, 732, 855, 856, 914, 1006, 1007, 1053, 1104, 1105, 1164, 1190, 1210, 1365, 1366, 1422, 1428, 1512, 1513, 1598, 1599, 1620, 1621, 1629, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1787, 1860, 1863, 1864, 1870, 1878, 1883, 1887, 1888, 1891, 1894, 1911, 1917, 1922, 1926], "_growth_track": 1, "recent": [1, 2, 8, 9, 25, 29, 61, 70, 1165, 1175, 1783, 1862, 1863, 1878, 1888, 1897, 1898, 1917, 1924], "consecut": [1, 41, 607, 1637, 1679, 1829, 1840, 1841, 1877, 1901], "unskip": 1, "empti": [1, 4, 15, 16, 41, 43, 49, 56, 63, 68, 71, 321, 511, 513, 534, 542, 814, 920, 921, 931, 937, 1063, 1065, 1188, 1191, 1215, 1235, 1236, 1241, 1248, 1271, 1272, 1273, 1274, 1281, 1339, 1358, 1366, 1429, 1494, 1513, 1559, 1642, 1654, 1658, 1793, 1808, 1822, 1856, 1859, 1860, 1861, 1862, 1863, 1865, 1871, 1876, 1877, 1878, 1881, 1884, 1886, 1888, 1901, 1903, 1905, 1917, 1918, 1925], "wish": [1, 1126, 1799, 1882, 1886, 1888, 1889], "checkpoint": [1, 12, 45, 59, 61, 63, 913, 1261, 1602, 1857, 1858, 1872, 1890, 1906, 1915], "carri": [1, 67, 336, 794, 835, 836, 854, 855, 1884, 1908], "out": [1, 2, 3, 4, 8, 9, 10, 15, 16, 17, 19, 20, 21, 22, 23, 28, 30, 33, 35, 38, 41, 43, 46, 47, 55, 56, 59, 64, 67, 71, 312, 314, 316, 318, 399, 401, 447, 494, 510, 512, 514, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 690, 692, 693, 694, 695, 696, 753, 757, 761, 769, 770, 771, 776, 778, 782, 794, 833, 835, 836, 854, 855, 862, 863, 864, 865, 866, 867, 868, 869, 874, 878, 879, 880, 881, 882, 891, 892, 893, 896, 905, 918, 920, 921, 922, 923, 924, 925, 926, 927, 930, 934, 937, 939, 940, 941, 942, 943, 945, 946, 948, 950, 952, 953, 954, 956, 957, 959, 960, 963, 968, 976, 978, 980, 1007, 1008, 1020, 1021, 1033, 1037, 1042, 1043, 1044, 1045, 1047, 1050, 1055, 1056, 1058, 1059, 1060, 1062, 1063, 1064, 1068, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1116, 1117, 1120, 1121, 1123, 1124, 1126, 1131, 1132, 1133, 1134, 1135, 1136, 1144, 1145, 1146, 1149, 1150, 1151, 1152, 1154, 1155, 1156, 1157, 1158, 1159, 1161, 1162, 1163, 1164, 1165, 1167, 1168, 1184, 1185, 1190, 1201, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1236, 1237, 1238, 1239, 1240, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1258, 1259, 1260, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1283, 1284, 1286, 1287, 1288, 1289, 1290, 1292, 1293, 1294, 1295, 1307, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1322, 1323, 1324, 1325, 1326, 1327, 1331, 1332, 1333, 1335, 1336, 1337, 1343, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1360, 1361, 1362, 1363, 1365, 1367, 1370, 1371, 1374, 1375, 1390, 1391, 1392, 1407, 1409, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1434, 1435, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1465, 1466, 1467, 1468, 1469, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1492, 1496, 1497, 1498, 1499, 1500, 1501, 1507, 1508, 1509, 1514, 1517, 1521, 1532, 1538, 1557, 1559, 1590, 1602, 1619, 1620, 1621, 1622, 1648, 1649, 1650, 1651, 1653, 1654, 1678, 1695, 1696, 1700, 1701, 1702, 1704, 1707, 1708, 1714, 1715, 1716, 1718, 1720, 1722, 1723, 1726, 1727, 1728, 1732, 1736, 1737, 1738, 1740, 1741, 1742, 1743, 1759, 1760, 1761, 1773, 1774, 1775, 1776, 1781, 1785, 1786, 1797, 1798, 1800, 1801, 1802, 1803, 1805, 1806, 1808, 1819, 1820, 1821, 1824, 1826, 1828, 1831, 1832, 1834, 1836, 1837, 1843, 1845, 1846, 1847, 1850, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1860, 1861, 1863, 1870, 1873, 1875, 1877, 1878, 1883, 1884, 1886, 1887, 1888, 1889, 1894, 1896, 1901, 1904, 1905, 1908, 1909, 1911, 1913, 1914, 1915, 1918, 1920, 1922, 1923, 1927, 1928], "follow": [1, 2, 3, 4, 6, 8, 10, 12, 13, 14, 15, 16, 17, 18, 21, 22, 23, 29, 30, 32, 33, 35, 36, 37, 38, 39, 41, 43, 45, 46, 47, 49, 55, 56, 57, 58, 59, 63, 65, 67, 68, 71, 83, 84, 486, 614, 677, 757, 776, 782, 789, 790, 791, 797, 811, 812, 813, 814, 816, 817, 818, 819, 821, 822, 851, 858, 859, 886, 887, 888, 892, 910, 911, 934, 939, 1006, 1020, 1063, 1081, 1083, 1107, 1116, 1129, 1143, 1190, 1191, 1199, 1203, 1210, 1221, 1232, 1242, 1245, 1246, 1259, 1262, 1281, 1284, 1330, 1339, 1345, 1358, 1366, 1369, 1374, 1392, 1422, 1437, 1453, 1469, 1473, 1540, 1571, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1609, 1649, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1686, 1689, 1697, 1708, 1736, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1783, 1784, 1785, 1786, 1793, 1804, 1829, 1837, 1843, 1857, 1860, 1861, 1862, 1863, 1864, 1865, 1869, 1870, 1871, 1872, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1884, 1885, 1886, 1888, 1889, 1890, 1891, 1892, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1905, 1906, 1908, 1909, 1911, 1913, 1914, 1915, 1917, 1918, 1920, 1921, 1923, 1924, 1928, 1929], "unscale_": [1, 1882], "unless": [1, 2, 5, 8, 15, 39, 41, 60, 63, 64, 71, 151, 497, 837, 855, 894, 921, 1119, 1190, 1233, 1238, 1251, 1261, 1290, 1376, 1422, 1469, 1597, 1625, 1644, 1672, 1678, 1743, 1843, 1863, 1869, 1883, 1886, 1898, 1901, 1905, 1909], "earlier": [1, 2, 7, 18, 1808, 1883, 1886, 1890, 1893, 1899, 1901, 1907], "part": [1, 2, 4, 5, 6, 7, 8, 10, 13, 16, 17, 18, 28, 29, 32, 33, 35, 38, 39, 41, 43, 47, 58, 59, 63, 67, 68, 71, 83, 84, 838, 904, 952, 1063, 1180, 1182, 1183, 1186, 1190, 1200, 1202, 1205, 1206, 1220, 1226, 1228, 1237, 1244, 1247, 1422, 1461, 1571, 1602, 1612, 1681, 1708, 1789, 1829, 1832, 1833, 1834, 1835, 1857, 1858, 1860, 1862, 1863, 1871, 1872, 1882, 1883, 1886, 1888, 1890, 1891, 1894, 1899, 1901, 1905, 1906, 1908, 1913, 1914, 1915, 1917, 1922, 1924], "check": [1, 5, 14, 15, 16, 17, 18, 21, 22, 23, 28, 29, 30, 32, 38, 41, 42, 47, 49, 58, 63, 222, 340, 497, 691, 858, 894, 896, 897, 905, 906, 966, 967, 969, 973, 1002, 1020, 1177, 1187, 1190, 1205, 1206, 1219, 1220, 1225, 1226, 1228, 1231, 1233, 1238, 1244, 1247, 1251, 1253, 1254, 1279, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1422, 1593, 1602, 1611, 1614, 1627, 1637, 1659, 1660, 1783, 1790, 1791, 1792, 1793, 1794, 1795, 1857, 1858, 1862, 1863, 1864, 1876, 1877, 1882, 1886, 1888, 1889, 1890, 1893, 1894, 1895, 1898, 1901, 1904, 1905, 1906, 1907, 1913, 1917, 1922, 1924, 1928], "inf": [1, 29, 47, 63, 681, 683, 686, 687, 688, 882, 918, 934, 1179, 1180, 1182, 1184, 1185, 1221, 1236, 1242, 1246, 1249, 1259, 1270, 1316, 1412, 1455, 1465, 1571, 1606, 1620, 1629, 1649, 1736, 1743, 1882, 1883, 1889, 1897, 1918, 1924], "found": [1, 8, 13, 16, 20, 23, 25, 28, 33, 35, 58, 71, 84, 934, 963, 1042, 1043, 1190, 1194, 1211, 1287, 1290, 1292, 1295, 1318, 1334, 1344, 1367, 1422, 1449, 1743, 1857, 1860, 1863, 1878, 1882, 1888, 1891, 1894, 1896, 1901, 1905, 1907, 1908, 1913, 1922, 1928], "otherwis": [1, 2, 4, 6, 8, 10, 30, 32, 38, 41, 42, 48, 51, 63, 64, 68, 71, 89, 210, 321, 328, 332, 336, 338, 342, 343, 493, 502, 557, 577, 578, 580, 600, 614, 677, 683, 684, 685, 686, 687, 690, 692, 693, 694, 696, 732, 757, 765, 766, 781, 791, 814, 817, 818, 858, 859, 862, 889, 892, 900, 905, 918, 934, 1004, 1063, 1069, 1102, 1114, 1181, 1187, 1190, 1193, 1196, 1202, 1211, 1235, 1250, 1259, 1261, 1262, 1277, 1282, 1287, 1289, 1290, 1292, 1294, 1295, 1317, 1320, 1336, 1337, 1356, 1358, 1361, 1362, 1363, 1367, 1374, 1378, 1379, 1380, 1381, 1383, 1392, 1408, 1422, 1426, 1427, 1428, 1429, 1430, 1432, 1437, 1438, 1440, 1453, 1459, 1461, 1464, 1465, 1467, 1469, 1470, 1471, 1489, 1490, 1523, 1525, 1526, 1530, 1565, 1575, 1602, 1609, 1614, 1635, 1639, 1647, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1672, 1674, 1675, 1676, 1677, 1695, 1697, 1705, 1707, 1714, 1723, 1730, 1743, 1751, 1759, 1802, 1803, 1804, 1807, 1839, 1840, 1841, 1845, 1846, 1853, 1857, 1860, 1862, 1863, 1870, 1871, 1876, 1882, 1888, 1889, 1896, 1901, 1909, 1911, 1912, 1913, 1915, 1918, 1919, 1920, 1921, 1922, 1924, 1928], "avoid": [1, 6, 9, 10, 15, 16, 17, 18, 21, 38, 41, 47, 56, 59, 63, 71, 89, 192, 209, 447, 778, 862, 890, 931, 1020, 1190, 1235, 1261, 1357, 1388, 1389, 1413, 1422, 1431, 1436, 1473, 1503, 1533, 1557, 1564, 1602, 1610, 1678, 1729, 1758, 1804, 1822, 1840, 1858, 1873, 1877, 1883, 1885, 1886, 1890, 1891, 1894, 1906, 1913, 1914, 1921, 1922, 1923], "corrupt": [1, 41, 58, 1359, 1886, 1896], "param": [1, 2, 45, 47, 50, 58, 63, 65, 67, 71, 761, 792, 1119, 1129, 1190, 1208, 1422, 1428, 1432, 1433, 1601, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1673, 1674, 1675, 1676, 1677, 1678, 1691, 1732, 1861, 1871, 1881, 1882, 1886, 1887, 1904, 1928], "closur": [1, 18, 45, 1667, 1672, 1678], "divid": [1, 6, 39, 41, 45, 238, 580, 581, 582, 980, 1058, 1061, 1081, 1099, 1108, 1152, 1153, 1200, 1338, 1339, 1345, 1346, 1356, 1382, 1383, 1389, 1413, 1414, 1425, 1426, 1427, 1436, 1453, 1454, 1470, 1471, 1493, 1494, 1504, 1505, 1533, 1556, 1564, 1602, 1808, 1851, 1861, 1903], "modifi": [1, 2, 14, 15, 16, 17, 24, 26, 29, 35, 38, 39, 41, 42, 43, 45, 63, 71, 260, 486, 788, 835, 836, 837, 894, 896, 897, 910, 911, 955, 956, 1143, 1187, 1190, 1193, 1194, 1209, 1365, 1422, 1465, 1467, 1469, 1512, 1513, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1606, 1607, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1672, 1674, 1675, 1676, 1677, 1678, 1681, 1689, 1771, 1860, 1863, 1876, 1882, 1886, 1888, 1889, 1894, 1899, 1905, 1906, 1908, 1913, 1918, 1921, 1923, 1927], "inspect": [1, 2, 17, 20, 23, 41, 63, 71, 913, 1190, 1201, 1882, 1888, 1893, 1905, 1909, 1920, 1928], "between": [1, 2, 3, 4, 8, 12, 17, 18, 19, 21, 29, 34, 35, 39, 41, 47, 48, 58, 59, 60, 63, 70, 71, 197, 511, 580, 581, 582, 584, 585, 604, 614, 686, 687, 688, 692, 693, 757, 769, 770, 771, 799, 854, 862, 881, 890, 892, 899, 901, 902, 903, 905, 906, 938, 950, 962, 966, 973, 975, 1022, 1026, 1040, 1041, 1046, 1063, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1114, 1143, 1150, 1187, 1190, 1201, 1225, 1226, 1248, 1253, 1319, 1338, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1358, 1361, 1362, 1363, 1367, 1369, 1374, 1383, 1389, 1398, 1399, 1400, 1401, 1402, 1403, 1413, 1415, 1416, 1417, 1422, 1425, 1426, 1427, 1431, 1450, 1453, 1454, 1455, 1470, 1471, 1473, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1520, 1545, 1546, 1547, 1561, 1577, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1656, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1682, 1683, 1689, 1691, 1700, 1708, 1712, 1713, 1718, 1719, 1723, 1748, 1801, 1802, 1803, 1804, 1808, 1828, 1829, 1845, 1846, 1860, 1862, 1863, 1864, 1870, 1875, 1878, 1882, 1883, 1885, 1886, 1887, 1891, 1892, 1894, 1896, 1898, 1899, 1901, 1904, 1906, 1908, 1909, 1913, 1915, 1917, 1919, 1922, 1926], "simpl": [1, 16, 20, 21, 33, 35, 39, 51, 58, 67, 69, 71, 962, 1020, 1121, 1129, 1130, 1131, 1190, 1194, 1201, 1340, 1341, 1342, 1365, 1395, 1396, 1397, 1422, 1461, 1512, 1657, 1764, 1850, 1857, 1860, 1864, 1878, 1885, 1886, 1887, 1888, 1890, 1891, 1893, 1901, 1905, 1913, 1917], "clip": [1, 63, 958, 1606, 1607, 1861, 1889, 1901, 1903], "util": [1, 8, 15, 17, 22, 29, 34, 59, 63, 64, 70, 71, 729, 732, 735, 736, 737, 742, 743, 753, 757, 761, 787, 795, 980, 1114, 1190, 1374, 1392, 1422, 1437, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1611, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1635, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1683, 1689, 1812, 1813, 1814, 1815, 1816, 1858, 1863, 1873, 1882, 1884, 1885, 1886, 1888, 1890, 1891, 1893, 1894, 1901, 1904, 1905, 1906], "clip_grad_norm_": [1, 63, 1882], "max_norm": [1, 63, 742, 743, 1365, 1366, 1512, 1513, 1606, 1861, 1882], "own": [1, 8, 10, 16, 20, 41, 42, 45, 47, 50, 58, 60, 63, 71, 677, 998, 1097, 1116, 1152, 1190, 1261, 1350, 1351, 1352, 1353, 1354, 1355, 1422, 1611, 1614, 1863, 1879, 1882, 1886, 1905, 1908, 1909, 1913, 1915, 1917], "onc": [1, 2, 8, 10, 12, 14, 17, 21, 23, 25, 33, 38, 39, 41, 42, 43, 45, 47, 48, 50, 51, 58, 63, 66, 68, 70, 71, 83, 894, 895, 896, 898, 900, 1063, 1190, 1194, 1261, 1359, 1422, 1602, 1612, 1614, 1687, 1691, 1707, 1754, 1758, 1860, 1863, 1871, 1873, 1875, 1882, 1883, 1885, 1886, 1888, 1891, 1893, 1894, 1904, 1905, 1922], "assign": [1, 2, 8, 10, 11, 38, 41, 49, 58, 59, 68, 71, 677, 835, 836, 837, 1188, 1191, 1330, 1358, 1422, 1429, 1432, 1433, 1603, 1614, 1860, 1864, 1882, 1888, 1889, 1890, 1901, 1908, 1914, 1915, 1921, 1922], "been": [1, 2, 6, 10, 12, 13, 17, 24, 29, 30, 38, 39, 41, 42, 45, 46, 47, 49, 51, 58, 61, 63, 66, 67, 71, 677, 757, 894, 967, 969, 974, 1002, 1005, 1062, 1067, 1120, 1193, 1194, 1199, 1204, 1261, 1374, 1381, 1392, 1437, 1486, 1521, 1602, 1611, 1616, 1620, 1622, 1642, 1643, 1656, 1661, 1681, 1682, 1683, 1689, 1691, 1707, 1804, 1852, 1869, 1873, 1875, 1876, 1877, 1882, 1883, 1885, 1886, 1891, 1892, 1894, 1896, 1898, 1900, 1901, 1904, 1905, 1913, 1915, 1917, 1922], "twice": [1, 16, 70, 614, 899, 1127, 1882, 1883, 1890, 1891], "trigger": [1, 8, 10, 12, 14, 17, 24, 25, 29, 41, 58, 63, 70, 222, 1037, 1756, 1882, 1886, 1887, 1893, 1899, 1913], "runtimeerror": [1, 2, 32, 41, 45, 68, 71, 89, 580, 694, 894, 931, 1111, 1165, 1175, 1190, 1219, 1220, 1221, 1229, 1230, 1231, 1233, 1237, 1243, 1250, 1255, 1256, 1282, 1312, 1422, 1658, 1745, 1783, 1843, 1860, 1862, 1863, 1876, 1878, 1882, 1884, 1890, 1898, 1900, 1901, 1908, 1912, 1917, 1920], "spars": [1, 2, 15, 30, 191, 192, 209, 219, 222, 323, 328, 342, 343, 434, 540, 541, 542, 543, 578, 580, 581, 582, 583, 584, 585, 611, 686, 742, 743, 905, 906, 1037, 1132, 1154, 1175, 1262, 1284, 1294, 1322, 1365, 1366, 1455, 1512, 1513, 1538, 1678, 1697, 1745, 1779, 1783, 1790, 1791, 1792, 1793, 1794, 1795, 1800, 1809, 1828, 1843, 1858, 1861, 1865, 1870, 1881, 1897, 1898, 1903, 1910, 1920, 1921, 1924], "place": [1, 4, 8, 15, 16, 21, 25, 27, 28, 30, 38, 39, 41, 43, 48, 49, 63, 66, 67, 71, 89, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 122, 124, 126, 128, 131, 132, 134, 142, 144, 147, 148, 150, 153, 159, 161, 163, 165, 167, 169, 178, 187, 195, 199, 202, 204, 214, 216, 222, 223, 232, 236, 238, 244, 247, 249, 251, 253, 254, 257, 260, 262, 269, 271, 273, 277, 279, 283, 285, 292, 294, 296, 304, 306, 308, 310, 312, 314, 316, 318, 356, 358, 360, 362, 364, 366, 368, 371, 373, 375, 376, 383, 385, 387, 389, 391, 395, 399, 401, 419, 422, 425, 427, 438, 440, 442, 450, 455, 465, 468, 484, 486, 488, 490, 494, 497, 506, 509, 510, 512, 514, 520, 524, 526, 529, 531, 533, 546, 548, 550, 559, 561, 568, 572, 574, 590, 593, 595, 597, 599, 600, 609, 619, 755, 790, 794, 811, 835, 836, 854, 855, 894, 896, 910, 911, 932, 976, 977, 979, 980, 1000, 1063, 1114, 1119, 1120, 1128, 1190, 1234, 1252, 1312, 1334, 1344, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1367, 1379, 1380, 1381, 1408, 1422, 1439, 1440, 1441, 1442, 1449, 1464, 1506, 1507, 1508, 1509, 1511, 1512, 1513, 1514, 1525, 1528, 1537, 1568, 1570, 1585, 1589, 1593, 1598, 1599, 1602, 1606, 1607, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1644, 1678, 1734, 1736, 1740, 1741, 1742, 1788, 1824, 1858, 1860, 1862, 1863, 1870, 1877, 1882, 1886, 1888, 1893, 1904, 1905, 1906, 1913, 1914, 1919, 1921, 1923], "replac": [1, 2, 13, 15, 20, 28, 32, 38, 39, 41, 43, 57, 59, 63, 65, 66, 67, 68, 69, 71, 83, 120, 420, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 744, 811, 836, 855, 941, 1009, 1063, 1119, 1120, 1195, 1197, 1207, 1279, 1280, 1312, 1316, 1453, 1464, 1593, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1644, 1646, 1707, 1804, 1808, 1831, 1860, 1861, 1863, 1871, 1886, 1889, 1891, 1893, 1896, 1900, 1901, 1903, 1905, 1908, 1924], "were": [1, 2, 3, 4, 12, 16, 17, 24, 28, 29, 35, 41, 49, 58, 61, 63, 68, 70, 71, 151, 321, 335, 470, 851, 886, 888, 890, 904, 1009, 1120, 1131, 1197, 1261, 1486, 1602, 1606, 1611, 1621, 1638, 1674, 1743, 1747, 1818, 1825, 1850, 1862, 1870, 1882, 1886, 1888, 1899, 1901, 1905], "reduc": [1, 3, 4, 12, 15, 17, 19, 24, 29, 32, 39, 41, 42, 43, 45, 63, 321, 511, 514, 515, 683, 690, 692, 693, 694, 696, 816, 817, 818, 819, 822, 824, 871, 872, 950, 977, 988, 1020, 1163, 1242, 1246, 1248, 1253, 1259, 1277, 1287, 1289, 1290, 1292, 1295, 1317, 1318, 1319, 1320, 1338, 1339, 1340, 1341, 1342, 1356, 1358, 1366, 1382, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1461, 1470, 1493, 1494, 1502, 1504, 1513, 1529, 1532, 1533, 1534, 1544, 1552, 1553, 1554, 1555, 1556, 1557, 1564, 1575, 1576, 1587, 1590, 1602, 1610, 1647, 1667, 1691, 1705, 1707, 1708, 1742, 1785, 1789, 1802, 1803, 1807, 1808, 1829, 1843, 1845, 1846, 1859, 1861, 1875, 1876, 1883, 1885, 1887, 1888, 1894, 1898, 1899, 1900, 1903, 1904, 1905, 1906, 1908, 1917, 1928], "occur": [1, 15, 17, 20, 24, 29, 30, 38, 41, 51, 52, 58, 63, 68, 83, 197, 315, 1023, 1063, 1187, 1193, 1203, 1233, 1345, 1461, 1505, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1862, 1873, 1877, 1882, 1883, 1886, 1890, 1897, 1901, 1907, 1913, 1915, 1921, 1924, 1928], "increas": [1, 2, 4, 8, 12, 17, 23, 39, 41, 47, 55, 63, 677, 851, 895, 934, 988, 1020, 1063, 1151, 1152, 1330, 1339, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1434, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1562, 1563, 1571, 1676, 1682, 1683, 1687, 1689, 1691, 1743, 1751, 1829, 1844, 1861, 1869, 1885, 1886, 1892, 1909, 1917], "fill": [1, 16, 21, 41, 155, 174, 258, 259, 260, 286, 317, 321, 377, 400, 444, 445, 446, 448, 453, 480, 605, 620, 921, 1051, 1064, 1066, 1117, 1118, 1220, 1231, 1233, 1366, 1465, 1513, 1559, 1653, 1654, 1716, 1717, 1718, 1719, 1720, 1721, 1808, 1855, 1856, 1859, 1861, 1867, 1877, 1878, 1881, 1886, 1888, 1899, 1903, 1917, 1924], "floattensor": [1, 41, 321, 486, 683, 684, 685, 686, 687, 732, 905, 906, 918, 1137, 1365, 1366, 1425, 1465, 1749, 1920, 1923], "end": [1, 8, 9, 10, 12, 16, 29, 38, 39, 41, 47, 51, 55, 66, 71, 361, 362, 535, 757, 781, 794, 817, 818, 862, 919, 957, 964, 1024, 1053, 1063, 1102, 1116, 1143, 1149, 1150, 1187, 1190, 1210, 1215, 1245, 1255, 1257, 1260, 1262, 1276, 1321, 1322, 1337, 1338, 1339, 1356, 1358, 1364, 1368, 1374, 1375, 1378, 1379, 1380, 1381, 1382, 1383, 1389, 1392, 1393, 1408, 1413, 1416, 1417, 1422, 1424, 1429, 1430, 1433, 1437, 1440, 1450, 1453, 1459, 1464, 1471, 1504, 1513, 1525, 1526, 1602, 1609, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1681, 1686, 1723, 1756, 1759, 1762, 1777, 1829, 1840, 1841, 1853, 1859, 1860, 1861, 1862, 1863, 1875, 1882, 1883, 1886, 1887, 1888, 1890, 1891, 1897, 1900, 1901, 1904, 1907, 1908, 1911, 1913, 1918], "reason": [1, 4, 9, 10, 13, 15, 16, 17, 21, 23, 29, 38, 41, 43, 63, 68, 677, 838, 1084, 1086, 1190, 1205, 1206, 1225, 1226, 1253, 1290, 1338, 1362, 1422, 1523, 1571, 1598, 1599, 1614, 1739, 1860, 1862, 1863, 1869, 1883, 1887, 1889, 1897, 1899, 1901, 1913, 1920, 1928], "synchron": [1, 4, 5, 17, 34, 35, 39, 43, 45, 49, 58, 63, 70, 874, 966, 967, 969, 977, 997, 1037, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1230, 1231, 1232, 1233, 1237, 1238, 1244, 1247, 1250, 1251, 1253, 1254, 1262, 1461, 1602, 1648, 1650, 1729, 1858, 1885, 1886, 1887, 1892, 1896, 1906, 1913], "fall": [1, 3, 8, 32, 38, 792, 905, 1152, 1203, 1261, 1383, 1453, 1530, 1575, 1606, 1607, 1857, 1901, 1908], "below": [1, 2, 6, 10, 13, 15, 17, 18, 20, 21, 22, 23, 24, 29, 32, 38, 39, 41, 47, 49, 50, 55, 58, 59, 60, 61, 71, 677, 731, 745, 754, 792, 811, 1006, 1050, 1051, 1052, 1053, 1054, 1063, 1091, 1093, 1097, 1135, 1143, 1190, 1206, 1246, 1247, 1252, 1259, 1291, 1353, 1354, 1355, 1374, 1376, 1383, 1392, 1394, 1418, 1419, 1420, 1422, 1437, 1453, 1474, 1504, 1530, 1575, 1602, 1614, 1648, 1678, 1748, 1788, 1819, 1829, 1832, 1833, 1834, 1835, 1860, 1862, 1863, 1865, 1869, 1870, 1875, 1876, 1882, 1883, 1886, 1887, 1888, 1891, 1892, 1894, 1896, 1898, 1899, 1901, 1904, 1905, 1906, 1908, 1910, 1913, 1914, 1915, 1918, 1921, 1924], "someth": [1, 4, 8, 13, 15, 17, 20, 21, 28, 29, 65, 71, 898, 900, 1063, 1190, 1205, 1422, 1865, 1873, 1875, 1876, 1883, 1892, 1900, 1901, 1913, 1928], "wrong": [1, 20, 41, 71, 894, 1188, 1191, 1887, 1896, 1900, 1901, 1904], "incompat": [1, 10, 32, 68, 931, 1187, 1884, 1905], "due": [1, 4, 5, 6, 8, 17, 21, 24, 29, 39, 41, 47, 57, 63, 68, 71, 485, 877, 898, 899, 904, 958, 1202, 1225, 1226, 1253, 1279, 1362, 1376, 1465, 1474, 1532, 1571, 1642, 1656, 1678, 1809, 1860, 1878, 1886, 1887, 1891, 1892, 1898, 1901, 1908, 1909, 1913, 1915], "float64": [1, 30, 240, 445, 448, 577, 877, 952, 1106, 1115, 1137, 1172, 1190, 1219, 1225, 1226, 1228, 1230, 1246, 1422, 1571, 1664, 1665, 1701, 1709, 1748, 1749, 1752, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1848, 1853, 1894, 1897, 1917, 1919, 1920, 1923, 1924, 1929], "variant": [1, 6, 24, 28, 39, 855, 1220, 1231, 1244, 1247, 1319, 1322, 1664, 1665, 1666, 1678, 1831, 1858, 1859, 1893, 1911, 1923], "suppli": [1, 6, 8, 17, 29, 32, 33, 41, 998, 1428, 1660, 1863, 1886, 1917], "won": [1, 9, 16, 17, 21, 29, 39, 43, 58, 66, 457, 1190, 1201, 1422, 1557, 1596, 1597, 1857, 1883, 1888, 1913, 1925], "go": [1, 2, 8, 13, 15, 16, 17, 21, 22, 33, 38, 41, 55, 60, 67, 71, 497, 498, 557, 895, 910, 1262, 1335, 1336, 1337, 1415, 1416, 1417, 1862, 1863, 1870, 1875, 1876, 1877, 1883, 1885, 1886, 1888, 1889, 1893, 1894, 1896, 1900, 1901, 1905, 1920, 1922], "addmm": [1, 28, 107, 1800, 1859, 1861, 1876, 1897, 1903, 1917], "c": [1, 2, 4, 9, 10, 15, 16, 17, 20, 21, 26, 28, 29, 32, 38, 41, 47, 56, 66, 71, 260, 335, 497, 518, 614, 682, 818, 874, 877, 896, 929, 940, 943, 958, 1000, 1006, 1040, 1055, 1058, 1063, 1109, 1110, 1111, 1120, 1121, 1125, 1130, 1133, 1143, 1190, 1200, 1212, 1219, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1235, 1236, 1239, 1241, 1245, 1246, 1248, 1250, 1252, 1253, 1311, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1339, 1340, 1341, 1342, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1358, 1361, 1362, 1363, 1367, 1369, 1370, 1371, 1377, 1385, 1386, 1387, 1390, 1391, 1393, 1394, 1404, 1405, 1406, 1410, 1415, 1416, 1417, 1418, 1419, 1420, 1425, 1426, 1427, 1429, 1434, 1435, 1443, 1444, 1445, 1446, 1447, 1448, 1456, 1461, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1486, 1494, 1504, 1505, 1517, 1521, 1556, 1562, 1563, 1571, 1609, 1637, 1639, 1640, 1641, 1648, 1649, 1695, 1711, 1727, 1765, 1785, 1799, 1804, 1824, 1841, 1858, 1859, 1860, 1861, 1862, 1863, 1867, 1876, 1877, 1885, 1886, 1887, 1889, 1891, 1893, 1900, 1902, 1905, 1914, 1915, 1917, 1918, 1921, 1922, 1928], "addmm_": [1, 1861, 1876, 1917], "d": [1, 2, 16, 17, 20, 29, 30, 38, 39, 41, 46, 47, 64, 71, 313, 321, 335, 470, 511, 513, 515, 541, 580, 614, 683, 687, 862, 877, 896, 918, 919, 921, 928, 929, 930, 934, 940, 1050, 1052, 1062, 1063, 1076, 1080, 1081, 1082, 1083, 1088, 1089, 1092, 1093, 1098, 1099, 1100, 1103, 1104, 1105, 1131, 1132, 1147, 1148, 1155, 1164, 1187, 1191, 1195, 1232, 1233, 1283, 1294, 1314, 1329, 1337, 1338, 1342, 1352, 1356, 1357, 1361, 1362, 1363, 1365, 1367, 1369, 1374, 1376, 1387, 1392, 1394, 1406, 1417, 1431, 1437, 1461, 1470, 1471, 1473, 1486, 1521, 1532, 1538, 1565, 1589, 1590, 1610, 1643, 1648, 1649, 1676, 1696, 1714, 1723, 1735, 1743, 1748, 1799, 1804, 1817, 1818, 1824, 1827, 1832, 1833, 1834, 1835, 1844, 1850, 1852, 1857, 1861, 1870, 1876, 1877, 1878, 1881, 1883, 1886, 1888, 1889, 1891, 1892, 1899, 1901, 1913, 1914, 1917, 1918, 1922, 1923], "best": [1, 2, 8, 17, 19, 23, 26, 33, 35, 38, 41, 47, 59, 63, 66, 858, 859, 914, 937, 950, 1205, 1206, 1235, 1428, 1678, 1691, 1858, 1860, 1862, 1875, 1881, 1882, 1883, 1888, 1890, 1905, 1913, 1917], "stabil": [1, 17, 29, 1221, 1277, 1339, 1340, 1341, 1342, 1376, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1458, 1461, 1518, 1579, 1610, 1643, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1711, 1889], "respect": [1, 2, 6, 9, 16, 23, 41, 42, 45, 47, 56, 58, 63, 69, 70, 71, 197, 210, 486, 577, 600, 686, 687, 688, 757, 792, 816, 838, 882, 888, 890, 904, 906, 910, 911, 945, 962, 1051, 1053, 1054, 1119, 1121, 1122, 1123, 1124, 1125, 1126, 1130, 1143, 1190, 1221, 1225, 1226, 1235, 1245, 1248, 1250, 1253, 1262, 1294, 1316, 1338, 1345, 1353, 1354, 1355, 1359, 1374, 1376, 1392, 1422, 1423, 1437, 1467, 1469, 1470, 1471, 1472, 1474, 1512, 1521, 1598, 1599, 1616, 1620, 1622, 1644, 1677, 1691, 1782, 1785, 1808, 1824, 1877, 1882, 1883, 1886, 1888, 1891, 1894, 1895, 1906, 1911, 1917, 1918, 1919, 1924], "describ": [1, 6, 8, 9, 10, 18, 24, 38, 39, 43, 45, 46, 49, 50, 56, 58, 63, 71, 511, 789, 790, 791, 812, 813, 814, 838, 856, 935, 989, 1006, 1023, 1063, 1143, 1210, 1250, 1330, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1360, 1361, 1362, 1363, 1364, 1367, 1369, 1370, 1371, 1377, 1380, 1383, 1385, 1386, 1387, 1389, 1394, 1413, 1415, 1416, 1417, 1428, 1429, 1436, 1440, 1453, 1461, 1469, 1470, 1471, 1473, 1504, 1516, 1517, 1526, 1559, 1689, 1829, 1858, 1860, 1862, 1863, 1881, 1882, 1883, 1886, 1887, 1890, 1891, 1893, 1894, 1899, 1901, 1905, 1907, 1908, 1911, 1914, 1915, 1924], "expos": [1, 2, 9, 22, 41, 45, 63, 70, 71, 792, 1116, 1883, 1886, 1893, 1905, 1908, 1928], "namespac": [1, 18, 71, 1037, 1860, 1864, 1867, 1888, 1894, 1901, 1906, 1911, 1928], "defin": [1, 2, 3, 4, 6, 10, 12, 13, 16, 21, 25, 32, 33, 38, 39, 41, 42, 43, 46, 47, 49, 50, 56, 58, 59, 63, 68, 71, 434, 444, 446, 448, 515, 563, 789, 794, 796, 835, 856, 857, 858, 859, 886, 887, 888, 889, 1020, 1046, 1063, 1064, 1083, 1111, 1117, 1133, 1135, 1149, 1151, 1152, 1179, 1190, 1212, 1219, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1235, 1236, 1239, 1241, 1242, 1246, 1247, 1248, 1250, 1252, 1253, 1259, 1295, 1359, 1364, 1378, 1379, 1380, 1381, 1388, 1390, 1391, 1422, 1428, 1440, 1455, 1457, 1462, 1464, 1486, 1521, 1571, 1577, 1593, 1602, 1620, 1622, 1629, 1630, 1650, 1653, 1658, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1680, 1681, 1683, 1686, 1689, 1707, 1716, 1718, 1720, 1727, 1756, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1785, 1787, 1829, 1832, 1833, 1834, 1835, 1853, 1855, 1857, 1860, 1863, 1865, 1867, 1875, 1876, 1878, 1883, 1886, 1887, 1891, 1892, 1894, 1900, 1901, 1904, 1905, 1906, 1907, 1908, 1911, 1913, 1917, 1918, 1923, 1924, 1925, 1928], "unlist": 1, "downstream": [1, 4, 17, 18, 21, 29, 1873], "stabl": [1, 2, 3, 41, 47, 58, 59, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 873, 1063, 1225, 1226, 1230, 1235, 1243, 1247, 1250, 1253, 1255, 1262, 1339, 1781, 1858, 1861, 1881, 1884, 1898, 1913], "believ": [1, 9, 27], "unstabl": [1, 47, 1225, 1226, 1253, 1270, 1279, 1540, 1808, 1918], "__matmul__": 1, "addbmm": [1, 101, 918, 1861, 1897, 1903], "addmv": [1, 109, 1861, 1876, 1903], "addr": [1, 41, 111, 1861, 1903], "baddbmm": [1, 153, 1861, 1897, 1903], "bmm": [1, 1843, 1859, 1861, 1876, 1878, 1897, 1898, 1903, 1917], "chain_matmul": [1, 1861, 1903], "multi_dot": [1, 940], "conv1d": [1, 705, 709, 712, 722, 738, 1353, 1361, 1398, 1843, 1861, 1903, 1908, 1910], "conv2d": [1, 706, 710, 713, 715, 723, 739, 789, 811, 1190, 1199, 1201, 1205, 1206, 1354, 1362, 1399, 1422, 1423, 1429, 1450, 1473, 1629, 1843, 1860, 1861, 1871, 1901, 1903, 1908, 1910, 1911, 1922, 1927], "conv3d": [1, 707, 711, 714, 716, 724, 740, 1355, 1363, 1400, 1843, 1861, 1903, 1908, 1910], "conv_transpose1d": [1, 1861, 1903, 1910], "conv_transpose2d": [1, 1861, 1903, 1910], "conv_transpose3d": [1, 1861, 1903, 1910], "grucel": [1, 1897, 1908, 1910, 1911], "lstmcell": [1, 1897, 1908, 1910, 1911], "matmul": [1, 3, 12, 19, 30, 930, 950, 1130, 1294, 1473, 1697, 1707, 1751, 1808, 1861, 1876, 1878, 1886, 1897, 1903, 1910, 1917], "mv": [1, 30, 1201, 1843, 1861, 1876, 1903, 1917], "prelu": [1, 1423, 1861, 1903, 1910], "rnncell": [1, 1908, 1910, 1911], "__pow__": 1, "__rdiv__": 1, "__rpow__": 1, "__rtruediv__": 1, "aco": [1, 95, 624, 625, 863, 1859, 1861, 1876, 1903, 1924], "asin": [1, 142, 626, 627, 865, 1859, 1861, 1876, 1903, 1917], "cosh": [1, 204, 634, 635, 681, 1859, 1861, 1876, 1903], "cosine_embedding_loss": [1, 1861, 1903], "cdist": [1, 1886, 1903], "cosine_similar": [1, 1471, 1861, 1903], "cross_entropi": [1, 1861], "cumprod": [1, 214, 1861, 1876, 1903], "cumsum": [1, 216, 1046, 1843, 1861, 1876, 1903], "dist": [1, 39, 41, 42, 45, 47, 59, 63, 941, 942, 1219, 1225, 1226, 1227, 1229, 1230, 1231, 1235, 1236, 1247, 1248, 1251, 1253, 1254, 1277, 1280, 1431, 1461, 1602, 1609, 1808, 1861, 1887, 1903, 1913, 1915], "erfinv": [1, 251, 1861, 1876, 1903, 1917, 1918], "exp": [1, 2, 47, 253, 640, 641, 767, 900, 901, 903, 1106, 1249, 1269, 1277, 1339, 1344, 1358, 1364, 1388, 1411, 1412, 1426, 1436, 1449, 1452, 1454, 1455, 1457, 1458, 1462, 1495, 1541, 1564, 1572, 1573, 1577, 1579, 1582, 1609, 1704, 1765, 1766, 1787, 1804, 1859, 1861, 1876, 1883, 1901, 1903, 1918], "expm1": [1, 257, 642, 643, 1859, 1861, 1876, 1903, 1917, 1918], "group_norm": [1, 1861, 1903, 1910], "hinge_embedding_loss": [1, 1861, 1903], "kl_div": [1, 1861, 1903], "l1_loss": [1, 1861, 1903], "layer_norm": [1, 1394, 1861, 1903, 1910], "log": [1, 14, 17, 18, 21, 23, 25, 29, 32, 38, 39, 47, 49, 51, 52, 55, 56, 60, 376, 377, 650, 657, 677, 1073, 1265, 1267, 1269, 1270, 1277, 1304, 1330, 1338, 1339, 1358, 1376, 1388, 1411, 1412, 1426, 1429, 1436, 1454, 1455, 1458, 1518, 1523, 1533, 1540, 1541, 1556, 1564, 1577, 1579, 1602, 1858, 1859, 1861, 1869, 1873, 1876, 1883, 1886, 1888, 1901, 1903, 1907, 1918, 1922, 1925, 1926, 1927], "log_softmax": [1, 1345, 1388, 1505, 1556, 1577, 1861, 1877, 1903, 1918], "log10": [1, 371, 651, 652, 1859, 1861, 1876, 1903], "log1p": [1, 373, 653, 654, 1859, 1861, 1876, 1903, 1917, 1918], "log2": [1, 375, 655, 656, 1859, 1861, 1876, 1903, 1918], "margin_ranking_loss": [1, 1861, 1903], "mse_loss": [1, 67, 1119, 1861, 1903], "multilabel_margin_loss": [1, 1861, 1903], "multi_margin_loss": [1, 1861, 1903], "nll_loss": [1, 1861, 1903], "norm": [1, 47, 63, 65, 71, 699, 700, 701, 702, 703, 704, 938, 1057, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1221, 1225, 1234, 1235, 1242, 1247, 1259, 1365, 1366, 1413, 1431, 1466, 1467, 1468, 1469, 1470, 1512, 1513, 1557, 1561, 1606, 1610, 1619, 1620, 1625, 1628, 1629, 1643, 1646, 1666, 1728, 1861, 1865, 1882, 1883, 1891, 1894, 1897, 1903], "normal": [1, 2, 39, 45, 58, 63, 71, 83, 336, 351, 377, 453, 553, 962, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1151, 1187, 1190, 1195, 1225, 1267, 1334, 1340, 1341, 1342, 1361, 1362, 1363, 1367, 1377, 1385, 1386, 1387, 1394, 1404, 1405, 1406, 1410, 1449, 1461, 1465, 1466, 1467, 1468, 1469, 1491, 1521, 1522, 1531, 1535, 1539, 1565, 1606, 1607, 1610, 1625, 1633, 1634, 1643, 1646, 1675, 1691, 1711, 1720, 1721, 1728, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1804, 1843, 1857, 1858, 1859, 1860, 1861, 1865, 1876, 1878, 1881, 1883, 1886, 1889, 1901, 1903, 1905, 1910, 1913, 1918, 1922, 1924, 1925, 1929], "pdist": [1, 1431, 1861, 1903], "poisson_nll_loss": [1, 1861, 1903], "pow": [1, 2, 468, 494, 898, 899, 902, 1106, 1859, 1861, 1863, 1876, 1882, 1883, 1903, 1917, 1923], "prod": [1, 55, 321, 515, 1080, 1082, 1085, 1086, 1088, 1089, 1092, 1093, 1095, 1096, 1098, 1100, 1255, 1256, 1365, 1369, 1473, 1843, 1859, 1861, 1876, 1903, 1917], "reciproc": [1, 484, 660, 661, 1738, 1859, 1861, 1876, 1903], "rsqrt": [1, 509, 1859, 1861, 1876, 1903], "sinh": [1, 533, 668, 669, 879, 1859, 1861, 1876, 1903, 1917], "smooth_l1_loss": [1, 1861, 1903], "soft_margin_loss": [1, 1861, 1903], "softmax": [1, 47, 793, 1330, 1358, 1388, 1412, 1456, 1504, 1523, 1533, 1540, 1571, 1578, 1784, 1861, 1876, 1877, 1878, 1886, 1903, 1910, 1917, 1918], "softmin": [1, 1861], "softplu": [1, 47, 1421, 1551, 1861, 1903], "sum": [1, 2, 12, 13, 14, 17, 21, 27, 29, 38, 41, 42, 45, 47, 49, 63, 68, 69, 71, 494, 515, 563, 743, 890, 898, 899, 900, 901, 902, 903, 904, 910, 911, 915, 962, 978, 979, 980, 1045, 1046, 1063, 1123, 1124, 1125, 1130, 1167, 1221, 1242, 1246, 1259, 1267, 1268, 1269, 1277, 1312, 1320, 1338, 1339, 1345, 1355, 1356, 1358, 1359, 1366, 1369, 1376, 1382, 1383, 1388, 1389, 1390, 1391, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1455, 1457, 1470, 1471, 1473, 1493, 1494, 1504, 1505, 1513, 1518, 1523, 1533, 1542, 1543, 1556, 1564, 1577, 1578, 1602, 1625, 1630, 1631, 1649, 1683, 1729, 1767, 1785, 1787, 1827, 1829, 1843, 1858, 1859, 1861, 1863, 1867, 1873, 1876, 1882, 1883, 1886, 1887, 1888, 1889, 1894, 1897, 1901, 1903, 1913, 1914, 1917, 1918, 1923], "renorm": [1, 490, 1365, 1366, 1512, 1513, 1861, 1903], "tan": [1, 572, 672, 673, 880, 1859, 1861, 1876, 1903, 1917, 1922], "triplet_margin_loss": [1, 1861, 1903], "addcdiv": [1, 103, 1861, 1903], "addcmul": [1, 105, 1861, 1903], "atan2": [1, 147, 868, 1859, 1861, 1876, 1903], "bilinear": [1, 776, 782, 783, 1063, 1474, 1475, 1521, 1532, 1590, 1591, 1843, 1861, 1903], "cross": [1, 8, 9, 21, 43, 47, 49, 1338, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1493, 1494, 1504, 1861, 1886, 1900, 1903], "dot": [1, 3, 32, 68, 69, 614, 899, 901, 902, 903, 1042, 1043, 1044, 1045, 1121, 1131, 1167, 1210, 1257, 1258, 1284, 1338, 1339, 1358, 1369, 1382, 1389, 1413, 1428, 1429, 1471, 1571, 1804, 1847, 1848, 1849, 1850, 1861, 1876, 1891, 1903, 1905], "grid_sampl": [1, 1486, 1843, 1861, 1903], "index_put": [1, 1843, 1861, 1903], "scatter_add": [1, 1859, 1861, 1903], "tensordot": [1, 1167, 1255, 1256, 1865, 1886, 1903], "binari": [1, 3, 32, 33, 39, 47, 49, 51, 56, 58, 71, 155, 732, 920, 1283, 1338, 1339, 1428, 1493, 1494, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1657, 1659, 1858, 1864, 1876, 1877, 1893, 1901, 1905, 1922], "nativ": [1, 3, 30, 39, 46, 63, 71, 989, 1120, 1200, 1606, 1607, 1751, 1860, 1863, 1875, 1886, 1888, 1904, 1905, 1913], "intervent": [1, 9, 1913], "mixtur": [1, 47, 1358, 1504], "bceloss": [1, 1339, 1493], "aren": [1, 9, 68, 71, 1120, 1876, 1883, 1914, 1928], "mean": [1, 3, 4, 6, 8, 9, 15, 16, 17, 21, 23, 24, 25, 33, 35, 38, 39, 41, 43, 45, 47, 58, 60, 63, 64, 66, 69, 70, 71, 254, 321, 335, 377, 453, 493, 515, 755, 757, 778, 791, 793, 858, 859, 918, 931, 962, 1119, 1121, 1200, 1290, 1307, 1312, 1317, 1321, 1322, 1328, 1329, 1330, 1332, 1333, 1334, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1356, 1358, 1360, 1364, 1366, 1367, 1368, 1372, 1373, 1374, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1392, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1408, 1409, 1411, 1412, 1413, 1414, 1421, 1425, 1426, 1427, 1429, 1430, 1436, 1437, 1440, 1441, 1442, 1449, 1451, 1452, 1453, 1454, 1455, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1470, 1471, 1472, 1492, 1493, 1494, 1502, 1504, 1505, 1513, 1514, 1518, 1529, 1530, 1533, 1534, 1538, 1544, 1552, 1553, 1554, 1555, 1556, 1564, 1575, 1576, 1587, 1588, 1602, 1650, 1678, 1711, 1720, 1721, 1765, 1785, 1802, 1803, 1809, 1843, 1845, 1846, 1857, 1859, 1860, 1861, 1862, 1873, 1875, 1876, 1877, 1878, 1881, 1882, 1883, 1886, 1887, 1888, 1890, 1891, 1894, 1900, 1901, 1903, 1904, 1905, 1907, 1908, 1909, 1910, 1913, 1914, 1915, 1917], "doesn": [1, 2, 3, 8, 9, 15, 16, 29, 30, 38, 41, 43, 66, 68, 70, 71, 820, 823, 877, 894, 904, 967, 988, 1120, 1131, 1197, 1203, 1229, 1253, 1261, 1270, 1350, 1351, 1352, 1359, 1388, 1455, 1496, 1497, 1498, 1533, 1577, 1602, 1603, 1625, 1667, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1782, 1785, 1850, 1859, 1860, 1863, 1864, 1876, 1878, 1883, 1884, 1886, 1888, 1889, 1893, 1896, 1900, 1904, 1906, 1914, 1917], "help": [1, 2, 5, 8, 9, 16, 18, 20, 21, 23, 29, 30, 32, 38, 39, 41, 55, 58, 63, 68, 71, 905, 906, 914, 988, 1020, 1120, 1121, 1131, 1190, 1191, 1209, 1291, 1303, 1304, 1361, 1362, 1363, 1367, 1422, 1609, 1758, 1850, 1857, 1863, 1870, 1876, 1877, 1882, 1883, 1884, 1886, 1887, 1889, 1892, 1894, 1897, 1901, 1902, 1905, 1913, 1914, 1917, 1925], "revers": [1, 47, 69, 71, 511, 731, 790, 898, 900, 1081, 1083, 1103, 1123, 1125, 1130, 1257, 1392, 1435, 1563, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1831, 1844, 1861, 1862, 1863, 1883, 1887, 1889, 1903, 1923], "therefor": [1, 4, 6, 18, 21, 38, 39, 41, 47, 48, 56, 63, 66, 447, 541, 904, 919, 928, 1009, 1097, 1114, 1116, 1119, 1147, 1148, 1202, 1205, 1235, 1248, 1365, 1366, 1473, 1512, 1513, 1521, 1644, 1683, 1863, 1882, 1883, 1886, 1888, 1890, 1893, 1901, 1915], "mani": [1, 4, 8, 13, 15, 16, 17, 20, 21, 23, 24, 28, 29, 30, 32, 38, 39, 41, 47, 58, 63, 67, 68, 71, 89, 402, 677, 886, 888, 898, 900, 1063, 1202, 1345, 1678, 1777, 1825, 1832, 1833, 1834, 1835, 1860, 1862, 1876, 1881, 1883, 1884, 1885, 1886, 1888, 1889, 1893, 1894, 1897, 1901, 1904, 1908, 1915, 1917, 1920, 1922, 1923, 1925], "sigmoid": [1, 47, 71, 524, 664, 665, 757, 792, 1338, 1339, 1365, 1374, 1375, 1392, 1393, 1451, 1493, 1520, 1574, 1859, 1861, 1876, 1877, 1881, 1902, 1903, 1910, 1918], "right": [1, 3, 8, 10, 16, 17, 22, 26, 41, 43, 47, 63, 71, 817, 862, 919, 926, 928, 929, 934, 939, 1057, 1063, 1104, 1107, 1108, 1112, 1143, 1147, 1148, 1152, 1156, 1187, 1209, 1234, 1239, 1250, 1252, 1253, 1261, 1267, 1268, 1312, 1330, 1335, 1336, 1337, 1338, 1339, 1350, 1351, 1352, 1369, 1376, 1389, 1390, 1391, 1410, 1411, 1412, 1413, 1415, 1416, 1417, 1425, 1426, 1427, 1431, 1432, 1438, 1470, 1473, 1474, 1475, 1476, 1521, 1541, 1559, 1607, 1614, 1667, 1681, 1682, 1723, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1804, 1824, 1829, 1831, 1844, 1857, 1861, 1863, 1875, 1876, 1877, 1883, 1888, 1891, 1901, 1904, 1911, 1915, 1918], "entropi": [1, 47, 1338, 1358, 1426, 1493, 1494, 1504, 1918], "combin": [1, 4, 13, 21, 38, 39, 41, 58, 69, 70, 614, 686, 709, 710, 711, 712, 713, 714, 715, 716, 790, 851, 887, 1020, 1092, 1093, 1098, 1100, 1152, 1284, 1294, 1339, 1369, 1383, 1428, 1473, 1515, 1538, 1621, 1860, 1861, 1862, 1882, 1886, 1889, 1901, 1903, 1904, 1906, 1908, 1911, 1913], "bcewithlogitsloss": [1, 1494], "bcewithlogit": 1, "safe": [1, 12, 17, 18, 21, 29, 41, 58, 70, 71, 1010, 1011, 1030, 1031, 1602, 1664, 1665, 1860, 1863, 1882, 1883, 1886, 1889, 1893, 1913], "_convolut": [1, 1903], "avg_pool3d": [1, 1861, 1903, 1910], "grid_sampler_2d": [1, 1859, 1861, 1903], "_grid_sampler_2d_cpu_fallback": [1, 1903], "grid_sampler_3d": [1, 1861, 1903], "polar": [1, 47, 1249, 1861, 1903], "quantil": [1, 1290, 1319, 1861, 1903, 1918], "nanquantil": [1, 1861, 1903], "stft": [1, 919, 928, 1147, 1148, 1187, 1209, 1861, 1903], "view_as_complex": [1, 30, 1861, 1903], "choleski": [1, 3, 47, 942, 943, 1220, 1226, 1262, 1861, 1903], "cholesky_invers": [1, 3, 1861, 1903], "cholesky_solv": [1, 3, 1861, 1903], "invers": [1, 47, 680, 681, 879, 882, 937, 942, 943, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1187, 1230, 1231, 1243, 1247, 1250, 1255, 1256, 1353, 1354, 1355, 1365, 1366, 1369, 1418, 1419, 1420, 1473, 1512, 1513, 1548, 1549, 1550, 1611, 1614, 1638, 1683, 1689, 1839, 1858, 1861, 1863, 1897, 1903, 1918], "lu_solv": [1, 3, 1237, 1861, 1903], "orgqr": [1, 1861, 1903], "ormqr": [1, 1135, 1229, 1861, 1903], "pinvers": [1, 1235, 1861, 1903], "max_pool3d": [1, 1861, 1903, 1910], "max_unpool2d": [1, 1516, 1546, 1861, 1903], "max_unpool3d": [1, 1517, 1547, 1861, 1903], "adaptive_avg_pool3d": [1, 1861, 1888, 1903, 1910], "reflection_pad1d": [1, 1861, 1903], "reflection_pad2d": [1, 1859, 1861, 1903], "replication_pad1d": [1, 1861, 1903], "replication_pad2d": [1, 1859, 1861, 1903], "replication_pad3d": [1, 1859, 1861, 1903], "ctc_loss": [1, 1345, 1861, 1903], "fft_fft": [1, 1861, 1903], "fft_ifft": [1, 1861, 1903], "fft_fft2": [1, 1861, 1903], "fft_ifft2": [1, 1861, 1903], "fft_fftn": [1, 1861, 1903], "fft_ifftn": [1, 1861, 1903], "fft_rfft": [1, 1861, 1903], "fft_irfft": [1, 1861, 1903], "fft_rfft2": [1, 1861, 1903], "fft_irfft2": [1, 1861, 1903], "fft_rfftn": [1, 1861, 1903], "fft_irfftn": [1, 1861, 1903], "fft_hfft": [1, 1861, 1903], "fft_ihfft": [1, 1861, 1903], "linalg_matrix_norm": [1, 1861, 1903], "linalg_cond": [1, 1861, 1903], "linalg_matrix_rank": [1, 1861, 1903], "linalg_solv": [1, 1861, 1903], "linalg_choleski": [1, 1861, 1903], "linalg_svdv": [1, 1861, 1903], "linalg_eigv": [1, 1861, 1903], "linalg_eigvalsh": [1, 1861, 1903], "linalg_inv": [1, 1861, 1903], "linalg_householder_product": [1, 1861, 1903], "linalg_tensorinv": [1, 1861, 1903], "linalg_tensorsolv": [1, 1861, 1903], "fake_quantize_per_tensor_affin": [1, 1861, 1903], "eig": [1, 1226, 1227, 1253, 1897], "geqrf": [1, 1229, 1695, 1861, 1903], "lstsq": [1, 1135, 1221, 1247], "_lu_with_info": [1, 1903], "qr": [1, 3, 1135, 1225, 1226, 1229, 1235, 1253, 1609, 1695, 1861, 1903], "solv": [1, 8, 17, 22, 30, 943, 1135, 1143, 1221, 1230, 1232, 1233, 1236, 1237, 1239, 1243, 1251, 1252, 1256, 1262, 1280, 1831, 1883, 1891, 1897, 1900], "svd": [1, 3, 30, 1225, 1226, 1235, 1247, 1254, 1270, 1614, 1697, 1809, 1859, 1861, 1897, 1903, 1917], "symeig": 1, "triangular_solv": [1, 1861, 1903], "fractional_max_pool2d": [1, 1861, 1903], "fractional_max_pool3d": [1, 1861, 1903], "adaptive_max_pool3d": [1, 1861, 1903], "multilabel_margin_loss_forward": [1, 1903], "linalg_qr": [1, 1861, 1903], "linalg_cholesky_ex": [1, 1861, 1903], "linalg_svd": [1, 1861, 1903], "linalg_eig": [1, 1861, 1903], "linalg_eigh": [1, 1861, 1903], "linalg_lstsq": [1, 1861, 1903], "linalg_inv_ex": [1, 1861, 1903], "cat": [1, 15, 41, 47, 71, 541, 744, 745, 754, 790, 793, 953, 954, 1291, 1441, 1789, 1859, 1860, 1861, 1876, 1901, 1903, 1905, 1908, 1910, 1917, 1926], "stack": [1, 9, 14, 16, 17, 18, 21, 22, 29, 35, 38, 39, 41, 47, 51, 67, 68, 71, 757, 914, 948, 1024, 1025, 1062, 1129, 1131, 1155, 1291, 1345, 1374, 1392, 1393, 1437, 1466, 1468, 1639, 1850, 1852, 1858, 1861, 1878, 1886, 1887, 1890, 1902, 1903, 1905, 1907, 1910, 1917], "index_copi": [1, 1843, 1861, 1903], "implement": [2, 3, 6, 9, 12, 15, 21, 24, 34, 38, 39, 41, 42, 43, 45, 46, 47, 50, 55, 56, 59, 63, 68, 71, 151, 511, 513, 515, 684, 735, 736, 737, 738, 739, 740, 757, 776, 778, 782, 790, 797, 816, 817, 818, 821, 822, 823, 875, 877, 890, 899, 905, 906, 960, 1063, 1106, 1111, 1116, 1123, 1124, 1126, 1127, 1190, 1197, 1199, 1200, 1203, 1245, 1248, 1261, 1262, 1290, 1330, 1345, 1359, 1374, 1390, 1391, 1422, 1428, 1434, 1441, 1458, 1467, 1469, 1521, 1559, 1571, 1579, 1602, 1606, 1607, 1609, 1610, 1614, 1625, 1638, 1642, 1643, 1646, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1681, 1683, 1689, 1707, 1714, 1727, 1736, 1739, 1776, 1785, 1808, 1809, 1824, 1840, 1843, 1862, 1863, 1864, 1867, 1870, 1875, 1878, 1879, 1881, 1882, 1883, 1885, 1886, 1888, 1889, 1890, 1893, 1894, 1896, 1897, 1898, 1899, 1900, 1904, 1905, 1906, 1908, 1911, 1913, 1914, 1917, 1918, 1921, 1923, 1925, 1928], "scalar": [2, 16, 28, 41, 47, 98, 151, 155, 260, 313, 445, 586, 684, 685, 735, 736, 737, 738, 739, 740, 876, 877, 890, 898, 899, 902, 904, 923, 926, 934, 958, 962, 1058, 1063, 1078, 1111, 1117, 1143, 1150, 1167, 1181, 1214, 1215, 1284, 1291, 1319, 1330, 1338, 1339, 1345, 1356, 1358, 1359, 1376, 1382, 1383, 1388, 1389, 1394, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1471, 1523, 1565, 1648, 1653, 1654, 1658, 1691, 1704, 1706, 1708, 1726, 1727, 1743, 1791, 1792, 1793, 1794, 1795, 1822, 1840, 1841, 1853, 1855, 1856, 1859, 1861, 1862, 1863, 1873, 1878, 1881, 1883, 1888, 1891, 1901, 1913, 1917, 1920, 1922, 1924, 1925], "minim": [2, 8, 9, 17, 29, 816, 872, 1292, 1659, 1661, 1662, 1663, 1664, 1665, 1666, 1675, 1676, 1677, 1678, 1691, 1857, 1873, 1882, 1886, 1894, 1896, 1899, 1901, 1906, 1908, 1925], "exist": [2, 8, 9, 10, 12, 13, 16, 18, 30, 32, 38, 41, 42, 43, 47, 49, 51, 56, 58, 59, 63, 67, 71, 83, 84, 254, 497, 789, 851, 875, 898, 899, 900, 901, 902, 903, 904, 905, 1004, 1190, 1194, 1205, 1225, 1230, 1236, 1237, 1262, 1319, 1422, 1423, 1432, 1783, 1857, 1859, 1860, 1867, 1870, 1875, 1876, 1878, 1879, 1883, 1884, 1886, 1888, 1889, 1892, 1893, 1894, 1895, 1897, 1901, 1905, 1906, 1907, 1908, 1913, 1915, 1917, 1921, 1923, 1925], "declar": [2, 10, 32, 38, 59, 1862, 1863, 1864, 1888, 1901, 1905, 1906, 1925], "requires_grad": [2, 6, 14, 16, 47, 69, 335, 444, 445, 446, 447, 448, 486, 494, 862, 877, 894, 896, 897, 905, 906, 908, 910, 911, 919, 928, 1009, 1064, 1065, 1066, 1067, 1076, 1081, 1099, 1116, 1117, 1118, 1121, 1131, 1147, 1148, 1165, 1190, 1209, 1260, 1276, 1338, 1339, 1358, 1365, 1366, 1376, 1388, 1389, 1413, 1414, 1422, 1428, 1429, 1436, 1469, 1470, 1493, 1494, 1504, 1556, 1602, 1603, 1604, 1605, 1642, 1647, 1653, 1654, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1753, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1785, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1843, 1850, 1855, 1856, 1859, 1861, 1865, 1876, 1877, 1878, 1886, 1888, 1889, 1894, 1899, 1901, 1903, 1913, 1914, 1923, 1924, 1925], "doubl": [2, 4, 49, 480, 486, 614, 746, 748, 749, 750, 751, 753, 763, 764, 778, 894, 896, 901, 905, 906, 935, 942, 952, 963, 1009, 1078, 1106, 1143, 1190, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1270, 1271, 1272, 1273, 1274, 1280, 1366, 1422, 1481, 1484, 1513, 1593, 1658, 1695, 1701, 1790, 1791, 1792, 1794, 1795, 1808, 1822, 1831, 1853, 1863, 1876, 1886, 1888, 1889, 1897, 1901, 1905, 1919, 1920, 1923, 1925], "bfloat16": [2, 39, 63, 1172, 1190, 1241, 1258, 1422, 1658, 1664, 1665, 1751, 1876, 1886, 1919, 1920, 1923, 1924, 1925, 1929], "cfloat": [2, 30, 41, 311, 482, 614, 942, 963, 1160, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1280, 1695, 1725, 1808, 1831, 1849, 1920, 1923, 1925], "cdoubl": [2, 30, 942, 963, 1190, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1280, 1422, 1695, 1808, 1831, 1920, 1923, 1925], "beta": [2, 3, 30, 64, 70, 100, 101, 106, 107, 108, 109, 110, 111, 152, 153, 321, 515, 551, 683, 686, 687, 688, 918, 964, 998, 999, 1006, 1007, 1009, 1147, 1209, 1284, 1294, 1340, 1341, 1342, 1377, 1383, 1385, 1386, 1387, 1394, 1410, 1453, 1458, 1461, 1538, 1539, 1571, 1575, 1579, 1664, 1665, 1666, 1668, 1674, 1678, 1711, 1769, 1771, 1782, 1786, 1800, 1858, 1859, 1861, 1871, 1886, 1901, 1908, 1913, 1917, 1920, 1925], "even": [2, 9, 12, 15, 16, 18, 20, 21, 38, 39, 41, 46, 49, 63, 70, 71, 541, 577, 812, 813, 814, 890, 962, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1094, 1095, 1096, 1099, 1130, 1175, 1202, 1219, 1221, 1225, 1226, 1227, 1228, 1242, 1246, 1248, 1249, 1253, 1254, 1259, 1284, 1290, 1359, 1461, 1496, 1497, 1498, 1559, 1602, 1609, 1647, 1649, 1689, 1736, 1747, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1808, 1848, 1860, 1863, 1864, 1873, 1878, 1882, 1883, 1886, 1888, 1890, 1892, 1894, 1896, 1897, 1898, 1899, 1904, 1905, 1906, 1915, 1920], "though": [2, 16, 41, 71, 151, 791, 887, 890, 900, 1079, 1080, 1082, 1188, 1191, 1284, 1649, 1860, 1864, 1877, 1878, 1883, 1889, 1896, 1897, 1904, 1908], "signatur": [2, 20, 21, 38, 51, 63, 71, 398, 486, 553, 910, 911, 965, 1190, 1422, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1614, 1635, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1804, 1886, 1888, 1889, 1901, 1905, 1906, 1913, 1917, 1928], "veri": [2, 5, 8, 9, 16, 17, 18, 20, 21, 22, 28, 29, 35, 38, 39, 41, 67, 69, 71, 960, 1121, 1129, 1131, 1252, 1385, 1386, 1387, 1602, 1603, 1609, 1667, 1689, 1695, 1772, 1776, 1831, 1850, 1862, 1875, 1883, 1888, 1890, 1891, 1892, 1894, 1896, 1897, 1900, 1904, 1905, 1912, 1913, 1914, 1917], "unlik": [2, 4, 8, 15, 18, 47, 63, 69, 491, 1060, 1099, 1102, 1106, 1165, 1225, 1226, 1245, 1248, 1253, 1257, 1287, 1290, 1292, 1394, 1604, 1605, 1726, 1748, 1847, 1862, 1863, 1875, 1878, 1886, 1896, 1898, 1920, 1925], "coverag": [2, 8, 20, 64, 71, 1123, 1124, 1858, 1860, 1865, 1877, 1908, 1917, 1928], "plan": [2, 3, 8, 10, 15, 28, 29, 41, 43, 46, 891, 1602, 1707, 1878, 1883, 1888, 1905, 1917], "consid": [2, 6, 9, 15, 28, 39, 41, 49, 58, 63, 68, 70, 71, 691, 776, 782, 791, 898, 900, 901, 905, 943, 962, 1050, 1051, 1052, 1053, 1054, 1084, 1119, 1179, 1183, 1186, 1190, 1230, 1232, 1233, 1234, 1235, 1243, 1244, 1247, 1252, 1255, 1358, 1369, 1422, 1425, 1473, 1486, 1521, 1532, 1590, 1603, 1609, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1644, 1677, 1745, 1765, 1799, 1832, 1833, 1834, 1835, 1857, 1860, 1863, 1867, 1870, 1882, 1883, 1884, 1888, 1890, 1891, 1894, 1897, 1905, 1907, 1909, 1914, 1915, 1917, 1920, 1923, 1924, 1928], "ad": [2, 4, 10, 13, 16, 17, 20, 24, 28, 32, 38, 39, 41, 45, 47, 55, 63, 66, 68, 69, 70, 71, 222, 223, 313, 319, 470, 513, 677, 683, 684, 685, 686, 687, 688, 732, 891, 892, 893, 898, 899, 900, 901, 905, 917, 918, 1063, 1067, 1123, 1124, 1126, 1165, 1190, 1203, 1267, 1335, 1336, 1337, 1339, 1340, 1341, 1342, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1428, 1429, 1431, 1436, 1450, 1461, 1465, 1473, 1499, 1500, 1501, 1518, 1545, 1546, 1547, 1571, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1614, 1621, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1647, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1711, 1712, 1713, 1753, 1782, 1786, 1800, 1857, 1858, 1859, 1860, 1862, 1867, 1873, 1877, 1882, 1889, 1891, 1893, 1894, 1905, 1908, 1911, 1917, 1922, 1925], "tutori": [2, 4, 10, 16, 20, 22, 33, 41, 42, 45, 71, 891, 892, 893, 896, 1858, 1860, 1867, 1870, 1879, 1888, 1893, 1894, 1899, 1901, 1908], "how": [2, 4, 6, 8, 9, 10, 15, 18, 20, 21, 22, 23, 27, 33, 34, 38, 41, 43, 46, 50, 58, 59, 60, 63, 64, 65, 67, 68, 71, 486, 782, 789, 790, 793, 838, 856, 858, 859, 891, 892, 893, 896, 910, 911, 1046, 1067, 1120, 1129, 1143, 1165, 1190, 1200, 1261, 1369, 1422, 1473, 1474, 1559, 1590, 1602, 1635, 1647, 1727, 1751, 1753, 1766, 1777, 1858, 1860, 1862, 1863, 1867, 1870, 1872, 1875, 1876, 1877, 1879, 1882, 1885, 1887, 1889, 1890, 1891, 1894, 1896, 1898, 1899, 1901, 1906, 1908, 1911, 1913, 1914, 1915, 1922], "major": [2, 7, 8, 9, 10, 15, 17, 20, 23, 991, 1808, 1858, 1863, 1904], "build": [2, 9, 10, 12, 20, 29, 32, 33, 41, 47, 71, 1190, 1199, 1422, 1468, 1486, 1521, 1858, 1860, 1870, 1879, 1883, 1901, 1906, 1908, 1914, 1922, 1923], "basic": [2, 4, 8, 10, 17, 21, 43, 58, 71, 1123, 1124, 1125, 1196, 1262, 1602, 1683, 1858, 1864, 1879, 1884, 1886, 1887, 1891, 1905, 1914, 1921, 1922], "jacobian": [2, 47, 64, 65, 67, 68, 890, 892, 898, 901, 903, 904, 905, 906, 1124, 1125, 1126, 1130, 1131, 1850, 1883, 1888, 1891], "hessian": [2, 64, 67, 68, 899, 902, 1124, 1125, 1881, 1889], "etc": [2, 4, 6, 12, 14, 18, 21, 27, 30, 38, 39, 41, 47, 49, 58, 59, 63, 856, 857, 858, 1187, 1190, 1358, 1422, 1602, 1656, 1729, 1857, 1862, 1863, 1870, 1888, 1889, 1890, 1894, 1896, 1901, 1904, 1905, 1908, 1913, 1917, 1919, 1922, 1925], "user": [2, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 20, 21, 22, 24, 29, 30, 33, 38, 39, 41, 42, 43, 46, 47, 48, 49, 51, 55, 58, 59, 61, 63, 64, 67, 68, 70, 71, 151, 335, 729, 735, 736, 737, 742, 743, 753, 761, 791, 794, 796, 835, 851, 858, 859, 890, 896, 904, 967, 1000, 1114, 1119, 1120, 1190, 1261, 1422, 1465, 1467, 1468, 1469, 1571, 1597, 1602, 1611, 1625, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1857, 1858, 1860, 1862, 1863, 1867, 1870, 1875, 1877, 1878, 1882, 1883, 1884, 1886, 1888, 1891, 1892, 1893, 1894, 1896, 1901, 1902, 1904, 1906, 1907, 1908, 1910, 1913, 1914, 1917, 1921, 1922, 1924, 1928], "lambda": [2, 38, 43, 47, 66, 69, 70, 71, 258, 486, 910, 911, 938, 1121, 1126, 1130, 1131, 1225, 1226, 1227, 1228, 1261, 1378, 1459, 1471, 1561, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1677, 1683, 1685, 1688, 1850, 1864, 1883, 1888, 1889, 1904, 1905, 1913, 1924, 1928], "three": [2, 3, 7, 10, 25, 41, 45, 46, 63, 65, 68, 71, 885, 1061, 1063, 1143, 1152, 1233, 1236, 1237, 1238, 1253, 1281, 1337, 1352, 1355, 1394, 1417, 1571, 1609, 1649, 1683, 1751, 1863, 1883, 1886, 1887, 1888, 1901, 1905, 1906, 1908, 1913, 1915, 1917, 1922], "anoth": [2, 6, 8, 12, 13, 17, 21, 24, 28, 38, 39, 41, 43, 47, 48, 49, 60, 63, 71, 485, 964, 966, 967, 969, 1114, 1199, 1225, 1226, 1229, 1253, 1365, 1366, 1423, 1432, 1593, 1610, 1747, 1860, 1862, 1863, 1869, 1882, 1883, 1885, 1886, 1888, 1894, 1896, 1900, 1905, 1906, 1914, 1915, 1917, 1923, 1925], "constant": [2, 16, 20, 21, 38, 71, 741, 772, 818, 819, 1046, 1103, 1104, 1105, 1187, 1190, 1194, 1205, 1237, 1262, 1347, 1348, 1349, 1366, 1369, 1376, 1431, 1453, 1473, 1518, 1521, 1559, 1610, 1659, 1675, 1680, 1683, 1829, 1861, 1863, 1882, 1888, 1894, 1898, 1901, 1904, 1917], "boolean": [2, 32, 47, 58, 71, 400, 402, 886, 922, 924, 925, 927, 966, 967, 969, 1068, 1134, 1146, 1179, 1180, 1181, 1182, 1183, 1186, 1214, 1262, 1278, 1283, 1323, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1461, 1571, 1611, 1614, 1707, 1802, 1803, 1826, 1845, 1846, 1862, 1864, 1888, 1919, 1920, 1922, 1923, 1924, 1925], "inform": [2, 3, 4, 5, 8, 9, 10, 15, 16, 21, 23, 29, 34, 35, 37, 38, 39, 41, 42, 45, 49, 50, 51, 54, 58, 59, 63, 65, 71, 192, 209, 255, 313, 321, 486, 496, 513, 515, 615, 677, 732, 900, 905, 906, 910, 911, 921, 1067, 1098, 1100, 1120, 1165, 1187, 1190, 1206, 1219, 1226, 1235, 1350, 1351, 1352, 1353, 1354, 1355, 1383, 1392, 1418, 1419, 1420, 1422, 1428, 1437, 1449, 1465, 1467, 1469, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1513, 1532, 1571, 1590, 1591, 1592, 1602, 1635, 1647, 1659, 1706, 1733, 1753, 1758, 1783, 1843, 1860, 1863, 1869, 1870, 1878, 1879, 1883, 1885, 1886, 1887, 1888, 1893, 1894, 1897, 1901, 1902, 1905, 1907, 1908, 1920, 1922, 1923, 1924, 1927, 1929], "relat": [2, 7, 8, 10, 38, 41, 49, 62, 63, 68, 677, 1143, 1229, 1369, 1453, 1473, 1602, 1697, 1878, 1883, 1905, 1913, 1917, 1918, 1924, 1928], "mechan": [2, 9, 12, 41, 52, 56, 58, 71, 876, 1067, 1165, 1190, 1422, 1571, 1647, 1753, 1822, 1858, 1875, 1878, 1887, 1888, 1893, 1894, 1911, 1913, 1914], "confus": [2, 9, 18, 21, 1190, 1422, 1883, 1886, 1905, 1917], "receiv": [2, 8, 10, 15, 21, 29, 38, 41, 45, 47, 68, 70, 1020, 1190, 1422, 1598, 1599, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1692, 1863, 1873, 1875, 1882, 1883, 1896, 1906, 1913, 1914, 1915, 1917], "memori": [2, 3, 4, 6, 12, 16, 17, 20, 22, 25, 28, 30, 39, 43, 45, 47, 48, 63, 67, 71, 151, 156, 171, 173, 176, 179, 180, 181, 196, 207, 210, 240, 254, 267, 297, 325, 331, 337, 339, 340, 393, 444, 445, 446, 447, 448, 457, 462, 485, 497, 498, 521, 522, 577, 600, 614, 731, 760, 875, 877, 890, 896, 905, 906, 932, 947, 964, 965, 968, 971, 972, 974, 988, 989, 998, 999, 1002, 1006, 1008, 1009, 1012, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1022, 1027, 1028, 1029, 1033, 1063, 1064, 1065, 1066, 1114, 1115, 1116, 1118, 1119, 1120, 1125, 1127, 1131, 1190, 1207, 1235, 1298, 1299, 1300, 1307, 1366, 1392, 1393, 1422, 1465, 1466, 1467, 1469, 1571, 1589, 1602, 1609, 1635, 1647, 1654, 1656, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1716, 1717, 1719, 1720, 1721, 1722, 1822, 1843, 1850, 1856, 1858, 1860, 1871, 1875, 1877, 1878, 1883, 1888, 1896, 1901, 1906, 1907, 1908, 1913, 1917, 1919, 1920, 1921, 1923, 1924], "overlap": [2, 15, 17, 28, 38, 39, 41, 45, 63, 71, 875, 905, 906, 1066, 1120, 1187, 1369, 1473, 1602, 1804, 1843, 1886, 1887, 1920], "dens": [2, 15, 45, 219, 542, 543, 580, 581, 582, 583, 584, 585, 919, 928, 1147, 1148, 1209, 1262, 1678, 1779, 1782, 1785, 1786, 1789, 1790, 1791, 1792, 1794, 1795, 1800, 1809, 1843, 1878, 1898, 1917, 1920], "stride": [2, 14, 15, 16, 29, 30, 139, 222, 254, 339, 444, 445, 446, 447, 448, 497, 518, 541, 578, 580, 581, 582, 584, 585, 614, 709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 765, 766, 769, 770, 771, 779, 780, 862, 875, 919, 928, 1064, 1066, 1076, 1081, 1099, 1117, 1118, 1147, 1148, 1154, 1190, 1199, 1203, 1209, 1260, 1276, 1294, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1390, 1391, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1434, 1473, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1515, 1542, 1543, 1545, 1546, 1547, 1548, 1549, 1550, 1589, 1602, 1653, 1712, 1713, 1716, 1718, 1719, 1720, 1722, 1723, 1730, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1785, 1828, 1833, 1835, 1848, 1855, 1859, 1861, 1864, 1876, 1901, 1903, 1913, 1917, 1919, 1920, 1922, 1923, 1924], "thu": [2, 30, 38, 41, 47, 59, 63, 71, 782, 819, 822, 851, 1063, 1084, 1253, 1284, 1362, 1474, 1590, 1602, 1664, 1665, 1675, 1793, 1860, 1863, 1870, 1871, 1883, 1885, 1890, 1891, 1893, 1894, 1901, 1908, 1913, 1917, 1921, 1923, 1924], "rowmajor": [2, 1602], "contigu": [2, 30, 39, 43, 331, 497, 518, 614, 1368, 1425, 1561, 1602, 1724, 1730, 1808, 1861, 1877, 1878, 1903, 1910, 1917, 1919, 1921], "create_graph": [2, 151, 890, 898, 899, 900, 901, 902, 903, 904, 1861, 1882], "preserv": [2, 12, 16, 38, 47, 63, 71, 497, 776, 782, 851, 873, 876, 1104, 1105, 1120, 1194, 1200, 1423, 1432, 1474, 1532, 1590, 1660, 1739, 1743, 1781, 1822, 1860, 1871, 1876, 1878, 1881, 1886, 1889, 1898, 1901, 1913, 1917, 1920], "preexist": [2, 15, 16], "let": [2, 8, 9, 12, 13, 16, 20, 21, 23, 28, 29, 38, 39, 46, 47, 59, 68, 71, 485, 494, 945, 1143, 1190, 1209, 1219, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1235, 1236, 1239, 1241, 1248, 1250, 1252, 1253, 1422, 1602, 1609, 1822, 1867, 1876, 1877, 1883, 1886, 1887, 1888, 1889, 1894, 1896, 1897, 1898, 1899, 1900, 1905, 1914, 1915, 1917, 1922], "first": [2, 5, 6, 8, 10, 12, 13, 14, 15, 16, 17, 21, 28, 29, 32, 35, 38, 39, 41, 42, 43, 45, 46, 47, 49, 51, 55, 58, 59, 63, 69, 71, 217, 254, 290, 586, 607, 683, 686, 688, 691, 757, 790, 791, 811, 851, 854, 856, 871, 872, 881, 886, 887, 888, 889, 904, 905, 918, 922, 923, 925, 926, 927, 930, 932, 934, 948, 963, 966, 977, 1051, 1053, 1054, 1055, 1060, 1063, 1068, 1081, 1083, 1102, 1116, 1121, 1122, 1124, 1125, 1126, 1130, 1131, 1134, 1143, 1146, 1154, 1155, 1156, 1167, 1179, 1188, 1197, 1202, 1203, 1209, 1214, 1219, 1222, 1229, 1245, 1248, 1255, 1256, 1258, 1261, 1262, 1278, 1284, 1287, 1290, 1291, 1292, 1294, 1310, 1312, 1318, 1323, 1326, 1330, 1336, 1337, 1343, 1351, 1352, 1354, 1355, 1365, 1366, 1368, 1373, 1374, 1388, 1391, 1392, 1407, 1414, 1416, 1417, 1437, 1450, 1503, 1589, 1593, 1602, 1611, 1612, 1614, 1625, 1635, 1641, 1664, 1665, 1666, 1667, 1668, 1674, 1677, 1678, 1682, 1686, 1689, 1691, 1697, 1707, 1708, 1734, 1735, 1743, 1771, 1785, 1788, 1793, 1823, 1824, 1828, 1833, 1835, 1841, 1844, 1847, 1850, 1852, 1857, 1860, 1862, 1863, 1870, 1872, 1875, 1876, 1878, 1882, 1883, 1886, 1888, 1890, 1891, 1894, 1896, 1897, 1898, 1899, 1900, 1901, 1904, 1906, 1907, 1908, 1913, 1914, 1915, 1917, 1918, 1922, 1926, 1928], "accord": [2, 10, 29, 49, 794, 858, 859, 877, 920, 932, 1061, 1153, 1250, 1283, 1312, 1330, 1366, 1593, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1683, 1689, 1708, 1772, 1796, 1823, 1851, 1863, 1873, 1877, 1878, 1881, 1894, 1898, 1900, 1905, 1915, 1924], "retain": [2, 10, 41, 690, 692, 693, 696, 871, 872, 877, 1194, 1211, 1242, 1246, 1259, 1277, 1287, 1289, 1290, 1292, 1295, 1317, 1318, 1319, 1320, 1649, 1705, 1708, 1739, 1802, 1803, 1807, 1832, 1833, 1834, 1835, 1845, 1846, 1875, 1896], "over": [2, 10, 12, 15, 16, 17, 21, 22, 29, 38, 39, 41, 42, 46, 47, 49, 56, 59, 63, 64, 65, 66, 67, 68, 69, 71, 480, 677, 694, 735, 736, 737, 738, 739, 740, 763, 764, 769, 770, 771, 779, 780, 889, 914, 937, 975, 1020, 1022, 1026, 1040, 1041, 1042, 1043, 1044, 1045, 1063, 1119, 1123, 1125, 1129, 1131, 1143, 1151, 1190, 1205, 1222, 1242, 1246, 1258, 1259, 1261, 1269, 1289, 1291, 1320, 1327, 1328, 1329, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1366, 1369, 1370, 1371, 1377, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1394, 1410, 1413, 1414, 1415, 1416, 1417, 1422, 1425, 1426, 1427, 1429, 1436, 1450, 1453, 1454, 1456, 1461, 1470, 1473, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1505, 1516, 1517, 1533, 1539, 1542, 1543, 1545, 1546, 1547, 1556, 1557, 1564, 1571, 1597, 1606, 1646, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1712, 1713, 1728, 1787, 1789, 1802, 1803, 1804, 1807, 1824, 1839, 1845, 1846, 1850, 1863, 1873, 1875, 1876, 1877, 1882, 1884, 1885, 1887, 1888, 1889, 1891, 1894, 1896, 1897, 1904, 1913, 1914, 1917, 1925], "fact": [2, 4, 9, 12, 16, 23, 63, 493, 919, 928, 956, 1143, 1147, 1148, 1225, 1226, 1253, 1860, 1888, 1891, 1901, 1914, 1917], "phase": [2, 17, 29, 39, 790, 1225, 1226, 1689, 1808, 1861, 1900], "recreat": [2, 28, 1883], "altern": [2, 10, 17, 38, 41, 71, 677, 811, 1123, 1124, 1152, 1197, 1261, 1450, 1467, 1469, 1540, 1602, 1654, 1678, 1750, 1843, 1856, 1857, 1864, 1883, 1892, 1894, 1897, 1898, 1900], "never": [2, 6, 8, 12, 15, 39, 41, 58, 59, 222, 223, 793, 876, 938, 1187, 1236, 1237, 1248, 1261, 1602, 1635, 1883, 1886, 1888, 1905, 1906, 1913, 1924], "long": [2, 8, 10, 17, 29, 38, 58, 70, 731, 746, 748, 749, 750, 751, 753, 760, 778, 1120, 1166, 1290, 1295, 1318, 1345, 1358, 1366, 1392, 1393, 1429, 1505, 1658, 1706, 1819, 1823, 1833, 1835, 1840, 1858, 1863, 1870, 1875, 1876, 1877, 1883, 1884, 1886, 1888, 1890, 1896, 1898, 1901, 1905, 1907, 1912, 1919, 1920, 1922, 1923], "hard": [2, 8, 9, 17, 18, 20, 41, 46, 59, 1063, 1262, 1378, 1523, 1524, 1860, 1861, 1862, 1883, 1901, 1905], "matter": [2, 5, 41, 63, 894, 1051, 1063, 1197, 1200, 1205, 1602, 1878, 1883, 1905], "discourag": [2, 1032, 1036, 1883, 1913], "aggress": [2, 17, 1187, 1883, 1913], "buffer": [2, 5, 17, 38, 39, 41, 63, 67, 877, 977, 1009, 1116, 1119, 1129, 1190, 1197, 1200, 1211, 1261, 1340, 1341, 1342, 1359, 1395, 1396, 1397, 1422, 1461, 1595, 1602, 1604, 1611, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1632, 1642, 1644, 1657, 1675, 1677, 1739, 1781, 1826, 1862, 1879, 1883, 1887, 1888, 1894, 1899, 1901, 1906], "free": [2, 8, 15, 41, 43, 47, 49, 58, 59, 63, 71, 1015, 1033, 1193, 1205, 1262, 1871, 1881, 1883, 1886, 1888, 1890, 1896, 1900, 1901], "reus": [2, 12, 15, 17, 29, 41, 46, 71, 485, 1859, 1883, 1886, 1913], "effici": [2, 3, 4, 9, 30, 38, 47, 63, 64, 69, 151, 757, 890, 895, 904, 940, 1127, 1135, 1207, 1245, 1262, 1281, 1330, 1361, 1362, 1363, 1366, 1367, 1374, 1428, 1434, 1435, 1469, 1571, 1871, 1878, 1883, 1887, 1888, 1891, 1895, 1897, 1904, 1906, 1908, 1913, 1914, 1917, 1920, 1921, 1925], "occas": [2, 8, 1883], "actual": [2, 9, 15, 16, 17, 20, 21, 22, 27, 43, 49, 51, 63, 68, 71, 787, 955, 1081, 1099, 1201, 1205, 1353, 1354, 1355, 1521, 1602, 1626, 1656, 1678, 1683, 1857, 1862, 1863, 1876, 1883, 1886, 1887, 1888, 1891, 1896, 1900, 1908, 1913, 1919, 1924], "signific": [2, 4, 20, 24, 43, 1691, 1883, 1886, 1917], "amount": [2, 3, 4, 5, 8, 15, 23, 29, 38, 41, 43, 49, 58, 71, 906, 988, 1014, 1016, 1020, 1187, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1369, 1410, 1425, 1473, 1504, 1619, 1620, 1622, 1623, 1625, 1627, 1628, 1629, 1630, 1631, 1632, 1877, 1883, 1885, 1886, 1889, 1890, 1892, 1913, 1917], "heavi": [2, 16, 41, 1883, 1900], "pressur": [2, 1883], "keep": [2, 4, 8, 15, 16, 21, 38, 39, 43, 45, 49, 58, 63, 967, 1261, 1340, 1341, 1342, 1346, 1365, 1385, 1386, 1387, 1431, 1461, 1521, 1532, 1602, 1621, 1660, 1728, 1857, 1858, 1860, 1875, 1877, 1878, 1883, 1886, 1887, 1889, 1890, 1891, 1896, 1902, 1904, 1908, 1913, 1914, 1915], "track": [2, 15, 16, 17, 21, 25, 27, 49, 335, 972, 1012, 1014, 1027, 1028, 1029, 1119, 1120, 1165, 1291, 1340, 1341, 1342, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1602, 1621, 1873, 1875, 1877, 1878, 1883, 1886, 1888, 1889, 1890, 1893, 1894, 1902, 1904, 1906, 1907, 1914, 1915, 1917], "save": [2, 6, 8, 12, 17, 30, 33, 39, 41, 43, 45, 63, 494, 834, 886, 887, 896, 1127, 1189, 1190, 1195, 1197, 1205, 1207, 1261, 1422, 1602, 1656, 1657, 1679, 1685, 1688, 1692, 1860, 1861, 1872, 1877, 1888, 1889, 1894, 1896, 1898, 1901, 1903, 1904, 1905, 1907, 1917, 1922, 1926], "afterward": [2, 1422, 1593, 1602], "start": [2, 4, 5, 9, 10, 15, 17, 22, 25, 38, 39, 41, 43, 49, 55, 57, 58, 59, 60, 63, 67, 70, 71, 402, 432, 433, 494, 535, 695, 862, 1012, 1014, 1025, 1027, 1028, 1085, 1086, 1102, 1116, 1188, 1202, 1215, 1260, 1276, 1321, 1322, 1330, 1335, 1336, 1337, 1366, 1368, 1415, 1416, 1417, 1423, 1425, 1513, 1559, 1602, 1616, 1620, 1622, 1635, 1661, 1683, 1689, 1723, 1754, 1777, 1790, 1791, 1792, 1794, 1795, 1857, 1858, 1859, 1861, 1862, 1867, 1870, 1875, 1877, 1883, 1884, 1886, 1887, 1890, 1894, 1895, 1896, 1900, 1901, 1904, 1907, 1913, 1914, 1915, 1917], "sure": [2, 8, 10, 17, 20, 29, 38, 41, 43, 48, 50, 59, 61, 66, 71, 858, 859, 890, 1067, 1114, 1165, 1194, 1205, 1206, 1262, 1602, 1647, 1685, 1826, 1863, 1876, 1883, 1887, 1890, 1891, 1900, 1901, 1907, 1908, 1913, 1914, 1915, 1917, 1922], "longer": [2, 12, 29, 41, 60, 67, 68, 684, 887, 905, 906, 1187, 1194, 1602, 1649, 1873, 1883, 1886, 1913, 1915], "find": [2, 8, 15, 16, 17, 18, 21, 22, 23, 28, 29, 32, 41, 58, 68, 71, 83, 1063, 1143, 1211, 1262, 1353, 1354, 1355, 1392, 1659, 1697, 1708, 1743, 1809, 1857, 1871, 1875, 1877, 1883, 1885, 1886, 1887, 1888, 1890, 1891, 1896, 1898, 1901, 1903, 1908, 1913, 1917, 1920, 1922, 1924, 1926, 1928], "quick": [2, 8, 66, 1870, 1894], "guid": [2, 9, 10, 21, 22, 27, 38, 83, 84, 1201, 1858, 1886, 1889, 1905, 1908], "var": [2, 15, 21, 29, 51, 56, 58, 61, 1340, 1341, 1342, 1376, 1377, 1385, 1386, 1387, 1394, 1461, 1518, 1711, 1846, 1859, 1861, 1863, 1876, 1903], "detach": [2, 6, 28, 223, 447, 457, 947, 1119, 1190, 1345, 1422, 1505, 1523, 1785, 1822, 1860, 1861, 1876, 1878, 1890, 1901, 1903, 1910, 1917, 1921, 1923], "register_hook": [2, 1876, 1883], "factori": [2, 3, 16, 30, 47, 49, 52, 56, 68, 821, 1063, 1647, 1659, 1747, 1858, 1861, 1877, 1886, 1903, 1920], "ones": [2, 17, 19, 23, 28, 29, 38, 41, 45, 47, 63, 68, 69, 70, 71, 151, 254, 313, 402, 444, 445, 447, 513, 791, 856, 890, 899, 901, 902, 903, 904, 905, 920, 932, 950, 1046, 1054, 1076, 1119, 1126, 1127, 1130, 1165, 1187, 1190, 1201, 1210, 1236, 1252, 1261, 1339, 1365, 1369, 1376, 1377, 1394, 1422, 1426, 1427, 1429, 1431, 1473, 1512, 1571, 1589, 1593, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1626, 1639, 1641, 1644, 1654, 1658, 1711, 1728, 1746, 1777, 1825, 1829, 1853, 1861, 1863, 1865, 1876, 1877, 1883, 1884, 1886, 1888, 1895, 1897, 1898, 1901, 1903, 1904, 1905, 1908, 1913, 1915, 1918, 1920, 1923], "autograd_tensor": 2, "base": [2, 4, 8, 10, 14, 15, 17, 19, 20, 21, 32, 33, 38, 41, 42, 43, 45, 46, 47, 49, 51, 56, 58, 59, 60, 63, 68, 71, 76, 788, 793, 797, 799, 817, 818, 819, 821, 822, 858, 859, 896, 917, 950, 962, 1024, 1025, 1061, 1063, 1106, 1143, 1153, 1192, 1203, 1215, 1253, 1264, 1266, 1268, 1276, 1359, 1422, 1425, 1426, 1427, 1431, 1465, 1467, 1469, 1538, 1571, 1602, 1606, 1607, 1609, 1616, 1620, 1622, 1661, 1662, 1663, 1664, 1665, 1666, 1675, 1676, 1677, 1678, 1704, 1714, 1739, 1753, 1808, 1809, 1823, 1833, 1835, 1851, 1858, 1861, 1863, 1885, 1886, 1887, 1888, 1894, 1902, 1906, 1907, 1908, 1913, 1914, 1917, 1918, 1921, 1922, 1924, 1926, 1927], "Then": [2, 12, 18, 41, 59, 71, 1369, 1473, 1611, 1659, 1883, 1884, 1887, 1888, 1889, 1897, 1898, 1901, 1904, 1905, 1913, 1914, 1926], "ctx": [2, 56, 886, 887, 888, 894, 895, 896, 897, 1882, 1888, 1889, 1901], "gradcheck": [2, 906, 1858, 1888], "extend": [2, 38, 41, 43, 47, 50, 60, 71, 858, 887, 889, 896, 1424, 1433, 1858, 1867, 1878, 1883, 1893, 1895, 1896, 1901, 1903, 1905, 1911, 1917, 1928], "staticmethod": [2, 887, 889, 894, 895, 896, 897, 1863, 1882, 1888, 1901, 1913], "save_for_backward": [2, 887, 895, 897, 1882, 1883, 1888, 1889, 1901], "grad_output": [2, 886, 894, 904, 906, 910, 911, 1190, 1422, 1598, 1599, 1859, 1861, 1883, 1886, 1888, 1889, 1894], "saved_tensor": [2, 895, 896, 897, 1882, 1883, 1888, 1889], "avail": [2, 3, 6, 9, 10, 17, 20, 22, 29, 32, 33, 38, 41, 49, 58, 59, 83, 84, 986, 988, 989, 1000, 1003, 1010, 1011, 1030, 1031, 1033, 1063, 1196, 1253, 1254, 1279, 1465, 1474, 1532, 1571, 1590, 1697, 1751, 1804, 1809, 1843, 1857, 1858, 1860, 1862, 1863, 1867, 1870, 1875, 1883, 1886, 1888, 1892, 1894, 1895, 1898, 1900, 1904, 1905, 1907, 1908, 1909, 1913, 1927, 1928], "cost": [2, 4, 5, 9, 10, 24, 29, 39, 63, 940, 1245, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1747, 1886, 1898, 1909, 1914, 1920], "cpu": [2, 5, 6, 12, 16, 20, 23, 25, 26, 29, 32, 34, 38, 41, 43, 63, 89, 120, 197, 289, 326, 335, 444, 445, 446, 447, 448, 457, 577, 586, 862, 877, 915, 919, 928, 960, 966, 976, 977, 978, 980, 1064, 1066, 1076, 1081, 1099, 1111, 1116, 1117, 1140, 1141, 1147, 1148, 1190, 1197, 1199, 1200, 1209, 1219, 1221, 1225, 1226, 1227, 1228, 1230, 1232, 1235, 1237, 1238, 1244, 1247, 1250, 1253, 1254, 1260, 1261, 1276, 1279, 1290, 1359, 1365, 1422, 1465, 1586, 1602, 1606, 1607, 1635, 1636, 1650, 1653, 1707, 1716, 1718, 1720, 1722, 1723, 1747, 1752, 1754, 1755, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1776, 1785, 1790, 1791, 1792, 1793, 1794, 1795, 1808, 1822, 1823, 1824, 1833, 1835, 1840, 1843, 1855, 1858, 1860, 1861, 1863, 1867, 1871, 1875, 1876, 1878, 1886, 1889, 1892, 1894, 1896, 1897, 1898, 1900, 1901, 1903, 1906, 1907, 1909, 1912, 1913, 1917, 1919, 1920, 1923, 1924, 1925], "There": [2, 6, 7, 8, 10, 12, 15, 16, 17, 21, 22, 23, 28, 29, 32, 37, 41, 43, 58, 64, 68, 69, 71, 677, 731, 790, 887, 1120, 1359, 1392, 1437, 1571, 1602, 1642, 1647, 1857, 1860, 1862, 1863, 1869, 1870, 1877, 1883, 1886, 1888, 1889, 1890, 1893, 1896, 1900, 1901, 1905, 1908, 1909, 1913, 1915, 1923, 1925], "moment": [2, 21, 25, 769, 770, 771, 958, 1664, 1665, 1666, 1668, 1674, 1678, 1871, 1875, 1878, 1907, 1913], "nvprof": [2, 5, 912, 1886], "regist": [2, 16, 19, 20, 24, 33, 39, 41, 45, 46, 47, 58, 60, 63, 71, 83, 84, 486, 677, 789, 790, 851, 910, 911, 950, 1009, 1190, 1261, 1422, 1423, 1424, 1432, 1433, 1450, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1603, 1609, 1610, 1611, 1612, 1614, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1867, 1873, 1875, 1887, 1888, 1893, 1894, 1901, 1905, 1913], "activ": [2, 6, 8, 10, 12, 16, 29, 60, 63, 69, 789, 791, 793, 800, 804, 838, 839, 848, 858, 859, 965, 974, 989, 1002, 1020, 1119, 1121, 1131, 1262, 1334, 1361, 1362, 1363, 1367, 1377, 1394, 1421, 1423, 1440, 1451, 1465, 1467, 1469, 1514, 1551, 1574, 1602, 1612, 1613, 1614, 1644, 1649, 1850, 1858, 1859, 1871, 1875, 1886, 1888, 1889, 1894, 1901, 1904, 1906, 1907, 1908, 1909, 1910, 1913, 1917, 1926, 1927], "emit_nvtx": [2, 5], "vtune": [2, 5], "emit_itt": [2, 5], "use_cuda": [2, 1907], "record_shap": [2, 1907], "with_flop": [2, 1907], "profile_memori": [2, 1907], "with_stack": [2, 1907], "with_modul": [2, 1907], "use_kineto": 2, "use_cpu": 2, "experimental_config": [2, 1907], "hold": [2, 15, 21, 41, 56, 58, 60, 61, 63, 67, 70, 71, 534, 1262, 1369, 1423, 1424, 1432, 1433, 1473, 1593, 1602, 1604, 1605, 1611, 1621, 1635, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1790, 1791, 1792, 1793, 1794, 1795, 1884, 1886, 1888, 1890, 1893, 1896, 1904, 1907, 1913, 1914, 1915, 1917, 1919, 1920, 1922, 1923], "summari": [2, 4, 23, 29, 59, 1021, 1756, 1858, 1873, 1922, 1927], "hood": [2, 16, 21, 70, 1875, 1883, 1886, 1887, 1896, 1905, 1915], "record": [2, 6, 12, 15, 17, 29, 45, 50, 51, 52, 56, 59, 70, 71, 444, 445, 446, 447, 448, 494, 816, 817, 818, 819, 822, 824, 862, 919, 928, 966, 967, 969, 1064, 1065, 1066, 1076, 1081, 1099, 1116, 1117, 1118, 1147, 1148, 1190, 1205, 1209, 1260, 1276, 1303, 1304, 1359, 1422, 1653, 1654, 1656, 1659, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1855, 1856, 1860, 1862, 1878, 1882, 1883, 1886, 1888, 1901, 1902, 1907, 1913, 1922, 1923, 1924, 1925, 1926, 1927], "event": [2, 44, 47, 49, 57, 60, 70, 914, 915, 916, 967, 969, 1020, 1023, 1205, 1206, 1267, 1303, 1304, 1571, 1858, 1873, 1875, 1886, 1907, 1922], "being": [2, 4, 6, 10, 12, 15, 16, 17, 20, 21, 27, 29, 38, 41, 43, 45, 47, 49, 51, 58, 59, 60, 63, 67, 68, 70, 71, 98, 402, 757, 790, 796, 889, 898, 904, 948, 967, 975, 1022, 1026, 1040, 1041, 1076, 1109, 1110, 1120, 1129, 1130, 1179, 1190, 1194, 1279, 1288, 1293, 1338, 1339, 1356, 1358, 1365, 1366, 1370, 1371, 1376, 1382, 1389, 1413, 1414, 1422, 1425, 1426, 1427, 1428, 1429, 1436, 1453, 1454, 1470, 1486, 1493, 1494, 1504, 1516, 1517, 1521, 1533, 1556, 1564, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1628, 1629, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1707, 1708, 1802, 1803, 1804, 1845, 1846, 1860, 1863, 1870, 1873, 1876, 1877, 1878, 1882, 1883, 1886, 1888, 1889, 1890, 1891, 1894, 1896, 1897, 1901, 1905, 1908, 1911, 1913, 1914, 1917, 1924, 1926, 1928], "those": [2, 3, 5, 12, 14, 16, 17, 20, 21, 23, 25, 29, 32, 38, 39, 41, 43, 45, 47, 63, 68, 70, 71, 821, 905, 978, 988, 1051, 1053, 1131, 1205, 1247, 1253, 1261, 1300, 1330, 1338, 1339, 1356, 1358, 1366, 1382, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1474, 1493, 1494, 1504, 1513, 1533, 1556, 1564, 1659, 1678, 1751, 1808, 1829, 1850, 1862, 1876, 1877, 1882, 1883, 1886, 1888, 1889, 1892, 1894, 1898, 1899, 1901, 1904, 1911, 1913, 1915], "report": [2, 4, 5, 17, 23, 25, 29, 35, 41, 51, 59, 70, 71, 1020, 1123, 1124, 1126, 1882, 1886, 1906, 1917], "runtim": [2, 4, 6, 17, 24, 32, 41, 71, 824, 875, 914, 1061, 1063, 1153, 1190, 1205, 1422, 1604, 1605, 1660, 1703, 1843, 1851, 1863, 1876, 1877, 1883, 1886, 1888, 1896, 1901], "propag": [2, 15, 16, 21, 28, 43, 44, 47, 49, 58, 71, 511, 683, 686, 687, 688, 692, 693, 694, 695, 763, 764, 765, 766, 776, 779, 780, 782, 783, 784, 835, 837, 918, 1109, 1110, 1317, 1789, 1858, 1875, 1876, 1882, 1886, 1888, 1891, 1893, 1913, 1926, 1927], "async": [2, 41, 42, 70, 600, 1602, 1864, 1886, 1893, 1919], "task": [2, 4, 8, 39, 64, 69, 1193, 1208, 1385, 1386, 1387, 1863, 1885, 1893, 1894, 1900], "cuda": [2, 4, 5, 6, 16, 17, 19, 20, 22, 25, 29, 32, 37, 38, 39, 41, 43, 45, 63, 89, 151, 289, 313, 321, 335, 340, 513, 515, 521, 577, 862, 874, 876, 890, 904, 919, 921, 928, 950, 964, 965, 966, 967, 969, 970, 985, 987, 998, 1064, 1065, 1066, 1076, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1117, 1147, 1148, 1190, 1209, 1211, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1230, 1231, 1232, 1233, 1235, 1236, 1237, 1238, 1244, 1247, 1250, 1251, 1253, 1254, 1260, 1261, 1276, 1279, 1295, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1359, 1365, 1392, 1422, 1437, 1461, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1513, 1521, 1532, 1559, 1571, 1590, 1591, 1592, 1593, 1602, 1604, 1605, 1606, 1607, 1648, 1650, 1653, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1707, 1716, 1718, 1720, 1722, 1723, 1747, 1751, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1786, 1790, 1791, 1792, 1793, 1794, 1795, 1808, 1822, 1824, 1833, 1835, 1840, 1843, 1855, 1858, 1861, 1867, 1876, 1878, 1888, 1889, 1894, 1897, 1901, 1903, 1904, 1906, 1907, 1912, 1913, 1919, 1920, 1923, 1924, 1925], "cudaev": 2, "approxim": [2, 4, 39, 45, 58, 71, 1127, 1143, 1253, 1262, 1330, 1372, 1436, 1451, 1458, 1519, 1564, 1574, 1610, 1661, 1678, 1697, 1809, 1829, 1859, 1861, 1863, 1886, 1887, 1888, 1891, 1901, 1929], "4u": 2, "about": [2, 9, 10, 13, 15, 17, 18, 21, 22, 24, 29, 34, 38, 41, 42, 45, 49, 51, 55, 57, 59, 64, 68, 71, 255, 496, 615, 905, 906, 971, 972, 988, 1012, 1014, 1015, 1016, 1018, 1019, 1020, 1021, 1027, 1028, 1029, 1120, 1219, 1226, 1366, 1635, 1678, 1689, 1750, 1857, 1860, 1862, 1863, 1867, 1870, 1885, 1886, 1887, 1888, 1890, 1893, 1896, 1897, 1899, 1905, 1907, 1908, 1911, 1914, 1915, 1917, 1921, 1923], "collect": [2, 4, 8, 17, 21, 25, 28, 29, 38, 42, 43, 45, 49, 58, 63, 70, 71, 796, 797, 821, 858, 859, 938, 1002, 1064, 1152, 1291, 1602, 1625, 1653, 1716, 1720, 1855, 1858, 1861, 1862, 1863, 1873, 1886, 1887, 1889, 1904, 1907, 1908, 1911, 1915, 1917, 1922, 1924], "group": [2, 4, 10, 13, 17, 29, 38, 39, 42, 43, 45, 49, 55, 58, 59, 60, 61, 63, 66, 71, 607, 677, 709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 769, 770, 771, 877, 914, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1377, 1398, 1399, 1400, 1401, 1402, 1403, 1461, 1496, 1497, 1498, 1499, 1500, 1501, 1522, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1671, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1841, 1857, 1858, 1859, 1861, 1863, 1875, 1881, 1886, 1887, 1901, 1904, 1905, 1907, 1913, 1922], "prof": [2, 17, 29, 55, 1907], "key_averag": [2, 1907], "group_by_input_shap": [2, 914, 1907], "skew": [2, 4, 5, 1241, 1609], "neglig": [2, 1202, 1751], "bottom": [2, 1521, 1870], "But": [2, 8, 16, 18, 21, 23, 63, 70, 485, 1205, 1235, 1602, 1883, 1888, 1890, 1891, 1905, 1906, 1917, 1921, 1928], "total": [2, 4, 5, 8, 38, 39, 41, 55, 57, 58, 59, 63, 874, 915, 980, 1015, 1020, 1033, 1116, 1151, 1152, 1299, 1345, 1369, 1382, 1389, 1413, 1428, 1473, 1558, 1602, 1606, 1648, 1650, 1652, 1683, 1689, 1729, 1756, 1804, 1857, 1862, 1873, 1886, 1892, 1904], "artifici": [2, 1917], "estim": [2, 4, 38, 47, 958, 962, 1143, 1187, 1340, 1341, 1342, 1372, 1376, 1377, 1385, 1386, 1387, 1394, 1461, 1519, 1610, 1675, 1772, 1907], "flop": [2, 1907], "hardwar": [2, 9, 17, 29, 856, 858, 859, 1225, 1226, 1253, 1843, 1886, 1898, 1909], "matrix": [2, 3, 17, 19, 39, 41, 47, 192, 209, 683, 686, 687, 688, 757, 918, 920, 929, 930, 938, 940, 941, 942, 943, 950, 958, 962, 1046, 1050, 1051, 1053, 1063, 1131, 1135, 1139, 1154, 1210, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1255, 1257, 1259, 1262, 1270, 1279, 1281, 1284, 1294, 1312, 1314, 1365, 1366, 1374, 1392, 1473, 1512, 1513, 1609, 1614, 1643, 1649, 1695, 1696, 1697, 1707, 1751, 1779, 1782, 1785, 1786, 1788, 1790, 1791, 1792, 1793, 1794, 1795, 1800, 1808, 1809, 1824, 1827, 1829, 1831, 1832, 1833, 1834, 1835, 1844, 1850, 1858, 1863, 1876, 1877, 1878, 1881, 1885, 1886, 1888, 1891, 1894, 1897, 1907, 1917, 1922, 1923], "2d": [2, 43, 46, 47, 584, 585, 697, 700, 703, 732, 736, 739, 763, 765, 770, 776, 780, 782, 783, 784, 943, 958, 962, 1051, 1063, 1245, 1246, 1328, 1332, 1336, 1339, 1340, 1341, 1351, 1354, 1358, 1362, 1366, 1370, 1385, 1386, 1391, 1416, 1425, 1427, 1428, 1429, 1474, 1475, 1476, 1481, 1484, 1486, 1489, 1494, 1497, 1500, 1508, 1513, 1516, 1543, 1546, 1556, 1559, 1610, 1643, 1713, 1788, 1793, 1831, 1871, 1881, 1888, 1907, 1908, 1917], "alloc": [2, 5, 12, 15, 16, 30, 35, 39, 43, 47, 49, 58, 254, 331, 444, 445, 446, 447, 448, 485, 965, 967, 969, 971, 972, 974, 987, 988, 989, 1012, 1014, 1016, 1018, 1019, 1020, 1021, 1028, 1029, 1033, 1064, 1066, 1298, 1299, 1300, 1307, 1657, 1716, 1720, 1722, 1747, 1822, 1875, 1878, 1883, 1887, 1892, 1907, 1920], "dealloc": [2, 71, 1116, 1875, 1886, 1890, 1892, 1907], "line": [2, 5, 17, 20, 21, 22, 23, 25, 26, 29, 35, 41, 71, 914, 1063, 1120, 1165, 1190, 1200, 1422, 1486, 1521, 1756, 1783, 1860, 1863, 1864, 1878, 1884, 1888, 1891, 1892, 1898, 1900, 1901, 1907, 1917], "hierarchi": [2, 15, 71, 837, 1194, 1664, 1665, 1864, 1888, 1907, 1908], "callstack": [2, 41, 1907], "torchscript": [2, 4, 9, 20, 45, 71, 614, 1188, 1191, 1193, 1194, 1195, 1196, 1201, 1205, 1207, 1659, 1858, 1864, 1899, 1901, 1907, 1913], "kineto": [2, 1907], "_experimentalconfig": [2, 1907], "librari": [2, 3, 4, 5, 9, 10, 17, 20, 22, 30, 32, 33, 38, 41, 48, 56, 60, 64, 67, 68, 69, 71, 677, 960, 967, 990, 994, 1006, 1114, 1202, 1233, 1279, 1776, 1873, 1885, 1886, 1887, 1888, 1889, 1890, 1893, 1894, 1896, 1897, 1900, 1901, 1905, 1907, 1908, 1913, 1928], "100": [2, 13, 21, 23, 38, 41, 45, 47, 71, 300, 735, 736, 739, 740, 1150, 1190, 1201, 1207, 1245, 1260, 1267, 1276, 1291, 1311, 1330, 1338, 1339, 1340, 1341, 1342, 1351, 1352, 1354, 1355, 1357, 1358, 1385, 1386, 1387, 1422, 1429, 1431, 1461, 1470, 1503, 1504, 1556, 1667, 1679, 1680, 1685, 1686, 1687, 1688, 1690, 1692, 1693, 1709, 1765, 1861, 1863, 1875, 1885, 1886, 1901, 1904, 1909, 1915, 1917, 1922], "realli": [2, 8, 16, 18, 71, 1863, 1883, 1905], "y": [2, 12, 13, 15, 20, 21, 28, 29, 30, 32, 38, 47, 55, 63, 68, 69, 71, 614, 617, 778, 881, 883, 884, 885, 892, 893, 896, 898, 899, 900, 901, 902, 903, 932, 938, 955, 962, 1006, 1007, 1046, 1057, 1063, 1067, 1119, 1121, 1124, 1125, 1126, 1130, 1131, 1165, 1196, 1201, 1205, 1258, 1267, 1268, 1291, 1338, 1339, 1340, 1341, 1342, 1343, 1356, 1358, 1377, 1382, 1383, 1385, 1386, 1387, 1389, 1394, 1409, 1413, 1414, 1425, 1426, 1427, 1429, 1431, 1453, 1454, 1461, 1464, 1470, 1471, 1492, 1521, 1538, 1561, 1593, 1614, 1647, 1656, 1711, 1729, 1731, 1732, 1753, 1785, 1799, 1825, 1829, 1830, 1850, 1853, 1860, 1861, 1862, 1863, 1876, 1877, 1881, 1883, 1884, 1885, 1886, 1889, 1891, 1892, 1895, 1901, 1905, 1908, 1913, 1915, 1918, 1922, 1925, 1926, 1927], "column": [2, 4, 39, 46, 192, 260, 581, 584, 948, 958, 962, 1046, 1076, 1104, 1105, 1155, 1225, 1226, 1229, 1245, 1248, 1253, 1257, 1262, 1312, 1431, 1473, 1512, 1513, 1609, 1697, 1707, 1788, 1790, 1791, 1792, 1794, 1795, 1808, 1829, 1833, 1835, 1844, 1881, 1891, 1917], "remov": [2, 4, 17, 18, 20, 24, 28, 38, 39, 41, 43, 47, 59, 61, 63, 71, 486, 511, 543, 554, 694, 794, 812, 813, 814, 856, 910, 911, 940, 941, 1009, 1120, 1136, 1187, 1190, 1194, 1279, 1280, 1284, 1422, 1423, 1432, 1523, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1610, 1615, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1628, 1629, 1630, 1631, 1633, 1634, 1644, 1649, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1707, 1723, 1745, 1799, 1808, 1831, 1838, 1857, 1858, 1871, 1883, 1894, 1899, 1901, 1903, 1905, 1915, 1919, 1924], "breviti": [2, 71, 1901], "print": [2, 4, 13, 17, 21, 29, 35, 38, 41, 49, 50, 55, 56, 59, 63, 68, 70, 717, 725, 726, 731, 742, 743, 753, 761, 908, 910, 911, 1119, 1120, 1129, 1190, 1194, 1196, 1197, 1201, 1279, 1343, 1346, 1384, 1409, 1422, 1434, 1435, 1503, 1559, 1562, 1563, 1614, 1624, 1625, 1626, 1627, 1630, 1640, 1644, 1656, 1659, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1756, 1857, 1860, 1861, 1883, 1885, 1886, 1888, 1894, 1895, 1901, 1903, 1905, 1907, 1913, 1922, 1923, 1926, 1927], "tabl": [2, 4, 16, 23, 25, 29, 41, 71, 1365, 1512, 1861, 1863, 1888, 1904, 1905, 1907, 1908, 1913, 1917, 1924], "sort_bi": [2, 1907], "self_cpu_time_tot": [2, 1907], "avg": [2, 41, 1662], "mul": [2, 13, 15, 28, 35, 71, 419, 744, 745, 754, 1167, 1313, 1859, 1860, 1861, 1863, 1876, 1878, 1888, 1901, 1903, 1910, 1914, 1917, 1920, 1926], "32": [2, 3, 14, 21, 23, 39, 41, 743, 1116, 1187, 1199, 1279, 1336, 1361, 1362, 1363, 1367, 1368, 1370, 1371, 1391, 1410, 1416, 1427, 1465, 1466, 1467, 1468, 1469, 1486, 1516, 1517, 1523, 1571, 1877, 1878, 1894, 1898, 1901, 1911, 1917, 1920, 1922, 1923], "048m": 2, "200": [2, 29, 45, 1190, 1267, 1422, 1709, 1863, 1917], "27": [2, 614, 1257, 1682, 1704, 1844, 1901], "041m": 2, "powbackward0": 2, "9": [2, 8, 14, 38, 39, 41, 48, 71, 88, 313, 315, 317, 321, 401, 402, 470, 511, 557, 578, 580, 694, 742, 743, 851, 934, 940, 944, 948, 962, 1046, 1061, 1064, 1085, 1086, 1095, 1096, 1106, 1109, 1110, 1113, 1114, 1143, 1153, 1219, 1221, 1242, 1244, 1246, 1257, 1259, 1321, 1322, 1328, 1329, 1332, 1333, 1346, 1365, 1366, 1418, 1419, 1434, 1435, 1444, 1447, 1512, 1513, 1559, 1562, 1563, 1649, 1650, 1662, 1664, 1665, 1666, 1667, 1668, 1674, 1677, 1678, 1679, 1683, 1689, 1691, 1692, 1696, 1700, 1736, 1743, 1752, 1756, 1766, 1771, 1781, 1788, 1796, 1822, 1823, 1827, 1829, 1838, 1844, 1851, 1860, 1864, 1870, 1890, 1894, 1899, 1900, 1901, 1903, 1904, 1905, 1913, 1917, 1918, 1920, 1924], "727m": 2, "55": [2, 1376, 1901], "483m": 2, "accumulategrad": [2, 1883], "148m": 2, "graphroot": 2, "691": 2, "816u": 2, "emit": [2, 32, 50, 55, 71, 677, 1205, 1758, 1863, 1869, 1902, 1912, 1917], "nvtx": [2, 5, 1858], "off": [2, 8, 9, 16, 21, 25, 32, 41, 49, 63, 71, 917, 919, 928, 1024, 1120, 1147, 1148, 1187, 1205, 1253, 1335, 1336, 1337, 1339, 1415, 1416, 1417, 1521, 1559, 1753, 1885, 1886, 1887, 1890, 1893, 1897, 1907, 1908, 1909, 1913, 1914], "o": [2, 29, 39, 41, 42, 47, 59, 60, 61, 71, 1190, 1261, 1303, 1304, 1305, 1393, 1422, 1428, 1602, 1739, 1857, 1864, 1875, 1883, 1886, 1887, 1890, 1900, 1905, 1906, 1913], "trace_nam": 2, "regular": [2, 4, 5, 21, 41, 49, 59, 63, 66, 71, 1006, 1007, 1119, 1237, 1238, 1345, 1360, 1361, 1362, 1363, 1367, 1407, 1421, 1422, 1423, 1424, 1432, 1433, 1514, 1551, 1593, 1604, 1605, 1644, 1665, 1863, 1877, 1878, 1888, 1889, 1893, 1894, 1901, 1905, 1908, 1911, 1913, 1917, 1918, 1925, 1927], "command": [2, 5, 23, 25, 41, 49, 56, 59, 71, 1886, 1892, 1900, 1906, 1907, 1914], "unfortun": [2, 10, 14, 16, 38, 1602, 1883], "wai": [2, 4, 6, 8, 9, 10, 12, 13, 15, 16, 17, 21, 28, 29, 32, 38, 39, 41, 43, 45, 47, 51, 55, 63, 65, 66, 70, 71, 151, 577, 677, 793, 816, 819, 822, 858, 859, 887, 890, 899, 901, 902, 903, 904, 905, 1084, 1086, 1120, 1143, 1190, 1219, 1220, 1235, 1250, 1338, 1366, 1385, 1386, 1387, 1392, 1404, 1405, 1406, 1422, 1450, 1467, 1469, 1513, 1565, 1602, 1612, 1642, 1678, 1682, 1689, 1860, 1862, 1863, 1867, 1869, 1870, 1873, 1875, 1876, 1877, 1883, 1885, 1888, 1889, 1890, 1891, 1894, 1896, 1897, 1900, 1901, 1902, 1904, 1905, 1908, 1913, 1914, 1917, 1921, 1923, 1927], "disk": [2, 38, 1739, 1883, 1894, 1905, 1922], "annot": [2, 18, 20, 21, 27, 51, 56, 71, 912, 1188, 1201, 1860, 1862, 1864, 1901, 1913], "wait": [2, 17, 22, 35, 41, 49, 56, 58, 70, 821, 966, 967, 969, 1039, 1193, 1303, 1304, 1309, 1691, 1861, 1863, 1875, 1885, 1886, 1887, 1903, 1907, 1913], "nvidia": [2, 25, 29, 32, 41, 975, 988, 1016, 1022, 1026, 1040, 1041, 1843, 1858, 1886, 1890, 1892, 1898, 1900, 1908, 1925], "visual": [2, 17, 29, 71, 1291, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1415, 1416, 1417, 1473, 1894, 1900, 1907, 1922], "nvvp": 2, "timelin": [2, 5, 1303, 1304, 1907], "load_nvprof": 2, "repl": [2, 20], "append": [2, 21, 28, 41, 70, 71, 230, 254, 604, 758, 760, 762, 1009, 1053, 1055, 1284, 1375, 1393, 1424, 1433, 1439, 1450, 1602, 1861, 1862, 1863, 1883, 1885, 1896, 1900, 1901, 1903, 1922], "size": [2, 3, 4, 8, 12, 14, 15, 16, 17, 23, 29, 35, 38, 39, 41, 43, 47, 49, 58, 63, 66, 71, 139, 209, 222, 242, 254, 255, 313, 315, 321, 339, 444, 445, 446, 448, 486, 491, 496, 497, 498, 511, 513, 515, 518, 541, 542, 543, 563, 578, 580, 581, 582, 584, 585, 603, 604, 614, 615, 687, 688, 690, 692, 693, 694, 696, 717, 725, 726, 732, 738, 739, 740, 742, 743, 753, 761, 763, 764, 765, 766, 776, 782, 783, 784, 793, 855, 862, 874, 875, 877, 889, 898, 899, 900, 901, 902, 903, 914, 918, 919, 921, 928, 930, 931, 932, 933, 934, 941, 942, 943, 944, 962, 963, 965, 971, 977, 978, 980, 1020, 1044, 1045, 1051, 1054, 1061, 1063, 1064, 1065, 1066, 1069, 1080, 1081, 1082, 1084, 1085, 1086, 1088, 1089, 1092, 1093, 1094, 1095, 1096, 1098, 1099, 1100, 1116, 1117, 1118, 1125, 1126, 1131, 1132, 1147, 1148, 1152, 1153, 1164, 1167, 1187, 1190, 1211, 1220, 1229, 1234, 1242, 1246, 1250, 1253, 1255, 1256, 1257, 1259, 1260, 1262, 1270, 1276, 1277, 1279, 1280, 1284, 1287, 1289, 1290, 1291, 1292, 1295, 1296, 1297, 1298, 1299, 1312, 1314, 1317, 1320, 1322, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1365, 1366, 1368, 1369, 1370, 1371, 1374, 1376, 1377, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1410, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1434, 1435, 1437, 1443, 1444, 1445, 1446, 1447, 1448, 1453, 1461, 1465, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1488, 1489, 1490, 1494, 1499, 1500, 1501, 1504, 1505, 1512, 1513, 1516, 1517, 1521, 1532, 1539, 1545, 1546, 1547, 1556, 1557, 1559, 1562, 1563, 1565, 1571, 1590, 1591, 1592, 1593, 1602, 1625, 1635, 1636, 1637, 1638, 1639, 1641, 1643, 1646, 1648, 1650, 1653, 1654, 1667, 1676, 1695, 1696, 1697, 1698, 1700, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1723, 1729, 1734, 1743, 1746, 1765, 1785, 1786, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1799, 1801, 1802, 1803, 1804, 1807, 1808, 1809, 1822, 1823, 1824, 1829, 1831, 1839, 1840, 1841, 1842, 1845, 1846, 1848, 1849, 1850, 1851, 1855, 1856, 1858, 1859, 1860, 1861, 1863, 1871, 1873, 1876, 1877, 1882, 1883, 1884, 1886, 1887, 1888, 1889, 1890, 1891, 1892, 1893, 1898, 1899, 1901, 1903, 1906, 1907, 1908, 1910, 1917, 1919, 1920, 1922, 1923], "arg0": [2, 41], "arg1": [2, 41, 56, 57, 59], "order": [2, 4, 6, 12, 13, 15, 17, 23, 26, 29, 41, 42, 43, 45, 47, 59, 63, 64, 69, 70, 71, 151, 192, 209, 313, 315, 317, 321, 331, 402, 486, 677, 789, 790, 799, 851, 873, 890, 891, 904, 910, 911, 929, 940, 967, 1009, 1020, 1051, 1054, 1055, 1063, 1081, 1083, 1084, 1090, 1102, 1103, 1104, 1105, 1121, 1131, 1143, 1190, 1209, 1220, 1226, 1228, 1235, 1242, 1245, 1246, 1253, 1254, 1257, 1259, 1262, 1291, 1297, 1310, 1312, 1330, 1339, 1345, 1359, 1422, 1423, 1432, 1449, 1450, 1486, 1494, 1521, 1545, 1546, 1547, 1571, 1593, 1602, 1611, 1621, 1635, 1636, 1637, 1638, 1649, 1667, 1689, 1695, 1698, 1708, 1743, 1746, 1771, 1781, 1808, 1826, 1833, 1835, 1840, 1843, 1844, 1850, 1857, 1858, 1860, 1861, 1863, 1864, 1875, 1876, 1877, 1878, 1881, 1884, 1886, 1887, 1888, 1889, 1891, 1894, 1897, 1901, 1904, 1905, 1906, 1908, 1910, 1913, 1914, 1915, 1917, 1918, 1920, 1924, 1927], "side": [2, 12, 21, 32, 41, 58, 60, 68, 71, 765, 766, 769, 770, 771, 998, 1057, 1079, 1080, 1082, 1085, 1086, 1091, 1093, 1094, 1095, 1096, 1099, 1187, 1188, 1234, 1239, 1250, 1252, 1335, 1336, 1337, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1443, 1444, 1446, 1447, 1448, 1473, 1477, 1478, 1479, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1545, 1546, 1547, 1559, 1683, 1712, 1713, 1743, 1804, 1831, 1857, 1860, 1861, 1863, 1882, 1883, 1886, 1888, 1891, 1913], "creation": [2, 3, 15, 21, 38, 41, 43, 71, 742, 743, 753, 761, 821, 966, 1120, 1602, 1603, 1616, 1860, 1864, 1873, 1875, 1883, 1886, 1913, 1915, 1917, 1923], "warmup": [2, 4, 12, 17, 1009, 1886, 1907], "correl": [2, 47, 59, 958, 1350, 1351, 1352, 1353, 1354, 1355, 1361, 1362, 1363, 1367], "view": [2, 8, 9, 15, 16, 25, 28, 29, 30, 35, 38, 39, 43, 45, 49, 63, 71, 223, 254, 434, 495, 496, 497, 604, 615, 689, 694, 757, 875, 883, 884, 885, 893, 932, 944, 955, 956, 1053, 1054, 1061, 1102, 1103, 1104, 1105, 1120, 1153, 1165, 1190, 1245, 1256, 1304, 1366, 1374, 1392, 1422, 1437, 1473, 1474, 1475, 1476, 1513, 1558, 1598, 1599, 1602, 1606, 1698, 1730, 1734, 1735, 1739, 1745, 1746, 1777, 1796, 1807, 1818, 1823, 1827, 1839, 1848, 1849, 1851, 1858, 1859, 1860, 1861, 1875, 1877, 1878, 1884, 1888, 1903, 1910, 1915, 1917, 1919, 1920, 1923], "difficult": [2, 8, 10, 16, 17, 24, 29, 68, 1131, 1850], "eas": [2, 15, 28, 71, 1885, 1888, 1892], "seq": [2, 602, 757, 937, 949, 1291, 1374, 1392, 1428, 1437, 1465, 1467, 1469, 1638, 1838], "n": [2, 4, 21, 41, 43, 46, 47, 49, 51, 56, 59, 71, 230, 260, 406, 464, 465, 683, 686, 687, 688, 732, 755, 757, 778, 874, 914, 918, 919, 921, 928, 930, 934, 940, 941, 942, 962, 1044, 1045, 1055, 1076, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1103, 1123, 1126, 1131, 1143, 1147, 1148, 1152, 1187, 1190, 1201, 1205, 1206, 1209, 1210, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1262, 1270, 1279, 1284, 1286, 1291, 1294, 1314, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1370, 1371, 1373, 1374, 1375, 1376, 1377, 1382, 1383, 1385, 1386, 1387, 1389, 1390, 1391, 1392, 1394, 1404, 1405, 1406, 1410, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1425, 1426, 1427, 1428, 1429, 1431, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1453, 1455, 1456, 1457, 1461, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1486, 1492, 1504, 1505, 1513, 1517, 1521, 1556, 1559, 1561, 1571, 1602, 1609, 1620, 1629, 1648, 1695, 1696, 1697, 1702, 1707, 1708, 1714, 1720, 1722, 1735, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1785, 1786, 1802, 1803, 1804, 1808, 1809, 1823, 1824, 1829, 1833, 1835, 1844, 1845, 1846, 1847, 1850, 1859, 1861, 1863, 1867, 1876, 1877, 1881, 1883, 1886, 1888, 1890, 1891, 1905, 1907, 1908, 1909, 1917, 1918, 1922, 1923, 1924], "counter": [2, 41, 1002, 1020, 1165, 1359, 1873, 1875, 1883], "increment": [2, 12, 41, 58, 1116, 1152, 1194, 1359, 1860, 1862, 1883, 1913], "stash": [2, 6, 1886, 1888, 1906], "tell": [2, 8, 71, 494, 1191, 1197, 1261, 1660, 1860, 1870, 1883, 1888, 1889, 1905], "top": [2, 4, 8, 9, 14, 25, 38, 43, 46, 47, 51, 63, 67, 71, 744, 914, 1338, 1339, 1358, 1382, 1389, 1413, 1429, 1471, 1474, 1521, 1616, 1620, 1622, 1772, 1826, 1864, 1870, 1875, 1888, 1904], "m": [2, 5, 9, 20, 39, 41, 46, 47, 55, 59, 71, 683, 686, 687, 688, 717, 725, 726, 735, 736, 737, 738, 739, 740, 742, 743, 753, 755, 761, 811, 857, 858, 859, 918, 930, 934, 938, 943, 1076, 1129, 1152, 1188, 1190, 1195, 1196, 1200, 1201, 1207, 1210, 1221, 1229, 1235, 1236, 1237, 1238, 1242, 1243, 1244, 1246, 1247, 1248, 1253, 1254, 1255, 1256, 1262, 1279, 1280, 1284, 1294, 1312, 1314, 1327, 1328, 1329, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1340, 1341, 1342, 1343, 1344, 1347, 1348, 1349, 1350, 1351, 1352, 1354, 1355, 1360, 1361, 1362, 1363, 1364, 1365, 1367, 1368, 1370, 1371, 1372, 1373, 1377, 1378, 1379, 1380, 1381, 1384, 1385, 1386, 1387, 1390, 1391, 1408, 1409, 1411, 1412, 1415, 1416, 1417, 1421, 1422, 1429, 1430, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1472, 1474, 1475, 1476, 1477, 1478, 1479, 1559, 1561, 1602, 1609, 1614, 1624, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1642, 1643, 1646, 1695, 1696, 1697, 1707, 1714, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1785, 1786, 1804, 1808, 1809, 1824, 1831, 1860, 1861, 1862, 1863, 1886, 1888, 1890, 1891, 1894, 1899, 1908, 1917, 1927], "compar": [2, 4, 6, 12, 18, 25, 32, 38, 63, 71, 691, 862, 873, 904, 1020, 1067, 1068, 1091, 1092, 1093, 1097, 1098, 1099, 1100, 1109, 1110, 1134, 1146, 1165, 1179, 1214, 1278, 1288, 1293, 1323, 1428, 1602, 1647, 1753, 1863, 1873, 1886, 1888, 1891, 1897, 1900, 1908, 1909, 1913, 1917, 1922, 1924, 1926, 1927], "down": [2, 8, 23, 29, 32, 38, 47, 49, 56, 57, 59, 63, 71, 776, 1020, 1058, 1105, 1111, 1199, 1235, 1532, 1708, 1736, 1893, 1896, 1901, 1913, 1915, 1922], "irrelev": [2, 4, 1864], "simpli": [2, 4, 15, 17, 24, 32, 38, 47, 51, 59, 70, 71, 860, 1120, 1177, 1188, 1334, 1360, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1860, 1862, 1883, 1889, 1891, 1894, 1895, 1907, 1917], "hand": [2, 5, 16, 21, 41, 63, 68, 71, 1057, 1063, 1188, 1234, 1239, 1250, 1252, 1334, 1432, 1450, 1831, 1843, 1860, 1862, 1863, 1883, 1891, 1894, 1899, 1905, 1917], "underwai": [2, 1004, 1886], "up": [2, 7, 8, 9, 10, 12, 14, 16, 20, 21, 22, 24, 29, 32, 38, 39, 41, 45, 47, 49, 51, 55, 57, 58, 60, 61, 66, 71, 776, 782, 887, 1006, 1007, 1009, 1046, 1063, 1092, 1093, 1098, 1100, 1105, 1120, 1181, 1194, 1199, 1202, 1203, 1248, 1330, 1345, 1369, 1428, 1467, 1469, 1473, 1474, 1486, 1512, 1521, 1532, 1590, 1602, 1678, 1714, 1736, 1840, 1841, 1857, 1860, 1862, 1867, 1870, 1873, 1875, 1876, 1877, 1883, 1884, 1885, 1886, 1890, 1891, 1892, 1894, 1897, 1901, 1905, 1907, 1908, 1913, 1914, 1924], "nonzero": [2, 15, 16, 63, 1187, 1271, 1273, 1274, 1279, 1853, 1859, 1861, 1903], "themselv": [2, 10, 47, 58, 63, 790, 838, 1826, 1886, 1905, 1928], "did": [2, 8, 9, 20, 21, 41, 58, 1319, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1862, 1863, 1891, 1899, 1905], "relationship": [2, 10, 16, 21, 55, 71, 947, 1143, 1471, 1883, 1886, 1899, 1905], "conceptu": [2, 4, 1883, 1889, 1915], "itt": [2, 1907], "intel": [2, 5, 25, 1858, 1900], "r": [2, 21, 29, 47, 69, 151, 886, 888, 890, 904, 905, 938, 949, 958, 1063, 1121, 1123, 1126, 1131, 1132, 1135, 1143, 1201, 1219, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1235, 1236, 1239, 1241, 1248, 1250, 1252, 1253, 1262, 1365, 1366, 1375, 1434, 1435, 1453, 1512, 1513, 1562, 1563, 1609, 1676, 1707, 1850, 1860, 1861, 1862, 1883, 1885, 1888, 1891, 1900, 1920, 1922], "instrument": [2, 4, 39, 1304, 1858, 1893, 1927], "technologi": [2, 1858], "applic": [2, 3, 10, 17, 47, 58, 796, 807, 808, 809, 810, 896, 988, 1125, 1300, 1358, 1359, 1467, 1469, 1504, 1602, 1843, 1858, 1870, 1878, 1883, 1885, 1886, 1887, 1888, 1892, 1893, 1894, 1898, 1901, 1904, 1908, 1913, 1914, 1915, 1917, 1923], "across": [2, 9, 12, 15, 17, 21, 29, 32, 38, 39, 41, 43, 45, 49, 59, 63, 68, 71, 614, 732, 816, 871, 915, 980, 1019, 1020, 1063, 1077, 1131, 1200, 1205, 1291, 1339, 1359, 1369, 1410, 1428, 1430, 1461, 1473, 1491, 1494, 1523, 1539, 1586, 1602, 1621, 1625, 1649, 1739, 1850, 1858, 1860, 1873, 1876, 1878, 1883, 1887, 1890, 1893, 1894, 1896, 1897, 1898, 1904, 1906, 1909, 1913, 1914, 1919, 1922, 1927], "tool": [2, 5, 9, 10, 17, 20, 22, 23, 29, 35, 41, 59, 71, 858, 913, 1304, 1783, 1857, 1858, 1860, 1862, 1885, 1886, 1900, 1901, 1905, 1907, 1927], "With": [2, 17, 18, 21, 25, 29, 35, 38, 41, 47, 63, 70, 736, 737, 738, 739, 740, 782, 1020, 1084, 1085, 1086, 1094, 1095, 1096, 1206, 1340, 1341, 1342, 1351, 1352, 1354, 1355, 1368, 1385, 1386, 1387, 1461, 1472, 1474, 1497, 1500, 1532, 1557, 1590, 1675, 1718, 1864, 1883, 1886, 1888, 1913, 1917, 1922], "abl": [2, 3, 8, 9, 13, 15, 16, 17, 18, 24, 29, 35, 41, 43, 58, 68, 1120, 1188, 1200, 1465, 1602, 1860, 1867, 1876, 1883, 1888, 1889, 1899, 1901, 1905, 1908, 1913, 1917, 1924], "labl": 2, "gui": 2, "detect_anomali": 2, "check_nan": 2, "engin": [2, 9, 10, 17, 30, 33, 335, 738, 739, 740, 894, 904, 1131, 1714, 1850, 1858, 1883, 1886, 1887, 1888, 1913, 1914], "traceback": [2, 29, 35, 51, 59, 70, 71, 1165, 1175, 1783, 1862, 1863, 1864, 1875, 1878, 1888, 1898, 1917, 1924], "fail": [2, 8, 13, 14, 15, 17, 18, 21, 22, 29, 41, 47, 49, 50, 51, 56, 57, 58, 59, 61, 70, 71, 74, 905, 906, 967, 1020, 1191, 1197, 1200, 1219, 1248, 1253, 1261, 1262, 1279, 1658, 1863, 1865, 1875, 1883, 1886, 1888, 1896, 1897, 1900, 1901, 1905, 1913], "test": [2, 4, 16, 17, 19, 29, 32, 35, 41, 46, 56, 58, 59, 71, 690, 696, 950, 1080, 1082, 1083, 1088, 1089, 1094, 1095, 1096, 1098, 1100, 1176, 1177, 1181, 1182, 1184, 1185, 1659, 1773, 1858, 1860, 1864, 1873, 1875, 1883, 1891, 1898, 1901, 1904, 1922, 1927, 1928], "slow": [2, 16, 905, 1199, 1203, 1219, 1220, 1606, 1607, 1642, 1840, 1891, 1896, 1922], "myfunc": [2, 1889], "inp": [2, 38, 41, 71, 891, 892, 893, 1473, 1602, 1859, 1928], "clone": [2, 33, 38, 63, 254, 447, 894, 897, 908, 910, 911, 932, 1194, 1365, 1589, 1822, 1831, 1859, 1861, 1875, 1878, 1899, 1903, 1907, 1917, 1919, 1920, 1924], "run_fn": [2, 6, 854, 860], "10": [2, 12, 13, 14, 17, 20, 21, 22, 29, 37, 38, 39, 41, 42, 47, 48, 58, 60, 313, 321, 335, 470, 511, 557, 578, 580, 581, 582, 682, 683, 694, 731, 742, 743, 757, 758, 759, 760, 762, 918, 930, 940, 942, 943, 944, 948, 962, 1042, 1043, 1044, 1045, 1046, 1061, 1063, 1080, 1082, 1085, 1086, 1088, 1089, 1092, 1093, 1095, 1096, 1098, 1100, 1106, 1114, 1133, 1143, 1153, 1179, 1195, 1200, 1201, 1207, 1212, 1215, 1242, 1244, 1245, 1260, 1262, 1264, 1269, 1271, 1272, 1273, 1274, 1276, 1284, 1295, 1312, 1328, 1329, 1330, 1332, 1333, 1339, 1342, 1345, 1346, 1349, 1352, 1355, 1365, 1366, 1374, 1375, 1376, 1377, 1387, 1392, 1393, 1394, 1419, 1423, 1424, 1429, 1432, 1433, 1437, 1439, 1461, 1465, 1466, 1467, 1468, 1469, 1473, 1479, 1498, 1501, 1505, 1512, 1513, 1523, 1593, 1602, 1625, 1633, 1647, 1650, 1659, 1663, 1683, 1689, 1691, 1709, 1710, 1718, 1743, 1756, 1762, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1772, 1781, 1796, 1808, 1809, 1819, 1823, 1824, 1827, 1829, 1843, 1851, 1857, 1860, 1861, 1862, 1863, 1864, 1870, 1883, 1886, 1887, 1894, 1897, 1898, 1899, 1900, 1901, 1903, 1917, 1918, 1920, 1922, 1923, 1924, 1929], "last": [2, 6, 7, 13, 23, 29, 30, 38, 39, 42, 45, 46, 47, 58, 70, 71, 315, 614, 689, 757, 874, 919, 928, 934, 944, 1006, 1046, 1051, 1055, 1080, 1082, 1085, 1086, 1088, 1089, 1092, 1093, 1095, 1096, 1098, 1100, 1102, 1147, 1148, 1152, 1165, 1167, 1175, 1187, 1211, 1245, 1248, 1253, 1290, 1295, 1330, 1343, 1358, 1366, 1368, 1374, 1392, 1394, 1409, 1429, 1432, 1436, 1437, 1450, 1466, 1467, 1473, 1492, 1513, 1522, 1535, 1558, 1559, 1602, 1603, 1648, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1734, 1743, 1781, 1783, 1790, 1791, 1792, 1794, 1795, 1796, 1804, 1808, 1824, 1826, 1829, 1848, 1849, 1862, 1863, 1873, 1876, 1878, 1883, 1886, 1888, 1891, 1898, 1901, 1905, 1906, 1917, 1923, 1924], "stdin": [2, 1165, 1783, 1878, 1888, 1898, 1917], "instal": [2, 4, 13, 15, 21, 24, 32, 33, 41, 71, 1857, 1894, 1895, 1901, 1905, 1913, 1922], "_tensor": [2, 155], "py": [2, 5, 13, 14, 15, 16, 17, 20, 21, 23, 25, 28, 29, 32, 35, 41, 45, 47, 50, 57, 59, 63, 71, 857, 1602, 1857, 1860, 1863, 1869, 1887, 1891, 1893, 1901, 1905, 1908, 1914], "93": [2, 614], "retain_graph": [2, 151, 890, 904, 910, 911, 1131, 1850, 1861, 1882, 1883, 1913], "90": [2, 1047, 1693, 1735], "allow_unreach": 2, "76": 2, "_forward_cl": 2, "tmp": [2, 4, 23, 32, 41, 56, 58, 1857, 1886, 1907], "53": [2, 480], "44": [2, 14, 321, 444, 1066, 1337, 1417, 1642], "set_detect_anomali": 2, "behaviour": [2, 690, 691, 696, 963, 1521, 1559, 1689, 1758, 1857, 1897], "interpos": 2, "grad_fn": [2, 151, 335, 877, 890, 898, 899, 900, 901, 902, 903, 908, 910, 911, 1119, 1610, 1785, 1883, 1894, 1899], "node": [2, 15, 16, 17, 25, 28, 29, 41, 45, 49, 51, 57, 58, 63, 71, 83, 86, 87, 816, 817, 818, 821, 822, 823, 1009, 1129, 1204, 1345, 1359, 1602, 1659, 1871, 1886, 1901, 1902, 1905, 1906, 1913, 1914, 1915, 1925, 1927], "grad_mod": [2, 1861], "intermediari": [2, 32, 47, 896, 1883, 1891], "access": [2, 10, 12, 15, 16, 17, 20, 24, 35, 38, 41, 43, 63, 70, 554, 731, 896, 973, 1190, 1193, 1205, 1252, 1330, 1422, 1593, 1604, 1605, 1610, 1614, 1636, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1858, 1860, 1861, 1863, 1864, 1867, 1871, 1874, 1875, 1877, 1878, 1883, 1886, 1890, 1891, 1893, 1894, 1913, 1917, 1920, 1921, 1923, 1929], "isinst": [2, 28, 29, 38, 47, 71, 908, 910, 911, 1177, 1188, 1861, 1863, 1883, 1888, 1894, 1905, 1917], "dir": [2, 1006, 1659, 1857, 1863, 1905], "__call__": [2, 1190, 1422], "__class__": 2, "__delattr__": 2, "__dir__": 2, "__doc__": 2, "__eq__": 2, "__format__": [2, 1864], "__ge__": 2, "__getattribute__": 2, "__gt__": 2, "__hash__": [2, 1864], "__init_subclass__": 2, "__le__": 2, "__lt__": [2, 1863], "__ne__": 2, "__new__": [2, 1862, 1864], "__reduce__": [2, 1905], "__reduce_ex__": 2, "__repr__": [2, 4, 1888], "__setattr__": 2, "__sizeof__": 2, "__str__": [2, 71, 1861, 1863], "__subclasshook__": 2, "_raw_saved_result": 2, "_register_hook_dict": 2, "_saved_result": [2, 1883], "metadata": [2, 4, 16, 28, 43, 51, 52, 1261, 1739, 1878, 1883, 1888, 1889, 1899, 1905, 1907, 1913, 1914, 1922], "next_funct": 2, "register_prehook": [2, 1883], "allclos": [2, 68, 69, 71, 905, 906, 1006, 1085, 1086, 1092, 1093, 1120, 1121, 1123, 1124, 1125, 1126, 1130, 1131, 1237, 1239, 1250, 1252, 1255, 1256, 1281, 1614, 1641, 1707, 1850, 1861, 1889, 1903], "pack": [2, 45, 735, 736, 737, 738, 739, 740, 742, 743, 757, 778, 1205, 1206, 1281, 1359, 1374, 1392, 1437, 1635, 1636, 1637, 1638, 1861, 1871, 1878, 1883, 1890, 1900, 1908], "unpack": [2, 757, 893, 1205, 1237, 1281, 1359, 1638, 1640, 1647, 1660, 1863, 1864, 1883, 1888, 1890], "common": [2, 4, 9, 15, 21, 24, 27, 28, 29, 38, 49, 58, 68, 682, 790, 862, 923, 926, 931, 957, 1058, 1063, 1108, 1109, 1110, 1111, 1133, 1212, 1261, 1311, 1340, 1341, 1342, 1345, 1461, 1503, 1594, 1595, 1597, 1598, 1599, 1600, 1601, 1727, 1739, 1805, 1858, 1863, 1868, 1877, 1883, 1886, 1888, 1889, 1890, 1894, 1896, 1899, 1901, 1905, 1917, 1918, 1921, 1924], "trade": [2, 6, 9, 63, 1253, 1339, 1885, 1890, 1909], "leav": [2, 9, 21, 49, 59, 151, 890, 1195, 1207, 1612, 1615, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1799, 1860, 1862, 1863, 1883, 1905, 1909], "especi": [2, 10, 12, 16, 17, 19, 20, 21, 30, 38, 41, 71, 254, 932, 950, 1589, 1862, 1883, 1888, 1889, 1897, 1899, 1908, 1913, 1917], "notic": [2, 24, 41, 686, 1083, 1097, 1284, 1294, 1338, 1474, 1538, 1680, 1681, 1686, 1687, 1693, 1858, 1860, 1883, 1917], "fit": [2, 10, 29, 50, 67, 68, 497, 914, 1187, 1667, 1729, 1906, 1924], "evalu": [2, 5, 9, 10, 15, 16, 18, 26, 45, 46, 47, 66, 71, 690, 696, 795, 860, 905, 1020, 1126, 1127, 1190, 1330, 1334, 1340, 1341, 1342, 1360, 1377, 1385, 1386, 1387, 1394, 1422, 1436, 1440, 1461, 1564, 1586, 1612, 1667, 1683, 1714, 1863, 1864, 1888, 1894, 1917, 1925], "saved_tensors_hook": [2, 896, 1883], "pack_hook": [2, 1883], "unpack_hook": [2, 1883], "pair": [2, 17, 41, 43, 46, 47, 58, 60, 614, 732, 862, 938, 962, 1097, 1203, 1253, 1291, 1414, 1423, 1428, 1432, 1561, 1676, 1723, 1862, 1863, 1869, 1876, 1883, 1886, 1906, 1913, 1914, 1915, 1922, 1924, 1927], "retriev": [2, 21, 38, 39, 41, 45, 49, 58, 71, 534, 886, 887, 1365, 1369, 1473, 1512, 1602, 1636, 1659, 1783, 1878, 1883, 1893, 1901, 1905, 1906, 1913, 1914, 1915], "everytim": 2, "store": [2, 4, 6, 16, 20, 21, 32, 35, 39, 43, 49, 59, 63, 71, 326, 332, 398, 683, 819, 822, 887, 930, 976, 978, 980, 1135, 1190, 1197, 1200, 1220, 1231, 1232, 1233, 1262, 1267, 1279, 1341, 1365, 1422, 1450, 1602, 1609, 1611, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1635, 1788, 1857, 1858, 1860, 1877, 1878, 1879, 1887, 1888, 1889, 1890, 1893, 1905, 1908, 1913, 1914, 1915, 1917, 1919, 1922, 1923, 1927], "content": [2, 4, 8, 24, 29, 43, 51, 71, 896, 1197, 1200, 1220, 1231, 1233, 1238, 1251, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1799, 1828, 1857, 1863, 1872, 1875, 1883, 1913, 1921, 1922, 1923], "equal": [2, 28, 39, 41, 47, 58, 59, 60, 71, 260, 497, 542, 614, 677, 691, 692, 693, 736, 737, 738, 739, 740, 757, 765, 766, 817, 818, 819, 822, 858, 873, 919, 928, 939, 940, 952, 962, 978, 980, 1033, 1052, 1068, 1107, 1121, 1122, 1134, 1147, 1148, 1150, 1151, 1152, 1175, 1179, 1214, 1235, 1248, 1252, 1255, 1256, 1279, 1280, 1291, 1307, 1323, 1327, 1328, 1329, 1331, 1332, 1333, 1338, 1339, 1345, 1351, 1352, 1354, 1355, 1359, 1366, 1369, 1370, 1371, 1374, 1376, 1392, 1427, 1428, 1436, 1437, 1473, 1489, 1490, 1494, 1497, 1500, 1512, 1513, 1516, 1517, 1523, 1602, 1636, 1639, 1695, 1708, 1765, 1766, 1771, 1796, 1804, 1823, 1839, 1853, 1861, 1864, 1870, 1876, 1877, 1878, 1883, 1884, 1891, 1897, 1903, 1904, 1906, 1918, 1922, 1924], "term": [2, 9, 10, 15, 47, 58, 71, 555, 731, 760, 789, 940, 1079, 1080, 1081, 1082, 1083, 1084, 1086, 1094, 1095, 1096, 1099, 1111, 1221, 1330, 1338, 1376, 1383, 1392, 1393, 1427, 1436, 1453, 1518, 1530, 1564, 1575, 1602, 1609, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1727, 1772, 1858, 1863, 1882, 1883, 1888, 1889, 1890, 1891, 1901, 1905, 1908, 1914, 1917], "mulbackward0": [2, 899, 902, 903], "inplac": [2, 28, 66, 68, 71, 752, 755, 773, 775, 777, 788, 794, 811, 835, 836, 837, 854, 855, 860, 894, 1120, 1190, 1334, 1344, 1360, 1361, 1362, 1363, 1364, 1367, 1379, 1380, 1381, 1408, 1421, 1422, 1440, 1441, 1442, 1449, 1451, 1464, 1487, 1495, 1506, 1507, 1508, 1509, 1510, 1514, 1525, 1526, 1527, 1536, 1551, 1566, 1567, 1569, 1572, 1574, 1584, 1596, 1843, 1859, 1861, 1870, 1883, 1888, 1901, 1927], "lead": [2, 6, 8, 12, 18, 37, 41, 48, 63, 69, 71, 894, 898, 900, 904, 906, 1114, 1131, 1220, 1392, 1437, 1453, 1799, 1850, 1863, 1877, 1878, 1883, 1885, 1887, 1888, 1889, 1897, 1900, 1904, 1905, 1908, 1917, 1922, 1923], "undefin": [2, 41, 48, 51, 63, 319, 470, 614, 875, 897, 905, 906, 934, 1066, 1115, 1116, 1338, 1658, 1701, 1883, 1886, 1888, 1889], "inner": [2, 4, 63, 64, 69, 812, 814, 898, 1046, 1121, 1125, 1130, 1829, 1861, 1903, 1913, 1927], "save_on_cpu": 2, "pin_memori": [2, 38, 444, 445, 446, 447, 448, 1064, 1066, 1716, 1720, 1722, 1822, 1859, 1860, 1861, 1878, 1886, 1903, 1919], "within": [2, 6, 10, 15, 17, 20, 28, 29, 38, 39, 41, 45, 46, 47, 58, 59, 60, 63, 70, 71, 89, 875, 905, 906, 970, 1046, 1190, 1194, 1282, 1335, 1336, 1337, 1345, 1361, 1362, 1363, 1367, 1369, 1415, 1416, 1417, 1422, 1428, 1461, 1473, 1521, 1545, 1546, 1547, 1602, 1612, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1630, 1631, 1632, 1712, 1713, 1743, 1765, 1842, 1860, 1862, 1863, 1873, 1878, 1881, 1885, 1886, 1888, 1892, 1893, 1894, 1897, 1901, 1904, 1905, 1908, 1911, 1912, 1913, 1914, 1922], "move": [2, 6, 8, 9, 10, 18, 21, 29, 32, 41, 43, 63, 71, 521, 586, 818, 1083, 1190, 1197, 1256, 1261, 1297, 1340, 1341, 1342, 1395, 1396, 1397, 1422, 1461, 1559, 1604, 1605, 1675, 1862, 1871, 1872, 1875, 1877, 1886, 1889, 1890, 1894, 1895, 1896, 1904, 1905, 1906, 1913, 1919, 1924], "copi": [2, 8, 16, 20, 28, 30, 38, 39, 41, 43, 49, 56, 63, 67, 68, 71, 191, 197, 207, 210, 315, 402, 447, 457, 462, 470, 491, 497, 577, 578, 579, 580, 600, 614, 789, 811, 835, 836, 876, 877, 892, 939, 947, 976, 977, 1102, 1103, 1104, 1105, 1107, 1120, 1190, 1201, 1262, 1322, 1359, 1369, 1422, 1432, 1473, 1602, 1635, 1724, 1730, 1736, 1822, 1831, 1837, 1860, 1861, 1875, 1878, 1883, 1884, 1886, 1888, 1896, 1903, 1905, 1906, 1907, 1908, 1913, 1917, 1919, 1920, 1921, 1923, 1927], "pin": [2, 210, 337, 444, 445, 446, 447, 448, 462, 577, 600, 1064, 1066, 1190, 1422, 1635, 1716, 1720, 1722, 1822, 1858, 1878, 1919], "asynchron": [2, 4, 5, 70, 197, 210, 577, 600, 989, 1190, 1193, 1208, 1422, 1858, 1864, 1885, 1887, 1913, 1919, 1922], "prod_1": 2, "prod_2": 2, "del": [2, 1864, 1875, 1888, 1890], "illustr": [2, 12, 21, 23, 1863, 1882, 1888, 1917], "aliv": [2, 38, 49, 58, 967, 1883, 1886, 1890, 1896, 1913, 1914, 1915], "live": [2, 12, 16, 45, 1006, 1009, 1190, 1422, 1860, 1886, 1890, 1913, 1915], "releas": [2, 8, 29, 37, 41, 58, 60, 67, 71, 511, 684, 940, 941, 963, 964, 965, 971, 988, 998, 999, 1002, 1006, 1007, 1009, 1020, 1136, 1190, 1220, 1231, 1233, 1234, 1235, 1238, 1251, 1279, 1280, 1300, 1362, 1392, 1422, 1437, 1545, 1546, 1547, 1649, 1707, 1723, 1739, 1804, 1808, 1831, 1857, 1858, 1862, 1873, 1875, 1883, 1885, 1886, 1892, 1897, 1898, 1899, 1900, 1901, 1908, 1913, 1923, 1924], "delet": [2, 28, 41, 71, 891, 964, 972, 1857, 1871, 1875, 1883, 1903, 1912, 1913, 1915], "disable_saved_tensors_hook": 2, "error_messag": 2, "featur": [2, 6, 9, 10, 18, 20, 22, 30, 33, 35, 41, 43, 45, 59, 64, 70, 677, 686, 757, 765, 766, 898, 900, 904, 1037, 1201, 1284, 1294, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1340, 1355, 1360, 1361, 1362, 1363, 1367, 1370, 1371, 1374, 1375, 1385, 1392, 1393, 1428, 1437, 1439, 1456, 1465, 1467, 1469, 1470, 1471, 1472, 1489, 1490, 1507, 1508, 1509, 1514, 1516, 1517, 1538, 1602, 1697, 1843, 1858, 1860, 1862, 1863, 1864, 1867, 1869, 1877, 1878, 1883, 1888, 1890, 1891, 1898, 1901, 1902, 1907, 1908, 1913, 1917, 1922], "messag": [2, 3, 29, 35, 41, 51, 60, 68, 71, 84, 621, 677, 1023, 1025, 1219, 1220, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1857, 1860, 1861, 1863, 1864, 1869, 1890, 1901, 1906, 1907, 1913, 1915, 1924], "get": [2, 9, 12, 15, 16, 21, 22, 23, 26, 27, 29, 32, 38, 41, 42, 43, 58, 59, 60, 61, 63, 68, 70, 71, 89, 151, 335, 683, 731, 785, 786, 858, 859, 890, 893, 934, 991, 992, 993, 1010, 1050, 1120, 1123, 1124, 1125, 1137, 1165, 1205, 1257, 1365, 1366, 1390, 1391, 1418, 1419, 1420, 1432, 1449, 1602, 1603, 1610, 1636, 1643, 1728, 1743, 1857, 1858, 1860, 1863, 1873, 1875, 1876, 1883, 1886, 1888, 1889, 1890, 1891, 1893, 1894, 1895, 1903, 1905, 1908, 1913, 1915, 1917, 1921, 1922, 1923, 1928], "register_multi_grad_hook": [2, 1883], "multi": [2, 5, 46, 49, 58, 757, 967, 1010, 1030, 1063, 1083, 1152, 1190, 1339, 1359, 1374, 1392, 1422, 1425, 1426, 1427, 1428, 1437, 1465, 1467, 1474, 1494, 1602, 1858, 1860, 1863, 1883, 1885, 1886, 1894, 1898, 1904, 1913, 1917, 1920, 1923, 1925], "ignor": [2, 6, 8, 12, 24, 28, 41, 45, 50, 56, 63, 71, 151, 497, 541, 683, 686, 687, 688, 732, 791, 792, 855, 858, 859, 871, 890, 904, 905, 906, 918, 940, 962, 1010, 1011, 1030, 1031, 1084, 1086, 1094, 1095, 1096, 1135, 1150, 1190, 1201, 1207, 1210, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1236, 1237, 1238, 1239, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1258, 1259, 1281, 1317, 1318, 1319, 1335, 1336, 1337, 1338, 1339, 1356, 1358, 1366, 1374, 1376, 1382, 1388, 1389, 1392, 1413, 1414, 1415, 1416, 1417, 1422, 1425, 1426, 1427, 1428, 1429, 1436, 1437, 1453, 1454, 1465, 1470, 1493, 1494, 1504, 1513, 1533, 1556, 1564, 1602, 1649, 1660, 1683, 1691, 1695, 1756, 1786, 1787, 1804, 1808, 1831, 1860, 1863, 1864, 1870, 1877, 1883, 1886, 1888, 1901, 1917, 1924], "rel": [2, 9, 10, 21, 32, 39, 41, 47, 63, 71, 486, 691, 873, 905, 906, 910, 911, 962, 1179, 1244, 1247, 1470, 1471, 1486, 1521, 1660, 1664, 1665, 1691, 1870, 1873, 1885, 1886, 1893, 1901, 1905, 1924], "allow_mutation_on_saved_tensor": 2, "mutat": [2, 16, 17, 27, 71, 794, 835, 836, 854, 855, 1120, 1194, 1905, 1923], "version": [2, 3, 6, 9, 18, 29, 32, 37, 39, 41, 43, 47, 59, 63, 66, 67, 71, 91, 93, 95, 97, 99, 101, 103, 105, 107, 109, 111, 122, 124, 126, 128, 131, 132, 134, 142, 144, 147, 148, 150, 153, 159, 161, 163, 165, 167, 169, 178, 187, 195, 199, 202, 204, 214, 216, 232, 236, 238, 244, 247, 249, 251, 253, 257, 262, 269, 271, 273, 277, 279, 283, 285, 292, 294, 296, 304, 306, 308, 310, 312, 314, 316, 318, 356, 358, 360, 362, 364, 366, 368, 371, 373, 375, 376, 383, 385, 387, 389, 391, 395, 399, 401, 419, 422, 425, 427, 438, 440, 442, 450, 455, 465, 468, 484, 488, 490, 506, 509, 510, 512, 514, 520, 524, 526, 529, 531, 533, 546, 548, 550, 553, 559, 561, 568, 572, 574, 590, 593, 595, 597, 599, 609, 619, 732, 733, 734, 746, 747, 748, 749, 750, 751, 772, 773, 774, 775, 777, 781, 782, 801, 802, 803, 836, 844, 852, 853, 855, 1009, 1119, 1147, 1165, 1187, 1190, 1193, 1194, 1197, 1200, 1219, 1232, 1233, 1237, 1238, 1251, 1284, 1321, 1339, 1392, 1422, 1423, 1437, 1474, 1486, 1511, 1521, 1528, 1537, 1568, 1570, 1585, 1586, 1590, 1594, 1614, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1643, 1644, 1675, 1677, 1678, 1740, 1741, 1742, 1799, 1802, 1803, 1804, 1808, 1828, 1843, 1845, 1846, 1857, 1876, 1877, 1883, 1884, 1886, 1888, 1889, 1891, 1892, 1893, 1894, 1895, 1898, 1900, 1901, 1902, 1904, 1905, 1907, 1911, 1917, 1924, 1925], "_allowmutationonsavedcontext": 2, "purpos": [2, 13, 20, 21, 23, 29, 39, 41, 71, 470, 497, 757, 905, 1199, 1284, 1345, 1374, 1428, 1596, 1597, 1598, 1599, 1756, 1873, 1878, 1883, 1905, 1914], "upon": [2, 3, 38, 42, 49, 51, 71, 1602, 1611, 1614, 1875, 1883, 1886, 1901, 1908, 1915], "sin_": [2, 1861, 1876], "8415": [2, 1917], "sinbackward0": 2, "variou": [3, 6, 16, 32, 38, 41, 71, 1262, 1867, 1870, 1875, 1878, 1888, 1894, 1896, 1904, 1908, 1910, 1917, 1928], "get_cpu_cap": 3, "capabl": [3, 9, 32, 33, 41, 991, 1714, 1867, 1886, 1892, 1893, 1895, 1925], "possibl": [3, 10, 12, 13, 15, 16, 17, 18, 21, 22, 24, 29, 32, 33, 35, 41, 43, 47, 67, 68, 71, 495, 496, 577, 614, 855, 876, 877, 944, 973, 1111, 1123, 1190, 1203, 1230, 1243, 1246, 1247, 1250, 1255, 1261, 1339, 1345, 1422, 1428, 1512, 1513, 1532, 1565, 1590, 1614, 1615, 1727, 1730, 1745, 1796, 1804, 1822, 1860, 1862, 1863, 1875, 1876, 1881, 1883, 1885, 1886, 1887, 1888, 1891, 1896, 1897, 1898, 1900, 1905, 1908, 1913, 1915, 1920, 1924], "vsx": 3, "z": [3, 4, 11, 12, 15, 28, 29, 47, 63, 68, 614, 817, 874, 896, 941, 942, 952, 1063, 1067, 1291, 1375, 1521, 1614, 1647, 1648, 1656, 1701, 1731, 1732, 1860, 1861, 1862, 1877, 1883, 1885, 1886, 1891, 1892, 1901, 1905, 1911, 1913, 1915], "vector": [3, 20, 30, 39, 47, 63, 64, 68, 254, 313, 315, 321, 686, 687, 688, 881, 890, 892, 898, 899, 900, 901, 902, 903, 904, 931, 932, 938, 949, 958, 962, 963, 1044, 1045, 1050, 1052, 1126, 1130, 1131, 1135, 1222, 1229, 1237, 1245, 1246, 1250, 1253, 1257, 1258, 1259, 1279, 1284, 1291, 1312, 1314, 1340, 1341, 1342, 1345, 1359, 1365, 1366, 1369, 1377, 1385, 1386, 1387, 1431, 1461, 1470, 1473, 1512, 1513, 1521, 1523, 1557, 1561, 1589, 1606, 1608, 1610, 1614, 1645, 1649, 1696, 1697, 1788, 1808, 1844, 1847, 1850, 1883, 1891, 1908, 1917, 1922], "NO": 3, "avx": 3, "avx2": [3, 1908], "avx512": 3, "is_built": [3, 1895], "built": [3, 4, 8, 9, 13, 14, 21, 29, 32, 39, 41, 46, 51, 66, 71, 951, 989, 1199, 1471, 1683, 1858, 1878, 1883, 1885, 1886, 1888, 1892, 1894, 1895, 1896, 1910, 1928], "necessarili": [3, 39, 41, 47, 49, 58, 470, 905, 1226, 1248, 1259, 1290, 1358, 1429, 1886, 1888], "machin": [3, 41, 49, 58, 63, 64, 69, 1194, 1199, 1235, 1458, 1892, 1893, 1894, 1895, 1898, 1901, 1902, 1905, 1912, 1913, 1914], "driver": [3, 29, 1135, 1235, 1253, 1254, 1299, 1861, 1886, 1897, 1913], "allow_tf32": [3, 1751, 1861, 1886, 1897], "tensorfloat": 3, "core": [3, 4, 8, 9, 15, 19, 21, 22, 25, 67, 950, 1020, 1658, 1863, 1867, 1885, 1886, 1887, 1897, 1905, 1925], "amper": [3, 22], "newer": [3, 20, 32, 1026, 1643, 1885, 1886, 1899, 1902, 1904, 1905, 1909], "tf32": 3, "allow_fp16_reduced_precision_reduct": [3, 1886, 1897], "precis": [3, 4, 9, 25, 30, 32, 39, 47, 63, 683, 686, 905, 906, 918, 930, 1009, 1106, 1139, 1235, 1253, 1259, 1284, 1294, 1335, 1336, 1337, 1339, 1350, 1351, 1352, 1353, 1354, 1355, 1375, 1393, 1409, 1415, 1416, 1417, 1474, 1532, 1571, 1602, 1736, 1751, 1756, 1858, 1863, 1873, 1879, 1883, 1894, 1905, 1908, 1909, 1911, 1918, 1920, 1922, 1923, 1929], "gemm": [3, 17, 1885, 1901], "allow_bf16_reduced_precision_reduct": [3, 1886, 1897], "cufft_plan_cach": [3, 1886], "cufft": 3, "queri": [3, 15, 16, 21, 41, 58, 71, 732, 966, 967, 969, 975, 1022, 1026, 1040, 1041, 1190, 1422, 1428, 1571, 1613, 1861, 1886, 1905], "specif": [3, 4, 8, 9, 10, 15, 16, 18, 20, 21, 25, 28, 29, 32, 41, 43, 45, 47, 49, 56, 58, 60, 63, 68, 71, 89, 511, 851, 858, 914, 969, 1054, 1083, 1152, 1187, 1194, 1199, 1203, 1205, 1206, 1290, 1369, 1394, 1571, 1596, 1597, 1616, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1746, 1785, 1857, 1860, 1862, 1863, 1865, 1867, 1869, 1873, 1877, 1879, 1883, 1886, 1892, 1896, 1898, 1901, 1904, 1905, 1907, 1908, 1909, 1911, 1913, 1915, 1922, 1923], "via": [3, 8, 13, 15, 16, 17, 21, 24, 27, 32, 33, 38, 41, 43, 47, 56, 63, 67, 71, 515, 614, 905, 906, 937, 964, 1000, 1020, 1067, 1123, 1262, 1340, 1341, 1342, 1359, 1377, 1385, 1386, 1387, 1394, 1461, 1609, 1643, 1646, 1689, 1860, 1862, 1863, 1873, 1875, 1878, 1881, 1883, 1886, 1888, 1889, 1890, 1892, 1894, 1896, 1897, 1901, 1905, 1908, 1913, 1914, 1917, 1920, 1921, 1928], "readonli": 3, "show": [3, 5, 8, 19, 22, 23, 25, 29, 31, 35, 38, 39, 41, 43, 48, 63, 71, 898, 904, 950, 1114, 1190, 1291, 1422, 1593, 1659, 1857, 1858, 1863, 1876, 1885, 1886, 1887, 1891, 1892, 1894, 1901, 1904, 1905, 1913, 1915], "max_siz": [3, 57, 59, 1886], "capac": [3, 1033, 1886], "preferred_linalg_librari": 3, "algebra": [3, 10, 1063, 1247, 1858, 1868], "cusolv": [3, 1253, 1254, 1808], "magma": [3, 942, 1235, 1279, 1707, 1808, 1900, 1917], "decid": [3, 5, 8, 16, 17, 18, 23, 41, 58, 67, 1625, 1870, 1901, 1917], "heurist": [3, 17, 23, 29, 32, 38, 58, 59, 71, 1063], "overrid": [3, 28, 32, 39, 41, 42, 47, 51, 59, 63, 68, 71, 789, 790, 851, 887, 889, 1006, 1338, 1339, 1356, 1358, 1382, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1493, 1494, 1504, 1533, 1556, 1564, 1616, 1678, 1739, 1756, 1858, 1863, 1867, 1904, 1905, 1908, 1913, 1922, 1927], "wherev": [3, 10, 21, 1876], "pick": [3, 14, 15, 19, 23, 41, 57, 59, 511, 950, 1883, 1913], "prefer": [3, 10, 38, 43, 49, 63, 859, 875, 900, 1188, 1230, 1243, 1247, 1255, 1262, 1429, 1571, 1743, 1804, 1822, 1860, 1883, 1886, 1905, 1917], "achiev": [3, 29, 38, 39, 41, 47, 59, 63, 1063, 1127, 1190, 1339, 1345, 1422, 1428, 1429, 1494, 1523, 1602, 1886, 1893, 1905, 1913, 1915], "better": [3, 4, 8, 9, 10, 13, 14, 17, 19, 21, 25, 29, 32, 38, 41, 49, 67, 950, 1032, 1119, 1123, 1124, 1165, 1177, 1205, 1358, 1455, 1577, 1602, 1689, 1714, 1863, 1882, 1883, 1885, 1886, 1891, 1900, 1901, 1904, 1907, 1909, 1917, 1922, 1927], "select": [3, 6, 21, 25, 33, 36, 38, 41, 47, 49, 313, 315, 317, 321, 757, 940, 970, 971, 975, 982, 983, 984, 985, 987, 1008, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1032, 1033, 1036, 1038, 1040, 1041, 1083, 1262, 1291, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1374, 1392, 1437, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1630, 1631, 1746, 1819, 1853, 1859, 1860, 1861, 1863, 1875, 1876, 1877, 1878, 1883, 1885, 1886, 1891, 1898, 1903, 1908, 1917, 1921, 1924], "incorrect": [3, 5, 6, 63, 71, 254, 511, 553, 896, 905, 932, 1205, 1248, 1261, 1428, 1466, 1467, 1468, 1469, 1589, 1649, 1804, 1860, 1863, 1886, 1897, 1901], "linalg": [3, 406, 940, 941, 942, 943, 963, 1049, 1135, 1168, 1270, 1279, 1280, 1281, 1285, 1286, 1609, 1610, 1614, 1649, 1694, 1699, 1701, 1707, 1778, 1808, 1809, 1831, 1847, 1858], "inv": [3, 47, 942, 1168, 1221, 1225, 1231, 1247, 1251, 1255], "inv_ex": 3, "cholesky_ex": [3, 1219], "lu_factor": [3, 1238, 1239, 1279, 1280, 1281], "lu": [3, 11, 1231, 1237, 1238, 1239, 1280, 1281, 1861], "eigh": [3, 1219, 1225, 1228, 1247, 1253, 1897], "eighval": 3, "svdval": [3, 1221, 1235, 1244, 1253, 1808, 1897], "_linalgbackend": 3, "sdpbackend": 3, "enum": [3, 21, 41, 793, 1901, 1908, 1913], "scale": [3, 8, 17, 38, 47, 49, 57, 59, 98, 472, 474, 614, 682, 686, 687, 688, 735, 736, 737, 738, 739, 740, 741, 746, 747, 748, 749, 750, 751, 752, 753, 756, 767, 769, 770, 771, 772, 774, 777, 778, 792, 796, 799, 816, 817, 818, 819, 822, 918, 1077, 1078, 1081, 1099, 1130, 1131, 1276, 1334, 1360, 1365, 1366, 1367, 1383, 1394, 1449, 1474, 1475, 1476, 1512, 1513, 1514, 1530, 1532, 1571, 1572, 1577, 1662, 1683, 1709, 1710, 1711, 1712, 1713, 1786, 1787, 1805, 1850, 1858, 1861, 1877, 1881, 1886, 1890, 1894, 1908, 1909, 1911, 1918], "product": [3, 22, 33, 41, 47, 58, 151, 683, 686, 687, 688, 757, 890, 892, 899, 901, 902, 903, 904, 918, 930, 936, 940, 958, 963, 975, 1022, 1026, 1040, 1041, 1044, 1060, 1063, 1126, 1130, 1131, 1167, 1210, 1222, 1229, 1255, 1256, 1258, 1284, 1291, 1294, 1314, 1374, 1375, 1392, 1393, 1520, 1571, 1609, 1695, 1696, 1705, 1824, 1839, 1847, 1850, 1858, 1860, 1876, 1883, 1891, 1893, 1897, 1905, 1917], "attent": [3, 8, 46, 732, 1339, 1428, 1465, 1467, 1469, 1494, 1571, 1858, 1900, 1921], "stai": [3, 8, 45, 140, 1359, 1886, 1896, 1908, 1913, 1917], "align": [3, 10, 19, 39, 757, 776, 782, 817, 823, 950, 1063, 1143, 1245, 1337, 1345, 1358, 1374, 1388, 1392, 1416, 1417, 1437, 1474, 1504, 1505, 1532, 1533, 1590, 1609, 1649, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1681, 1829, 1858, 1876, 1883, 1891, 1901, 1911, 1918], "src": [3, 4, 41, 71, 197, 229, 313, 321, 470, 510, 511, 512, 513, 514, 515, 517, 535, 1054, 1120, 1312, 1465, 1468, 1469, 1658, 1740, 1741, 1742, 1746, 1777, 1818, 1843, 1859, 1861, 1905], "transform": [3, 4, 20, 21, 22, 38, 43, 46, 63, 68, 778, 794, 835, 836, 854, 855, 941, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1119, 1120, 1121, 1125, 1130, 1187, 1199, 1343, 1377, 1385, 1386, 1387, 1394, 1409, 1450, 1466, 1467, 1468, 1469, 1486, 1492, 1521, 1538, 1557, 1593, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1772, 1804, 1858, 1889, 1906, 1908, 1922, 1927], "sdp_utils_cpp": 3, "h": [3, 5, 11, 15, 25, 32, 47, 486, 738, 739, 740, 757, 1219, 1226, 1229, 1239, 1253, 1328, 1329, 1336, 1337, 1339, 1341, 1342, 1346, 1351, 1352, 1354, 1362, 1363, 1365, 1367, 1374, 1375, 1386, 1387, 1392, 1393, 1394, 1405, 1406, 1416, 1417, 1434, 1435, 1437, 1439, 1456, 1472, 1475, 1476, 1486, 1494, 1521, 1556, 1562, 1563, 1609, 1610, 1643, 1658, 1808, 1861, 1876, 1877, 1883, 1886, 1887, 1890, 1891, 1901, 1921, 1922, 1923], "flash_sdp_en": 3, "flash": 3, "enable_mem_efficient_sdp": [3, 1571], "mem_efficient_sdp_en": 3, "enable_flash_sdp": [3, 1571], "math_sdp_en": 3, "math": [3, 29, 38, 71, 1073, 1239, 1241, 1533, 1571, 1697, 1714, 1809, 1858, 1860, 1862, 1863, 1897, 1917, 1918, 1924], "enable_math_sdp": [3, 1571], "sdp_kernel": [3, 1571], "enable_flash": 3, "enable_math": [3, 1571], "enable_mem_effici": 3, "temporarili": [3, 23, 49, 1747, 1883, 1901, 1907], "previou": [3, 17, 35, 41, 58, 63, 71, 553, 757, 998, 1108, 1143, 1200, 1260, 1276, 1374, 1392, 1437, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1659, 1714, 1804, 1871, 1883, 1886, 1888, 1894, 1900, 1908, 1915], "is_avail": [3, 34, 41, 1858, 1886, 1892, 1895, 1907], "determinist": [3, 4, 6, 37, 41, 47, 71, 89, 511, 870, 1138, 1171, 1193, 1205, 1206, 1287, 1290, 1292, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1392, 1437, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1744, 1750, 1843, 1861, 1883, 1898, 1904, 1912], "algorithm": [3, 4, 8, 30, 36, 39, 42, 45, 47, 49, 63, 89, 757, 776, 782, 940, 1187, 1230, 1237, 1243, 1247, 1253, 1262, 1279, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1372, 1374, 1392, 1437, 1473, 1474, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1521, 1532, 1571, 1590, 1602, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1678, 1697, 1736, 1751, 1808, 1809, 1843, 1858, 1883, 1886, 1897, 1913, 1917], "are_deterministic_algorithms_en": 3, "use_deterministic_algorithm": [3, 870, 1171, 1750, 1898], "benchmark": [3, 12, 17, 22, 25, 1858, 1861, 1886, 1892], "fastest": [3, 874, 1602, 1648, 1664, 1665, 1891, 1898, 1904], "benchmark_limit": 3, "maximum": [3, 15, 47, 58, 59, 692, 694, 768, 792, 817, 818, 819, 822, 823, 871, 977, 1012, 1014, 1020, 1027, 1028, 1042, 1043, 1109, 1125, 1150, 1151, 1152, 1262, 1287, 1307, 1381, 1512, 1513, 1607, 1681, 1689, 1714, 1728, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1859, 1861, 1869, 1881, 1882, 1886, 1903, 1911, 1924], "try": [3, 4, 5, 8, 9, 13, 15, 16, 17, 19, 20, 29, 41, 43, 50, 51, 55, 58, 63, 67, 68, 83, 84, 950, 1033, 1116, 1125, 1131, 1195, 1196, 1205, 1307, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1466, 1468, 1474, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1850, 1857, 1860, 1863, 1864, 1883, 1886, 1888, 1890, 1891, 1896, 1901, 1904, 1905, 1908, 1909, 1913, 1917], "dispatch": [3, 17, 18, 41, 63, 71, 1195, 1303, 1304, 1863, 1867, 1886, 1888, 1901, 1928], "v8": 3, "verbos": [3, 17, 29, 32, 41, 71, 677, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1857, 1869, 1877, 1901, 1902, 1922], "On": [3, 12, 15, 16, 32, 37, 38, 41, 42, 47, 59, 63, 68, 71, 683, 686, 918, 930, 1237, 1284, 1294, 1350, 1351, 1352, 1353, 1354, 1355, 1375, 1390, 1391, 1392, 1393, 1409, 1432, 1437, 1450, 1602, 1664, 1665, 1674, 1677, 1858, 1860, 1870, 1883, 1885, 1886, 1897, 1905, 1913, 1914, 1915, 1917], "demand": [3, 38, 1000, 1862, 1893, 1913], "onemkl": 3, "dump": [3, 17, 21, 29, 71, 964, 1887, 1900], "durat": [3, 17, 29, 41, 55, 58, 1303, 1304, 1873, 1907], "kernel": [3, 4, 5, 12, 16, 17, 18, 20, 29, 30, 32, 35, 41, 63, 70, 736, 737, 738, 739, 740, 769, 770, 771, 967, 969, 970, 1006, 1007, 1039, 1041, 1309, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1370, 1371, 1390, 1391, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1418, 1419, 1420, 1473, 1496, 1497, 1498, 1499, 1500, 1501, 1516, 1517, 1571, 1612, 1858, 1860, 1867, 1871, 1878, 1886, 1888, 1889, 1895, 1897, 1901, 1904, 1907, 1909, 1917], "environ": [3, 4, 8, 13, 17, 29, 32, 33, 35, 37, 39, 47, 49, 51, 56, 61, 71, 677, 1199, 1205, 1392, 1437, 1843, 1857, 1858, 1860, 1869, 1883, 1885, 1887, 1892, 1897, 1898, 1900, 1906, 1913], "mkl_verbos": 3, "methodologi": 3, "larg": [3, 4, 8, 9, 12, 17, 29, 38, 41, 71, 89, 677, 855, 960, 962, 1020, 1235, 1253, 1330, 1369, 1473, 1515, 1602, 1689, 1776, 1788, 1858, 1875, 1877, 1878, 1885, 1886, 1890, 1894, 1897, 1899, 1901, 1905, 1906, 1909, 1913, 1917, 1920, 1923], "moreov": [3, 63, 511, 1602, 1677], "investig": [3, 8, 41, 68], "enough": [3, 9, 18, 39, 71, 1201, 1312, 1471, 1790, 1791, 1792, 1793, 1794, 1795, 1843, 1862, 1875, 1878, 1888, 1891, 1904, 1905, 1920, 1928], "scope": [3, 8, 16, 28, 60, 71, 1116, 1461, 1625, 1860, 1862, 1863, 1886, 1890, 1901, 1905, 1915], "second": [3, 6, 12, 21, 32, 35, 41, 45, 49, 51, 58, 60, 69, 71, 683, 686, 688, 691, 757, 791, 871, 872, 873, 881, 889, 905, 906, 918, 922, 923, 925, 926, 927, 930, 963, 975, 1022, 1026, 1040, 1041, 1051, 1053, 1054, 1060, 1068, 1109, 1110, 1121, 1124, 1125, 1126, 1130, 1131, 1133, 1134, 1143, 1146, 1154, 1155, 1156, 1167, 1179, 1212, 1214, 1222, 1258, 1261, 1267, 1268, 1278, 1284, 1288, 1290, 1291, 1293, 1294, 1318, 1323, 1326, 1330, 1336, 1337, 1343, 1351, 1352, 1354, 1355, 1365, 1366, 1373, 1374, 1388, 1391, 1392, 1410, 1414, 1416, 1417, 1437, 1450, 1503, 1505, 1539, 1593, 1625, 1664, 1665, 1668, 1674, 1678, 1689, 1735, 1785, 1793, 1828, 1833, 1835, 1844, 1847, 1850, 1862, 1863, 1883, 1886, 1888, 1889, 1890, 1891, 1894, 1898, 1901, 1907, 1913, 1918, 1922], "verbose_on": 3, "level": [3, 4, 8, 9, 10, 15, 17, 18, 21, 26, 28, 29, 33, 35, 38, 41, 49, 50, 51, 55, 63, 67, 71, 497, 677, 744, 891, 892, 893, 901, 1120, 1135, 1359, 1602, 1858, 1859, 1860, 1863, 1864, 1869, 1873, 1875, 1878, 1881, 1883, 1885, 1888, 1891, 1905, 1907, 1908, 1909, 1913, 1917, 1922, 1926, 1927, 1928], "verbose_off": 3, "dnn": [3, 1885], "onednn": [3, 852, 853, 856, 1192, 1198, 1908], "former": [3, 63, 1392, 1422, 1883], "dnnl_verbos": 3, "verbose_on_cr": 3, "get_opt_einsum": 3, "packag": [3, 8, 9, 13, 34, 39, 47, 67, 70, 1521, 1602, 1857, 1858, 1874, 1888, 1894, 1904, 1911, 1913, 1922, 1925], "els": [3, 8, 12, 13, 15, 28, 38, 41, 43, 47, 49, 50, 58, 71, 600, 757, 921, 1201, 1207, 1388, 1461, 1558, 1571, 1602, 1656, 1664, 1665, 1674, 1675, 1676, 1677, 1731, 1732, 1765, 1771, 1860, 1862, 1864, 1865, 1870, 1875, 1878, 1886, 1888, 1889, 1894, 1895, 1901, 1904, 1905, 1919], "einsum": [3, 1861, 1903], "readthedoc": [3, 1063], "io": [3, 8, 38, 43, 1063, 1197, 1200, 1261, 1392, 1393, 1469, 1571, 1657, 1739, 1900, 1908], "en": [3, 39, 1063, 1892, 1922, 1929], "path_find": [3, 1063], "html": [3, 4, 5, 8, 19, 33, 59, 677, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 950, 1063, 1471, 1843, 1884, 1892, 1894, 1898, 1905, 1922], "calcul": [3, 38, 41, 55, 757, 765, 766, 796, 799, 816, 817, 821, 938, 962, 1051, 1055, 1063, 1067, 1181, 1187, 1245, 1267, 1268, 1270, 1335, 1336, 1337, 1340, 1341, 1342, 1345, 1353, 1354, 1355, 1369, 1374, 1376, 1377, 1385, 1386, 1387, 1394, 1461, 1473, 1474, 1488, 1489, 1490, 1518, 1521, 1532, 1561, 1610, 1621, 1643, 1647, 1649, 1683, 1729, 1753, 1802, 1803, 1833, 1835, 1845, 1846, 1883, 1884, 1887, 1891, 1897, 1900, 1908, 1927], "path": [3, 4, 5, 9, 12, 17, 21, 23, 32, 41, 43, 56, 58, 60, 61, 63, 71, 731, 912, 913, 964, 965, 1063, 1190, 1422, 1438, 1469, 1659, 1857, 1861, 1862, 1883, 1886, 1888, 1892, 1899, 1905, 1907, 1917, 1926], "contract": [3, 13, 21, 1063, 1824, 1858, 1877, 1905], "left": [3, 38, 71, 459, 497, 811, 817, 862, 919, 923, 928, 929, 934, 939, 1063, 1083, 1090, 1104, 1107, 1108, 1112, 1143, 1147, 1148, 1152, 1187, 1188, 1195, 1209, 1230, 1239, 1243, 1247, 1250, 1251, 1252, 1253, 1255, 1267, 1268, 1312, 1330, 1335, 1336, 1337, 1338, 1339, 1350, 1351, 1352, 1369, 1376, 1389, 1390, 1391, 1410, 1411, 1412, 1413, 1415, 1416, 1417, 1425, 1426, 1427, 1431, 1432, 1470, 1473, 1474, 1475, 1476, 1521, 1541, 1559, 1607, 1681, 1682, 1695, 1723, 1736, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1804, 1824, 1829, 1844, 1860, 1861, 1863, 1883, 1888, 1894, 1911, 1918], "strategi": [3, 4, 8, 17, 38, 39, 41, 45, 51, 63, 898, 900, 1063, 1123, 1203, 1330, 1602, 1689, 1862, 1889, 1891, 1909], "auto": [3, 16, 41, 63, 64, 83, 84, 1063, 1338, 1339, 1863, 1901, 1922], "greedi": [3, 45, 1063], "doc": [3, 4, 5, 10, 18, 19, 24, 33, 58, 59, 83, 677, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 837, 950, 1131, 1208, 1466, 1467, 1468, 1469, 1843, 1850, 1864, 1875, 1884, 1887, 1888, 1894, 1898, 1901, 1905, 1922], "timer": [4, 44, 1858], "stmt": [4, 1885], "setup": [4, 13, 32, 39, 58, 59, 817, 818, 819, 822, 1131, 1602, 1850, 1885, 1886, 1895, 1913, 1914], "global_setup": 4, "perf_count": 4, "global": [4, 6, 9, 14, 16, 17, 18, 27, 28, 29, 38, 41, 43, 45, 46, 47, 49, 59, 63, 68, 70, 71, 851, 858, 862, 870, 919, 928, 1015, 1022, 1064, 1066, 1076, 1081, 1099, 1117, 1120, 1147, 1148, 1171, 1178, 1190, 1193, 1205, 1209, 1260, 1276, 1422, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1602, 1621, 1625, 1653, 1716, 1718, 1720, 1723, 1747, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1855, 1860, 1863, 1864, 1879, 1882, 1888, 1893, 1894, 1896, 1898, 1908, 1913, 1914, 1915, 1917, 1920, 1922], "label": [4, 7, 8, 38, 45, 1063, 1330, 1339, 1345, 1356, 1358, 1382, 1414, 1425, 1426, 1505, 1636, 1682, 1887, 1896, 1898, 1922], "sub_label": 4, "descript": [4, 8, 18, 29, 31, 32, 38, 51, 58, 71, 731, 1161, 1162, 1163, 1235, 1262, 1486, 1707, 1862, 1863, 1886, 1888, 1891, 1893, 1894, 1901, 1929], "env": [4, 17, 29, 41, 47, 51, 56, 58, 59, 61, 71, 1020, 1656, 1887, 1897, 1913], "num_thread": 4, "languag": [4, 32, 51, 1201, 1330, 1465, 1520, 1890], "measur": [4, 47, 55, 966, 1012, 1014, 1221, 1338, 1339, 1356, 1382, 1389, 1413, 1414, 1470, 1471, 1493, 1494, 1552, 1691, 1858, 1886, 1893, 1894, 1904, 1917], "statement": [4, 13, 21, 47, 68, 71, 1191, 1205, 1864, 1883, 1888, 1896, 1899, 1901, 1905, 1911, 1913], "org": [4, 5, 8, 10, 11, 19, 33, 39, 46, 47, 59, 677, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 950, 1262, 1392, 1440, 1441, 1468, 1471, 1646, 1697, 1772, 1857, 1864, 1883, 1884, 1894, 1898, 1900, 1901, 1905, 1922, 1929], "timeit": [4, 1885], "sever": [4, 19, 33, 38, 41, 46, 47, 63, 71, 735, 736, 737, 738, 739, 740, 763, 764, 769, 770, 771, 779, 780, 950, 1009, 1067, 1165, 1190, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1350, 1351, 1352, 1353, 1354, 1355, 1370, 1371, 1390, 1391, 1410, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1475, 1476, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1496, 1497, 1498, 1499, 1500, 1501, 1516, 1517, 1539, 1542, 1543, 1545, 1546, 1547, 1602, 1611, 1612, 1614, 1615, 1647, 1658, 1712, 1713, 1753, 1839, 1860, 1882, 1883, 1885, 1886, 1893, 1894, 1901, 1904, 1908, 1913], "kei": [4, 18, 20, 21, 25, 28, 38, 43, 49, 56, 58, 59, 63, 71, 600, 677, 732, 851, 856, 914, 1029, 1119, 1129, 1190, 1205, 1206, 1261, 1422, 1423, 1428, 1432, 1465, 1466, 1467, 1468, 1469, 1571, 1628, 1644, 1858, 1861, 1862, 1863, 1867, 1886, 1888, 1893, 1894, 1899, 1901, 1903, 1904, 1907, 1908, 1911, 1913, 1914, 1919, 1922, 1924, 1926], "awar": [4, 8, 25, 485, 709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 730, 835, 836, 852, 859, 860, 1469, 1571, 1602, 1812, 1813, 1814, 1815, 1816, 1877, 1883, 1886, 1905, 1911, 1914, 1917], "element": [4, 16, 20, 38, 41, 47, 68, 69, 71, 98, 120, 151, 155, 197, 217, 242, 254, 258, 286, 313, 315, 317, 319, 321, 352, 398, 400, 402, 434, 453, 470, 472, 473, 495, 497, 511, 513, 515, 518, 542, 543, 555, 557, 606, 607, 614, 678, 680, 681, 684, 685, 690, 691, 695, 696, 732, 755, 757, 767, 768, 769, 770, 771, 777, 781, 790, 871, 873, 874, 875, 878, 879, 880, 881, 882, 890, 898, 899, 901, 902, 903, 905, 906, 920, 929, 932, 939, 945, 949, 956, 958, 959, 960, 1006, 1042, 1043, 1044, 1045, 1046, 1047, 1050, 1052, 1053, 1054, 1058, 1060, 1063, 1066, 1068, 1069, 1073, 1093, 1097, 1098, 1100, 1102, 1107, 1109, 1110, 1112, 1116, 1121, 1122, 1124, 1125, 1126, 1130, 1131, 1132, 1133, 1134, 1135, 1143, 1146, 1149, 1150, 1151, 1152, 1167, 1175, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1209, 1211, 1212, 1214, 1231, 1233, 1237, 1248, 1252, 1263, 1264, 1266, 1269, 1271, 1272, 1273, 1274, 1278, 1279, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1310, 1312, 1317, 1318, 1320, 1321, 1322, 1323, 1324, 1334, 1335, 1338, 1339, 1340, 1341, 1342, 1344, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1360, 1361, 1362, 1363, 1364, 1366, 1367, 1369, 1374, 1375, 1378, 1379, 1380, 1381, 1382, 1383, 1388, 1389, 1392, 1394, 1398, 1399, 1400, 1401, 1402, 1403, 1408, 1411, 1413, 1414, 1415, 1416, 1417, 1421, 1423, 1425, 1426, 1427, 1428, 1429, 1430, 1432, 1433, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1449, 1451, 1452, 1453, 1454, 1455, 1457, 1458, 1460, 1461, 1462, 1463, 1464, 1465, 1470, 1471, 1473, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1506, 1510, 1513, 1514, 1519, 1520, 1524, 1525, 1526, 1527, 1530, 1533, 1534, 1536, 1541, 1545, 1546, 1547, 1551, 1552, 1556, 1557, 1559, 1562, 1563, 1564, 1565, 1566, 1567, 1571, 1572, 1573, 1574, 1575, 1577, 1579, 1581, 1582, 1583, 1584, 1589, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1628, 1629, 1635, 1636, 1638, 1639, 1648, 1649, 1650, 1652, 1660, 1700, 1701, 1704, 1705, 1712, 1713, 1715, 1726, 1729, 1730, 1734, 1736, 1738, 1756, 1759, 1761, 1773, 1774, 1776, 1777, 1781, 1787, 1790, 1791, 1792, 1793, 1794, 1795, 1797, 1798, 1802, 1803, 1807, 1818, 1820, 1821, 1825, 1826, 1827, 1829, 1831, 1832, 1833, 1834, 1835, 1837, 1839, 1840, 1841, 1845, 1846, 1847, 1850, 1853, 1861, 1863, 1870, 1878, 1881, 1884, 1885, 1888, 1891, 1897, 1899, 1901, 1904, 1917, 1918, 1919, 1920, 1921, 1922, 1923, 1924, 1925, 1928], "lazili": [4, 34, 43, 966, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1593, 1860], "threadpool": 4, "comparison": [4, 26, 39, 41, 71, 1190, 1205, 1206, 1422, 1660, 1864, 1888, 1924, 1927], "appl": 4, "focu": [4, 17, 21, 1691], "replic": [4, 38, 46, 63, 1143, 1200, 1350, 1351, 1352, 1359, 1369, 1398, 1399, 1400, 1446, 1447, 1448, 1473, 1559, 1586, 1906], "particularli": [4, 15, 38, 39, 60, 1358, 1359, 1429, 1860, 1886], "variat": [4, 29, 47, 1863, 1888, 1904, 1909], "confound": 4, "quantifi": [4, 1471], "nois": [4, 29, 1861, 1898], "median": [4, 47, 174, 1318, 1843, 1861, 1876, 1903], "deviat": [4, 47, 377, 1334, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1461, 1650, 1766, 1771, 1802, 1803, 1881], "merg": [4, 7, 8, 10, 38, 41, 43, 59, 1423, 1428, 1432], "repeat": [4, 47, 68, 492, 962, 1063, 1253, 1279, 1418, 1419, 1420, 1493, 1494, 1697, 1729, 1788, 1808, 1809, 1825, 1859, 1861, 1863, 1903, 1907, 1910, 1917], "autorang": 4, "exact": [4, 16, 17, 19, 25, 29, 32, 38, 49, 60, 339, 738, 739, 740, 792, 871, 872, 873, 905, 906, 950, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1290, 1354, 1392, 1469, 1532, 1571, 1602, 1692, 1782, 1881, 1887, 1896, 1917, 1928], "discuss": [4, 6, 9, 10, 11, 17, 18, 26, 47, 71, 1383, 1870, 1883, 1888, 1894, 1898, 1913, 1915, 1917], "docstr": [4, 32, 71, 858, 859, 1190, 1422, 1857, 1886], "adapt": [4, 15, 763, 764, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1360, 1480, 1481, 1482, 1483, 1484, 1485, 1656, 1662, 1663, 1674, 1676, 1683, 1886], "field": [4, 8, 21, 28, 29, 41, 45, 49, 51, 55, 56, 71, 823, 890, 1188, 1190, 1330, 1338, 1339, 1356, 1358, 1382, 1388, 1389, 1413, 1414, 1422, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1486, 1493, 1494, 1504, 1521, 1533, 1556, 1564, 1635, 1672, 1678, 1873, 1883, 1887, 1896, 1901, 1913, 1914, 1922], "displai": [4, 17, 29, 35, 1008, 1021, 1532, 1590, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693, 1857, 1864, 1869, 1872, 1901, 1922, 1924], "instruct": [4, 5, 16, 17, 21, 29, 30, 32, 60, 70, 1860, 1863, 1897, 1901, 1924], "count": [4, 21, 38, 47, 55, 71, 921, 961, 1002, 1116, 1151, 1152, 1188, 1227, 1228, 1635, 1840, 1841, 1861, 1873, 1886, 1903, 1907, 1913, 1915, 1917], "wall": [4, 23], "callgrind": 4, "analog": [4, 15, 21, 71, 691, 1046, 1084, 1086, 1165, 1239, 1392, 1677, 1808, 1825, 1878, 1894], "constructor": [4, 32, 38, 39, 45, 63, 71, 821, 858, 859, 1330, 1427, 1432, 1433, 1450, 1475, 1476, 1602, 1642, 1783, 1858, 1860, 1863, 1864, 1886, 1887, 1894, 1913, 1917, 1919, 1920, 1923, 1929], "snippet": [4, 21, 59, 1857, 1894, 1899], "loop": [4, 12, 16, 21, 22, 28, 39, 60, 64, 68, 69, 71, 859, 860, 904, 1009, 1012, 1014, 1125, 1131, 1205, 1602, 1612, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1850, 1860, 1861, 1863, 1873, 1885, 1886, 1890, 1891, 1894, 1897, 1901, 1904, 1907, 1908, 1922], "default_tim": 4, "summar": [4, 5, 21, 29, 59, 1756, 1863, 1878, 1917], "relu": [4, 13, 20, 28, 29, 39, 68, 69, 71, 697, 698, 702, 703, 704, 705, 706, 707, 708, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 762, 789, 790, 811, 851, 857, 1006, 1121, 1131, 1201, 1422, 1437, 1439, 1450, 1458, 1465, 1467, 1469, 1568, 1569, 1593, 1659, 1850, 1859, 1860, 1861, 1871, 1877, 1878, 1881, 1883, 1894, 1899, 1901, 1903, 1908, 1910, 1911], "readabl": [4, 29, 31, 38, 56, 71, 1008, 1021, 1822, 1901, 1904, 1928], "supplement": 4, "disambigu": [4, 29, 56, 71, 1267], "ident": [4, 16, 29, 32, 38, 41, 47, 63, 71, 785, 811, 905, 906, 1051, 1227, 1228, 1229, 1230, 1243, 1255, 1258, 1262, 1279, 1317, 1318, 1334, 1360, 1561, 1609, 1611, 1847, 1853, 1864, 1881, 1897, 1898, 1905, 1910, 1917], "easi": [4, 13, 21, 26, 29, 38, 43, 58, 1860, 1883, 1890, 1893, 1894, 1896, 1905, 1908, 1913, 1914, 1917], "differenti": [4, 47, 64, 69, 151, 352, 586, 799, 886, 888, 890, 892, 893, 895, 898, 899, 900, 901, 902, 903, 904, 905, 906, 947, 1009, 1124, 1125, 1126, 1130, 1204, 1236, 1237, 1248, 1279, 1344, 1345, 1365, 1523, 1557, 1602, 1614, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1843, 1858, 1870, 1888, 1890, 1891, 1901, 1904, 1913, 1923, 1925], "distinguish": [4, 1908, 1917], "princip": [4, 1236, 1697], "signal": [4, 18, 30, 43, 49, 58, 60, 735, 736, 737, 763, 764, 779, 780, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1187, 1252, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1350, 1351, 1352, 1370, 1371, 1390, 1391, 1410, 1415, 1416, 1417, 1475, 1476, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1496, 1499, 1516, 1517, 1539, 1542, 1543, 1545, 1546, 1547, 1804, 1858, 1875, 1896, 1907, 1913], "form": [4, 8, 10, 14, 28, 30, 38, 41, 47, 57, 58, 59, 63, 68, 71, 757, 776, 782, 941, 1051, 1091, 1093, 1190, 1229, 1232, 1237, 1248, 1253, 1328, 1329, 1332, 1333, 1345, 1370, 1371, 1374, 1392, 1422, 1437, 1473, 1474, 1505, 1516, 1517, 1520, 1532, 1559, 1590, 1614, 1677, 1695, 1824, 1857, 1860, 1864, 1878, 1883, 1888, 1894, 1901, 1905, 1908, 1922], "treat": [4, 18, 24, 28, 47, 57, 66, 71, 321, 470, 790, 905, 906, 1006, 1119, 1242, 1245, 1247, 1259, 1261, 1271, 1272, 1273, 1274, 1291, 1320, 1366, 1376, 1394, 1426, 1427, 1428, 1429, 1432, 1450, 1455, 1513, 1602, 1644, 1648, 1683, 1736, 1804, 1818, 1825, 1862, 1863, 1876, 1883, 1913, 1917, 1920, 1927], "distinct": [4, 1119, 1225, 1226, 1270, 1863, 1888, 1899, 1913, 1914], "workload": [4, 9, 38, 41, 63, 1009, 1886, 1893, 1897, 1913], "good": [4, 8, 9, 16, 19, 21, 25, 32, 63, 71, 89, 950, 1123, 1430, 1772, 1857, 1867, 1875, 1888, 1893, 1894, 1901, 1905, 1906, 1908], "intrins": [4, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 789, 790, 1909, 1910], "contrast": [4, 47, 49, 757, 1374, 1677, 1859, 1881, 1883, 1889, 1917], "blocked_autorang": 4, "callback": [4, 39, 58, 60, 70, 71, 1602, 1873, 1893, 1907, 1913], "min_run_tim": 4, "minimum": [4, 32, 39, 49, 58, 59, 693, 694, 768, 792, 817, 818, 819, 822, 823, 872, 921, 1043, 1110, 1150, 1151, 1152, 1292, 1345, 1381, 1471, 1681, 1682, 1689, 1772, 1790, 1791, 1792, 1793, 1794, 1795, 1859, 1861, 1881, 1883, 1891, 1903, 1911, 1920], "At": [4, 6, 7, 8, 14, 17, 21, 29, 33, 38, 1097, 1341, 1350, 1351, 1352, 1353, 1354, 1355, 1390, 1391, 1871, 1878, 1885, 1891, 1908, 1913, 1918], "high": [4, 5, 8, 9, 10, 11, 12, 17, 21, 22, 29, 33, 39, 41, 47, 49, 55, 57, 59, 71, 120, 1345, 1468, 1718, 1719, 1751, 1859, 1861, 1873, 1875, 1891, 1892, 1894, 1895, 1904, 1908, 1909, 1913, 1917, 1922, 1923, 1924, 1927], "pseudo": [4, 89], "total_tim": 4, "block_siz": 4, "choic": [4, 9, 10, 15, 17, 29, 41, 1205, 1253, 1423, 1432, 1714, 1885, 1901, 1911, 1917], "block": [4, 8, 9, 38, 41, 45, 46, 58, 60, 70, 71, 580, 581, 582, 929, 966, 1020, 1210, 1262, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1398, 1399, 1400, 1401, 1402, 1403, 1425, 1473, 1515, 1589, 1602, 1790, 1791, 1792, 1860, 1862, 1863, 1873, 1875, 1879, 1883, 1886, 1887, 1891, 1901, 1908, 1913, 1917], "qualiti": [4, 8, 39], "balanc": [4, 19, 89, 950], "compet": 4, "statist": [4, 17, 29, 39, 41, 47, 796, 797, 817, 818, 819, 821, 822, 975, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1040, 1041, 1267, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1873, 1883, 1890, 1904, 1906, 1908, 1911], "amort": 4, "invoc": [4, 6, 12, 21, 71, 838, 1193, 1205, 1860, 1863, 1886, 1888, 1893, 1901, 1913, 1915], "less": [4, 7, 8, 17, 32, 38, 39, 41, 47, 49, 60, 364, 677, 898, 900, 905, 906, 962, 1016, 1033, 1063, 1107, 1111, 1116, 1119, 1214, 1226, 1262, 1278, 1279, 1330, 1383, 1436, 1453, 1459, 1638, 1727, 1833, 1835, 1857, 1861, 1863, 1878, 1886, 1888, 1896, 1897, 1903, 1906, 1908], "bias": [4, 39, 731, 757, 791, 1340, 1341, 1342, 1374, 1375, 1377, 1385, 1386, 1387, 1392, 1393, 1394, 1437, 1439, 1461], "trivial": [4, 16, 49, 51, 732, 940, 1609, 1901, 1915], "low": [4, 8, 23, 35, 39, 47, 63, 497, 901, 1135, 1345, 1697, 1714, 1718, 1719, 1736, 1809, 1859, 1861, 1873, 1875, 1886, 1907, 1924, 1928], "digit": [4, 1756, 1857, 1872, 1893, 1897], "microsecond": [4, 1886], "bia": [4, 10, 41, 46, 709, 710, 711, 712, 713, 714, 715, 716, 717, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 735, 736, 737, 738, 739, 740, 746, 748, 749, 750, 751, 753, 757, 758, 761, 762, 769, 770, 771, 778, 789, 1129, 1190, 1199, 1330, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1374, 1375, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1422, 1428, 1437, 1438, 1439, 1491, 1492, 1496, 1497, 1498, 1499, 1500, 1501, 1522, 1531, 1535, 1538, 1593, 1602, 1609, 1610, 1624, 1626, 1628, 1643, 1646, 1711, 1859, 1861, 1871, 1888, 1894, 1899, 1908, 1910, 1922], "period": [4, 10, 45, 58, 919, 928, 975, 1008, 1021, 1022, 1026, 1040, 1041, 1083, 1147, 1148, 1209, 1693, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1861, 1873, 1896], "until": [4, 8, 17, 38, 39, 41, 45, 49, 58, 63, 70, 71, 485, 966, 967, 969, 1000, 1116, 1210, 1262, 1303, 1304, 1521, 1593, 1602, 1680, 1686, 1825, 1875, 1881, 1886, 1890, 1901, 1907, 1913, 1915], "overal": [4, 10, 23, 38, 41, 58, 905, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1468, 1883, 1885, 1886, 1896, 1909], "repetit": [4, 1729, 1825], "collect_callgrind": 4, "collect_baselin": 4, "retain_out_fil": 4, "callgrindstat": [4, 1858], "modulo": [4, 47, 1111, 1727], "determin": [4, 6, 9, 15, 16, 17, 28, 29, 30, 32, 34, 35, 37, 38, 39, 41, 47, 49, 56, 58, 63, 68, 71, 820, 823, 898, 900, 905, 906, 919, 928, 935, 940, 1010, 1065, 1084, 1094, 1118, 1119, 1147, 1148, 1151, 1152, 1203, 1223, 1235, 1246, 1249, 1270, 1284, 1366, 1370, 1371, 1392, 1428, 1431, 1437, 1513, 1516, 1517, 1532, 1565, 1590, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1644, 1654, 1689, 1717, 1719, 1721, 1748, 1790, 1791, 1792, 1793, 1794, 1795, 1804, 1856, 1863, 1864, 1877, 1886, 1887, 1888, 1894, 1901, 1905, 1908, 1913, 1915, 1919, 1920, 1922, 1924], "itself": [4, 6, 8, 9, 13, 16, 21, 29, 41, 42, 63, 69, 71, 690, 696, 876, 962, 1124, 1125, 1190, 1201, 1205, 1422, 1455, 1577, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1860, 1875, 1894, 1898, 1901, 1905, 1913, 1917, 1921], "jitter": 4, "interpret": [4, 21, 38, 41, 45, 47, 49, 58, 60, 76, 776, 782, 877, 904, 1019, 1084, 1085, 1086, 1091, 1093, 1094, 1095, 1096, 1116, 1140, 1152, 1190, 1195, 1201, 1205, 1242, 1262, 1362, 1521, 1532, 1533, 1590, 1748, 1754, 1857, 1862, 1863, 1875, 1885, 1886, 1901, 1917, 1919, 1921], "ideal": [4, 17, 57, 59, 1205, 1678, 1877], "analysi": [4, 13, 16, 26, 39, 47, 71, 1209, 1697, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1864, 1894, 1902, 1927], "valgrind": 4, "degrad": [4, 32, 1885, 1887, 1888, 1917], "amelior": 4, "suffici": [4, 17, 29, 32, 39, 47, 50, 58, 63, 1664, 1665, 1857, 1917, 1920], "obtain": [4, 38, 41, 47, 51, 70, 71, 494, 915, 1135, 1307, 1345, 1429, 1505, 1602, 1697, 1714, 1809, 1863, 1875, 1876, 1885, 1898, 1901, 1904, 1907, 1908], "callgrind_control": 4, "callgrind_annot": 4, "boundari": [4, 17, 71, 776, 782, 934, 1143, 1347, 1348, 1349, 1443, 1444, 1445, 1446, 1447, 1448, 1474, 1477, 1478, 1479, 1532, 1590, 1683, 1689, 1743, 1861, 1887, 1905, 1906, 1913], "caller": [4, 49, 58, 71, 851, 1190, 1422, 1469, 1598, 1599, 1883, 1886, 1913, 1915], "structur": [4, 6, 10, 15, 18, 24, 38, 39, 41, 48, 49, 51, 59, 63, 71, 889, 1114, 1126, 1131, 1205, 1422, 1621, 1625, 1660, 1697, 1809, 1850, 1862, 1864, 1870, 1873, 1878, 1886, 1887, 1888, 1889, 1896, 1899, 1900, 1901, 1902, 1904, 1905, 1913, 1917, 1922, 1923, 1924, 1925, 1927], "restrict": [4, 9, 15, 38, 47, 63, 68, 69, 1261, 1284, 1358, 1862, 1863, 1864, 1877, 1878, 1883, 1886, 1891, 1906, 1908], "builtin": [4, 17, 29, 41, 71, 1202, 1261, 1723, 1860, 1862, 1864, 1913, 1915], "surpris": [4, 9, 16, 63, 1857, 1891, 1897], "serial": [4, 33, 38, 41, 43, 45, 58, 1190, 1199, 1200, 1261, 1422, 1593, 1656, 1657, 1739, 1857, 1858, 1861, 1872, 1877, 1883, 1886, 1893, 1894, 1896, 1905, 1908, 1914], "subsequ": [4, 8, 12, 17, 21, 32, 33, 41, 71, 967, 1190, 1201, 1205, 1350, 1351, 1352, 1353, 1354, 1355, 1422, 1450, 1598, 1599, 1886, 1898, 1901, 1913, 1917], "deseri": [4, 43, 1261, 1593, 1857, 1872], "globalsbridg": 4, "care": [4, 8, 12, 16, 17, 18, 29, 32, 41, 47, 63, 70, 71, 1084, 1086, 1422, 1875, 1885, 1886, 1887, 1888, 1890, 1894, 1896, 1899, 1901, 1913, 1917], "reli": [4, 10, 16, 17, 18, 23, 32, 38, 39, 49, 51, 63, 71, 151, 890, 905, 1063, 1359, 1678, 1883, 1885, 1887, 1888, 1898, 1899, 1917, 1921], "pickl": [4, 38, 39, 41, 1190, 1261, 1422, 1739, 1857, 1872, 1875, 1899, 1905], "transfer": [4, 38, 41, 1871, 1875, 1886, 1892, 1894, 1905, 1913], "properli": [4, 8, 38, 39, 43, 45, 49, 58, 63, 70, 1084, 1085, 1086, 1094, 1095, 1096, 1291, 1423, 1424, 1432, 1433, 1602, 1857, 1870, 1888, 1891, 1894, 1896, 1899, 1913, 1914, 1920], "profil": [4, 5, 17, 19, 55, 71, 950, 1203, 1596, 1597, 1598, 1599, 1756, 1858, 1903, 1913], "drive": [4, 10, 21, 41, 1883], "facil": [4, 1261, 1875], "analyz": [4, 5, 29, 35, 71, 1887, 1888, 1897], "manipul": [4, 28, 63, 70, 1194, 1858, 1882, 1890, 1894, 1906, 1911], "1000000": [4, 1661], "mirror": [4, 140], "semant": [4, 10, 34, 41, 58, 59, 63, 71, 151, 791, 871, 872, 873, 890, 904, 932, 969, 1020, 1120, 1131, 1194, 1200, 1259, 1339, 1494, 1565, 1678, 1841, 1850, 1858, 1862, 1863, 1867, 1870, 1878, 1889, 1894, 1901, 1917], "number_per_run": 4, "raw_tim": 4, "task_spec": 4, "serializ": [4, 39, 1860], "consum": [4, 21, 38, 43, 48, 60, 70, 434, 1063, 1875, 1886, 1896, 1901, 1902, 1922], "extrapol": 4, "sinc": [4, 8, 12, 17, 21, 24, 28, 29, 38, 39, 41, 46, 47, 51, 60, 63, 71, 315, 531, 744, 782, 790, 805, 806, 940, 1012, 1014, 1016, 1063, 1103, 1104, 1105, 1119, 1187, 1190, 1195, 1200, 1203, 1279, 1338, 1365, 1418, 1419, 1420, 1422, 1474, 1486, 1521, 1523, 1590, 1593, 1596, 1625, 1644, 1649, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1681, 1682, 1683, 1689, 1804, 1860, 1861, 1862, 1863, 1869, 1871, 1873, 1878, 1882, 1883, 1886, 1888, 1889, 1890, 1891, 1893, 1894, 1899, 1900, 1901, 1903, 1905, 1906, 1907, 1908, 1912, 1913, 1914, 1915, 1917, 1918, 1920, 1921, 1923, 1924], "properti": [4, 14, 15, 16, 38, 41, 42, 43, 47, 50, 55, 58, 63, 71, 789, 877, 909, 915, 993, 1079, 1080, 1082, 1084, 1085, 1086, 1094, 1095, 1096, 1190, 1334, 1455, 1577, 1593, 1603, 1604, 1605, 1635, 1656, 1858, 1863, 1867, 1873, 1883, 1886, 1891, 1904, 1907, 1913, 1917, 1919, 1920, 1923, 1925, 1928, 1929], "significant_figur": 4, "figur": [4, 8, 9, 17, 43, 71, 1885, 1887, 1901, 1906, 1915, 1922, 1927], "intend": [4, 58, 63, 71, 887, 896, 971, 1209, 1486, 1596, 1597, 1598, 1599, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1678, 1863, 1878, 1881, 1883, 1894, 1905], "interquartil": 4, "mitig": 4, "tail": [4, 38, 56], "645": 4, "trim_sigfig": 4, "human": [4, 31, 56, 1008, 1021, 1881, 1901, 1928], "raw": [4, 71, 1116, 1248, 1886, 1905], "built_with_debug_symbol": 4, "baseline_inclusive_stat": 4, "baseline_exclusive_stat": 4, "stmt_inclusive_stat": 4, "stmt_exclusive_stat": 4, "stmt_callgrind_out": 4, "done": [4, 13, 15, 16, 21, 25, 28, 33, 38, 41, 43, 46, 47, 49, 56, 63, 70, 71, 494, 677, 757, 905, 1080, 1082, 1085, 1086, 1088, 1089, 1092, 1093, 1095, 1096, 1098, 1100, 1205, 1279, 1340, 1341, 1342, 1359, 1362, 1374, 1385, 1386, 1387, 1404, 1405, 1406, 1407, 1432, 1461, 1467, 1469, 1602, 1799, 1863, 1867, 1871, 1875, 1883, 1885, 1886, 1887, 1889, 1890, 1894, 1897, 1901, 1904, 1906, 1908, 1909, 1913, 1915], "functioncount": [4, 1858], "stat": [4, 17, 29, 66, 823, 833, 834, 1020, 1027, 1028, 1029, 1461, 1602, 1873, 1886, 1926], "as_standard": 4, "strip": [4, 1523, 1602, 1860, 1903], "prefix": [4, 41, 43, 58, 63, 745, 754, 1190, 1422, 1602, 1857, 1869, 1883, 1901, 1905, 1926], "stumbl": 4, "filepath": 4, "dif": 4, "compon": [4, 8, 10, 13, 18, 21, 29, 33, 35, 41, 47, 71, 677, 905, 1083, 1084, 1086, 1094, 1095, 1096, 1229, 1465, 1466, 1467, 1468, 1469, 1593, 1697, 1804, 1848, 1849, 1864, 1869, 1883, 1887, 1893, 1894, 1906, 1917], "locat": [4, 10, 12, 16, 17, 32, 41, 47, 55, 151, 155, 254, 511, 932, 934, 978, 1042, 1043, 1211, 1261, 1287, 1292, 1295, 1312, 1359, 1369, 1456, 1473, 1486, 1521, 1586, 1589, 1602, 1614, 1708, 1743, 1765, 1786, 1789, 1843, 1857, 1860, 1872, 1886, 1901, 1905, 1907, 1913, 1915, 1917, 1922, 1926], "resembl": [4, 33], "23234231": 4, "first_build_dir": 4, "foo": [4, 12, 19, 32, 41, 55, 56, 70, 71, 821, 851, 856, 950, 1119, 1120, 1129, 1188, 1193, 1197, 1200, 1201, 1204, 1205, 1644, 1857, 1860, 1862, 1863, 1867, 1888, 1894, 1901, 1905, 1924], "9823794": 4, "bar": [4, 8, 21, 55, 71, 851, 856, 962, 1119, 1193, 1200, 1802, 1803, 1845, 1846, 1857, 1860, 1862, 1872, 1894, 1901, 1905, 1924], "53453": 4, "function_that_actually_chang": 4, "second_build_dir": 4, "cancel": [4, 1187], "site": [4, 8], "denois": 4, "explan": [4, 10, 17, 18, 25, 29, 51, 859, 1190, 1422, 1858, 1887, 1888, 1894], "delta": [4, 47, 757, 1374, 1383, 1392, 1453, 1530, 1662, 1802, 1803, 1829, 1845, 1846, 1861, 1881], "inclus": [4, 47, 89, 511, 1150, 1152, 1260, 1276, 1282, 1718, 1719, 1801, 1912, 1924], "diff": [4, 8, 1860, 1861, 1903], "unit": [4, 12, 30, 32, 47, 49, 59, 63, 71, 757, 758, 1081, 1099, 1334, 1344, 1364, 1367, 1372, 1373, 1374, 1375, 1440, 1441, 1451, 1486, 1510, 1514, 1519, 1520, 1566, 1574, 1618, 1619, 1623, 1626, 1628, 1631, 1831, 1883, 1885, 1891, 1905], "next": [4, 14, 17, 20, 21, 27, 38, 41, 47, 58, 63, 71, 557, 757, 1194, 1326, 1375, 1393, 1439, 1602, 1637, 1875, 1882, 1883, 1885, 1889, 1894, 1896, 1906, 1907, 1913, 1914, 1917, 1920, 1922], "logic": [4, 6, 21, 32, 38, 46, 61, 63, 71, 922, 924, 925, 927, 1080, 1082, 1085, 1086, 1088, 1089, 1092, 1093, 1095, 1096, 1098, 1100, 1120, 1194, 1271, 1272, 1273, 1274, 1284, 1428, 1602, 1706, 1733, 1816, 1863, 1864, 1886, 1887, 1888, 1889, 1891, 1908], "question": [4, 11, 16, 22, 38, 71, 1858, 1883], "why": [4, 8, 16, 38, 63, 68, 71, 1063, 1194, 1571, 1858, 1870, 1889], "involv": [4, 6, 8, 10, 15, 16, 22, 30, 38, 41, 63, 66, 68, 71, 1602, 1863, 1876, 1878, 1883, 1886, 1887, 1890, 1894, 1901, 1913, 1914, 1915, 1917], "look": [4, 5, 8, 9, 10, 12, 13, 15, 17, 18, 21, 23, 25, 28, 29, 33, 41, 47, 57, 58, 65, 68, 71, 859, 898, 900, 1190, 1284, 1330, 1422, 1512, 1627, 1678, 1790, 1791, 1792, 1794, 1795, 1860, 1862, 1876, 1882, 1883, 1886, 1889, 1893, 1894, 1896, 1900, 1901, 1905, 1908, 1913, 1914, 1927], "autom": [4, 9, 17, 29, 71, 1860, 1908], "easili": [4, 8, 9, 20, 28, 29, 30, 39, 41, 1120, 1429, 1521, 1559, 1678, 1736, 1889, 1891, 1894, 1899, 1904, 1912, 1915, 1922], "exclus": [4, 38, 41, 47, 49, 58, 71, 732, 1152, 1602, 1718, 1719, 1722, 1883, 1924], "basi": [4, 10, 11, 47, 1262, 1683, 1886, 1893, 1908, 1913], "thought": [4, 55, 71, 1081, 1083, 1099], "path_and_function_nam": 4, "children": [4, 51, 63, 71, 788, 1190, 1422, 1875, 1894, 1905, 1915], "identifi": [4, 8, 10, 15, 21, 41, 49, 52, 55, 58, 59, 60, 71, 814, 1152, 1261, 1461, 1864, 1875, 1884, 1893, 1894, 1905, 1913, 1914, 1915, 1922], "hot": [4, 21, 47, 1523, 1558, 1891], "spot": 4, "_data": 4, "truncate_row": 4, "_linewidth": 4, "subtract": [4, 313, 561, 862, 1116, 1523, 1790, 1791, 1792, 1794, 1795, 1805, 1861, 1878, 1903, 1917], "cpython": [4, 26, 71], "known": [4, 8, 10, 15, 18, 29, 37, 41, 45, 52, 64, 67, 69, 1126, 1127, 1205, 1206, 1261, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1392, 1437, 1451, 1453, 1473, 1532, 1574, 1593, 1764, 1765, 1822, 1858, 1861, 1865, 1873, 1875, 1878, 1881, 1883, 1885, 1898, 1901, 1904, 1915, 1918], "quit": [4, 8, 23, 71, 1863, 1888, 1890, 1905, 1913], "noisi": 4, "higher": [4, 8, 9, 15, 39, 41, 63, 64, 69, 151, 890, 891, 904, 969, 1009, 1020, 1055, 1121, 1127, 1131, 1150, 1167, 1319, 1358, 1414, 1429, 1571, 1708, 1809, 1850, 1858, 1886, 1888, 1889, 1891, 1893, 1908, 1909, 1913, 1920], "filter": [4, 29, 541, 769, 770, 771, 1187, 1209, 1350, 1351, 1352, 1353, 1354, 1355, 1496, 1497, 1498, 1499, 1500, 1501, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1804, 1863, 1905], "rather": [4, 9, 10, 12, 13, 16, 20, 21, 32, 41, 49, 51, 60, 71, 776, 782, 914, 940, 1188, 1191, 1322, 1486, 1521, 1532, 1590, 1610, 1756, 1860, 1863, 1877, 1878, 1884, 1886, 1888, 1889, 1901, 1905, 1908, 1913, 1917, 1922], "unicod": [4, 1864], "lookup": [4, 21, 23, 43, 47, 1365, 1512, 1860, 1864, 1885, 1914], "agnost": [4, 58, 1521, 1877], "reliabl": [4, 22], "warrant": 4, "filter_fn": 4, "map_fn": 4, "coalesc": [4, 17, 21, 323, 328, 541, 611, 977, 1789, 1839, 1861, 1887, 1903, 1917], "finit": [5, 47, 905, 906, 1179, 1180, 1225, 1226, 1236, 1237, 1253, 1279, 1312, 1316, 1338, 1808, 1888, 1891, 1924], "natur": [5, 8, 9, 30, 41, 47, 63, 905, 906, 1218, 1223, 1249, 1263, 1265, 1270, 1330, 1469, 1571, 1891, 1917, 1918], "against": [5, 25, 32, 41, 49, 58, 791, 862, 905, 906, 1091, 1092, 1093, 1097, 1098, 1100, 1132, 1181, 1190, 1205, 1206, 1422, 1428, 1659, 1857, 1863, 1905, 1927], "cprofil": 5, "correct": [5, 7, 8, 28, 39, 41, 42, 43, 47, 58, 206, 207, 210, 222, 552, 577, 600, 601, 612, 894, 906, 962, 1084, 1086, 1094, 1095, 1096, 1164, 1188, 1191, 1205, 1206, 1225, 1359, 1376, 1388, 1593, 1602, 1635, 1755, 1802, 1803, 1845, 1846, 1859, 1860, 1861, 1862, 1876, 1877, 1886, 1888, 1891, 1919], "launch": [5, 12, 20, 32, 38, 44, 49, 50, 51, 56, 57, 58, 61, 70, 967, 1602, 1858, 1883, 1885, 1886, 1887, 1913], "spent": [5, 17, 29, 41, 915, 1689, 1885, 1894], "appear": [5, 27, 39, 41, 47, 71, 851, 1009, 1063, 1104, 1105, 1131, 1261, 1295, 1297, 1598, 1603, 1729, 1758, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1850, 1860, 1863, 1876, 1877, 1888, 1889, 1894, 1901, 1905], "extrem": [5, 16, 21, 1602, 1883, 1901], "expens": [5, 15, 17, 23, 25, 29, 38, 47, 63, 1609, 1886, 1891, 1893, 1907, 1913, 1923], "bound": [5, 15, 16, 29, 33, 39, 63, 480, 792, 934, 945, 1077, 1078, 1190, 1335, 1336, 1337, 1415, 1416, 1417, 1422, 1440, 1521, 1691, 1722, 1743, 1863, 1864, 1881, 1883, 1905, 1908, 1918], "greater": [5, 41, 58, 292, 614, 677, 939, 940, 945, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1134, 1146, 1244, 1307, 1338, 1470, 1521, 1532, 1558, 1571, 1590, 1610, 1643, 1843, 1861, 1883, 1886, 1898, 1903, 1918], "spend": [5, 8, 23, 1262], "sens": [5, 18, 47, 58, 71, 1625, 1840, 1841, 1863, 1883], "respons": [5, 8, 10, 16, 41, 43, 45, 47, 49, 55, 60, 63, 70, 967, 1410, 1539, 1602, 1883, 1886, 1888, 1889, 1894, 1913], "Of": [5, 1648, 1857, 1887, 1888], "cours": [5, 17, 21, 71, 1857, 1887, 1888, 1913], "realiti": 5, "complic": [5, 16, 39, 71, 790, 1867, 1877, 1884, 1905, 1913, 1915], "depend": [5, 6, 12, 13, 15, 16, 17, 20, 21, 24, 27, 28, 32, 38, 41, 45, 47, 49, 58, 59, 60, 63, 71, 315, 782, 875, 975, 1022, 1026, 1040, 1041, 1084, 1086, 1094, 1095, 1096, 1121, 1125, 1130, 1201, 1205, 1225, 1226, 1253, 1279, 1284, 1338, 1339, 1356, 1358, 1366, 1369, 1382, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1473, 1474, 1486, 1493, 1494, 1504, 1513, 1521, 1533, 1556, 1564, 1571, 1590, 1593, 1602, 1614, 1615, 1621, 1656, 1683, 1695, 1697, 1714, 1730, 1790, 1791, 1792, 1794, 1795, 1808, 1831, 1853, 1857, 1860, 1862, 1863, 1870, 1875, 1883, 1885, 1886, 1888, 1889, 1891, 1894, 1901, 1907, 1908, 1913, 1917, 1923, 1924], "could": [5, 6, 8, 9, 13, 17, 18, 24, 29, 38, 41, 47, 49, 58, 63, 68, 70, 71, 580, 581, 582, 584, 585, 1002, 1084, 1086, 1094, 1095, 1096, 1187, 1220, 1261, 1279, 1303, 1304, 1682, 1785, 1840, 1862, 1863, 1870, 1875, 1883, 1886, 1887, 1900, 1901, 1905, 1908, 1909, 1913, 1914, 1915, 1917, 1921, 1922], "account": [5, 12, 56, 71, 1602, 1881, 1885, 1917], "heavili": [5, 1667, 1885, 1888, 1905], "similarli": [5, 8, 12, 16, 20, 70, 71, 757, 787, 791, 855, 941, 1083, 1190, 1245, 1422, 1598, 1599, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1832, 1833, 1834, 1835, 1862, 1883, 1888, 1890, 1891, 1897, 1917], "platform": [5, 9, 10, 32, 41, 50, 51, 55, 1236, 1237, 1248, 1707, 1808, 1871, 1892, 1897, 1898, 1908], "startup": 5, "slower": [5, 16, 32, 41, 873, 899, 1103, 1104, 1105, 1219, 1226, 1540, 1609, 1888, 1898, 1904, 1918], "rerun": [6, 41, 1886], "segment": [6, 17, 24, 1020, 1116, 1453, 1905], "persist": [6, 12, 16, 23, 36, 43, 63, 757, 812, 813, 814, 1190, 1374, 1392, 1422, 1437, 1886, 1894, 1899, 1900], "rng": [6, 38, 995, 1034, 1744, 1886, 1898, 1912], "advanc": [6, 17, 33, 38, 39, 49, 1465, 1467, 1469, 1648, 1657, 1867, 1870, 1877, 1886, 1892, 1896, 1921, 1922], "juggl": 6, "dropout": [6, 46, 71, 731, 732, 757, 1190, 1334, 1361, 1362, 1363, 1367, 1374, 1392, 1422, 1428, 1437, 1438, 1465, 1467, 1469, 1487, 1507, 1508, 1509, 1514, 1571, 1858, 1861, 1871, 1877, 1878, 1883, 1886, 1903, 1910], "moder": 6, "hit": [6, 9, 12, 17, 23, 29, 32, 1602, 1857, 1886], "preserve_rng_st": 6, "checkpoint_sequenti": [6, 1858], "omit": [6, 32, 41, 59, 1097, 1098, 1100, 1376, 1436, 1900, 1901, 1913, 1924], "_infer_device_typ": 6, "remain": [6, 9, 47, 58, 71, 1297, 1365, 1366, 1512, 1513, 1593, 1602, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1708, 1730, 1873, 1875, 1882, 1890, 1894], "consequ": [6, 68, 1253, 1392, 1808, 1863, 1883, 1886, 1898], "random": [6, 17, 29, 47, 49, 58, 59, 64, 71, 89, 155, 757, 889, 920, 995, 996, 1001, 1010, 1011, 1030, 1031, 1034, 1035, 1124, 1131, 1142, 1166, 1262, 1282, 1301, 1302, 1306, 1308, 1334, 1345, 1367, 1374, 1392, 1440, 1514, 1564, 1569, 1593, 1610, 1616, 1622, 1623, 1630, 1631, 1650, 1697, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1744, 1757, 1809, 1850, 1857, 1858, 1861, 1869, 1881, 1889, 1891, 1897, 1901, 1903, 1922], "gradient": [6, 17, 30, 38, 39, 41, 45, 47, 63, 64, 67, 151, 222, 223, 290, 335, 486, 493, 511, 692, 693, 877, 886, 888, 890, 892, 893, 894, 895, 896, 898, 899, 900, 901, 902, 903, 904, 905, 906, 910, 911, 921, 947, 1067, 1119, 1120, 1121, 1122, 1126, 1131, 1132, 1165, 1190, 1225, 1226, 1229, 1236, 1237, 1253, 1262, 1279, 1281, 1287, 1290, 1292, 1338, 1345, 1353, 1354, 1355, 1358, 1359, 1365, 1366, 1376, 1390, 1391, 1422, 1429, 1453, 1504, 1505, 1512, 1513, 1523, 1532, 1540, 1542, 1543, 1556, 1590, 1591, 1592, 1598, 1599, 1602, 1603, 1606, 1607, 1609, 1614, 1647, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1681, 1682, 1695, 1753, 1789, 1808, 1850, 1858, 1860, 1861, 1870, 1877, 1878, 1881, 1886, 1887, 1888, 1890, 1891, 1894, 1897, 1903, 1904, 1913, 1914, 1917], "among": [6, 16, 38, 39, 41, 45, 47, 58, 976, 977, 980, 1152, 1359, 1650, 1863], "detect": [6, 15, 17, 29, 32, 34, 35, 38, 41, 42, 49, 51, 63, 898, 899, 900, 901, 902, 903, 1120, 1194, 1466, 1468, 1602, 1843, 1858, 1875, 1878, 1886, 1891, 1897, 1901, 1905, 1913], "priorit": [6, 1123, 1124, 1126, 1664, 1665, 1917], "defaultdevicetyp": 6, "anticip": 6, "belong": [6, 21, 28, 41, 43, 45, 47, 55, 71, 934, 969, 1679, 1857, 1886, 1904, 1928], "use_reentr": 6, "context_fn": 6, "noop_context_fn": 6, "techniqu": [6, 21, 29, 71, 1360, 1616, 1829, 1879, 1894, 1904, 1906, 1908], "intermedi": [6, 15, 16, 32, 48, 68, 71, 931, 1114, 1120, 1127, 1279, 1366, 1465, 1467, 1469, 1513, 1860, 1863, 1886, 1888, 1889, 1890, 1897, 1927], "entir": [6, 8, 13, 14, 15, 16, 17, 21, 22, 29, 32, 38, 41, 49, 59, 71, 694, 905, 906, 1120, 1143, 1361, 1362, 1363, 1367, 1385, 1386, 1387, 1394, 1507, 1508, 1509, 1514, 1602, 1620, 1622, 1646, 1863, 1878, 1883, 1886, 1888, 1889, 1890, 1893, 1894, 1901, 1905, 1908, 1913, 1915, 1917], "recomput": [6, 15, 896, 1474, 1532, 1646, 1904], "refer": [6, 13, 21, 22, 24, 29, 32, 38, 39, 41, 42, 43, 45, 47, 50, 53, 54, 58, 59, 63, 64, 70, 254, 731, 732, 753, 761, 789, 790, 791, 816, 817, 818, 821, 822, 823, 856, 870, 875, 890, 932, 1002, 1007, 1066, 1116, 1138, 1139, 1171, 1178, 1190, 1193, 1201, 1208, 1221, 1242, 1246, 1259, 1262, 1345, 1376, 1422, 1471, 1486, 1494, 1503, 1521, 1589, 1602, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1697, 1714, 1750, 1772, 1809, 1843, 1857, 1858, 1861, 1875, 1876, 1878, 1879, 1882, 1883, 1886, 1887, 1888, 1889, 1890, 1891, 1894, 1896, 1898, 1904, 1909, 1910, 1913, 1914, 1917, 1920, 1921, 1922, 1925], "potenti": [6, 9, 15, 17, 21, 41, 58, 60, 192, 209, 1199, 1235, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1602, 1843, 1862, 1870, 1875, 1883, 1886, 1905, 1917, 1921], "silent": [6, 20, 1010, 1011, 1030, 1031, 1164, 1205, 1422, 1606, 1607, 1886, 1897, 1901], "consider": [6, 8, 881, 1187, 1366, 1602, 1863, 1885], "limit": [6, 9, 10, 15, 16, 17, 20, 21, 25, 29, 38, 46, 63, 64, 69, 1033, 1120, 1203, 1307, 1345, 1365, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1571, 1602, 1625, 1756, 1858, 1863, 1867, 1875, 1877, 1878, 1883, 1886, 1887, 1894, 1897, 1898, 1899, 1905, 1908, 1911, 1913, 1914, 1924], "reentrant": [6, 1602], "stop": [6, 18, 47, 49, 58, 59, 60, 862, 1002, 1188, 1262, 1345, 1635, 1691, 1723, 1860, 1863, 1913], "soon": [6, 21, 29, 58, 63, 790, 1883, 1908, 1913, 1915], "set_checkpoint_early_stop": 6, "entireti": 6, "no_grad": [6, 858, 1067, 1121, 1125, 1130, 1165, 1190, 1365, 1422, 1428, 1469, 1603, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1881, 1883, 1894, 1925], "condit": [6, 15, 16, 36, 38, 68, 71, 614, 617, 621, 691, 757, 899, 905, 906, 1187, 1205, 1219, 1221, 1229, 1235, 1236, 1237, 1248, 1253, 1374, 1392, 1437, 1469, 1637, 1642, 1831, 1853, 1859, 1860, 1861, 1862, 1864, 1878, 1883, 1888, 1897, 1906, 1922], "unmet": 6, "particip": [6, 10, 15, 38, 41, 42, 45, 58, 59, 1602, 1914], "wherea": [6, 16, 1245, 1303, 1304, 1317, 1678, 1808, 1863, 1924], "know": [6, 8, 9, 12, 15, 16, 17, 21, 32, 42, 48, 71, 485, 894, 899, 1114, 1120, 1200, 1602, 1860, 1863, 1870, 1882, 1883, 1886, 1891, 1901, 1905, 1913, 1914, 1915, 1917], "lstm": [6, 760, 1393, 1861, 1886, 1901, 1903, 1908, 1910, 1911, 1922], "hidden": [6, 757, 1129, 1374, 1375, 1392, 1393, 1437, 1439, 1603, 1886, 1922], "correctli": [6, 20, 38, 41, 58, 63, 485, 1120, 1190, 1205, 1422, 1540, 1860, 1862, 1863, 1873, 1877, 1882, 1883, 1887, 1888, 1889, 1896, 1898, 1908, 1913], "entrant": 6, "futur": [6, 9, 10, 15, 17, 39, 41, 43, 49, 58, 59, 68, 71, 290, 321, 511, 515, 554, 677, 684, 790, 812, 813, 814, 823, 858, 896, 940, 941, 955, 956, 963, 964, 966, 967, 969, 998, 999, 1006, 1007, 1009, 1136, 1190, 1193, 1199, 1200, 1203, 1208, 1220, 1231, 1233, 1234, 1235, 1238, 1251, 1279, 1280, 1291, 1362, 1422, 1523, 1545, 1546, 1547, 1594, 1602, 1606, 1643, 1644, 1649, 1667, 1707, 1723, 1804, 1808, 1831, 1858, 1859, 1860, 1861, 1862, 1863, 1864, 1869, 1870, 1871, 1873, 1877, 1878, 1885, 1886, 1888, 1899, 1901, 1902, 1904, 1905, 1906, 1907, 1908, 1910, 1913, 1917, 1919, 1923, 1924, 1925, 1927], "sequenti": [6, 17, 29, 38, 45, 63, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 790, 1131, 1190, 1199, 1368, 1422, 1461, 1472, 1611, 1625, 1692, 1850, 1860, 1875, 1878, 1886, 1894, 1901, 1904, 1906, 1908, 1927], "func": [6, 41, 46, 66, 68, 71, 859, 889, 891, 895, 896, 897, 898, 899, 900, 901, 902, 903, 905, 906, 1165, 1193, 1205, 1206, 1521, 1644, 1850, 1858, 1863, 1882, 1913, 1915, 1928], "compris": [6, 59], "chunk": [6, 38, 41, 43, 63, 937, 980, 1125, 1359, 1602, 1796, 1860, 1861, 1876, 1903, 1904, 1906, 1913, 1921], "input_var": [6, 1359], "person": [7, 8, 10], "land": [7, 10, 11, 25], "six": [7, 1352], "commit": [7, 8, 10, 25, 32, 64, 1857, 1858, 1897, 1898], "repositori": [7, 10, 67, 71, 1857, 1888, 1896], "submit": [7, 10, 25, 966, 967, 969, 1886, 1898], "month": [7, 10], "qualifi": [7, 41, 46, 55, 71, 677, 1190, 1422, 1869, 1905], "pr": [7, 8, 15, 1697, 1809, 1927], "interest": [7, 8, 10, 14, 16, 18, 20, 22, 23, 1883, 1889, 1891, 1894], "merge_rul": 7, "vote": [7, 10], "decis": [7, 15, 43, 49, 58, 60, 71, 1205, 1870, 1882], "criteria": [7, 10, 1262], "approv": [7, 10], "Not": [7, 21, 59, 1320, 1860, 1862, 1863, 1864, 1888, 1903, 1908, 1913], "busi": [7, 10, 23], "dai": [7, 8, 16, 25], "contributor": [7, 8, 9, 10], "seen": [7, 19, 21, 35, 47, 71, 222, 937, 950, 1291, 1353, 1354, 1355, 1453, 1545, 1546, 1547, 1691, 1860, 1870, 1883, 1886, 1901, 1917], "thumb": [7, 41], "acceler": [8, 12, 17, 39, 1340, 1341, 1342, 1461, 1661, 1892], "deep": [8, 10, 15, 17, 26, 29, 71, 1340, 1341, 1342, 1364, 1461, 1677, 1858, 1881, 1894, 1908], "neural": [8, 9, 15, 33, 71, 1334, 1345, 1360, 1367, 1376, 1388, 1421, 1422, 1429, 1434, 1435, 1449, 1451, 1465, 1467, 1469, 1551, 1574, 1612, 1675, 1683, 1689, 1860, 1862, 1863, 1881, 1886, 1897, 1901], "tape": [8, 12], "system": [8, 9, 15, 32, 33, 34, 38, 59, 68, 71, 943, 1143, 1197, 1221, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1250, 1251, 1252, 1256, 1261, 1280, 1307, 1465, 1467, 1469, 1602, 1612, 1614, 1752, 1831, 1864, 1869, 1873, 1883, 1885, 1886, 1893, 1894, 1900, 1905, 1913], "organ": [8, 17, 21, 1887, 1893, 1905], "technic": [8, 10, 15, 22, 58, 71, 1190, 1422, 1598, 1599, 1858, 1883, 1890, 1905], "md": [8, 71, 789, 1905], "healthi": [8, 49, 58], "team": [8, 41, 64, 1899, 1906], "commun": [8, 9, 10, 17, 20, 22, 42, 43, 45, 49, 58, 60, 63, 1602, 1883, 1887, 1913, 1914], "ve": [8, 16, 17, 21, 22, 66, 67, 68, 71, 1194, 1870, 1875, 1883, 1889, 1914, 1922], "come": [8, 9, 10, 21, 24, 38, 46, 47, 48, 55, 58, 64, 68, 1063, 1114, 1120, 1261, 1361, 1362, 1363, 1367, 1388, 1658, 1867, 1871, 1887, 1889, 1893, 1905, 1913, 1915, 1917], "peopl": [8, 20, 23, 1883, 1908], "scratch": [8, 29, 1883], "itch": 8, "acquaint": 8, "tip": [8, 17, 1886], "tracker": [8, 1262], "confirm": [8, 17, 24, 1857, 1860, 1888, 1901, 1913, 1915], "tend": [8, 900, 1843], "bootcamp": 8, "1hr": 8, "although": [8, 9, 28, 46, 47, 68, 71, 1353, 1354, 1355, 1422, 1430, 1602, 1858, 1863, 1882, 1888, 1897, 1906, 1908], "join": [8, 39, 41, 45, 58, 59, 70, 71, 1602, 1857, 1858, 1864, 1875, 1883, 1887, 1896, 1903, 1923], "dev": [8, 11, 26, 29, 50, 55], "happi": 8, "research": [8, 9, 10, 1602, 1857, 1883, 1891, 1899], "partner": 8, "speed": [8, 9, 21, 22, 32, 45, 975, 1063, 1119, 1181, 1194, 1199, 1253, 1330, 1428, 1808, 1883, 1885, 1886, 1887, 1888, 1890, 1892, 1897, 1908, 1913], "reach": [8, 9, 10, 14, 38, 39, 41, 42, 49, 58, 64, 1262, 1602, 1680, 1683, 1686, 1687, 1883, 1896, 1906, 1908, 1909, 1913], "design": [8, 10, 15, 17, 20, 26, 29, 38, 47, 55, 58, 64, 67, 68, 69, 905, 906, 1190, 1209, 1422, 1656, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1819, 1857, 1858, 1859, 1873, 1886, 1888, 1892, 1894, 1905], "comment": [8, 23, 71, 1747, 1863, 1864, 1888, 1920, 1922], "crack": 8, "usual": [8, 16, 23, 32, 38, 39, 43, 58, 59, 71, 85, 480, 828, 829, 830, 831, 838, 890, 898, 900, 904, 1131, 1361, 1362, 1363, 1367, 1382, 1385, 1386, 1387, 1388, 1593, 1602, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1850, 1860, 1863, 1878, 1882, 1883, 1885, 1886, 1890, 1893, 1904, 1909, 1911, 1913, 1922, 1928], "idea": [8, 17, 29, 64, 1063, 1330, 1602, 1886, 1893, 1901, 1914], "rfc": [8, 1883, 1908, 1914], "big": [8, 16, 23, 1664, 1665, 1668, 1674, 1675, 1790, 1791, 1792, 1793, 1794, 1795, 1904, 1908], "post": [8, 9, 16, 26, 29, 42, 43, 45, 63, 853, 854, 858, 1190, 1422, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1858, 1867, 1883, 1887, 1890, 1900], "standard": [8, 32, 35, 39, 47, 51, 52, 56, 68, 71, 85, 352, 377, 586, 1083, 1334, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1388, 1394, 1461, 1467, 1469, 1650, 1697, 1720, 1766, 1771, 1802, 1803, 1862, 1864, 1878, 1881, 1885, 1886, 1896, 1897, 1901, 1902, 1905, 1918], "lot": [8, 15, 16, 20, 21, 22, 23, 32, 38, 1875, 1883, 1886, 1891, 1896, 1905, 1906, 1912, 1914, 1922], "boil": 8, "mostli": [8, 47, 1188, 1602, 1886, 1917, 1928], "evid": 8, "peer": [8, 41, 45, 58, 63, 973, 1602, 1886, 1913], "paper": [8, 10, 39, 47, 757, 1330, 1334, 1340, 1341, 1342, 1344, 1353, 1354, 1355, 1360, 1361, 1362, 1363, 1364, 1367, 1370, 1371, 1374, 1377, 1380, 1385, 1386, 1387, 1394, 1428, 1434, 1435, 1440, 1449, 1453, 1461, 1465, 1467, 1469, 1470, 1471, 1516, 1517, 1526, 1664, 1665, 1676, 1683, 1689, 1891, 1906], "framework": [8, 9, 10, 47, 55, 64, 70, 757, 971, 1299, 1374, 1602, 1609, 1677, 1756, 1858, 1895, 1906, 1908, 1914, 1915], "bit": [8, 20, 21, 23, 71, 89, 330, 457, 758, 760, 762, 816, 817, 818, 819, 822, 824, 855, 923, 926, 955, 956, 1116, 1170, 1731, 1732, 1744, 1773, 1886, 1894, 1897, 1900, 1908, 1911, 1912, 1917, 1920, 1923, 1929], "accept": [8, 10, 29, 38, 41, 43, 46, 64, 65, 67, 69, 151, 511, 799, 886, 887, 888, 889, 890, 895, 904, 940, 1006, 1009, 1115, 1131, 1152, 1190, 1194, 1358, 1422, 1429, 1450, 1621, 1635, 1636, 1642, 1660, 1748, 1785, 1799, 1850, 1863, 1877, 1886, 1888, 1889, 1901, 1904, 1913, 1920, 1922], "overwhelm": [8, 17, 29, 1913], "newli": [8, 21, 63, 71, 1077, 1078, 1365, 1366, 1709, 1710, 1867], "publish": [8, 10, 50, 55, 58, 1262, 1858], "ground": [8, 10, 1358, 1504, 1922], "becom": [8, 9, 10, 17, 21, 29, 38, 41, 47, 71, 290, 757, 873, 1143, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1374, 1392, 1407, 1427, 1437, 1450, 1504, 1521, 1593, 1681, 1781, 1829, 1870, 1871, 1883, 1887, 1901, 1905, 1907, 1913], "refactor": [8, 18, 71, 1900, 1908], "coordin": [8, 17, 29, 41, 43, 47, 49, 580, 583, 881, 1143, 1152, 1291, 1701, 1793, 1833, 1835, 1883, 1917, 1922], "pace": 8, "branch": [8, 15, 25, 71, 1857, 1862, 1863, 1886], "fast": [8, 9, 16, 20, 23, 38, 41, 905, 1364, 1385, 1386, 1387, 1453, 1469, 1571, 1689, 1695, 1714, 1736, 1751, 1858, 1885, 1886, 1888, 1892, 1904, 1913, 1917, 1920, 1921], "definit": [8, 9, 21, 38, 41, 42, 47, 54, 71, 941, 942, 943, 962, 1006, 1111, 1210, 1219, 1220, 1262, 1388, 1533, 1578, 1649, 1727, 1829, 1857, 1860, 1862, 1864, 1882, 1883, 1888, 1891, 1905, 1908, 1922, 1924], "fundament": [8, 16, 68, 1862, 1894, 1913, 1917], "cut": [8, 17], "guidanc": [8, 10, 15, 33, 65, 1906], "stage": [8, 29, 35, 39, 45, 55, 63, 70, 1858, 1870, 1878, 1906, 1915], "piec": [8, 21, 1869, 1878, 1914], "advic": 8, "readi": [8, 12, 22, 32, 70, 858, 859, 919, 928, 1147, 1148, 1602, 1860, 1887, 1913, 1914], "draft": 8, "convert": [8, 21, 28, 29, 38, 41, 46, 47, 48, 63, 67, 71, 83, 151, 577, 581, 582, 583, 584, 585, 732, 785, 786, 787, 789, 790, 791, 812, 813, 814, 835, 836, 851, 854, 855, 856, 876, 877, 936, 949, 1047, 1083, 1114, 1190, 1259, 1422, 1432, 1433, 1461, 1468, 1593, 1604, 1605, 1608, 1645, 1656, 1658, 1659, 1678, 1709, 1710, 1715, 1790, 1791, 1792, 1793, 1794, 1795, 1860, 1861, 1862, 1863, 1878, 1888, 1892, 1901, 1902, 1908, 1911, 1917, 1922, 1924, 1927], "press": [8, 71], "button": [8, 25], "prepend": [8, 32, 38, 41, 45, 71, 230, 1055, 1190, 1284, 1422, 1825, 1861, 1884], "titl": [8, 1903, 1907], "wip": 8, "progress": [8, 41, 45, 49, 59, 61, 966, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1844, 1857, 1872], "ci": [8, 25, 1858], "folk": 8, "who": [8, 9, 10, 21, 22, 30, 58, 1905], "regularli": 8, "queue": [8, 49, 60, 1875, 1922], "everyth": [8, 15, 17, 21, 23, 29, 38, 47, 67, 1860, 1875, 1905], "happen": [8, 10, 12, 21, 22, 41, 43, 45, 47, 49, 51, 58, 63, 68, 71, 85, 604, 788, 811, 1120, 1461, 1602, 1609, 1680, 1686, 1687, 1693, 1808, 1858, 1873, 1875, 1883, 1886, 1887, 1888, 1889, 1890, 1895, 1896, 1900, 1901, 1908, 1913, 1921], "subsystem": [8, 30, 64, 69, 1858, 1888], "feel": [8, 1878, 1901, 1917], "ll": [8, 13, 16, 23, 68, 71, 757, 817, 818, 858, 859, 941, 1009, 1219, 1374, 1375, 1392, 1393, 1870, 1883, 1886, 1888, 1889, 1896, 1901, 1908, 1914], "round": [8, 38, 41, 506, 662, 663, 796, 799, 817, 862, 958, 960, 1020, 1058, 1084, 1085, 1086, 1090, 1094, 1095, 1096, 1111, 1235, 1248, 1474, 1532, 1707, 1708, 1727, 1776, 1859, 1861, 1863, 1876, 1886, 1903, 1908, 1911, 1917, 1918], "trip": [8, 71, 1084, 1085, 1086, 1090, 1094, 1095, 1096], "noth": [8, 32, 49, 71, 677, 1000, 1614, 1664, 1665, 1692, 1860, 1862, 1915], "accompani": [8, 84], "solut": [8, 9, 68, 1234, 1235, 1239, 1247, 1250, 1252, 1256, 1338, 1602, 1831, 1860, 1861, 1881, 1882, 1890, 1896], "think": [8, 10, 16, 17, 18, 71, 1678, 1860, 1862, 1883, 1904, 1905, 1915], "confid": [8, 18, 1922], "ahead": [8, 15, 17, 1858, 1908], "search": [8, 13, 16, 25, 29, 30, 39, 816, 934, 1380, 1526, 1602, 1659, 1714, 1743, 1860, 1876, 1877, 1901, 1905, 1917], "repo": [8, 1683, 1857, 1900], "unabl": [8, 27, 29, 68, 83, 1901, 1904], "reproduc": [8, 17, 29, 38, 68, 313, 321, 513, 515, 921, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1418, 1419, 1420, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1513, 1521, 1532, 1559, 1571, 1590, 1591, 1592, 1593, 1843, 1857, 1858, 1904, 1905], "problemat": [8, 38, 71, 1860, 1897, 1909], "insight": [8, 35], "individu": [8, 10, 12, 20, 25, 32, 38, 39, 41, 43, 45, 63, 71, 84, 242, 677, 789, 835, 836, 941, 1029, 1081, 1099, 1190, 1345, 1422, 1461, 1602, 1656, 1858, 1863, 1876, 1882, 1883, 1886, 1888, 1893, 1897, 1898, 1901, 1911, 1913, 1924], "intent": [8, 24, 56, 58, 68, 1748, 1870, 1905], "lock": [8, 38, 41, 45, 47, 1883, 1886, 1896, 1905, 1914], "strike": 8, "convers": [8, 16, 28, 457, 577, 580, 790, 935, 1175, 1635, 1858, 1864, 1892, 1901, 1908, 1909, 1917], "medium": [8, 63, 1751], "prioriti": [8, 10, 11, 41, 677, 851, 969, 1862], "entranc": [8, 1886], "great": [8, 12, 15, 1883, 1891], "deal": [8, 9, 15, 16, 21, 23, 38, 49, 60, 1824, 1875, 1890, 1913], "welcom": [8, 1878, 1904, 1917], "aim": [8, 1889, 1917], "rare": [8, 15, 18, 1882, 1901, 1928], "typo": 8, "send": [8, 16, 20, 38, 41, 49, 60, 1002, 1593, 1602, 1875, 1887, 1896, 1900, 1903, 1907, 1913, 1914, 1915, 1925, 1927], "forum": [8, 10, 1890, 1896], "share": [8, 11, 12, 18, 32, 38, 42, 45, 47, 48, 58, 59, 63, 68, 222, 311, 340, 457, 482, 518, 521, 614, 856, 876, 877, 894, 905, 906, 964, 966, 998, 1002, 1114, 1115, 1116, 1160, 1237, 1321, 1322, 1359, 1602, 1612, 1650, 1725, 1739, 1799, 1822, 1828, 1842, 1861, 1882, 1883, 1885, 1896, 1899, 1900, 1901, 1913, 1917, 1919, 1921, 1926], "resolv": [8, 9, 10, 15, 43, 47, 71, 83, 84, 1190, 1353, 1354, 1355, 1369, 1419, 1422, 1862, 1863, 1864, 1900, 1905, 1919, 1928], "challeng": [8, 17, 41, 1914], "feedback": [8, 29, 35, 39, 63, 64, 1602, 1858], "direct": [8, 10, 21, 28, 30, 41, 757, 789, 1104, 1105, 1190, 1374, 1392, 1422, 1437, 1646, 1676, 1697, 1714, 1735, 1883, 1886, 1888, 1894, 1913], "yourself": [8, 17, 66, 964, 1888, 1894, 1896, 1928], "problem": [8, 15, 17, 22, 29, 38, 41, 58, 68, 1063, 1205, 1235, 1247, 1262, 1358, 1429, 1486, 1747, 1875, 1883, 1886, 1890, 1891, 1896, 1900, 1906, 1908, 1909, 1915, 1920], "area": [8, 10, 1532, 1894, 1908, 1918], "appreci": 8, "strive": 8, "respond": [8, 41], "quickli": [8, 9, 20, 39, 58], "ey": [8, 47, 192, 209, 942, 1131, 1210, 1219, 1230, 1241, 1244, 1247, 1248, 1255, 1256, 1609, 1707, 1786, 1850, 1861, 1865, 1888, 1903], "everyon": [8, 49, 58], "touch": [8, 56, 71], "versu": [8, 1426], "write": [8, 9, 10, 15, 17, 20, 22, 23, 29, 35, 38, 41, 43, 46, 49, 51, 55, 56, 57, 58, 63, 68, 69, 83, 84, 254, 511, 694, 932, 1115, 1131, 1167, 1200, 1220, 1231, 1232, 1233, 1237, 1238, 1251, 1589, 1657, 1739, 1831, 1843, 1850, 1858, 1862, 1873, 1877, 1886, 1889, 1890, 1891, 1904, 1905, 1917, 1922], "blog": [8, 9, 1867, 1887, 1908], "around": [8, 10, 12, 21, 27, 29, 30, 41, 47, 67, 68, 70, 71, 151, 621, 890, 904, 964, 966, 967, 969, 1038, 1109, 1110, 1120, 1190, 1602, 1736, 1860, 1875, 1883, 1886, 1901, 1913], "internet": 8, "grow": [8, 9, 20, 71, 1917], "market": [8, 10], "benefit": [8, 9, 29, 41, 71, 844, 1691, 1875, 1886, 1908, 1917], "opinion": [8, 9, 1917], "isn": [8, 16, 38, 71, 457, 1187, 1883, 1886, 1888, 1913, 1924], "aspect": [8, 41, 71, 1888, 1894], "seem": [8, 1901], "unusu": [8, 16], "claim": [8, 1689, 1891], "wast": [8, 1886], "someon": [8, 10, 1188, 1877], "too": [8, 10, 15, 16, 22, 29, 32, 39, 43, 58, 63, 68, 71, 1020, 1119, 1235, 1253, 1318, 1345, 1358, 1422, 1505, 1603, 1644, 1863, 1885, 1890, 1891, 1896, 1897, 1898, 1900, 1902, 1905, 1906, 1915, 1917], "advisori": 8, "fashion": [8, 38, 41, 60, 513, 1267, 1625, 1860], "rough": [8, 10], "consensu": [8, 10], "corpor": [8, 29], "wrote": [8, 9], "implicitli": [8, 41, 51, 63, 71, 1046, 1135, 1143, 1205, 1206, 1261, 1335, 1336, 1337, 1415, 1416, 1417, 1748, 1829, 1860, 1862, 1863, 1883, 1892], "lifetim": [8, 16, 1886, 1913], "immedi": [8, 9, 10, 15, 16, 58, 59, 63, 70, 1190, 1193, 1422, 1863, 1894, 1899, 1904, 1913, 1915], "sai": [8, 12, 15, 21, 23, 28, 71, 494, 1123, 1124, 1125, 1190, 1422, 1860, 1882, 1883, 1890, 1905, 1914, 1915, 1917], "bugfix": 8, "motiv": [8, 9, 17, 29, 71, 732, 1894, 1914], "ye": [8, 1901, 1904, 1917], "knuth": 8, "bewar": 8, "mere": 8, "proven": [8, 1360, 1602], "ok": [8, 19, 51, 56, 67, 950, 1195, 1915], "sometim": [8, 15, 16, 23, 71, 901, 1020, 1205, 1369, 1473, 1499, 1500, 1501, 1614, 1858, 1863, 1875, 1883, 1886, 1889, 1890, 1894, 1896, 1905, 1920, 1923, 1928], "obvious": [8, 16, 20], "broken": [8, 15, 38, 1020, 1901, 1905], "contrari": [8, 1885], "accident": 8, "put": [8, 10, 16, 18, 27, 38, 41, 49, 67, 70, 71, 319, 1083, 1261, 1377, 1683, 1857, 1861, 1875, 1886, 1896, 1903, 1905, 1914, 1915], "difficulti": [8, 1881], "nonlinearli": 8, "sign": [8, 47, 341, 526, 881, 957, 1051, 1099, 1111, 1116, 1223, 1248, 1249, 1270, 1414, 1676, 1727, 1759, 1773, 1859, 1861, 1876, 1903, 1911, 1917, 1920, 1923, 1924], "split": [8, 38, 41, 71, 614, 769, 770, 771, 856, 858, 859, 937, 944, 1020, 1061, 1153, 1359, 1373, 1374, 1392, 1428, 1437, 1496, 1497, 1498, 1499, 1500, 1501, 1520, 1823, 1851, 1860, 1861, 1876, 1886, 1903, 1905, 1906, 1908, 1913, 1917, 1921], "shippabl": 8, "subtl": [8, 16, 17, 29, 1385, 1386, 1387, 1888], "nuanc": [8, 21, 22], "extra": [8, 16, 21, 23, 32, 38, 39, 41, 45, 47, 63, 71, 1063, 1120, 1131, 1190, 1197, 1200, 1235, 1261, 1422, 1429, 1609, 1804, 1850, 1862, 1877, 1883, 1885, 1887, 1888, 1890, 1893, 1905, 1907, 1917, 1924, 1925], "understand": [8, 9, 10, 13, 14, 15, 16, 17, 20, 21, 22, 29, 41, 43, 49, 50, 1120, 1247, 1867, 1881, 1883, 1886, 1892, 1899, 1907, 1922], "hack": 8, "answer": [8, 11, 16, 71, 821, 1339, 1627], "regress": [8, 12, 24, 1338, 1898], "scrutini": 8, "undertak": 8, "rest": [8, 18, 21, 23, 38, 39, 59, 71, 790, 811, 1116, 1255, 1256, 1823, 1877, 1894, 1898, 1905, 1906, 1908, 1913], "chanc": [8, 16, 23, 43, 47], "unrel": [8, 1129, 1882, 1888, 1905], "aid": [8, 29, 71, 1883], "troubleshoot": [8, 41, 1858], "mayb": [8, 16, 1127], "bracnh": 8, "rebas": 8, "latest": [8, 41, 45, 47, 1621, 1857, 1892, 1901], "statu": [8, 10, 49, 1279, 1858, 1864, 1875, 1908], "hud": 8, "risk": [8, 9, 63, 1611, 1614], "anyth": [8, 15, 48, 51, 70, 820, 823, 1201, 1678, 1860, 1867, 1878, 1894, 1905], "configur": [8, 15, 17, 19, 25, 29, 31, 38, 39, 41, 49, 50, 55, 58, 59, 60, 63, 785, 786, 789, 790, 794, 811, 812, 813, 814, 820, 823, 835, 836, 837, 840, 842, 845, 855, 856, 857, 858, 859, 950, 1020, 1602, 1635, 1752, 1843, 1858, 1869, 1873, 1886, 1887, 1898, 1900, 1905, 1911, 1913, 1922, 1924], "riski": 8, "had": [8, 15, 20, 24, 71, 1205, 1593, 1825, 1883, 1889], "beforehand": [8, 17, 70], "hei": 8, "my": [8, 38, 1359, 1893, 1901, 1908], "member": [8, 10, 38, 41, 49, 58, 59, 71, 1190, 1376, 1422, 1518, 1860, 1862, 1863, 1873, 1890, 1907, 1913, 1924, 1925], "sphinx": 8, "folder": [8, 10, 20, 29, 32, 38, 71, 1659, 1857, 1922], "tree": [8, 19, 51, 67, 950, 1422, 1465, 1659, 1858, 1901, 1905, 1907, 1915], "master": [8, 19, 41, 61, 789, 950, 1120, 1465, 1857, 1913], "doxygen": 8, "special": [8, 14, 15, 16, 21, 24, 30, 51, 60, 68, 71, 738, 739, 740, 820, 823, 905, 1056, 1070, 1071, 1072, 1074, 1075, 1084, 1086, 1157, 1158, 1159, 1203, 1261, 1275, 1315, 1359, 1469, 1603, 1604, 1605, 1648, 1678, 1702, 1760, 1771, 1775, 1854, 1858, 1864, 1869, 1877, 1886, 1888, 1891, 1893, 1901, 1905, 1908, 1921, 1922], "server": [8, 38, 41, 59, 1194, 1886, 1905, 1908, 1913], "cppdoc": [8, 33], "cpp": [8, 15, 32, 41, 1312, 1887], "accomplish": [8, 17, 43, 1894], "holist": 8, "concept": [8, 18, 68, 71, 1867, 1889, 1894, 1920], "galleri": 8, "restructur": [8, 1905], "text": [8, 20, 38, 47, 72, 77, 78, 79, 80, 81, 82, 154, 155, 174, 605, 614, 678, 680, 681, 682, 683, 684, 685, 686, 687, 688, 691, 695, 742, 743, 753, 755, 757, 761, 765, 766, 767, 769, 770, 771, 777, 781, 817, 818, 862, 878, 879, 880, 881, 882, 918, 919, 920, 923, 926, 928, 930, 939, 945, 956, 957, 959, 960, 962, 1058, 1077, 1078, 1107, 1108, 1112, 1113, 1134, 1146, 1147, 1148, 1149, 1156, 1179, 1187, 1210, 1213, 1214, 1215, 1218, 1219, 1226, 1229, 1235, 1239, 1244, 1247, 1253, 1260, 1269, 1276, 1277, 1278, 1279, 1311, 1312, 1323, 1324, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1361, 1362, 1363, 1364, 1365, 1367, 1368, 1369, 1370, 1371, 1372, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1407, 1408, 1409, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1425, 1426, 1427, 1428, 1429, 1430, 1434, 1435, 1436, 1437, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1451, 1452, 1453, 1454, 1455, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1488, 1489, 1490, 1492, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1504, 1507, 1508, 1509, 1514, 1517, 1519, 1520, 1521, 1525, 1526, 1536, 1541, 1545, 1546, 1547, 1551, 1556, 1559, 1564, 1565, 1567, 1571, 1572, 1573, 1574, 1577, 1578, 1579, 1581, 1582, 1583, 1607, 1609, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1683, 1700, 1701, 1704, 1707, 1720, 1723, 1726, 1738, 1759, 1761, 1762, 1774, 1776, 1786, 1787, 1797, 1804, 1805, 1808, 1820, 1821, 1853, 1878, 1881, 1891, 1901, 1905, 1911, 1918, 1922, 1924], "rst": 8, "rebuild": [8, 39], "circleci": 8, "shard": [8, 17, 38, 43, 45, 46, 63, 1602], "worker": [8, 32, 38, 39, 41, 42, 45, 49, 50, 51, 52, 58, 60, 61, 63, 1602, 1863, 1898, 1906, 1907, 1913, 1914, 1915], "40": [8, 14, 1143, 1262, 1343, 1385, 1609, 1610, 1633, 1634, 1643, 1646, 1819], "minut": [8, 11, 41, 1922], "netlifi": 8, "noplot": 8, "render": [8, 41, 1922], "notebook": 8, "rebuilt": [8, 39, 45], "deploi": [8, 49, 58, 1858, 1893, 1899, 1905], "action": [8, 41, 47, 49, 52, 71, 1886, 1905, 1907, 1915], "develop": [9, 10, 11, 22, 29, 32, 39, 41, 71, 1859, 1862, 1863, 1870, 1883, 1888, 1893, 1894, 1898, 1905, 1908, 1909, 1913, 1917], "meant": [9, 42, 58, 60, 1635, 1882, 1913], "rule": [9, 10, 16, 32, 41, 47, 71, 151, 857, 889, 890, 934, 935, 1046, 1239, 1250, 1340, 1341, 1342, 1385, 1386, 1387, 1461, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1743, 1829, 1858, 1860, 1862, 1876, 1878, 1883, 1884, 1888, 1891, 1920, 1924], "concern": [9, 38, 1875, 1886, 1901], "disagr": 9, "contribut": [9, 10, 43, 914, 1151, 1152, 1358, 1365, 1366, 1429, 1504, 1512, 1513, 1556, 1602, 1858, 1878, 1888, 1889, 1906], "maintainership": [9, 10], "escal": [9, 10], "hacker": 9, "poster": 9, "amaz": 9, "ml": [9, 20], "obsess": 9, "soumith": [9, 11], "goe": [9, 18, 21, 71, 1116, 1334, 1664, 1665, 1890], "depth": [9, 10, 776, 782, 1024, 1025, 1203, 1337, 1352, 1355, 1417, 1474, 1532, 1590, 1870, 1887, 1894, 1907], "primari": [9, 10, 16, 41, 71, 1199, 1864, 1870, 1917], "goal": [9, 20, 55, 67, 71, 1291, 1870, 1883, 1887, 1891, 1902, 1915], "secondari": 9, "abil": [9, 1739, 1870, 1893, 1905], "flexibl": [9, 21, 39, 63, 67, 1246, 1602, 1870, 1886, 1888, 1894], "abstract": [9, 12, 21, 38, 39, 42, 43, 47, 49, 58, 60, 907, 908, 909, 910, 911, 1616, 1863, 1887, 1908, 1913], "critic": [9, 17, 18, 21, 58, 677, 1610, 1643, 1873, 1885, 1886], "concret": [9, 15, 16, 21, 47, 61, 67, 71, 782, 797, 821, 838, 1474, 1559, 1590, 1860, 1863, 1886, 1888, 1896], "manner": [9, 49, 511, 898, 900, 1877, 1879, 1884], "jump": [9, 557, 1920], "regim": 9, "ei": 9, "tradeoff": [9, 17, 24, 39, 1908, 1914], "temptat": 9, "impos": [9, 60, 69, 1747, 1875, 1882, 1920], "strict": [9, 898, 899, 900, 901, 902, 903, 1119, 1126, 1190, 1205, 1206, 1422, 1644, 1905, 1922, 1924], "upfront": [9, 15], "simplifi": [9, 15, 39, 70, 1197, 1412, 1610, 1678, 1870, 1883, 1891, 1894, 1904, 1914], "worth": [9, 10, 21, 23, 38, 39, 61, 1120, 1857, 1921], "friction": 9, "compel": 9, "narrow": [9, 17, 29, 1259, 1322, 1678, 1766, 1861, 1863, 1876, 1903, 1910, 1921], "subproblem": 9, "fragment": [9, 29, 988, 1020, 1867, 1886], "ecosystem": [9, 20, 1893, 1895], "incomprehens": 9, "seamlessli": [9, 1878], "softwar": [9, 1225, 1226, 1253, 1843, 1886, 1892], "experi": [9, 10, 18, 22, 26, 29, 30, 39, 69, 72, 77, 78, 79, 80, 81, 82, 1131, 1451, 1574, 1602, 1850, 1870, 1888, 1922], "rich": [9, 1863], "denomin": [9, 684, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1711], "subset": [9, 38, 41, 45, 59, 1201, 1678, 1859, 1860, 1862, 1863, 1888, 1901, 1911], "borrow": 9, "zen": 9, "implicit": [9, 765, 766, 769, 770, 771, 1135, 1143, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1415, 1416, 1417, 1473, 1488, 1489, 1490, 1496, 1497, 1498, 1545, 1546, 1547, 1695, 1859, 1861, 1863, 1864, 1901, 1905, 1921], "concis": [9, 51, 1913], "interchang": [9, 47, 1675, 1828, 1862, 1892, 1902], "everydai": 9, "english": 9, "movement": [9, 1921], "worri": [9, 1913], "placement": [9, 17, 46, 49, 856, 1593, 1908, 1913], "favor": [9, 21, 41, 782, 783, 784, 941, 1032, 1036, 1190, 1244, 1247, 1279, 1280, 1381, 1422, 1475, 1476, 1590, 1591, 1592, 1594, 1707, 1808, 1831], "practition": 9, "debugg": [9, 17, 29, 1195, 1891], "plug": 9, "ir": [9, 15, 16, 17, 22, 29, 71, 757, 1193, 1194, 1374, 1375, 1659, 1858, 1860, 1863, 1901, 1902], "classic": [9, 1883], "sort": [9, 15, 21, 45, 49, 71, 587, 606, 873, 874, 895, 1063, 1150, 1310, 1330, 1636, 1637, 1648, 1708, 1743, 1826, 1840, 1859, 1861, 1863, 1888, 1890, 1903, 1917], "distribut": [9, 22, 30, 38, 39, 42, 49, 50, 51, 52, 55, 56, 57, 58, 60, 61, 63, 70, 174, 258, 286, 377, 453, 480, 605, 692, 693, 816, 920, 1037, 1312, 1330, 1334, 1358, 1359, 1360, 1361, 1362, 1363, 1367, 1372, 1376, 1388, 1436, 1440, 1461, 1504, 1506, 1507, 1508, 1509, 1514, 1518, 1519, 1523, 1533, 1564, 1602, 1650, 1700, 1714, 1716, 1717, 1718, 1719, 1720, 1721, 1858, 1863, 1877, 1878, 1881, 1882, 1886, 1906, 1907, 1909, 1915, 1918, 1922, 1925], "tldr": 9, "resourc": [9, 17, 25, 32, 38, 49, 54, 58, 71, 1863, 1875, 1917], "characterist": [9, 1809, 1889, 1894], "uniformli": [9, 47, 1718, 1719, 1924], "leak": [9, 890, 896, 1863, 1875, 1883], "smart": [9, 1888, 1905, 1913], "anywai": [9, 1883], "obviou": [9, 16, 1890, 1915], "extens": [9, 16, 17, 29, 32, 35, 41, 43, 46, 47, 1261, 1262, 1739, 1759, 1858, 1870, 1878, 1882, 1899, 1905, 1917], "unavoid": 9, "latenc": [9, 17, 25, 55, 1885, 1886], "caveat": [9, 13, 24, 29, 63, 1593, 1642, 1870, 1875, 1886, 1894, 1899], "valuabl": 9, "certainli": [9, 1870], "heterogen": [9, 1862], "cluster": [9, 41, 43, 57, 58, 59, 1330, 1922], "focus": [9, 29, 1862, 1863, 1888], "beaten": 9, "space": [9, 10, 38, 47, 769, 770, 771, 1046, 1081, 1083, 1085, 1086, 1092, 1099, 1143, 1152, 1205, 1206, 1260, 1276, 1330, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1388, 1398, 1399, 1400, 1401, 1402, 1403, 1416, 1417, 1473, 1496, 1497, 1498, 1499, 1500, 1501, 1533, 1829, 1861, 1879, 1883, 1891, 1894, 1899], "innov": 9, "ultim": [9, 10, 32, 51, 60, 63, 1887], "evidenc": 9, "began": 9, "bind": [9, 32, 71, 1000, 1863, 1864, 1905], "monolith": 9, "deepli": 9, "integr": [9, 13, 38, 46, 52, 67, 155, 920, 922, 923, 924, 925, 926, 927, 962, 1046, 1151, 1190, 1213, 1257, 1258, 1321, 1422, 1714, 1726, 1829, 1878, 1888, 1893, 1894, 1904, 1906, 1908, 1918, 1920, 1924], "numpi": [9, 38, 68, 447, 491, 690, 691, 696, 874, 876, 877, 894, 1058, 1060, 1061, 1063, 1081, 1102, 1103, 1104, 1105, 1109, 1110, 1115, 1131, 1153, 1220, 1221, 1231, 1242, 1244, 1245, 1246, 1247, 1248, 1253, 1254, 1257, 1259, 1291, 1296, 1701, 1726, 1729, 1736, 1748, 1756, 1790, 1791, 1792, 1793, 1794, 1795, 1808, 1810, 1811, 1819, 1822, 1823, 1825, 1847, 1850, 1851, 1870, 1884, 1888, 1889, 1897, 1898, 1900, 1905, 1920, 1921, 1922, 1923, 1924, 1929], "scipi": [9, 938, 1236, 1237, 1561, 1701, 1905, 1916, 1918, 1922], "scikit": [9, 1532], "favorit": 9, "cython": 9, "numba": 9, "reinvent": 9, "wheel": [9, 1900], "year": [9, 1917], "rewrot": 9, "frontend": [9, 17, 33, 67, 71, 1902], "familiar": [9, 17, 28, 33, 71, 1019, 1860, 1883, 1889, 1905, 1908, 1914, 1915], "perhap": [9, 21, 1889], "importantli": [9, 21], "huge": [9, 1809, 1873], "scientif": [9, 1756], "pareto": [9, 1858], "close": [9, 33, 41, 58, 71, 934, 1002, 1179, 1225, 1226, 1252, 1253, 1279, 1339, 1453, 1471, 1494, 1743, 1808, 1831, 1873, 1883, 1888, 1897, 1901, 1905, 1908, 1913, 1922, 1924], "curv": [9, 1922], "torch_funct": [9, 1888], "torch_dispatch": 9, "torch": [9, 10, 12, 13, 14, 15, 16, 17, 20, 21, 24, 26, 28, 29, 30, 33, 35, 36, 39, 42, 45, 49, 50, 51, 52, 55, 56, 58, 60, 61, 63, 66, 73, 74, 75, 76, 83, 88, 89, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 891, 917, 964, 965, 966, 967, 969, 970, 985, 987, 998, 1067, 1165, 1188, 1189, 1190, 1204, 1327, 1328, 1329, 1330, 1331, 1332, 1333, 1334, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1344, 1345, 1346, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1357, 1358, 1359, 1360, 1361, 1362, 1363, 1364, 1365, 1366, 1367, 1368, 1369, 1370, 1371, 1372, 1373, 1374, 1375, 1376, 1377, 1378, 1379, 1380, 1381, 1382, 1383, 1384, 1385, 1386, 1387, 1388, 1389, 1390, 1391, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1408, 1409, 1410, 1411, 1412, 1413, 1414, 1415, 1416, 1417, 1418, 1419, 1420, 1421, 1422, 1423, 1424, 1425, 1426, 1427, 1428, 1429, 1430, 1431, 1432, 1433, 1434, 1435, 1436, 1437, 1438, 1439, 1440, 1441, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1449, 1450, 1451, 1452, 1453, 1454, 1455, 1456, 1457, 1458, 1459, 1460, 1461, 1462, 1463, 1464, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1472, 1473, 1474, 1475, 1476, 1477, 1478, 1479, 1593, 1602, 1603, 1604, 1605, 1611, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1635, 1647, 1655, 1656, 1657, 1658, 1659, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1714, 1753, 1783, 1860, 1861, 1862, 1876, 1877, 1882, 1883, 1884, 1885, 1887, 1890, 1891, 1893, 1894, 1895, 1896, 1898, 1900, 1906, 1908, 1909, 1910, 1913, 1914, 1915, 1921], "tracer": [9, 21, 75, 1205, 1901, 1902, 1922, 1927], "functorch": [9, 13, 27, 64, 69], "anchor": [9, 28, 71, 1470, 1471, 1587, 1588, 1861], "hackabl": 9, "todai": [9, 15, 18, 27, 64, 69, 1908], "open": [9, 10, 17, 32, 38, 47, 58, 64, 686, 912, 1113, 1197, 1261, 1284, 1294, 1538, 1860, 1870, 1875, 1878, 1892, 1900, 1901, 1905, 1908, 1913, 1917, 1918], "evolv": [9, 1887], "ai": [9, 1901, 1918], "adopt": [10, 41, 717, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762], "hierarch": [10, 1922], "pull": [10, 11, 16, 33, 71, 151, 890, 1905], "request": [10, 11, 15, 30, 41, 43, 60, 686, 858, 876, 877, 1020, 1262, 1284, 1294, 1538, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1857, 1878, 1882, 1883, 1885, 1886, 1901, 1905, 1913, 1914, 1915, 1917, 1918], "overseen": 10, "catch": [10, 18, 51, 1860, 1883, 1889, 1891], "maker": 10, "strong": 10, "toward": [10, 1058, 1151, 1152, 1262, 1326, 1602, 1686, 1727, 1735, 1736, 1906], "philosophi": [10, 67, 1858], "beyond": [10, 39, 1307, 1358, 1664, 1665, 1674, 1734, 1890, 1894], "encourag": [10, 49, 1878, 1908, 1917, 1924], "propos": [10, 1661, 1681, 1682, 1870, 1891, 1904, 1914], "review": [10, 11, 21, 39, 1905], "willing": 10, "invest": 10, "anyon": 10, "ownership": [10, 71], "codebas": 10, "strictli": [10, 38, 151, 192, 209, 890, 934, 1152, 1190, 1194, 1422, 1883, 1918], "compani": 10, "bui": 10, "addition": [10, 38, 39, 41, 47, 63, 151, 511, 614, 890, 1120, 1124, 1125, 1194, 1253, 1330, 1385, 1386, 1387, 1785, 1890, 1925], "membership": [10, 49, 57, 58, 1864], "That": [10, 27, 49, 56, 59, 65, 71, 1187, 1260, 1276, 1843, 1871, 1888, 1889, 1890, 1899, 1905, 1913], "seat": 10, "reserv": [10, 55, 1020, 1864, 1886, 1894], "emploi": [10, 1677, 1894, 1905, 1906], "directori": [10, 17, 18, 29, 32, 41, 43, 56, 1659, 1857, 1872, 1893, 1905, 1907, 1922], "procedur": [10, 29, 47, 856, 1205, 1206, 1262, 1783, 1913], "disput": 10, "public": [10, 11, 1120, 1888, 1928], "relev": [10, 18, 20, 21, 42, 49, 58, 63, 70, 677, 1253, 1858, 1864, 1882, 1883, 1905, 1908], "resolut": [10, 1434, 1435, 1486, 1521, 1562, 1563, 1829, 1864, 1905, 1929], "conclus": 10, "publicli": [10, 1928], "vision": [10, 20, 1199, 1358, 1504, 1857, 1858], "roadmap": [10, 11], "parti": [10, 58, 1857, 1858, 1860, 1886, 1889, 1894, 1905], "triag": [10, 11], "meet": [10, 11, 57, 1219, 1886], "Their": [10, 16, 1055], "articul": 10, "cohes": 10, "negoti": [10, 1913], "contenti": 10, "broad": [10, 1894], "stakehold": 10, "power": [10, 22, 57, 1026, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1106, 1213, 1243, 1257, 1390, 1391, 1542, 1543, 1610, 1643, 1661, 1690, 1704, 1728, 1844, 1864, 1886, 1917], "veto": 10, "admin": 10, "amongst": 10, "commonli": [10, 15, 20, 47, 63, 1291, 1863, 1865, 1882, 1883, 1904, 1908, 1920], "merit": 10, "demonstr": [10, 20, 59, 71, 1345, 1860, 1894, 1899, 1906, 1913], "expertis": 10, "continu": [10, 13, 14, 18, 21, 38, 41, 47, 61, 63, 71, 402, 605, 816, 899, 1143, 1225, 1226, 1253, 1344, 1345, 1602, 1864, 1870, 1883, 1899, 1907, 1925], "light": [10, 1922], "mainten": [10, 58, 59], "emeritu": [10, 11], "inact": [10, 1020, 1886], "contact": 10, "item": [10, 12, 15, 16, 21, 38, 43, 580, 581, 582, 586, 789, 790, 791, 811, 812, 813, 814, 1358, 1423, 1432, 1614, 1756, 1857, 1859, 1860, 1861, 1862, 1863, 1876, 1886, 1901, 1903, 1905, 1913, 1922, 1923], "nomine": 10, "breadth": 10, "testimoni": 10, "posit": [10, 38, 47, 71, 89, 402, 470, 542, 732, 854, 858, 860, 905, 919, 921, 928, 941, 942, 943, 1079, 1080, 1081, 1082, 1083, 1091, 1093, 1097, 1099, 1116, 1126, 1127, 1130, 1147, 1148, 1182, 1185, 1190, 1193, 1219, 1220, 1231, 1233, 1244, 1247, 1248, 1262, 1282, 1297, 1316, 1321, 1322, 1339, 1350, 1351, 1352, 1357, 1358, 1359, 1366, 1376, 1383, 1422, 1428, 1458, 1465, 1470, 1471, 1486, 1494, 1513, 1518, 1521, 1587, 1588, 1596, 1597, 1598, 1734, 1736, 1786, 1788, 1832, 1833, 1834, 1835, 1842, 1857, 1861, 1876, 1877, 1888, 1889, 1891, 1901, 1903, 1906, 1912, 1917, 1918, 1924, 1928, 1929], "neg": [10, 15, 30, 32, 38, 41, 47, 60, 71, 89, 440, 442, 457, 658, 659, 695, 752, 777, 921, 957, 960, 969, 985, 991, 992, 1020, 1032, 1079, 1080, 1081, 1082, 1083, 1084, 1098, 1099, 1100, 1106, 1116, 1180, 1182, 1184, 1243, 1270, 1282, 1303, 1304, 1312, 1316, 1321, 1322, 1330, 1339, 1367, 1376, 1408, 1415, 1416, 1417, 1425, 1429, 1431, 1436, 1453, 1470, 1471, 1514, 1518, 1521, 1523, 1532, 1536, 1545, 1546, 1547, 1556, 1564, 1587, 1588, 1590, 1700, 1701, 1732, 1736, 1771, 1773, 1776, 1787, 1824, 1832, 1833, 1834, 1835, 1842, 1859, 1860, 1861, 1876, 1878, 1881, 1883, 1889, 1901, 1902, 1903, 1912, 1917, 1918], "interact": [10, 12, 17, 23, 33, 38, 46, 71, 859, 967, 1000, 1165, 1858, 1864, 1887, 1905, 1922], "final": [10, 12, 14, 15, 29, 41, 43, 45, 47, 49, 58, 67, 68, 683, 686, 687, 757, 918, 936, 949, 1063, 1102, 1120, 1143, 1261, 1279, 1284, 1374, 1376, 1392, 1437, 1450, 1593, 1786, 1829, 1860, 1862, 1863, 1864, 1876, 1888, 1891, 1894, 1897, 1899, 1901, 1905, 1914, 1915], "declin": 10, "conflict": [10, 39, 59, 1905], "lack": [10, 30, 1225, 1226, 1253], "unfit": 10, "conduct": [10, 1602, 1697, 1809, 1913], "filial": 10, "romant": 10, "strength": 10, "candid": [10, 914, 1861, 1905], "letter": [10, 1063], "befit": 10, "candidaci": 10, "behind": [10, 16, 1858, 1899, 1914], "75": [10, 1151, 1410, 1521, 1539, 1661, 1708, 1861, 1918], "choos": [10, 33, 71, 889, 914, 989, 1235, 1248, 1253, 1338, 1881, 1882, 1885, 1905, 1909, 1922], "unforeseen": 10, "circumst": [10, 58, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1886], "perman": [10, 71, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1883, 1915], "unavail": [10, 1862], "rank": [10, 15, 29, 38, 39, 41, 42, 43, 45, 46, 47, 49, 56, 58, 59, 61, 63, 1235, 1236, 1237, 1244, 1279, 1414, 1461, 1602, 1614, 1697, 1809, 1861, 1887, 1896, 1901, 1906, 1913, 1914], "elect": 10, "invit": [10, 1857], "convinc": 10, "approach": [10, 17, 27, 39, 41, 71, 938, 1131, 1783, 1850, 1860, 1875, 1878, 1886, 1888, 1891, 1908, 1913], "interview": 10, "talk": [10, 60, 1893], "gather": [10, 41, 58, 63, 511, 1819, 1843, 1859, 1861, 1888, 1890, 1893, 1903, 1905], "read": [10, 12, 17, 20, 21, 26, 29, 35, 38, 41, 43, 48, 49, 51, 58, 59, 63, 67, 71, 447, 1022, 1046, 1114, 1115, 1116, 1197, 1261, 1691, 1858, 1876, 1877, 1883, 1884, 1886, 1887, 1889, 1893, 1897, 1905, 1908, 1913], "attend": [10, 732, 1428, 1465], "confer": [10, 1376], "pipelin": [10, 17, 71, 1858, 1913], "world": [10, 15, 18, 22, 26, 41, 45, 49, 56, 58, 59, 63, 1461, 1602, 1883, 1905, 1908], "cover": [10, 14, 21, 23, 64, 71, 1037, 1063, 1415, 1545, 1546, 1547, 1863, 1865, 1877, 1883, 1888, 1891, 1893, 1894, 1913], "push": [10, 21, 50, 1025, 1131, 1255, 1850, 1907], "codeown": 10, "notifi": [10, 42, 59, 1915], "expert": 10, "strongli": [10, 41, 49, 59, 1361, 1362, 1363, 1367, 1804, 1857], "failur": [10, 17, 21, 29, 41, 47, 49, 50, 51, 55, 56, 57, 58, 61, 677, 905, 906, 1120, 1205, 1206, 1307, 1863, 1869, 1875, 1902, 1906, 1913, 1915, 1924], "revert": [10, 47, 63, 1458, 1579, 1915], "substanti": [10, 12, 39, 1886], "syntact": [10, 51, 71], "establish": [10, 41, 58, 1883], "seri": [10, 12, 24, 71, 1345, 1385, 1898, 1901, 1928], "lf": 10, "llc": 10, "guidelin": [10, 1625, 1905, 1908, 1909], "trademark": 10, "www": [10, 1345, 1471, 1922], "lfproject": 10, "acknowledg": [10, 41, 1858, 1915, 1917], "copyright": [10, 29], "holder": 10, "independ": [10, 38, 41, 58, 63, 70, 154, 155, 776, 782, 898, 899, 900, 901, 902, 903, 969, 1143, 1152, 1248, 1360, 1361, 1362, 1363, 1367, 1507, 1508, 1509, 1514, 1532, 1590, 1646, 1707, 1858, 1860, 1882, 1883, 1886, 1899, 1905], "authorship": 10, "claus": [10, 1890], "bsd": 10, "licens": 10, "opensourc": 10, "outbound": 10, "inbound": 10, "q": [10, 16, 39, 47, 430, 478, 755, 1135, 1210, 1226, 1229, 1248, 1290, 1319, 1388, 1428, 1571, 1609, 1695, 1697, 1707, 1708, 1809, 1860, 1861, 1891, 1898, 1901, 1917, 1918], "partli": [10, 1863], "domain": [10, 47, 51, 681, 823, 882, 1077, 1078, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1091, 1093, 1094, 1095, 1096, 1143, 1878, 1901, 1908], "absolut": [10, 30, 32, 71, 93, 678, 691, 905, 906, 1111, 1179, 1218, 1223, 1244, 1247, 1249, 1270, 1383, 1389, 1453, 1530, 1534, 1575, 1619, 1620, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1649, 1660, 1701, 1727, 1759, 1861, 1894, 1901, 1903, 1918, 1923, 1924], "health": 10, "success": [10, 29, 43, 47, 49, 55, 71, 1220, 1231, 1233, 1279, 1621, 1790, 1791, 1792, 1794, 1795, 1886, 1894, 1901, 1902, 1917], "am": 10, "grant": 10, "purchas": 10, "board": 10, "driven": [10, 1901], "clearli": [10, 1870, 1905], "sponsorship": 10, "foundat": [10, 1902], "ptf": 10, "minor": [10, 991, 1220, 1236], "committ": 10, "facebook": 10, "infrastructur": [10, 15, 50, 1905], "employe": 10, "expand": [10, 47, 255, 491, 875, 897, 905, 906, 933, 1242, 1243, 1291, 1428, 1472, 1565, 1839, 1857, 1859, 1861, 1869, 1876, 1877, 1884, 1889, 1901, 1903, 1905, 1906, 1921], "deliv": [10, 1907], "offici": [10, 41, 1330, 1908], "showcas": [10, 1418, 1886, 1896], "whenev": [10, 16, 21, 877, 1609, 1610, 1873, 1875, 1911, 1914, 1915, 1928], "fix": [11, 12, 17, 29, 35, 38, 41, 46, 47, 49, 58, 63, 65, 68, 71, 83, 84, 262, 792, 798, 1120, 1203, 1235, 1365, 1366, 1440, 1512, 1513, 1532, 1602, 1860, 1861, 1873, 1881, 1882, 1886, 1887, 1890, 1896, 1900, 1901, 1903, 1904], "plu": [11, 32, 43, 898, 1116, 1236, 1917], "quarterli": 11, "chintala": 11, "edward": 11, "yang": [11, 1262], "ezyang": [11, 1921], "greg": 11, "chanan": 11, "gchanan": 11, "dmytro": 11, "dzhulgakov": 11, "nikita": 11, "shulga": 11, "malfet": 11, "joel": [11, 1697, 1809], "schlosser": 11, "jbschlosser": 11, "alban": 11, "desmaison": 11, "alband": 11, "sam": 11, "gross": 11, "colesburi": 11, "adam": [11, 42, 45, 47, 63, 1665, 1666, 1668, 1674, 1678, 1904], "paszk": 11, "apaszk": 11, "ilqar": 11, "ramazanli": 11, "iramazanli": 11, "vincent": 11, "quennevil": 11, "belair": 11, "vincentqb": 11, "jeffrei": 11, "wan": 11, "soulitz": 11, "elia": 11, "ellison": 11, "eellison": 11, "michael": [11, 29], "suo": 11, "yanan": 11, "cao": 11, "gmagogsfm": 11, "jame": 11, "reed": 11, "jamesr66a": 11, "jason": [11, 14], "ansel": [11, 14], "jansel": 11, "jiong": 11, "gong": 11, "jgong5": 11, "zach": 11, "devito": 11, "zdevito": 11, "fritz": 11, "obermey": 11, "fritzo": 11, "neeraj": 11, "pradhan": 11, "neerajprad": 11, "alican": 11, "bozkurt": 11, "alicanb": 11, "vishwak": 11, "srinivasan": 11, "vishwakftw": 11, "shen": 11, "li": [11, 1319, 1708, 1886], "mrshenli": 11, "pritam": 11, "damania": 11, "pritamdamania87": 11, "yanli": 11, "zhao": 11, "zhaojuanmao": 11, "rohan": 11, "varma": 11, "wanchao": 11, "liang": 11, "wanchaol": 11, "junji": 11, "wang": [11, 47], "fduwjj": 11, "howard": 11, "huang": 11, "tristan": 11, "rice": 11, "d4l3k": 11, "alisson": 11, "azzolini": 11, "aazzolini": 11, "ke": 11, "wen": 11, "kwen2501": 11, "kiuk": 11, "chung": 11, "kiukchung": 11, "pieter": 11, "noordhui": 11, "pietern": 11, "mingzh": 11, "mingzhe09088": 11, "omkar": 11, "salpekar": 11, "osalpekar": 11, "simon": 11, "ssnl": 11, "vitali": 11, "fedyunin": 11, "vitalyfedyunin": 11, "mike": 11, "ruberri": 11, "mruberri": 11, "mario": 11, "lezcano": 11, "ivan": 11, "yashchuk": 11, "ivanyashchuk": 11, "pearu": 11, "peterson": 11, "vedeneev": 11, "nikitav": 11, "christian": 11, "puhrsch": 11, "cpuhrsch": 11, "andrew": [11, 1262], "amjam": 11, "driss": 11, "guessou": 11, "drisspg": 11, "mikayla": 11, "gawarecki": 11, "mikaylagawarecki": 11, "natalia": 11, "gimelshein": 11, "ngimel": 11, "georg": 11, "qi": 11, "peter": 11, "bell": 11, "peterbell10": 11, "mingfei": 11, "ma": 11, "mingfeima": 11, "xiaob": 11, "zhang": 11, "xiaobingsup": 11, "xiaoqiang": 11, "zheng": 11, "xq": 11, "ilia": 11, "cherniavskii": 11, "cher": 11, "bai": 11, "bddppq": 11, "yinghai": 11, "jianhui": 11, "piotr": 11, "bialecki": 11, "ptrblck": 11, "sarofeen": 11, "csarofeen": 11, "tulloch": 11, "ajtulloch": 11, "alex": 11, "jann": 11, "jjsjann123": 11, "peng": 11, "sun": 11, "sunway513": 11, "jithun": 11, "nair": 11, "jithunnair": 11, "jeff": 11, "daili": 11, "jeffdaili": 11, "eli": 11, "uriega": 11, "seemether": 11, "mikei": 11, "dagits": 11, "zain": 11, "rizvi": 11, "zainrizvi": 11, "nirav": 11, "mehta": 11, "mehtanirav": 11, "andrei": 11, "talman": 11, "atalman": 11, "zhuoji": 11, "zhou": 11, "zhouzhuoji": 11, "karl": 11, "ostmo": 11, "kostmo": 11, "adnan": 11, "aziz": 11, "adnanaziz": 11, "ck": 11, "luk": 11, "ckluk": 11, "taylor": [11, 1143], "robi": 11, "robieta": 11, "xu": [11, 63], "xuzhao9": 11, "geeta": 11, "chauhan": 11, "chauhang": 11, "victor": 11, "bittorf": 11, "bitfort": 11, "gisl": 11, "dankel": 11, "gdankel": 11, "feng": 11, "yf225": 11, "brian": 11, "hirsh": 11, "bdhirsh": 11, "sebastian": 11, "messmer": 11, "smessmer": 11, "bowen": 11, "bao": [11, 25], "bowenbao": 11, "aaron": 11, "bockov": 11, "abock": 11, "gari": 11, "miguel": 11, "garymm": 11, "lara": 11, "haidar": 11, "hdr": 11, "fang": 11, "houseroad": 11, "negin": 11, "raoof": 11, "neginraoof": 11, "spandan": 11, "tiwari": 11, "spandantiwari": 11, "david": [11, 1330], "reiss": 11, "dreiss": 11, "raziel": 11, "guevara": 11, "linbin": 11, "yu": 11, "linbinyu": 11, "kobzarev": 11, "ivankobzarev": 11, "tao": 11, "xta0": 11, "vasilii": 11, "kuznetsov": 11, "vkuzo": 11, "jerri": 11, "jerryzh168": [11, 790], "zafar": 11, "takhirov": 11, "supriya": 11, "rao": 11, "supriyar": 11, "raghuraman": 11, "krishnamoorthi": 11, "raghuramank100": 11, "guoliang": 11, "hua": 11, "nbcsm": 11, "teng": 11, "gao": 11, "gaoteng": 11, "git": [11, 17, 29, 1907], "johnson": 11, "peterjc123": [11, 1900], "kulin": 11, "seth": 11, "kulinseth": 11, "ramin": 11, "azarmehr": 11, "razarmehr": 11, "alfredo": 11, "mendoza": 11, "avmgithub": 11, "svetlana": 11, "karslioglu": 11, "svekar": 11, "jack": 11, "jackcaog": 11, "daniel": [11, 47], "sohn": 11, "jysohn23": 11, "cain": 11, "zcain117": 11, "hirsch": 11, "gregori": 11, "ail": 11, "ailzhang": 11, "libenzi": 11, "dlibenzi": 11, "suhan": 11, "asuhan": 11, "manoj": 11, "mycpuorg": 11, "vamshi": 11, "dantu": 11, "vdantu": 11, "dhanasekar": 11, "karuppasami": 11, "dhanainm": 11, "francisco": 11, "massa": 11, "fmassa": 11, "vasili": 11, "vrynioti": 11, "datumbox": 11, "nicola": 11, "hug": 11, "nicolashug": 11, "yosua": 11, "maranatha": 11, "yosuamichael": 11, "joao": 11, "gome": 11, "jdsgome": 11, "philip": 11, "meier": 11, "pmeier": 11, "fomin": 11, "vfdev": 11, "nayef": 11, "ahm": 11, "nayef211": 11, "parmeet": 11, "singh": 11, "bhatia": 11, "guanheng": 11, "zhangguanheng66": 11, "moto": 11, "hira": 11, "mthrok": 11, "hwang": 11, "hwangjeff": 11, "carolin": 11, "chen": 11, "carolineechen": 11, "xiaohui": 11, "zhaoheng": 11, "ni": 11, "nateanl": 11, "qb": 11, "ivchenko": 11, "divchenko": 11, "colin": 11, "colin2328": 11, "wenlei": 11, "xie": 11, "wenleix": 11, "debut": 12, "encapsul": [12, 70, 71, 1913], "henc": [12, 39, 45, 49, 57, 58, 61, 63, 70, 920, 1116, 1418, 1419, 1420, 1474, 1793, 1878, 1883, 1886, 1887, 1913, 1915], "speedup": [12, 20, 21, 22, 25, 38, 39, 1428, 1469], "address": [12, 38, 41, 58, 61, 68, 217, 905, 906, 972, 1870, 1875, 1886, 1913, 1914], "host": [12, 16, 38, 41, 49, 51, 57, 58, 59, 60, 197, 210, 577, 600, 874, 1190, 1422, 1602, 1614, 1648, 1886, 1906, 1913, 1914, 1919], "essenti": [12, 38, 41, 46, 49, 71, 1279, 1877, 1886, 1900, 1917], "wrapper": [12, 39, 41, 46, 47, 63, 70, 71, 621, 754, 787, 821, 964, 966, 967, 969, 1036, 1038, 1109, 1110, 1129, 1190, 1359, 1860, 1862, 1863, 1873, 1875, 1886, 1887, 1901, 1906], "coupl": [12, 27, 28, 67, 1860, 1893, 1914], "tricki": [12, 50, 64, 69, 1883, 1894, 1915], "cachingalloc": 12, "pool": [12, 70, 763, 764, 765, 766, 779, 780, 964, 998, 999, 1009, 1020, 1298, 1299, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1370, 1371, 1390, 1391, 1415, 1416, 1417, 1418, 1419, 1420, 1423, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1489, 1490, 1516, 1517, 1542, 1543, 1545, 1546, 1547, 1712, 1713, 1858, 1885, 1886, 1888, 1894, 1896, 1910, 1913], "freed": [12, 63, 151, 890, 904, 972, 1020, 1875, 1886, 1892, 1913], "exactli": [12, 21, 32, 39, 41, 47, 60, 905, 906, 944, 976, 980, 1063, 1109, 1110, 1187, 1190, 1231, 1366, 1369, 1422, 1450, 1453, 1513, 1523, 1602, 1649, 1660, 1870, 1876, 1883, 1886, 1887, 1888, 1891, 1892, 1901, 1905, 1906], "replai": [12, 17, 29, 964, 998, 1656, 1886], "advantag": [12, 41, 58, 59, 1339, 1383, 1887, 1890, 1913, 1917], "overwrit": [12, 35, 38, 41, 71, 1423, 1432, 1863, 1883], "burn": 12, "forth": [12, 1683, 1844, 1857, 1907], "cudagraph_tre": 12, "reclaim": [12, 1886], "ab": [12, 13, 14, 17, 21, 29, 46, 47, 91, 92, 622, 623, 679, 938, 1063, 1221, 1242, 1243, 1245, 1246, 1259, 1262, 1392, 1441, 1468, 1471, 1473, 1561, 1646, 1649, 1691, 1697, 1701, 1858, 1859, 1861, 1863, 1876, 1877, 1878, 1886, 1894, 1903, 1917, 1923], "_dynamo": [12, 13, 14, 15, 17, 19, 20, 21, 24, 26, 29, 950, 1858, 1887], "rand_lik": [12, 1861, 1865, 1886, 1903, 1925], "warm": [12, 17, 39, 45, 1009, 1681, 1682, 1886, 1907], "cubla": [12, 30, 981, 1843, 1898], "triton": [12, 17, 19, 20, 26, 29, 950, 1858, 1889], "arang": [12, 20, 30, 38, 41, 48, 511, 604, 688, 689, 690, 694, 696, 883, 884, 885, 932, 944, 948, 1046, 1061, 1079, 1083, 1091, 1097, 1099, 1103, 1104, 1105, 1106, 1113, 1114, 1153, 1210, 1211, 1215, 1218, 1242, 1245, 1246, 1259, 1322, 1443, 1444, 1445, 1446, 1447, 1474, 1475, 1476, 1558, 1649, 1650, 1696, 1704, 1708, 1723, 1730, 1735, 1756, 1788, 1796, 1807, 1823, 1824, 1826, 1827, 1829, 1851, 1859, 1861, 1870, 1878, 1899, 1903, 1918, 1922, 1923], "invari": [12, 28, 47, 1635, 1783, 1790, 1791, 1792, 1793, 1794, 1795, 1915, 1917], "overwritten": [12, 742, 743, 753, 761, 794, 838, 858, 1883, 1924], "pattern": [12, 15, 16, 28, 41, 43, 789, 790, 791, 793, 851, 858, 1006, 1359, 1638, 1786, 1860, 1863, 1883, 1886, 1888, 1890, 1892, 1899, 1909, 1910], "di": [12, 21, 1875], "yet": [12, 16, 17, 21, 22, 24, 27, 29, 42, 49, 63, 68, 70, 71, 83, 84, 966, 1037, 1193, 1195, 1207, 1295, 1602, 1616, 1620, 1622, 1858, 1862, 1863, 1869, 1877, 1878, 1886, 1901, 1903, 1908, 1913, 1915, 1917, 1918, 1920], "privat": [12, 58, 1886, 1888, 1905], "reflect": [12, 67, 457, 518, 553, 1115, 1116, 1119, 1187, 1350, 1351, 1352, 1398, 1399, 1400, 1443, 1444, 1445, 1521, 1559, 1644, 1692, 1804, 1860, 1861, 1890, 1921], "fallback": [12, 17, 29, 32, 41, 58, 66, 1203, 1253, 1882, 1886], "my_model": [12, 17, 29, 43, 1602, 1860, 1901], "y1": [12, 1656, 1785], "y2": [12, 1656, 1785], "naiv": [12, 15, 17, 38, 1906], "pend": [12, 1913, 1922], "storag": [12, 16, 43, 63, 222, 311, 339, 342, 343, 434, 457, 482, 497, 518, 521, 555, 556, 581, 582, 584, 585, 875, 892, 894, 987, 1054, 1160, 1164, 1176, 1190, 1197, 1261, 1283, 1321, 1322, 1359, 1422, 1725, 1739, 1746, 1777, 1782, 1785, 1799, 1822, 1828, 1857, 1858, 1861, 1872, 1875, 1883, 1886, 1896, 1899, 1905, 1913, 1917, 1920, 1921, 1923], "footgun": [12, 16], "uniqu": [12, 41, 49, 55, 58, 59, 60, 511, 515, 1181, 1225, 1226, 1230, 1236, 1237, 1239, 1248, 1250, 1252, 1253, 1290, 1297, 1785, 1808, 1841, 1857, 1860, 1872, 1888, 1905, 1907, 1913, 1914, 1915, 1917, 1922], "straightforward": [13, 21, 71, 1870, 1878, 1894, 1904, 1917], "gm": [13, 16, 21, 28, 29, 71], "my_custom_backend": 13, "f_opt": 13, "my_compil": [13, 14, 21], "besid": [13, 39, 41, 1886, 1887, 1922], "plugin": [13, 1907, 1922], "entry_point": [13, 59], "torch_dynamo_backend": 13, "your_modul": 13, "submodul": [13, 28, 33, 63, 71, 788, 794, 811, 835, 836, 837, 855, 858, 859, 1129, 1190, 1194, 1200, 1201, 1359, 1422, 1423, 1424, 1450, 1600, 1860, 1862, 1863, 1871, 1894, 1899, 1905, 1908, 1913, 1927], "registr": [13, 45, 46, 70, 83, 1006, 1595, 1600, 1601, 1602, 1611, 1614, 1867, 1905], "minifi": [13, 17], "typic": [13, 15, 16, 29, 32, 38, 39, 41, 47, 48, 49, 51, 58, 59, 60, 63, 71, 84, 962, 964, 1106, 1114, 1190, 1210, 1213, 1356, 1382, 1422, 1593, 1602, 1664, 1665, 1790, 1791, 1792, 1794, 1795, 1857, 1858, 1860, 1863, 1869, 1883, 1885, 1886, 1897, 1898, 1899, 1901, 1904, 1906, 1908, 1913, 1921, 1929], "canon": [13, 16, 49, 51, 1860], "opset": [13, 1859, 1901, 1902, 1903], "significantli": [13, 41, 899, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1751, 1917], "smaller": [13, 38, 71, 497, 542, 962, 1602, 1691, 1706, 1796, 1886, 1899, 1905, 1929], "aot_autograd": 13, "fw_compil": 13, "bw_compil": 13, "box": [13, 15, 18, 20, 30, 41, 46, 59, 71, 1131, 1850, 1877, 1883, 1887], "make_boxed_func": 13, "my_backend": [13, 789], "model_opt": 13, "pretti": [13, 16, 21, 1190, 1659, 1756, 1860], "bytecod": [13, 14, 17, 21, 26, 27, 29, 38, 677, 1869, 1905], "print_tabular": [13, 21, 71], "co": [13, 19, 20, 22, 69, 202, 632, 633, 680, 928, 950, 1006, 1121, 1124, 1125, 1130, 1147, 1148, 1241, 1356, 1357, 1360, 1681, 1682, 1689, 1701, 1763, 1764, 1767, 1768, 1769, 1770, 1772, 1790, 1791, 1792, 1794, 1795, 1859, 1861, 1876, 1903, 1904, 1917, 1922, 1924], "sin": [13, 19, 20, 22, 27, 32, 68, 69, 529, 666, 667, 878, 950, 1006, 1121, 1123, 1124, 1125, 1127, 1130, 1148, 1241, 1291, 1701, 1764, 1770, 1859, 1861, 1876, 1883, 1903, 1917, 1918, 1922], "opcod": [13, 14, 21, 71, 1905], "placehold": [13, 14, 28, 71, 72, 77, 78, 79, 80, 81, 82, 831, 1384, 1886], "call_funct": [13, 14, 17, 21, 28, 29, 71, 83, 84], "0x7f1a894649a8": 13, "mockmodul": 13, "optimized_mod": 13, "abs_1": [13, 14], "0x7f8d259298a0": 13, "truediv": [13, 14, 71], "call_method": [13, 14, 21, 71], "sum_1": [13, 14, 71], "lt": [13, 14, 363, 395, 1216, 1859, 1860, 1861, 1876, 1903], "mul_1": 13, "nondeterminist": [13, 71, 313, 315, 321, 513, 515, 921, 1211, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1418, 1419, 1420, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1513, 1521, 1532, 1559, 1571, 1590, 1591, 1592, 1750, 1843], "offer": [13, 17, 41, 63, 66, 1602, 1843, 1859, 1886, 1892, 1905, 1917], "superior": 13, "real": [13, 15, 16, 20, 21, 22, 38, 47, 71, 683, 684, 685, 686, 687, 689, 695, 905, 918, 943, 952, 958, 1009, 1079, 1080, 1082, 1084, 1085, 1086, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1180, 1182, 1183, 1186, 1187, 1210, 1219, 1220, 1221, 1225, 1226, 1227, 1228, 1229, 1232, 1233, 1234, 1239, 1242, 1244, 1246, 1247, 1248, 1249, 1253, 1254, 1258, 1259, 1260, 1270, 1276, 1389, 1431, 1434, 1435, 1471, 1609, 1804, 1808, 1847, 1848, 1849, 1857, 1858, 1859, 1861, 1863, 1883, 1886, 1903, 1905, 1908, 1913, 1915, 1921, 1923, 1924, 1928], "optimize_for_infer": [13, 1194], "optimize_for_inference_compil": 13, "And": [13, 18, 20, 21, 67, 794, 821, 1042, 1043, 1119, 1190, 1211, 1287, 1292, 1345, 1422, 1883, 1888, 1889, 1900, 1901, 1908, 1927], "code_to_acceler": 13, "trt_compil": 13, "tensorrt": [13, 17, 20, 1908], "inductor_compil": 13, "tensor_match": 14, "function_match": 14, "recaptur": 14, "recompil": [14, 15, 21, 22, 24, 32, 71, 677, 1203, 1869, 1892], "dispatch_kei": [14, 1867], "ndim": [14, 1255, 1256, 1876, 1878, 1917, 1923], "log_level": [14, 17, 29, 1887], "info": [14, 15, 16, 17, 29, 41, 49, 52, 56, 677, 889, 966, 967, 969, 1220, 1231, 1233, 1234, 1238, 1251, 1279, 1303, 1304, 1658, 1858, 1861, 1869, 1887, 1888, 1889, 1901, 1905], "output_cod": [14, 29, 677, 1869], "spammi": [14, 1869], "printout": [14, 71, 1008, 1021], "__compiled_fn_0": 14, "eval_with_kei": 14, "0x7f9ca082f8a0": 14, "load_fast": [14, 21], "load_glob": 14, "load_method": 14, "6": [14, 17, 25, 29, 32, 35, 38, 39, 41, 47, 56, 71, 313, 315, 317, 321, 401, 402, 470, 486, 497, 511, 515, 557, 604, 682, 683, 688, 694, 738, 739, 740, 742, 743, 755, 758, 760, 762, 898, 899, 901, 902, 903, 921, 929, 934, 940, 943, 944, 948, 962, 975, 1022, 1026, 1040, 1041, 1042, 1046, 1047, 1058, 1061, 1062, 1079, 1087, 1092, 1093, 1097, 1098, 1100, 1102, 1103, 1106, 1113, 1143, 1153, 1155, 1156, 1179, 1200, 1211, 1215, 1226, 1242, 1246, 1247, 1248, 1255, 1256, 1260, 1262, 1291, 1295, 1320, 1321, 1322, 1335, 1346, 1349, 1354, 1357, 1365, 1366, 1375, 1376, 1377, 1379, 1380, 1418, 1419, 1423, 1431, 1439, 1442, 1443, 1444, 1445, 1446, 1447, 1448, 1465, 1466, 1468, 1473, 1479, 1488, 1518, 1525, 1526, 1558, 1560, 1567, 1593, 1637, 1638, 1640, 1642, 1648, 1649, 1650, 1662, 1676, 1696, 1697, 1700, 1707, 1708, 1714, 1715, 1718, 1724, 1734, 1735, 1739, 1743, 1756, 1777, 1781, 1785, 1788, 1790, 1791, 1796, 1807, 1809, 1810, 1811, 1818, 1823, 1824, 1825, 1826, 1827, 1829, 1832, 1834, 1838, 1843, 1851, 1852, 1858, 1859, 1860, 1863, 1864, 1870, 1878, 1881, 1883, 1888, 1889, 1894, 1899, 1901, 1913, 1914, 1917, 1918, 1920, 1923, 1924, 1928], "load_const": [14, 21], "12": [14, 25, 38, 39, 41, 63, 321, 515, 614, 683, 738, 739, 740, 742, 743, 940, 944, 1061, 1079, 1153, 1194, 1209, 1248, 1330, 1346, 1354, 1369, 1370, 1371, 1419, 1434, 1435, 1456, 1465, 1473, 1516, 1517, 1557, 1562, 1563, 1610, 1643, 1696, 1707, 1756, 1771, 1781, 1823, 1839, 1851, 1857, 1860, 1861, 1864, 1870, 1886, 1895, 1899, 1901, 1903, 1917, 1924], "binary_add": 14, "14": [14, 41, 321, 515, 943, 1006, 1007, 1046, 1061, 1153, 1242, 1248, 1316, 1346, 1419, 1707, 1714, 1781, 1823, 1824, 1829, 1851, 1860, 1864, 1901, 1903, 1917, 1921, 1922], "binary_true_divid": 14, "16": [14, 17, 29, 37, 41, 321, 614, 735, 736, 737, 738, 739, 740, 769, 1061, 1079, 1106, 1143, 1153, 1190, 1201, 1213, 1219, 1225, 1226, 1230, 1246, 1322, 1334, 1336, 1337, 1345, 1346, 1349, 1350, 1351, 1352, 1354, 1355, 1360, 1361, 1362, 1363, 1367, 1370, 1371, 1390, 1391, 1392, 1410, 1415, 1416, 1417, 1419, 1420, 1422, 1429, 1437, 1448, 1465, 1479, 1496, 1498, 1499, 1501, 1505, 1516, 1517, 1652, 1704, 1781, 1843, 1847, 1851, 1860, 1864, 1881, 1886, 1894, 1897, 1899, 1901, 1903, 1906, 1913, 1917, 1918, 1920, 1922, 1923], "store_fast": 14, "11": [14, 29, 32, 41, 321, 511, 940, 944, 1009, 1061, 1153, 1210, 1246, 1260, 1276, 1330, 1346, 1371, 1419, 1517, 1649, 1650, 1659, 1781, 1823, 1851, 1860, 1864, 1870, 1877, 1886, 1900, 1901, 1903, 1917, 1918], "18": [14, 41, 321, 444, 682, 1064, 1143, 1187, 1262, 1419, 1860, 1901, 1903, 1917], "20": [14, 16, 21, 41, 45, 47, 321, 682, 717, 725, 726, 731, 735, 736, 737, 738, 739, 740, 743, 753, 757, 758, 759, 760, 761, 762, 769, 1143, 1188, 1191, 1201, 1212, 1246, 1311, 1334, 1336, 1337, 1339, 1340, 1341, 1342, 1343, 1345, 1349, 1350, 1351, 1352, 1354, 1355, 1360, 1361, 1362, 1363, 1367, 1370, 1371, 1374, 1375, 1377, 1384, 1385, 1386, 1387, 1390, 1391, 1392, 1393, 1394, 1409, 1415, 1416, 1417, 1419, 1420, 1422, 1437, 1439, 1450, 1458, 1461, 1464, 1465, 1466, 1467, 1479, 1496, 1498, 1499, 1501, 1505, 1516, 1517, 1523, 1579, 1609, 1610, 1634, 1643, 1646, 1667, 1682, 1710, 1819, 1860, 1861, 1878, 1887, 1888, 1897, 1904, 1913, 1917], "22": [14, 41, 47, 321, 614, 1262, 1593, 1639, 1641, 1860, 1898, 1917], "24": [14, 39, 41, 47, 923, 1248, 1410, 1486, 1642, 1707, 1824, 1860, 1881, 1885, 1918], "26": [14, 29, 1245, 1682], "compare_op": 14, "28": [14, 23, 614, 743, 1046, 1829, 1901], "pop_jump_if_fals": 14, "38": [14, 1316], "30": [14, 22, 38, 41, 47, 49, 58, 444, 614, 717, 725, 726, 753, 761, 1143, 1212, 1343, 1345, 1349, 1409, 1473, 1479, 1496, 1505, 1593, 1685, 1687, 1693, 1710, 1819, 1888, 1901, 1904, 1913], "34": [14, 21, 29, 41], "binary_multipli": [14, 21], "36": [14, 21, 41, 321, 1106, 1143], "13": [14, 23, 29, 41, 872, 944, 1061, 1064, 1108, 1143, 1153, 1194, 1279, 1346, 1370, 1371, 1419, 1456, 1516, 1517, 1781, 1823, 1851, 1860, 1864, 1903, 1917], "42": [14, 38, 821, 928, 1311, 1763, 1886, 1894], "return_valu": [14, 49, 50, 56], "unpack_sequ": 14, "__resume_at_30_1": 14, "__resume_at_38_2": 14, "offset": [14, 21, 45, 49, 226, 227, 228, 229, 339, 518, 555, 743, 875, 1051, 1052, 1053, 1054, 1116, 1224, 1366, 1513, 1602, 1709, 1710, 1788, 1833, 1835, 1861, 1863], "__resume_at_": 14, "jump_absolut": 14, "resume_at": 14, "remaind": [14, 38, 488, 1111, 1143, 1859, 1861, 1903], "restart": [14, 39, 49, 57, 59, 61, 1681, 1682, 1875, 1922], "symbolic_shap": 15, "assumpt": [15, 17, 24, 29, 43, 55, 59, 905, 1345, 1376, 1883, 1887, 1891, 1913, 1914, 1917], "situat": [15, 16, 17, 20, 38, 47, 60, 71, 958, 1614, 1875, 1888, 1889, 1896, 1897, 1905, 1908, 1915, 1928], "insuffici": [15, 29, 1010], "batch": [15, 16, 17, 19, 23, 29, 39, 41, 47, 59, 61, 64, 65, 68, 69, 71, 580, 581, 582, 584, 585, 683, 699, 700, 701, 702, 703, 704, 732, 757, 776, 782, 904, 905, 906, 918, 930, 931, 938, 941, 942, 943, 950, 963, 1051, 1053, 1063, 1124, 1125, 1131, 1187, 1219, 1220, 1221, 1222, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1257, 1258, 1259, 1262, 1270, 1279, 1280, 1284, 1338, 1339, 1340, 1341, 1342, 1345, 1350, 1351, 1356, 1358, 1359, 1361, 1362, 1363, 1365, 1366, 1367, 1369, 1374, 1375, 1376, 1377, 1382, 1383, 1385, 1386, 1387, 1388, 1389, 1392, 1393, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1413, 1414, 1425, 1426, 1427, 1428, 1429, 1431, 1434, 1435, 1436, 1437, 1439, 1453, 1454, 1461, 1465, 1466, 1467, 1468, 1469, 1470, 1471, 1473, 1486, 1491, 1493, 1494, 1504, 1505, 1507, 1508, 1509, 1512, 1513, 1514, 1515, 1518, 1531, 1532, 1533, 1556, 1564, 1571, 1589, 1590, 1593, 1602, 1609, 1635, 1636, 1638, 1639, 1641, 1682, 1683, 1689, 1695, 1697, 1707, 1711, 1790, 1791, 1792, 1794, 1795, 1799, 1804, 1808, 1809, 1828, 1831, 1832, 1834, 1847, 1850, 1858, 1876, 1877, 1878, 1882, 1886, 1889, 1890, 1894, 1896, 1906, 1908, 1913, 1917, 1922, 1923], "vari": [15, 16, 17, 29, 816, 1453, 1635, 1765, 1873, 1897, 1904, 1908, 1909, 1917], "servic": [15, 50, 1887], "window": [15, 32, 38, 41, 71, 351, 553, 919, 928, 1147, 1148, 1187, 1209, 1335, 1336, 1337, 1370, 1371, 1390, 1391, 1415, 1416, 1417, 1418, 1419, 1420, 1488, 1516, 1517, 1545, 1546, 1547, 1712, 1713, 1804, 1858, 1861, 1873, 1886], "pad": [15, 19, 38, 39, 709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 732, 735, 736, 737, 738, 739, 740, 765, 766, 769, 770, 771, 776, 779, 780, 782, 950, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1187, 1335, 1336, 1337, 1345, 1347, 1348, 1349, 1350, 1351, 1352, 1353, 1354, 1355, 1365, 1366, 1369, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1418, 1419, 1420, 1425, 1426, 1428, 1443, 1444, 1445, 1446, 1447, 1448, 1468, 1469, 1473, 1477, 1478, 1479, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1512, 1513, 1515, 1521, 1532, 1545, 1546, 1547, 1548, 1549, 1550, 1589, 1590, 1636, 1638, 1639, 1641, 1712, 1713, 1804, 1858, 1859, 1861, 1878, 1890, 1901, 1903, 1908, 1922], "exhibit": [15, 29, 1659, 1901], "imag": [15, 17, 18, 29, 32, 38, 738, 739, 740, 858, 859, 952, 1328, 1332, 1333, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1369, 1370, 1371, 1386, 1394, 1429, 1434, 1435, 1456, 1473, 1475, 1476, 1486, 1497, 1498, 1500, 1501, 1515, 1516, 1521, 1532, 1589, 1590, 1732, 1858, 1859, 1861, 1878, 1891, 1903, 1906, 1921, 1922], "recognit": 15, "jag": 15, "chose": [15, 49, 1882], "whose": [15, 29, 41, 47, 63, 71, 541, 856, 892, 940, 957, 1051, 1063, 1068, 1116, 1134, 1143, 1146, 1152, 1190, 1206, 1214, 1260, 1276, 1278, 1323, 1422, 1602, 1650, 1701, 1759, 1825, 1863, 1883, 1888, 1891, 1905, 1917, 1922, 1924], "dimension": [15, 47, 511, 513, 877, 883, 884, 885, 929, 936, 948, 1051, 1053, 1054, 1063, 1079, 1080, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1097, 1098, 1100, 1102, 1104, 1105, 1116, 1143, 1152, 1153, 1154, 1222, 1227, 1228, 1229, 1230, 1255, 1260, 1276, 1284, 1291, 1330, 1347, 1348, 1349, 1358, 1359, 1365, 1366, 1394, 1412, 1429, 1443, 1444, 1445, 1446, 1447, 1448, 1455, 1457, 1461, 1477, 1478, 1479, 1504, 1556, 1559, 1591, 1592, 1609, 1648, 1714, 1790, 1791, 1792, 1793, 1794, 1795, 1804, 1819, 1822, 1823, 1829, 1863, 1878, 1881, 1884, 1891, 1897, 1917, 1919, 1920, 1923, 1925], "induct": 15, "pt2": [15, 16, 18], "integ": [15, 38, 41, 47, 58, 289, 444, 446, 448, 542, 557, 563, 682, 683, 684, 685, 686, 687, 763, 764, 782, 784, 862, 889, 918, 919, 928, 939, 957, 967, 969, 985, 991, 992, 1020, 1058, 1061, 1063, 1064, 1106, 1107, 1108, 1109, 1110, 1111, 1116, 1117, 1121, 1122, 1123, 1124, 1125, 1133, 1147, 1148, 1151, 1152, 1153, 1200, 1203, 1212, 1213, 1220, 1231, 1233, 1243, 1262, 1311, 1330, 1345, 1350, 1351, 1352, 1394, 1480, 1481, 1482, 1483, 1484, 1485, 1592, 1635, 1650, 1653, 1685, 1688, 1692, 1697, 1709, 1710, 1716, 1718, 1719, 1720, 1722, 1727, 1736, 1748, 1796, 1805, 1809, 1823, 1824, 1837, 1851, 1855, 1862, 1863, 1864, 1876, 1889, 1891, 1906, 1909, 1911, 1917, 1918, 1920, 1923, 1924, 1929], "opt": [15, 41, 45, 1201, 1679, 1680, 1686, 1690, 1692, 1860, 1891], "yolo": 15, "automat": [15, 16, 17, 20, 29, 32, 39, 41, 46, 58, 59, 71, 151, 586, 886, 888, 1000, 1009, 1152, 1199, 1205, 1291, 1468, 1571, 1603, 1726, 1756, 1857, 1858, 1862, 1863, 1871, 1872, 1876, 1877, 1883, 1884, 1886, 1888, 1894, 1896, 1901, 1905, 1906, 1908, 1909, 1913, 1922, 1923, 1925], "torch_log": [15, 677, 1869], "torchinductor": [15, 20, 26, 677, 1858, 1869], "written": [15, 20, 23, 28, 29, 41, 51, 68, 913, 1022, 1359, 1657, 1677, 1860, 1862, 1870, 1871, 1883, 1887, 1888, 1889, 1894, 1899, 1901, 1905, 1907, 1919, 1922], "hint": [15, 21, 964, 998, 1191, 1428, 1466, 1467, 1468, 1469, 1860, 1862, 1863, 1886], "consult": [15, 1905], "greatli": [15, 32, 71, 1886], "formula": [15, 47, 89, 765, 766, 886, 888, 919, 928, 1147, 1148, 1215, 1281, 1282, 1436, 1489, 1490, 1578, 1677, 1710, 1888, 1891, 1907, 1912], "flatten": [15, 39, 63, 71, 871, 872, 1052, 1152, 1246, 1259, 1473, 1649, 1656, 1660, 1708, 1724, 1729, 1734, 1839, 1840, 1841, 1861, 1876, 1877, 1881, 1901, 1903, 1910, 1921], "awai": [15, 39, 71, 1521, 1858, 1877, 1883, 1889], "bailout": [15, 1903], "express": [15, 17, 29, 30, 43, 64, 68, 69, 71, 319, 1188, 1191, 1804, 1864, 1871, 1878, 1883, 1888, 1928], "meta": [15, 16, 18, 20, 28, 63, 67, 71, 336, 1867, 1913, 1922, 1924], "workflow": [15, 16, 23, 24, 25, 33, 1857, 1888, 1908, 1909, 1925], "shapeenv": [15, 16], "attach": [15, 66, 70, 71, 140, 709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 730, 790, 835, 837, 861, 1593, 1857, 1860, 1862, 1876, 1883, 1888, 1908, 1914, 1926], "faketensormod": [15, 16], "knob": [15, 1886], "faithfulli": 15, "sympi": 15, "induc": [15, 897, 1521, 1559, 1881], "simplif": [15, 43], "s0": [15, 29], "occurr": [15, 63, 402, 1188, 1290, 1635, 1840, 1841], "reusabl": 15, "c10": [15, 58, 1893], "symfloat": [15, 1812, 1813, 1925], "symbool": [15, 1816, 1925], "plumb": 15, "symnodeimpl": 15, "csrc": [15, 1900], "python_symnod": 15, "init": [15, 41, 49, 51, 63, 1190, 1422, 1430, 1449, 1642, 1858, 1865, 1883, 1888, 1893, 1894], "_subclass": [15, 16], "fake_tensor": [15, 16], "_meta_registr": 15, "decomp": [15, 16], "primtorch": [15, 16, 20], "ref": [15, 21, 29, 1857], "visibl": [15, 18, 32, 41, 43, 55, 988, 1033, 1423, 1424, 1432, 1433], "simul": [15, 47, 796, 798, 1908, 1911], "counterpart": [15, 854, 861, 1259, 1602, 1863, 1871, 1925, 1926], "symnod": 15, "eras": [15, 71], "mix": [15, 26, 32, 39, 47, 63, 1009, 1602, 1858, 1883, 1885, 1908, 1917], "xla": [15, 1858], "far": [15, 59, 1199, 1521], "vice": [15, 71, 457, 600, 1115, 1116, 1414, 1883, 1911, 1919], "versa": [15, 71, 457, 600, 1115, 1116, 1414, 1883, 1911, 1919], "fairli": [15, 1906], "apparatu": 15, "traceabl": [15, 20, 71, 621, 814, 1860, 1908], "make_fx": [15, 29, 1120], "aka": [15, 41, 914, 1383, 1883, 1920], "aris": [15, 47, 71, 1883], "emerg": [15, 1900], "illeg": [15, 63, 1886], "enhanc": [15, 41, 63, 1602], "precomput": 15, "empty_strid": [15, 1859, 1861, 1865, 1903], "eagerli": [15, 995, 1001, 1886], "needlessli": [15, 1886], "nontrivi": [15, 41, 1886], "lazi": [15, 955, 1202, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1593, 1858], "constrain_rang": 15, "wherebi": 15, "trash": 16, "bad": [16, 71, 1875, 1901, 1905, 1908], "accur": [16, 22, 51, 966, 1143, 1265, 1364, 1714, 1829, 1886, 1914], "suppos": [16, 18, 41, 71, 1187, 1692, 1870, 1917], "val": [16, 21, 1006, 1196, 1861, 1863, 1881], "stuff": [16, 71], "probabl": [16, 17, 18, 24, 38, 155, 757, 920, 1151, 1267, 1312, 1330, 1334, 1338, 1345, 1358, 1360, 1361, 1362, 1363, 1367, 1374, 1376, 1392, 1428, 1429, 1437, 1493, 1504, 1505, 1506, 1507, 1508, 1509, 1514, 1523, 1533, 1556, 1571, 1707, 1875, 1888, 1900, 1901, 1918, 1922], "wouldn": [16, 1915], "alias": [16, 63, 892, 1120, 1131, 1532, 1850, 1862, 1863, 1867, 1888], "almost": [16, 1236, 1237, 1900], "subclass_zoo": 16, "subgraph": [16, 19, 29, 950, 1659, 1883, 1887, 1901, 1905, 1927], "possibli": [16, 38, 58, 63, 1190, 1205, 1232, 1237, 1422, 1602, 1860, 1867, 1898, 1905], "bunch": 16, "from_real_tensor": 16, "memo": [16, 1190, 1422], "fakeifi": 16, "alia": [16, 43, 47, 52, 92, 93, 112, 188, 189, 353, 406, 435, 436, 443, 538, 679, 863, 864, 865, 866, 867, 868, 869, 886, 946, 953, 954, 1049, 1056, 1059, 1070, 1071, 1072, 1074, 1075, 1101, 1136, 1144, 1145, 1157, 1158, 1159, 1168, 1188, 1190, 1216, 1217, 1224, 1240, 1244, 1247, 1275, 1285, 1286, 1296, 1313, 1315, 1325, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1422, 1532, 1605, 1635, 1651, 1694, 1699, 1702, 1737, 1760, 1775, 1778, 1780, 1806, 1810, 1811, 1830, 1836, 1854, 1859, 1863, 1888, 1903, 1918, 1919, 1923], "faketensor": 16, "__torch_dispatch__": 16, "dispatch_devic": 16, "lie": [16, 1455, 1457, 1577, 1787, 1918, 1922], "prone": [16, 1875, 1896], "ly": 16, "whatev": [16, 17, 60, 71, 447, 1602, 1747, 1831, 1863, 1889], "derefer": 16, "pointer": [16, 35, 140, 981, 1438, 1886, 1887, 1893, 1913, 1915], "segfault": [16, 1875, 1897], "backtrac": 16, "unexpect": [16, 17, 21, 41, 48, 71, 963, 1114, 1116, 1119, 1190, 1422, 1644, 1660, 1799, 1860, 1883, 1888, 1897], "reinterpret": [16, 47, 497], "magic": [16, 1861, 1864, 1925], "in_kernel_invocation_manag": 16, "underli": [16, 21, 41, 43, 45, 47, 49, 63, 68, 71, 98, 311, 326, 377, 400, 402, 472, 473, 474, 475, 482, 497, 518, 521, 554, 555, 556, 610, 745, 754, 875, 966, 1160, 1164, 1190, 1261, 1321, 1564, 1725, 1828, 1842, 1860, 1863, 1878, 1886, 1890, 1892, 1906, 1913, 1919, 1921], "unwrap": 16, "promot": [16, 63, 682, 923, 926, 935, 1006, 1058, 1106, 1108, 1109, 1110, 1111, 1311, 1361, 1362, 1363, 1367, 1503, 1706, 1726, 1727, 1733, 1748, 1805, 1859, 1863, 1920, 1924], "test_fake_tensor": 16, "fake_mod": 16, "fake_x": 16, "fake_i": 16, "fake_z": 16, "pre": [16, 24, 29, 33, 41, 45, 63, 71, 904, 911, 1190, 1422, 1597, 1599, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1657, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1680, 1686, 1857, 1860, 1863, 1871, 1883, 1885, 1894, 1901, 1906, 1923], "aotautograd": [16, 17, 18, 20, 29, 67, 677, 1869, 1887, 1902], "_guard": 16, "detect_fake_mod": 16, "fake_arg": 16, "lifecycl": [16, 21], "proxy_tensor": [16, 29, 1120], "maybe_disable_fake_tensor_mod": 16, "nich": 16, "faketensorprop": 16, "fake_tensor_prop": 16, "real_input": [16, 1886], "popul": [16, 28, 41, 47, 56, 63, 70, 71, 335, 493, 501, 502, 1290, 1318, 1886], "propagate_dont_convert_input": 16, "fake_input": 16, "real_tensor": 16, "t_": [16, 1291, 1371, 1517, 1681, 1682, 1861, 1917], "opportun": [16, 17, 1220, 1860, 1914], "conserv": [16, 1867, 1870, 1886], "annoi": 16, "practic": [16, 17, 38, 41, 47, 63, 1858, 1860, 1870, 1875, 1877, 1883, 1888, 1891, 1894, 1899, 1905, 1913], "feed": [16, 71, 1860, 1890, 1894, 1926], "somehow": 16, "fakecopymod": 16, "gave": 16, "fakeif": 16, "face": [16, 1888, 1905, 1922], "invalid": [16, 21, 51, 56, 1190, 1312, 1422, 1882, 1883, 1901, 1905, 1906], "old": [16, 21, 41, 48, 71, 851, 1114, 1362, 1654, 1691, 1739, 1856, 1858, 1860, 1883, 1886, 1888, 1900, 1908, 1922], "tension": 16, "seriou": [16, 1875, 1886], "analys": 16, "occasion": [16, 1886, 1917], "mistak": [16, 1863, 1890], "redispatch": 16, "lift": [16, 69, 1131, 1850, 1877, 1903], "recogn": [16, 38, 1863, 1913, 1917], "notimpl": [16, 1863, 1864, 1888], "hopefulli": 16, "desugar": [16, 1863], "plain": [16, 32, 1339, 1423, 1432, 1609, 1792, 1888, 1917], "infinit": [16, 38, 1182, 1262, 1338, 1345, 1505, 1701, 1888, 1897, 1913], "fastpath": [16, 1428], "certain": [16, 17, 21, 23, 29, 38, 39, 41, 55, 56, 68, 70, 71, 683, 686, 732, 918, 930, 988, 1051, 1165, 1187, 1190, 1197, 1261, 1284, 1294, 1350, 1351, 1352, 1353, 1354, 1355, 1375, 1393, 1409, 1422, 1428, 1473, 1522, 1533, 1535, 1648, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1863, 1870, 1877, 1883, 1884, 1886, 1888, 1893, 1894, 1897, 1901, 1906, 1907, 1913, 1914, 1917], "custom_op": [16, 1901], "impl_abstract": 16, "hardcod": 16, "nor": [16, 38, 41, 49, 63, 792, 896, 1225, 1226, 1253, 1428, 1469, 1602, 1649, 1706, 1808, 1888, 1901], "sensit": [16, 39, 1383, 1453, 1901, 1905, 1914], "carefulli": [16, 18, 67, 70, 1889, 1905], "leaf": [16, 55, 151, 223, 335, 447, 501, 502, 788, 835, 837, 876, 890, 1129, 1659, 1822, 1878, 1882, 1883, 1901, 1927], "ness": [16, 59], "bulk": [16, 38], "metaconvert": 16, "pointwis": [16, 19, 20, 23, 47, 950, 1124, 1125, 1267, 1268, 1388, 1876, 1884], "impli": [16, 39, 58, 63, 1875, 1883, 1901, 1906, 1911, 1913], "ti": [16, 1119, 1644, 1736], "die": 16, "unback": 16, "symint": [16, 1812, 1813, 1814, 1815, 1816, 1859, 1925], "memoiz": [16, 47], "colab": [16, 1867, 1905], "saroufim": 17, "evalfram": 17, "min": [17, 38, 41, 51, 58, 71, 117, 186, 187, 188, 189, 300, 692, 693, 694, 755, 767, 768, 777, 799, 816, 817, 818, 819, 822, 872, 945, 946, 1006, 1043, 1077, 1078, 1150, 1221, 1235, 1236, 1242, 1246, 1248, 1253, 1259, 1279, 1312, 1344, 1381, 1408, 1410, 1430, 1442, 1449, 1495, 1532, 1536, 1565, 1567, 1572, 1590, 1676, 1681, 1682, 1691, 1695, 1697, 1707, 1808, 1832, 1833, 1834, 1835, 1859, 1861, 1873, 1876, 1901, 1903, 1908, 1911, 1913, 1929], "partit": [17, 28, 45, 46, 1330, 1829, 1901, 1903, 1906, 1914, 1915], "usercod": 17, "ddp": [17, 41, 42, 43, 45, 63, 1461, 1602, 1858, 1886, 1887, 1913], "unrol": [17, 1862, 1863, 1901], "fsdp": [17, 43, 46, 63, 1858], "delai": [17, 1602, 1915], "outlin": [17, 42, 1906, 1914], "bucket": [17, 29, 39, 45, 1330, 1602, 1861, 1887, 1903], "broadcast": [17, 41, 45, 47, 63, 68, 98, 197, 398, 400, 401, 402, 511, 513, 515, 563, 682, 683, 684, 685, 686, 687, 688, 694, 732, 881, 918, 923, 926, 930, 931, 932, 933, 957, 977, 1006, 1057, 1058, 1063, 1068, 1108, 1109, 1110, 1111, 1132, 1134, 1146, 1156, 1214, 1215, 1222, 1235, 1239, 1244, 1245, 1247, 1250, 1258, 1278, 1283, 1284, 1294, 1311, 1314, 1323, 1326, 1339, 1357, 1376, 1428, 1494, 1503, 1565, 1602, 1660, 1696, 1704, 1727, 1729, 1805, 1824, 1829, 1853, 1858, 1859, 1863, 1876, 1877, 1878, 1887, 1901, 1903, 1918], "fraction": [17, 38, 47, 1033, 1106, 1112, 1307, 1353, 1354, 1355, 1370, 1371, 1428, 1469, 1516, 1517, 1619, 1620, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1708, 1881], "rob": 17, "fusion": [17, 19, 20, 28, 29, 71, 789, 811, 857, 858, 950, 1192, 1198, 1203, 1204, 1205, 1206, 1871, 1894, 1908], "diminish": 17, "vast": 17, "250k": 17, "aitempl": 17, "fuse": [17, 19, 20, 28, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 789, 790, 799, 801, 802, 803, 811, 844, 856, 857, 950, 1203, 1204, 1571, 1664, 1665, 1871, 1876, 1901, 1904, 1908, 1909, 1910, 1911], "mobil": [17, 1871, 1908], "ran": [17, 24, 29, 35, 63], "fine": [17, 32, 41, 43, 45, 48, 855, 858, 1114, 1205, 1571, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1857, 1858, 1875, 1883, 1886, 1888, 1901, 1905, 1906, 1908], "succeed": [17, 49, 58, 73, 75, 1279], "aot_eag": [17, 29], "warn": [17, 18, 21, 22, 29, 32, 35, 39, 41, 45, 63, 677, 898, 904, 940, 975, 1022, 1026, 1037, 1040, 1041, 1131, 1171, 1205, 1247, 1291, 1428, 1466, 1467, 1468, 1469, 1611, 1614, 1750, 1758, 1843, 1850, 1857, 1869, 1873, 1884, 1888, 1903, 1905, 1912], "torchdynamo_debug_funct": [17, 29], "desired_function_nam": 17, "replay_record_en": [17, 29], "hundr": [17, 29, 1882, 1893], "thousand": [17, 29], "highli": [17, 58, 1330, 1602, 1857, 1895, 1901, 1917, 1924], "tini": [17, 23, 1923, 1924, 1929], "torchdynamo_repro_aft": [17, 29], "aot": [17, 18, 29, 677, 1869], "your_model": 17, "quickest": 17, "repro": [17, 29, 1659], "torchdynamo_repro_dir": 17, "nvfuser": [17, 20, 29, 1860], "leverag": [17, 19, 950, 1913], "compile_tim": [17, 29], "torch_compile_debug": [17, 20], "_inductor": [17, 19, 22, 29, 950], "diagram": [17, 29, 49, 58, 1190, 1422, 1908, 1915], "cache_size_limit": [17, 21, 29], "troubl": [17, 18, 29], "compileprofil": [17, 29], "profiler_model": [17, 29], "upcom": [17, 29, 41, 63, 1882], "tune": [17, 29, 39, 41, 45, 1020, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1883, 1886, 1895, 1908], "traffic": 17, "frozen_toy_exampl": 17, "vertic": [17, 1851, 1852, 1904, 1906, 1922], "cosin": [17, 680, 681, 959, 960, 1356, 1357, 1503, 1681, 1682, 1689, 1767, 1904], "horizont": [17, 948, 1153, 1155, 1904, 1906], "simplest": [17, 21, 22, 38, 43, 49, 71, 855, 1335, 1336, 1337, 1350, 1351, 1352, 1415, 1416, 1417, 1612, 1887, 1888, 1894, 1908, 1915, 1917], "schedul": [17, 43, 49, 51, 57, 63, 70, 677, 1675, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1869, 1887, 1893, 1907], "physic": [17, 59, 1081, 1099, 1864, 1885, 1917], "principl": [17, 1886], "stream": [17, 38, 41, 49, 56, 63, 70, 151, 485, 890, 904, 964, 965, 966, 967, 970, 971, 972, 980, 983, 984, 998, 1004, 1036, 1039, 1303, 1304, 1309, 1657, 1729, 1858, 1861, 1863, 1913], "multiprocessor": 17, "tile": [17, 491, 1861, 1903], "some_fun": [17, 29], "insurmount": [17, 29], "invis": [17, 29, 1886], "introduc": [17, 22, 24, 29, 35, 47, 68, 757, 1262, 1374, 1392, 1437, 1532, 1734, 1857, 1863, 1884, 1887, 1895, 1901, 1905, 1906, 1907, 1913, 1923], "maxim": [17, 29, 871, 1287, 1418, 1419, 1420, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1675, 1676, 1677, 1678, 1917], "explain": [17, 29, 33, 41, 1678, 1857, 1863, 1882, 1886, 1889], "aggreg": [17, 29, 39, 41, 43, 51, 63, 1366, 1513, 1602, 1625, 1873, 1906], "woo": [17, 29], "out_guard": [17, 29], "ops_per_graph": [17, 29], "builtinvari": [17, 29], "constantvari": [17, 21, 29], "t2": [17, 29, 48, 684, 685, 877, 1114, 1143, 1602, 1913, 1914], "generic_jump": [17, 29], "17": [17, 29, 32, 41, 682, 1187, 1242, 1419, 1781, 1860, 1901, 1903, 1917], "throw": [17, 20, 29, 41, 42, 46, 63, 70, 71, 191, 323, 328, 542, 611, 1175, 1190, 1230, 1279, 1422, 1602, 1604, 1605, 1638, 1649, 1703, 1843, 1878, 1883, 1898, 1913, 1923], "fullgraph": [17, 19, 29, 950], "went": [17, 41, 71], "torchdynamo_dynamic_shap": 17, "cv": 17, "nlp": [17, 39, 1385, 1386, 1387, 1394], "client": [17, 41, 45, 58, 1020, 1905], "app": 17, "unnecessarili": 17, "cold": [17, 25], "metric": [17, 25, 44, 1012, 1014, 1020, 1691, 1873, 1894, 1907, 1922], "visibli": 17, "torchdynamo_repro_level": [17, 29], "bisect": [17, 29], "codegen": [17, 23, 29, 71], "dramat": [17, 29], "impact": [17, 24, 29, 39, 41, 1020, 1751, 1871, 1873, 1883, 1908, 1921], "fallback_random": [17, 19, 29, 950], "alpha": [17, 47, 98, 99, 100, 101, 106, 107, 108, 109, 110, 111, 152, 153, 312, 313, 551, 558, 559, 560, 561, 682, 683, 686, 687, 688, 741, 767, 772, 918, 1006, 1007, 1147, 1161, 1334, 1344, 1364, 1410, 1449, 1487, 1495, 1510, 1511, 1521, 1539, 1572, 1661, 1675, 1768, 1769, 1782, 1786, 1800, 1805, 1806, 1859, 1861, 1883, 1888, 1901, 1904], "root": [17, 41, 43, 51, 58, 59, 63, 71, 790, 1128, 1227, 1228, 1675, 1738, 1797, 1871, 1883, 1905, 1913, 1914, 1917], "allevi": [17, 1906], "cudagraph": [17, 19, 20, 23, 25, 950, 998, 1858, 1886], "amen": 18, "portion": [18, 29, 63, 1112, 1359, 1453, 1561, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1909], "usecas": 18, "excel": [18, 71], "unblock": 18, "friendli": 18, "disallow": [18, 71, 1905, 1913, 1920], "nnthi": 18, "suitabl": [18, 38, 47, 934, 1209, 1678, 1743, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1897, 1907, 1909, 1922], "fbgemm": [18, 739, 740, 753, 761, 830, 852, 853, 856, 858, 859, 1908, 1909], "black": 18, "nnnote": 18, "screen": 18, "deploy": [18, 49, 58, 1858], "tl": [18, 20], "dr": 18, "intercept": [18, 63, 71], "a_fn": 18, "b_fn": 18, "aa_fn": 18, "ab_fn": 18, "green": [18, 1862, 1863], "color": [18, 1387, 1862, 1863, 1922], "white": 18, "offend": [18, 1857], "syntax": [18, 1190, 1860, 1863, 1905], "style": [18, 43, 46, 48, 71, 874, 1058, 1114, 1648, 1860, 1862, 1863, 1901, 1905, 1922], "miss": [18, 21, 56, 63, 686, 1119, 1190, 1284, 1294, 1356, 1385, 1386, 1387, 1422, 1538, 1644, 1900, 1901, 1902, 1917], "incorrectli": [18, 35, 63, 967, 1108], "cautiou": 18, "switch": [18, 30, 38, 66, 70, 71, 1232, 1233, 1234, 1362, 1521, 1559, 1606, 1739, 1843, 1875, 1883, 1886, 1894, 1904], "safeti": [18, 49, 71, 1860, 1863, 1877], "bypass": [18, 1063, 1867, 1878, 1886], "sound": [18, 71, 1450, 1867, 1922], "inlin": [18, 32, 70, 1006, 1190, 1194, 1205, 1885], "begin": [18, 29, 35, 38, 39, 41, 42, 50, 58, 63, 71, 494, 757, 781, 817, 818, 862, 919, 957, 964, 1012, 1014, 1083, 1143, 1149, 1210, 1245, 1257, 1337, 1338, 1339, 1356, 1358, 1364, 1374, 1375, 1378, 1379, 1380, 1381, 1382, 1383, 1389, 1392, 1393, 1408, 1413, 1416, 1417, 1429, 1430, 1437, 1440, 1453, 1459, 1464, 1471, 1504, 1525, 1526, 1602, 1609, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1681, 1683, 1689, 1756, 1759, 1762, 1804, 1829, 1840, 1853, 1863, 1882, 1883, 1886, 1888, 1891, 1893, 1898, 1901, 1904, 1911, 1918], "deprec": [18, 41, 49, 58, 59, 63, 67, 406, 511, 554, 600, 782, 783, 784, 790, 823, 904, 905, 940, 941, 1013, 1017, 1136, 1190, 1244, 1247, 1279, 1280, 1338, 1339, 1356, 1358, 1381, 1382, 1388, 1389, 1413, 1414, 1422, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1475, 1476, 1493, 1494, 1504, 1533, 1556, 1564, 1590, 1591, 1592, 1594, 1602, 1643, 1644, 1649, 1707, 1723, 1804, 1808, 1831, 1858, 1860, 1865, 1875, 1884, 1907, 1911, 1919, 1923, 1924], "finer": [18, 46], "wishlist": 18, "cc": [18, 32, 41, 1886], "skipfiles_inline_module_allowlist": 18, "breadcrumb": 18, "forgot": 18, "autotun": [19, 22, 23, 950], "list_mode_opt": [19, 22, 950], "notabl": [19, 950, 1863], "epilogue_fus": [19, 950], "templat": [19, 950, 1006, 1007, 1904], "max_autotun": [19, 950], "shape_pad": [19, 950], "graph_diagram": [19, 950], "pictur": [19, 950], "list_opt": [19, 22, 950], "checkout": [20, 1901], "new_fn": 20, "input_tensor": [20, 41], "10000": [20, 35, 39, 691, 1689, 1736, 1890, 1894, 1917, 1922], "Its": [20, 41, 71, 962, 978, 1190, 1237, 1255, 1256, 1281, 1422, 1649, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1671, 1674, 1675, 1676, 1677, 1678, 1847, 1863, 1887], "famou": 20, "suboptim": [20, 39], "crucial": [20, 21, 22, 23, 33, 1867], "bottleneck": [20, 39, 1858, 1894], "bandwidth": [20, 23, 39, 41, 57, 59, 1908, 1913], "crunch": 20, "elimin": [20, 28, 41, 71, 607, 1840, 1841, 1898], "trig": 20, "size_hint": 20, "16384": [20, 1886], "filenam": [20, 32, 38, 71, 1189, 1197, 1200, 1857, 1861, 1872, 1883, 1905, 1919, 1922], "__file__": [20, 1857, 1900, 1905], "fp32": [20, 63, 778, 791, 814, 1048, 1602, 1886, 1897, 1908, 1909, 1911], "i32": 20, "instance_descriptor": 20, "divisible_by_16": 20, "equal_to_1": 20, "in_ptr0": 20, "out_ptr0": 20, "xnumel": 20, "xblock": 20, "constexpr": 20, "xoffset": 20, "program_id": 20, "xindex": 20, "reshap": [20, 33, 41, 47, 496, 497, 511, 541, 614, 689, 948, 1046, 1061, 1062, 1102, 1153, 1210, 1242, 1246, 1255, 1256, 1259, 1322, 1369, 1443, 1444, 1445, 1446, 1447, 1473, 1610, 1643, 1649, 1788, 1789, 1796, 1823, 1824, 1829, 1851, 1852, 1859, 1861, 1870, 1877, 1878, 1901, 1903, 1910, 1921, 1922], "xmask": 20, "x0": [20, 47], "tmp0": 20, "tmp1": 20, "tmp2": 20, "int32": [20, 192, 209, 313, 321, 325, 446, 614, 934, 1065, 1077, 1078, 1113, 1115, 1116, 1220, 1231, 1232, 1233, 1251, 1279, 1345, 1706, 1743, 1908, 1917, 1919, 1920, 1923, 1929], "temporari": [20, 32, 71, 820, 823, 1603, 1883, 1890], "held": [20, 70, 964, 988, 1016, 1300, 1882], "resnet50": [20, 1857, 1922], "hub": [20, 1858, 1872], "v0": 20, "resnet18": [20, 66, 71, 1857, 1860, 1862, 1872, 1905], "opt_model": 20, "64": [20, 66, 67, 69, 1124, 1125, 1129, 1327, 1328, 1329, 1331, 1332, 1333, 1339, 1450, 1571, 1744, 1878, 1900, 1901, 1908, 1912, 1917, 1920, 1922, 1923], "inspir": [20, 63, 1667, 1888], "frequent": [20, 22, 30, 43, 1330, 1858, 1897, 1899], "timm": [20, 22, 25], "download": [20, 1872, 1900, 1922], "huggingfac": [20, 22, 25], "berttoken": 20, "bertmodel": 20, "past": [20, 23, 25, 41, 71, 975, 1022, 1026, 1040, 1041, 1602, 1890], "bert": [20, 1468], "uncas": 20, "token": [20, 58, 964, 998, 999, 1857, 1864], "from_pretrain": [20, 1365, 1366], "me": 20, "encoded_input": 20, "return_tensor": 20, "pt": [20, 30, 39, 1195, 1197, 1200, 1207, 1261, 1739, 1860, 1894, 1899, 1905], "trigonometri": 20, "skim": 20, "create_model": 20, "resnext101_32x8d": 20, "7": [20, 25, 32, 38, 39, 41, 47, 71, 260, 313, 315, 317, 321, 401, 402, 470, 511, 557, 604, 614, 682, 694, 742, 743, 901, 903, 926, 929, 934, 940, 944, 948, 1046, 1058, 1060, 1061, 1064, 1079, 1102, 1103, 1106, 1109, 1113, 1143, 1153, 1167, 1211, 1215, 1225, 1230, 1232, 1233, 1236, 1237, 1241, 1242, 1246, 1253, 1320, 1321, 1322, 1328, 1329, 1332, 1333, 1335, 1346, 1365, 1410, 1418, 1419, 1443, 1444, 1445, 1446, 1447, 1473, 1488, 1559, 1627, 1632, 1642, 1649, 1667, 1714, 1718, 1724, 1734, 1735, 1736, 1743, 1756, 1759, 1761, 1772, 1773, 1781, 1788, 1790, 1791, 1796, 1808, 1810, 1811, 1818, 1823, 1824, 1827, 1829, 1838, 1847, 1851, 1860, 1864, 1870, 1877, 1878, 1884, 1886, 1888, 1897, 1899, 1901, 1903, 1908, 1917, 1920, 1921, 1922, 1923, 1924], "highest": [20, 677, 1330, 1718, 1719, 1751, 1909, 1924], "aot_ts_nvfus": 20, "nvprims_nvfus": 20, "onnxrt": 20, "ipex": 20, "tvm": 20, "apach": 20, "symbolic_trac": [20, 71], "smoother": [20, 1857, 1870], "transit": [20, 21, 1190, 1291, 1422, 1804, 1858, 1860], "ux": [21, 64, 69], "perspect": [21, 1887, 1897, 1914], "fn_foo": 21, "grab": 21, "dig": 21, "hole": 21, "perf": [21, 23, 32, 1908], "neutral": 21, "referenc": [21, 71, 967, 1190, 1422, 1831, 1862, 1883, 1901, 1913], "previous": [21, 24, 58, 63, 64, 67, 68, 69, 71, 222, 695, 789, 790, 1131, 1197, 1802, 1803, 1845, 1846, 1850, 1860, 1884, 1886, 1894, 1905, 1906, 1912, 1913, 1918], "translat": [21, 41, 86, 87, 1143, 1883, 1915], "check_fn": 21, "thrown": [21, 41, 46, 63, 70, 614, 875, 877, 1020, 1061, 1153, 1190, 1220, 1229, 1231, 1233, 1236, 1237, 1248, 1422, 1606, 1851, 1905], "_pyinterpreterstate_setevalframefunc": 21, "convert_fram": [21, 29], "convert_frame_assert": 21, "gloss": 21, "proxi": [21, 41, 43, 1908], "one_graph": 21, "_convert_frame_assert": 21, "frametyp": 21, "cache_s": [21, 47], "f_code": 21, "unsupport": [21, 24, 68, 83, 1860, 1864, 1877, 1902, 1913, 1917], "drop": [21, 38, 67, 69, 71, 1009, 1195, 1248, 1253, 1334, 1644, 1804, 1860, 1877, 1896], "needless": 21, "evict": 21, "alongsid": [21, 32, 1190, 1422], "transform_code_object": 21, "output_instruct": 21, "rememb": [21, 1890, 1896], "guardedcod": 21, "symbolic_loc": 21, "f_local": 21, "travers": [21, 63, 833, 1602, 1887, 1888, 1914, 1926, 1927], "ordereddict": [21, 1190, 1422, 1423, 1432, 1450, 1593, 1625, 1861, 1894, 1899, 1924], "k": [21, 23, 29, 38, 41, 43, 47, 59, 71, 286, 354, 504, 511, 513, 515, 587, 614, 757, 943, 1050, 1063, 1119, 1132, 1152, 1211, 1219, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1234, 1235, 1236, 1239, 1241, 1248, 1250, 1252, 1253, 1262, 1280, 1284, 1335, 1337, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1370, 1371, 1374, 1375, 1392, 1393, 1407, 1409, 1410, 1415, 1417, 1428, 1429, 1437, 1439, 1504, 1516, 1517, 1539, 1556, 1571, 1609, 1695, 1697, 1707, 1735, 1785, 1786, 1787, 1788, 1790, 1791, 1792, 1794, 1795, 1804, 1826, 1831, 1859, 1861, 1862, 1881, 1886, 1888, 1900, 1917, 1918, 1920], "variablebuild": 21, "localsourc": 21, "_wrap": 21, "construct": [21, 32, 33, 38, 41, 43, 45, 46, 47, 58, 63, 65, 67, 68, 71, 151, 447, 789, 790, 821, 875, 876, 890, 904, 952, 1050, 1066, 1131, 1152, 1190, 1201, 1205, 1206, 1213, 1220, 1260, 1261, 1276, 1291, 1365, 1366, 1422, 1512, 1593, 1602, 1604, 1605, 1635, 1642, 1656, 1697, 1701, 1748, 1783, 1790, 1791, 1792, 1793, 1794, 1795, 1809, 1822, 1825, 1850, 1858, 1860, 1873, 1886, 1887, 1894, 1896, 1899, 1905, 1908, 1913, 1915, 1920, 1922, 1923, 1924], "variabletrack": 21, "make_guard": 21, "outputgraph": [21, 71], "mention": [21, 23, 29, 41, 63, 1857, 1862, 1863, 1877, 1883, 1886, 1894, 1901, 1917, 1921], "recal": [21, 1339, 1888, 1922], "heart": [21, 38], "pump": 21, "cool": 21, "get_instruct": 21, "124": 21, "opnam": 21, "argval": 21, "starts_lin": 21, "is_jump_target": 21, "littl": [21, 41, 1888, 1915], "hasattr": [21, 71, 1861, 1888, 1908], "inst": 21, "unimpl": 21, "getattr": [21, 71, 1861, 1888], "inde": [21, 24, 48, 1860, 1870, 1905, 1915], "onto": [21, 28, 41, 63, 71, 1025, 1197, 1200, 1261, 1614, 1857, 1875, 1886, 1889, 1890, 1894, 1907], "dozen": 21, "symbolic_convert": [21, 29], "spoken": 21, "quiet": 21, "closer": [21, 23, 1143, 1471, 1708, 1888, 1894], "mind": [21, 22, 1235, 1253, 1365, 1883, 1889, 1891], "replace_guard": 21, "add_guard": 21, "visit": [21, 23, 61, 1901], "act": [21, 43, 47, 49, 56, 68, 855, 1339, 1423, 1424, 1433, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1626, 1628, 1629, 1630, 1631, 1632, 1843, 1886, 1894, 1898, 1904], "behalf": 21, "python_typ": 21, "as_proxi": 21, "as_python_proxi": 21, "bookkeep": 21, "came": 21, "somewher": [21, 1877, 1893], "flesh": 21, "notimplementederror": [21, 47, 1905], "relianc": 21, "fulfil": [21, 1883, 1889, 1905], "build_tupl": 21, "gist": [21, 23, 67, 790, 1891], "notion": [21, 38, 905, 1340, 1341, 1342, 1385, 1386, 1387, 1461], "popn": 21, "tuplevari": 21, "pydoc": 21, "tensorvari": 21, "instructiontranslatorbas": 21, "pop": [21, 68, 1024, 1423, 1432, 1903, 1906, 1907], "dataclass": [21, 28, 43], "ctor": 21, "guardsourc": 21, "create_fn": 21, "kind": [21, 41, 52, 71, 677, 1209, 1603, 1659, 1706, 1771, 1857, 1867, 1888, 1896, 1901, 1905, 1908, 1918, 1920], "guard_sourc": 21, "elif": [21, 28, 71, 1196, 1388, 1656, 1862, 1863, 1892], "istyp": 21, "guardbuild": 21, "equals_match": 21, "rangevari": 21, "appar": 21, "checkfunctionmanag": 21, "compile_check_fn": 21, "cacheentri": 21, "create_cache_entri": 21, "pyobject": 21, "guarded_cod": 21, "malloc": [21, 63], "sizeof": [21, 1919], "debug_null_check": 21, "pyobject_getattrstr": 21, "null_check": 21, "pycodeobject": 21, "compos": [21, 24, 47, 67, 71, 735, 736, 737, 738, 739, 740, 763, 764, 769, 770, 771, 779, 780, 941, 943, 1121, 1123, 1124, 1125, 1131, 1190, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1370, 1371, 1390, 1391, 1410, 1415, 1416, 1417, 1422, 1470, 1475, 1476, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1496, 1497, 1498, 1499, 1500, 1501, 1516, 1517, 1539, 1542, 1543, 1545, 1546, 1547, 1712, 1713, 1850, 1858, 1859, 1860, 1863, 1876, 1888, 1889, 1894, 1901, 1905, 1922], "sort_kei": 21, "guard_nn_modul": 21, "is_nn_modul": 21, "local_build": 21, "global_build": 21, "___guarded_cod": 21, "___check_type_id": 21, "94367738391392": 21, "___check_tensor": 21, "id": [21, 25, 29, 35, 38, 41, 45, 49, 57, 58, 59, 63, 71, 771, 821, 964, 999, 1461, 1547, 1586, 1602, 1659, 1863, 1893, 1901, 1903, 1905, 1912, 1913, 1914, 1919], "deeper": [21, 26, 1858, 1894, 1905], "dive": [21, 23, 26, 1858, 1887, 1891, 1905], "_eval_fram": 21, "anew": 21, "massiv": 21, "role": [21, 43, 49, 50, 58, 59], "weak": 21, "moduleinvalid": 21, "2x": [22, 23, 1922], "compress": [22, 25, 39, 63, 209, 584, 585, 1085, 1086, 1095, 1096, 1602, 1790, 1791, 1792, 1794, 1795, 1828, 1858], "varieti": [22, 1886, 1914], "announc": [22, 58], "compiled_fn": 22, "set_float32_matmul_precis": [22, 1139], "simpler": [22, 69, 1131, 1850, 1860, 1883, 1888, 1891, 1894], "bench_al": 22, "IF": 22, "odd": [22, 47, 1084, 1085, 1086, 1094, 1095, 1096, 1496, 1497, 1498], "quirk": 22, "ask": [22, 41, 67, 68, 1857, 1858, 1889, 1891], "overview": [22, 33, 41, 55, 1602, 1858, 1870, 1875, 1883, 1891, 1894, 1906, 1908, 1913], "nnmodul": 22, "torchinductor_unique_kernel_nam": 23, "triton_": 23, "envvar": 23, "meaning": [23, 49, 51, 52, 1020, 1886], "triton_poi_fused_cat_155": 23, "categori": [23, 24, 47, 51, 1312, 1863, 1865, 1901, 1904, 1907, 1909, 1920], "poi": 23, "torchinductor_benchmark_kernel": 23, "har": 23, "torchinductor_max_autotun": 23, "hope": [23, 1901], "mixnet_l": 23, "timm_model": 23, "amp": [23, 25, 29, 1009, 1858, 1882], "dashboard": [23, 26, 1858], "torchinductor_shunt": 23, "qz": 23, "cqz7hvhood7y3psp7fy6msjxsxyli7qiwiybizdwtjw6ffyq5wwd": 23, "shunting314": 23, "c2a4d8a28b00fcb5586d0e9d9bf77f9f": 23, "48efc83b12ec3ead950052e4a0220b10": 23, "p": [23, 39, 43, 47, 63, 71, 155, 234, 286, 424, 425, 452, 489, 490, 605, 683, 686, 918, 920, 930, 938, 1057, 1210, 1221, 1227, 1228, 1236, 1237, 1279, 1281, 1284, 1294, 1315, 1334, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1388, 1390, 1391, 1427, 1431, 1433, 1470, 1471, 1487, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1542, 1543, 1553, 1557, 1560, 1561, 1587, 1606, 1612, 1614, 1620, 1629, 1649, 1677, 1728, 1785, 1859, 1861, 1862, 1882, 1883, 1886, 1890, 1891, 1896, 1907, 1917, 1918], "8243734a38b5733ea78479209c0ae893": 23, "chrome": [23, 913, 1907], "compiled_module_profil": 23, "json": [23, 51, 56, 60, 1893, 1907], "browser": 23, "ui": [23, 25, 1891, 1922], "zoom": 23, "percent": [23, 1022, 1041], "regard": [23, 41, 1353, 1354, 1355, 1365, 1366, 1512, 1513, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1860, 1915, 1917], "102": [23, 1330], "88": 23, "distort": 23, "densenet121": 23, "69": 23, "58": [23, 41], "85": [23, 71, 1425, 1689], "89": [23, 614, 1715], "cutlass": 23, "cudnn": [23, 36, 37, 757, 1199, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1374, 1392, 1437, 1438, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1751, 1858, 1861, 1886, 1897, 1898], "conv": [23, 24, 71, 699, 700, 701, 702, 703, 704, 705, 706, 707, 789, 790, 793, 811, 851, 857, 1190, 1199, 1205, 1206, 1350, 1351, 1352, 1353, 1354, 1355, 1422, 1423, 1429, 1871, 1881, 1886, 1897, 1901, 1908, 1909, 1910, 1911], "56": [23, 737], "57": 23, "gain": [23, 1678, 1881], "effort": [23, 41, 1913], "nice": [23, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1415, 1416, 1417, 1473, 1877, 1883, 1905], "triton_red_fused__native_batch_norm_legit_functional_16": 23, "19": [23, 682, 743, 943, 1419, 1860, 1901, 1917], "jk": [23, 1063], "cjk2vm3446xrk7rth7hr6pun7xxo3dnzubwcn6ydrpifal4eykrz": 23, "renam": [23, 790, 1861, 1876, 1877, 1903], "96a0afef9dce53d6357bf1633094f358": 23, "standalon": [23, 32, 57, 58, 59, 814, 1201, 1205, 1860], "constabl": 24, "edg": [24, 776, 782, 1143, 1151, 1152, 1532, 1590, 1868, 1889, 1914], "orchestr": 24, "_forward_pre_hook": 24, "forward_hook": [24, 1894], "_backward_pre_hook": 24, "_backward_hook": 24, "_state_dict_hook": 24, "load_": 24, "alter": [24, 1882, 1888], "backward_hook": [24, 1894], "avoiabl": 24, "fire": [24, 1190, 1422, 1887, 1893], "presenc": [24, 68, 71, 1199, 1317, 1905, 1917], "opaqu": [24, 41, 48, 964, 998, 999, 1114], "skip_nnmodule_hook_guard": 24, "react": [24, 49], "pre_backward": 24, "accordingli": [24, 47, 71, 1199, 1392, 1614, 1878, 1913], "warn_onc": 24, "bin": [25, 49, 56, 58, 300, 301, 816, 921, 1150, 1151, 1152, 1861, 1863, 1903, 1922], "hui": 25, "nightli": 25, "gcp": [25, 41], "a100": [25, 29], "night": 25, "40gb": [25, 29], "2ghz": 25, "xeon": [25, 1858, 1885], "suit": [25, 41, 1860, 1862, 1863, 1901, 1909, 1913], "torchbench": 25, "trend": 25, "droplist": 25, "geometr": [25, 286, 776, 782, 1521, 1532, 1590, 1844, 1858, 1903, 1925], "peak": [25, 43, 45, 63, 1012, 1014, 1020, 1027, 1028, 1029, 1602, 1683, 1689, 1906], "footprint": [25, 39, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1886], "ratio": [25, 47, 49, 614, 1370, 1371, 1516, 1517, 1861], "click": [25, 1925], "with_cudagraph": 25, "kick": [25, 1887, 1913, 1914], "Be": [25, 1901], "wise": [25, 39, 41, 47, 684, 685, 695, 755, 767, 768, 777, 781, 881, 956, 1063, 1068, 1109, 1110, 1133, 1134, 1146, 1155, 1212, 1214, 1271, 1272, 1273, 1274, 1278, 1288, 1291, 1293, 1323, 1344, 1355, 1362, 1364, 1378, 1379, 1380, 1381, 1383, 1408, 1411, 1421, 1430, 1440, 1441, 1442, 1449, 1451, 1452, 1453, 1458, 1460, 1462, 1463, 1495, 1510, 1519, 1520, 1524, 1525, 1526, 1527, 1530, 1534, 1536, 1541, 1551, 1552, 1565, 1566, 1567, 1572, 1573, 1574, 1575, 1579, 1581, 1582, 1583, 1788, 1852, 1885, 1888, 1917, 1918, 1921], "pep": [26, 1860, 1862, 1901], "523": 26, "rewrit": [26, 43, 68, 83, 84, 1871, 1883, 1891, 1901], "customiz": [26, 1864, 1926], "usabl": [26, 29, 70, 1863, 1901], "openmp": [26, 1858, 1885, 1900], "video": [26, 1434, 1435, 1877, 1922], "topic": [26, 30, 1893, 1894], "vmap": [27, 64, 66, 67, 71, 898, 900, 904, 905, 906, 1121, 1124, 1125, 1127, 1129], "jacrev": [27, 65, 67, 68, 900, 1123, 1124, 1889], "100320": 27, "escap": 27, "hatch": 27, "introspect": [27, 71], "jax": [27, 64, 67, 68, 69, 1883, 1889], "promis": 27, "pure": [27, 32, 33, 68, 1193, 1860], "relax": [27, 47, 1205, 1206, 1614, 1908], "pitfal": [27, 1858], "functional_cal": [27, 65, 67, 1129], "sit": 28, "replace_add_with_mul": 28, "insert": [28, 38, 41, 47, 63, 70, 71, 744, 789, 790, 858, 859, 1423, 1424, 1432, 1602, 1743, 1746, 1756, 1777, 1801, 1842, 1860, 1871, 1886, 1903, 1908], "insert_relu_after_add": 28, "inserting_aft": [28, 71], "new_relu_nod": 28, "replace_all_uses_with": [28, 71], "roughli": [28, 38, 1388, 1887], "axi": [28, 511, 513, 515, 819, 822, 954, 1062, 1077, 1103, 1132, 1155, 1709, 1729, 1734, 1735, 1852, 1859, 1861, 1889, 1901, 1906, 1908], "eg": [28, 934, 1736, 1743], "dead": [28, 71], "frequenc": [28, 59, 921, 962, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1091, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1187, 1330, 1365, 1366, 1512, 1513, 1683, 1804], "replaceaddwithmul": 28, "transformed_graph_modul": 28, "graph_modul": [28, 856], "replaceaddwithmulsub": 28, "mul_r": 28, "removedetachpass": 28, "detach_copi": [28, 1861, 1903], "len": [28, 38, 41, 43, 71, 219, 542, 692, 693, 1082, 1086, 1089, 1093, 1096, 1100, 1130, 1194, 1256, 1277, 1289, 1317, 1320, 1359, 1559, 1620, 1622, 1638, 1682, 1689, 1793, 1796, 1802, 1803, 1807, 1844, 1845, 1846, 1860, 1861, 1863, 1888, 1903, 1917, 1922], "args_map": 28, "schema": [28, 35, 41, 43, 1859, 1860, 1861, 1863, 1867, 1901], "enumer": [28, 38, 47, 71, 1190, 1422, 1424, 1433, 1682, 1861, 1862, 1882, 1886, 1900, 1922], "_schema": 28, "kwarg_onli": 28, "scalartotensorpass": 28, "breakpoint": [28, 71, 1863], "try_coerc": 28, "tensortyp": [28, 1863], "wildcard": [28, 1877, 1905], "subgraph_rewrit": [28, 71], "replace_pattern": 28, "replaced_pattern": 28, "replace_pattern_with_filt": 28, "traced_modul": [28, 71, 1899], "replacedpattern": 28, "nodes_map": [28, 71], "passmanag": 28, "blob": [28, 789, 1120, 1891, 1893, 1922], "infra": [28, 29, 51, 1902], "pass_manag": 28, "__": [28, 1864], "pm": 28, "replace_add_with_div": 28, "replace_div_with_mul": 28, "run_checks_after_each_pass": 28, "suppress_check_failur": 28, "graph_module_out": 28, "set_check": 28, "check_div_target": 28, "div": [28, 39, 236, 1059, 1108, 1111, 1330, 1434, 1435, 1727, 1836, 1859, 1861, 1867, 1876, 1903, 1917, 1920], "valueerror": [28, 70, 1188, 1614, 1615, 1635, 1638, 1888, 1906, 1924], "add_check": 28, "subgraphmatch": 28, "matcher_util": 28, "match_output": 28, "match_placehold": 28, "remove_overlapping_match": 28, "ignore_liter": 28, "liter": [28, 1658, 1861, 1864, 1877, 1905], "largemodel": 28, "_weight": [28, 742, 743, 1365, 1366], "_bia": 28, "large_model_graph": 28, "patternmodel": 28, "_weight_1": 28, "_bias_1": 28, "pattern_graph": 28, "subgraph_match": 28, "match_result": 28, "internalmatch": 28, "default_factori": 28, "placeholder_nod": 28, "returning_nod": 28, "largest": [28, 63, 587, 921, 1107, 1221, 1242, 1244, 1246, 1247, 1262, 1558, 1610, 1826, 1859, 1861, 1862, 1863, 1929], "capabilitybasedpartition": 28, "l34": 28, "operator_support": 28, "operatorsupportbas": 28, "allows_single_node_partit": 28, "non_compute_op": 28, "ex": [28, 50, 1602, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1873], "_oper": 28, "getitem": 28, "allowed_single_node_partition_op": 28, "ll28c1": 28, "l28c1": 28, "is_node_support": 28, "chain": [28, 38, 39, 47, 70, 71, 151, 890, 940, 1245, 1366, 1450, 1679, 1692, 1863, 1883, 1886, 1888, 1891, 1894, 1904], "operatorsuppportbas": 28, "l150": 28, "any_chain": 28, "l164": 28, "addmuloperatorsupport": 28, "capability_partition": 28, "op_support": 28, "partition_list": 28, "propose_partit": 28, "call_modul": [28, 71], "fused_graph_modul": 28, "fuse_partit": 28, "lazo": 29, "meantim": [29, 1338, 1339, 1356, 1358, 1382, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1493, 1494, 1504, 1533, 1556, 1564], "smallest": [29, 51, 939, 1211, 1221, 1242, 1246, 1262, 1706, 1826, 1924, 1929], "suspect": [29, 35, 1678, 1886], "taken": [29, 41, 47, 63, 70, 71, 862, 1084, 1086, 1109, 1110, 1345, 1358, 1366, 1429, 1505, 1513, 1756, 1788, 1881, 1883, 1885, 1886, 1888, 1890, 1893, 1899, 1901, 1905, 1907], "proce": [29, 1882, 1886, 1913], "sampl": [29, 38, 43, 47, 64, 69, 71, 89, 154, 155, 377, 453, 480, 605, 776, 920, 962, 975, 1009, 1022, 1026, 1040, 1041, 1081, 1099, 1121, 1131, 1143, 1187, 1206, 1279, 1312, 1334, 1338, 1339, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1356, 1358, 1360, 1361, 1362, 1363, 1365, 1366, 1367, 1376, 1382, 1385, 1386, 1387, 1388, 1389, 1407, 1409, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1440, 1453, 1454, 1461, 1470, 1486, 1493, 1494, 1504, 1506, 1507, 1508, 1509, 1512, 1513, 1514, 1518, 1521, 1523, 1531, 1532, 1533, 1556, 1564, 1602, 1610, 1650, 1682, 1697, 1700, 1714, 1716, 1718, 1720, 1722, 1786, 1802, 1803, 1804, 1845, 1846, 1850, 1858, 1873, 1881, 1882, 1886, 1893, 1894, 1905, 1908, 1909, 1922], "test_assertion_error": 29, "compiled_test_assertion_error": 29, "mlazo": 29, "837": 29, "build_map": 29, "fortun": [29, 1890], "isol": [29, 71, 1593, 1875, 1906], "test_backend_error": 29, "_foobar": [29, 1903], "dummi": [29, 38, 45, 1883, 1888, 1928], "compiled_test_backend_error": 29, "246": [29, 614], "185": [29, 614], "decomp_fn": 29, "810": 29, "repro_aft": 29, "nearli": [29, 151, 890, 904, 1697, 1896, 1913], "minifier_launch": 29, "base_dir": 29, "successfulli": [29, 41, 49, 55, 73, 74, 75, 1196, 1752, 1875, 1894, 1899, 1913], "runnabl": [29, 71, 1882, 1901, 1922], "rand_strid": 29, "0a0": 29, "gitfddfc44": 29, "fddfc4488afb207971c54ad4bf58130fdc8a4dc5": 29, "nvcc": [29, 32, 994], "2005": [29, 680, 1846], "2022": 29, "thu_feb_10_18": 29, "23": [29, 41, 511, 1262, 1767, 1860, 1917], "41_pst_2022": 29, "v11": 29, "112": [29, 614], "cuda_11": 29, "r11": 29, "30978841_0": 29, "sxm4": 29, "float32": [29, 38, 39, 267, 577, 614, 816, 817, 818, 819, 822, 823, 877, 952, 1077, 1078, 1115, 1137, 1139, 1172, 1326, 1339, 1474, 1475, 1476, 1488, 1664, 1665, 1701, 1706, 1714, 1718, 1733, 1748, 1749, 1751, 1793, 1848, 1878, 1882, 1886, 1897, 1901, 1910, 1918, 1919, 1920, 1923, 1924, 1929], "compile_fx": 29, "compile_fx_inn": 29, "walk": [29, 33, 71, 1867, 1888, 1905, 1914, 1915, 1921], "toi": [29, 55], "toy_compil": 29, "debug_util": 29, "run_fwd_maybe_bwd": 29, "opt_mod": 29, "sh": [29, 765, 766, 770, 771, 1489, 1490, 1497, 1498, 1500, 1501, 1546, 1547], "st": [29, 1490, 1498, 1501, 1547], "dt": [29, 1498, 1501, 1918], "requires_grad_": [29, 335, 447, 1190, 1345, 1422, 1505, 1785, 1822, 1861, 1876, 1883, 1923], "rg": 29, "autocast": [29, 1009, 1428, 1858, 1886], "test_model": 29, "layernorm": [29, 1377, 1385, 1386, 1387, 1465, 1469, 1535, 1878, 1910], "overridden": [29, 32, 71, 886, 887, 888, 1006, 1422, 1783, 1863, 1883, 1888, 1897, 1906, 1928], "debug_dir_root": 29, "torch_compile_debug_dir": 29, "timestamp": [29, 51, 52, 55, 59, 1873, 1907, 1922], "cd": [29, 1900, 1905, 1907], "l": [29, 47, 732, 757, 919, 928, 934, 941, 942, 1063, 1147, 1148, 1190, 1209, 1219, 1220, 1225, 1226, 1227, 1228, 1232, 1236, 1237, 1279, 1281, 1335, 1338, 1339, 1340, 1350, 1358, 1361, 1362, 1369, 1374, 1382, 1383, 1385, 1388, 1389, 1392, 1404, 1413, 1415, 1422, 1424, 1428, 1429, 1437, 1453, 1470, 1471, 1473, 1571, 1620, 1629, 1637, 1639, 1667, 1743, 1804, 1861, 1863, 1883, 1922], "run_2023_03_01_08_20_52_143510": 29, "pid_180167": 29, "subfold": [29, 32], "artifact": [29, 677, 1869, 1893, 1905], "model__0_forward_1": 29, "aot_model___0_debug": 29, "fx_graph_read": 29, "fx_graph_runn": 29, "fx_graph_transform": 29, "ir_post_fus": 29, "txt": [29, 1197, 1200, 1905], "ir_pre_fus": 29, "fx_graph": 29, "buf1": 29, "schedulernod": 29, "computedbuff": 29, "memorydep": 29, "unmet_depend": 29, "buf0": 29, "c0": [29, 731, 759, 1392], "met_depend": 29, "primals_2": 29, "buf1_loop_bodi": 29, "var_rang": 29, "z0": 29, "index0": 29, "index1": 29, "bodi": [29, 71, 1201, 1860, 1862, 1863, 1864], "get_index": 29, "get_index_1": 29, "load_1": 29, "get_index_2": 29, "compiled_fun": 29, "hinder": 29, "break_reason": 29, "explanation_verbos": 29, "sublist": [29, 1063], "succe": [29, 41, 46, 58, 68, 1886, 1888, 1900], "compiled_toi": 29, "outweigh": [29, 1678], "readm": [29, 53, 54, 789, 1878], "verify_instal": 29, "log_fil": 29, "bj": 30, "j": [30, 41, 47, 313, 315, 321, 511, 513, 515, 689, 892, 898, 900, 952, 1063, 1079, 1080, 1087, 1093, 1097, 1098, 1132, 1187, 1190, 1225, 1226, 1237, 1253, 1262, 1269, 1277, 1279, 1284, 1361, 1362, 1363, 1367, 1422, 1425, 1507, 1508, 1509, 1514, 1701, 1708, 1787, 1804, 1808, 1847, 1862, 1881, 1883, 1888, 1891, 1899, 1922], "imaginari": [30, 311, 905, 952, 958, 1084, 1086, 1094, 1095, 1096, 1160, 1180, 1182, 1183, 1186, 1804, 1848, 1849, 1864, 1883, 1891, 1924], "satisfi": [30, 36, 39, 47, 614, 691, 757, 791, 899, 905, 906, 934, 1079, 1080, 1082, 1084, 1086, 1094, 1095, 1096, 1111, 1203, 1229, 1255, 1256, 1330, 1345, 1369, 1374, 1392, 1437, 1625, 1642, 1727, 1743, 1783, 1804, 1863, 1883, 1886, 1891, 1904, 1906, 1917, 1920], "equat": [30, 943, 1063, 1135, 1147, 1233, 1234, 1235, 1236, 1237, 1239, 1250, 1252, 1338, 1769, 1831, 1861, 1883, 1891, 1904, 1918], "mathemat": [30, 46, 71, 898, 899, 900, 901, 902, 903, 1111, 1143, 1338, 1340, 1341, 1342, 1385, 1386, 1387, 1388, 1461, 1540, 1578, 1602, 1649, 1727, 1785, 1786, 1863, 1883, 1897, 1918, 1925], "tradition": 30, "torchaudio": [30, 1858], "mimick": 30, "assembli": 30, "lapack": [30, 942, 1135, 1220, 1231, 1232, 1233, 1235, 1238, 1251, 1707, 1808], "spectral": [30, 1209, 1225, 1253, 1610, 1633, 1643, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1897], "fft": [30, 1858, 1886], "4621": 30, "0303j": 30, "2438": [30, 1235, 1512], "5874j": 30, "7706": 30, "1421j": 30, "2110": 30, "1918j": 30, "complex128": [30, 176, 952, 1106, 1115, 1169, 1190, 1219, 1220, 1225, 1226, 1227, 1228, 1229, 1230, 1350, 1351, 1352, 1422, 1496, 1497, 1498, 1658, 1701, 1748, 1919, 1920, 1923, 1924], "complex64": [30, 179, 952, 1080, 1082, 1083, 1088, 1089, 1115, 1169, 1221, 1244, 1247, 1350, 1351, 1352, 1496, 1497, 1498, 1658, 1701, 1748, 1919, 1920, 1923, 1924], "apart": [30, 1863, 1883], "linspac": [30, 921, 945, 1084, 1094, 1291, 1861, 1865, 1903], "logspac": [30, 1861, 1865, 1903], "view_as_r": [30, 1804, 1861, 1903, 1921], "6125": 30, "1681": 30, "3773": 30, "3487": 30, "0861": 30, "7981": 30, "1681j": 30, "3487j": 30, "7981j": 30, "mul_": [30, 1861, 1876, 1878, 1917], "2250": [30, 1246, 1649], "7546": [30, 943], "1722": 30, "x1": [30, 938, 1237, 1357, 1414, 1470, 1471, 1503, 1560, 1861], "3j": [30, 41, 695, 955, 956, 1731, 1732, 1748], "4j": [30, 41, 1759], "0000": [30, 47, 511, 862, 898, 900, 921, 941, 945, 958, 1044, 1050, 1051, 1052, 1077, 1078, 1081, 1083, 1084, 1090, 1091, 1094, 1099, 1111, 1112, 1113, 1143, 1149, 1152, 1156, 1215, 1218, 1219, 1220, 1232, 1233, 1236, 1241, 1242, 1246, 1248, 1260, 1276, 1317, 1365, 1366, 1474, 1475, 1477, 1478, 1512, 1513, 1649, 1701, 1707, 1712, 1713, 1714, 1723, 1727, 1728, 1752, 1759, 1761, 1762, 1764, 1767, 1768, 1769, 1770, 1786, 1831, 1832, 1834, 1853, 1870, 1878, 1886, 1917, 1918, 1923], "6569": [30, 1156], "5708": [30, 1047], "7854": 30, "complex_tensor": 30, "conjug": [30, 330, 457, 689, 905, 943, 955, 956, 1170, 1219, 1220, 1226, 1229, 1232, 1239, 1253, 1258, 1262, 1609, 1695, 1731, 1804, 1808, 1847, 1891, 1904, 1923], "wirting": [30, 905, 1891], "deriv": [30, 41, 63, 151, 735, 736, 737, 738, 739, 740, 778, 797, 821, 890, 904, 905, 906, 1126, 1130, 1143, 1187, 1247, 1279, 1593, 1858, 1862, 1888, 1889, 1891, 1913, 1917, 1918], "steepest": [30, 1883], "descent": [30, 47, 1661, 1677, 1681, 1682, 1883, 1894], "quantiz": [30, 71, 220, 326, 338, 471, 472, 473, 474, 475, 477, 697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 855, 856, 857, 858, 859, 860, 861, 914, 1048, 1077, 1078, 1709, 1710, 1711, 1712, 1713, 1858, 1903, 1920, 1923, 1924, 1926, 1927], "parallel_info": [31, 1858, 1885], "cppextens": [32, 1858], "setuptool": 32, "bare": 32, "buildextens": [32, 1858], "ext_modul": 32, "extra_compile_arg": [32, 1900], "cmdclass": 32, "build_ext": 32, "cudaextens": [32, 1858], "cuda_extens": 32, "extension_kernel": 32, "cu": 32, "cxx": 32, "o2": 32, "arch": 32, "card": [32, 1900], "ptx": 32, "road": 32, "newest": [32, 67], "torch_cuda_arch_list": 32, "build_my_extens": 32, "older": [32, 1886, 1899, 1905], "modestli": [32, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678], "pars": [32, 41, 61, 912, 1863, 1905, 1913], "workaround": [32, 38, 71, 1194, 1857, 1898, 1901, 1908], "sigmoidalphablendforwardcuda": 32, "69460": 32, "facebookresearch": 32, "pytorch3d": 32, "cb170ac024a949f1f9614ffe6af1c38d972f7d48": 32, "relocat": 32, "link": [32, 33, 47, 71, 83, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1415, 1416, 1417, 1473, 1523, 1877, 1893, 1894, 1917], "rdc": 32, "dc": 32, "anymor": [32, 41, 63, 222], "dlto": 32, "dlink": 32, "protent": 32, "lib": [32, 1900], "nvshmem": 32, "ninja": [32, 1900], "dlink_librari": 32, "dlink_lib": 32, "std": [32, 49, 56, 89, 377, 453, 1077, 1078, 1109, 1110, 1111, 1650, 1701, 1727, 1766, 1771, 1803, 1841, 1859, 1861, 1876, 1881, 1886, 1893, 1900, 1903], "use_ninja": 32, "distutil": 32, "max_job": 32, "extra_cflag": 32, "extra_cuda_cflag": 32, "extra_ldflag": 32, "extra_include_path": 32, "build_directori": 32, "with_cuda": [32, 1900], "is_python_modul": 32, "is_standalon": 32, "keep_intermedi": 32, "torch_extens": 32, "torch_extensions_dir": 32, "o3": 32, "cuh": 32, "Such": [32, 38, 39, 70, 1844, 1917], "lib64": 32, "cudart": [32, 1900], "cuda_hom": 32, "safest": 32, "pybind11": [32, 33, 1862], "union": [32, 38, 43, 46, 49, 52, 56, 59, 63, 71, 1201, 1261, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1370, 1371, 1390, 1391, 1415, 1416, 1417, 1422, 1465, 1467, 1469, 1472, 1614, 1656, 1658, 1739, 1861, 1862, 1863, 1901, 1905, 1919, 1924, 1927], "linker": 32, "workspac": 32, "header": [32, 56, 1900, 1924], "torch_lib_path": 32, "load_inlin": [32, 1858], "cpp_sourc": 32, "cuda_sourc": 32, "with_pytorch_error_handl": 32, "behav": [32, 33, 41, 70, 71, 313, 321, 491, 513, 515, 838, 1130, 1205, 1418, 1419, 1420, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1862, 1863, 1870, 1883, 1889, 1894, 1898, 1905, 1913, 1917], "concaten": [32, 38, 41, 46, 900, 937, 948, 978, 1062, 1155, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1366, 1392, 1505, 1513, 1606, 1614, 1801, 1852, 1861, 1864, 1901, 1903, 1917], "furthermor": [32, 56, 67, 1225, 1226, 1253, 1279, 1360, 1876, 1877, 1883, 1898, 1911, 1913], "cuda_runtim": 32, "se": 32, "macro": [32, 1892], "pybind": 32, "_safe_foo": 32, "redirect": [32, 49, 56, 1925], "obscur": 32, "sin_add": 32, "inline_extens": 32, "include_path": [32, 1858], "get_compiler_abi_compatibility_and_vers": [32, 1858], "abi": [32, 33], "shell": 32, "torchvers": 32, "verify_ninja_avail": [32, 1858], "is_ninja_avail": [32, 1858], "embed": [33, 71, 732, 743, 892, 1054, 1330, 1356, 1366, 1382, 1394, 1428, 1471, 1513, 1571, 1678, 1746, 1861, 1885, 1903, 1908, 1910, 1913, 1917, 1922], "preprocess": [33, 494, 1190], "augment": [33, 1864, 1924], "interfac": [33, 39, 43, 48, 50, 55, 58, 709, 710, 711, 712, 713, 714, 715, 716, 717, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 742, 743, 753, 758, 759, 760, 761, 762, 791, 1116, 1593, 1750, 1804, 1843, 1859, 1863, 1873, 1874, 1888, 1893, 1904, 1911, 1917, 1922], "opencv": [33, 1521, 1532], "struct": [33, 1130, 1131, 1850, 1871, 1893], "classat_1_1_tensor": 33, "tensor_index": 33, "cpp_autograd": 33, "undesir": [33, 1345, 1350, 1351, 1352, 1353, 1354, 1355, 1496, 1497, 1498, 1499, 1500, 1501, 1505, 1571, 1888], "cpp_frontend": 33, "library_root": 33, "libtorch": 33, "linux": [33, 41, 1857], "gcc": 33, "cxx11": 33, "race": [35, 1883], "enable_cuda_sanit": 35, "torch_cuda_sanit": 35, "concurr": [35, 41, 45, 1885, 1886, 1913, 1914], "uniniti": [35, 444, 497, 1064, 1065, 1593, 1604, 1605, 1642, 1878, 1903], "commandlin": 35, "example_error": 35, "csan": 35, "139719969079296": 35, "94646435460352": 35, "_sanit": 35, "364": 35, "_handle_kernel_launch": 35, "stack_trac": [35, 71], "stacksummari": 35, "420": 35, "_handle_memory_alloc": 35, "faulti": [35, 41], "current_stream": [35, 966, 1858, 1886], "wait_stream": [35, 41, 967, 969, 1886], "default_stream": [35, 41, 1858], "float16": [36, 39, 43, 63, 297, 683, 686, 757, 820, 823, 831, 847, 848, 855, 918, 930, 1115, 1172, 1190, 1284, 1294, 1350, 1351, 1352, 1353, 1354, 1355, 1374, 1375, 1392, 1393, 1409, 1422, 1437, 1571, 1664, 1665, 1736, 1882, 1894, 1908, 1910, 1919, 1920, 1923, 1924, 1929], "v100": [36, 757, 1374, 1392, 1437, 1886], "packedsequ": [36, 757, 1374, 1392, 1437, 1636, 1637, 1638, 1640], "rnn": [37, 731, 757, 758, 759, 760, 762, 855, 1374, 1375, 1392, 1393, 1439, 1603, 1612, 1635, 1865, 1890, 1894, 1910, 1922], "enforc": [37, 39, 70, 792, 887, 1190, 1392, 1422, 1437, 1863, 1894, 1921], "cuda_launch_block": [37, 1392, 1437, 1886], "colon": [37, 1392, 1437, 1913], "cublas_workspace_config": [37, 1392, 1437, 1843, 1886, 1898], "4096": [37, 1392, 1437, 1843, 1886, 1901], "dataload": [38, 494, 1602, 1682, 1683, 1689, 1886, 1890, 1900, 1904, 1922], "batch_siz": [38, 47, 67, 69, 889, 1121, 1129, 1131, 1428, 1635, 1637, 1638, 1640, 1850, 1861, 1889, 1890, 1898, 1901, 1922], "shuffl": [38, 1858, 1922], "batch_sampl": 38, "num_work": [38, 49, 1898, 1900], "drop_last": 38, "timeout": [38, 41, 58, 1875, 1913], "worker_init_fn": [38, 1890, 1898], "prefetch_factor": 38, "persistent_work": 38, "__getitem__": [38, 1843], "__len__": [38, 71, 1861], "protocol": [38, 43, 48, 58, 60, 877, 1114, 1116, 1657, 1739, 1888, 1900, 1901, 1913, 1928], "idx": [38, 71, 895, 1190, 1330, 1365, 1422, 1610, 1861, 1877], "th": [38, 155, 313, 315, 321, 757, 898, 900, 920, 940, 1050, 1055, 1164, 1187, 1211, 1229, 1237, 1243, 1279, 1312, 1361, 1362, 1363, 1367, 1374, 1382, 1392, 1437, 1507, 1508, 1509, 1514, 1708, 1804, 1888, 1900, 1918, 1920], "iterabledataset": [38, 1893], "__iter__": [38, 1864], "improb": 38, "fetch": [38, 70, 71, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1658, 1913], "databas": 38, "remot": [38, 41, 45, 49, 1602, 1906, 1913, 1914], "replica": [38, 39, 41, 45, 56, 1359, 1602, 1887], "duplic": [38, 315, 319, 470, 541, 919, 928, 949, 1147, 1148, 1190, 1422, 1840, 1841, 1917], "yield": [38, 39, 63, 71, 1051, 1053, 1190, 1236, 1237, 1422, 1853, 1863, 1864, 1870, 1906, 1908, 1918], "stochast": [38, 47, 1370, 1371, 1516, 1517, 1661, 1663, 1664, 1666, 1677, 1681, 1682, 1894, 1904], "decent": 38, "randomli": [38, 742, 743, 753, 761, 906, 1334, 1360, 1361, 1362, 1363, 1367, 1440, 1506, 1507, 1508, 1509, 1514, 1622, 1878, 1893, 1894], "permut": [38, 1063, 1236, 1237, 1256, 1279, 1281, 1722, 1858, 1859, 1861, 1877, 1903, 1910, 1921, 1923], "mini": [38, 776, 782, 1340, 1341, 1342, 1365, 1366, 1377, 1382, 1385, 1386, 1387, 1394, 1414, 1425, 1427, 1461, 1470, 1512, 1513, 1532, 1590, 1906], "neither": [38, 41, 792, 893, 896, 1046, 1106, 1428, 1469, 1649, 1829, 1888, 1897, 1913], "collat": 38, "minibatch": [38, 765, 766, 769, 770, 771, 1279, 1330, 1338, 1339, 1356, 1358, 1382, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1474, 1488, 1489, 1490, 1493, 1494, 1496, 1497, 1498, 1499, 1500, 1501, 1504, 1533, 1545, 1546, 1547, 1556, 1564, 1906], "loader": [38, 1904], "dataset_it": 38, "cheaper": [38, 70], "arrai": [38, 49, 447, 757, 817, 818, 876, 877, 921, 939, 958, 962, 1063, 1107, 1115, 1116, 1124, 1125, 1261, 1291, 1369, 1374, 1375, 1392, 1393, 1515, 1729, 1736, 1756, 1790, 1791, 1792, 1794, 1795, 1822, 1829, 1837, 1844, 1860, 1864, 1886, 1894, 1917, 1919, 1923, 1924], "untouch": 38, "slightli": [38, 41, 47, 63, 1649, 1697, 1809, 1857, 1886, 1891, 1897, 1905], "default_col": 38, "channel": [38, 66, 471, 472, 473, 776, 782, 805, 819, 822, 830, 842, 850, 1077, 1340, 1341, 1342, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1360, 1361, 1362, 1363, 1367, 1369, 1377, 1385, 1386, 1387, 1394, 1398, 1399, 1400, 1401, 1402, 1403, 1410, 1430, 1456, 1461, 1473, 1474, 1475, 1476, 1491, 1507, 1508, 1509, 1514, 1531, 1532, 1539, 1565, 1590, 1620, 1621, 1622, 1629, 1630, 1646, 1709, 1877, 1879, 1881, 1883, 1908, 1909, 1911, 1922], "class_index": 38, "namedtupl": [38, 71, 893, 1042, 1043, 1135, 1190, 1201, 1211, 1231, 1281, 1287, 1290, 1292, 1295, 1318, 1330, 1422, 1697, 1707, 1781, 1808, 1826, 1831, 1860, 1862, 1863, 1908], "gil": [38, 41, 45, 1883, 1886, 1913], "descriptor": [38, 1470, 1471, 1864, 1901], "parent": [38, 51, 56, 60, 63, 677, 785, 786, 814, 1422, 1875, 1900, 1905, 1915, 1922], "refcount": [38, 1875, 1896], "panda": 38, "pyarrow": 38, "13246": 38, "get_worker_info": [38, 1913], "seed": [38, 89, 1001, 1010, 1011, 1031, 1166, 1282, 1302, 1697, 1714, 1809, 1858, 1861, 1890, 1898, 1912], "shut": [38, 1913], "garbag": [38, 1915], "subtleti": [38, 1359, 1888, 1890], "multiprocess": [38, 41, 42, 44, 49, 51, 59, 60, 1359, 1602, 1858, 1877, 1887, 1914], "unix": [38, 56, 965, 1875], "fork": [38, 56, 1208, 1602, 1863, 1885, 1886, 1890, 1893, 1896, 1900, 1912, 1913, 1915], "child": [38, 49, 51, 63, 788, 1190, 1422, 1621, 1875, 1894, 1900, 1915], "maco": [38, 41, 1875, 1895], "spawn": [38, 39, 42, 49, 50, 56, 60, 1193, 1602, 1858, 1882, 1887, 1896, 1900, 1914], "__main__": [38, 39, 41, 50, 51, 59, 1884, 1887, 1896, 1900, 1914], "base_se": 38, "worker_id": [38, 60, 1898], "therebi": [38, 47, 1904, 1908], "mandatorili": 38, "faq": [38, 1359, 1638, 1858], "initial_se": [38, 89, 1858, 1898, 1912], "simplecustombatch": 38, "transposed_data": 38, "zip": [38, 43, 1857, 1861, 1862, 1872, 1886, 1893, 1917], "tgt": [38, 1465, 1466, 1467], "collate_wrapp": 38, "tensordataset": 38, "batch_ndx": 38, "is_pin": [38, 1635, 1861, 1876, 1903, 1919], "multiprocessing_context": 38, "pin_memory_devic": 38, "reshuffl": 38, "draw": [38, 155, 920, 1026, 1312, 1714, 1922], "mutual": [38, 41, 49, 732, 1924], "subprocess": [38, 41, 56, 58, 60, 1890, 1896], "incomplet": [38, 898, 1865, 1918], "divis": [38, 580, 614, 684, 769, 770, 771, 944, 1058, 1108, 1111, 1200, 1233, 1350, 1351, 1352, 1353, 1354, 1355, 1357, 1377, 1389, 1413, 1431, 1496, 1497, 1498, 1499, 1500, 1501, 1503, 1557, 1727, 1796, 1823, 1863, 1882, 1886], "basecontext": 38, "randomsampl": 38, "prefetch": [38, 63], "unpickl": [38, 41, 1261, 1905], "proper": [38, 49, 70, 71, 1054, 1746, 1862, 1883, 1886, 1888, 1900], "guess": 38, "trust": [38, 41, 1261, 1857, 1905], "inaccur": [38, 39], "kwd": 38, "__getitems__": 38, "myiterabledataset": 38, "worker_info": 38, "iter_start": 38, "iter_end": 38, "per_work": 38, "ceil": [38, 178, 630, 631, 765, 766, 1335, 1336, 1337, 1390, 1391, 1415, 1416, 1417, 1488, 1489, 1490, 1545, 1546, 1547, 1712, 1713, 1736, 1859, 1861, 1876, 1886, 1903, 1917], "mult": 38, "overall_start": 38, "overall_end": 38, "stackdataset": 38, "assembl": 38, "imagedataset": 38, "textdataset": 38, "tuple_stack": 38, "dict_stack": 38, "concatdataset": 38, "chaindataset": 38, "fly": [38, 1006, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1883], "_util": 38, "collate_fn_map": 38, "default_collate_fn_map": 38, "collate_tensor_fn": 38, "custom_col": 38, "collate_map": 38, "outer": [38, 688, 898, 1063, 1121, 1125, 1130, 1136, 1861, 1863, 1903], "unchang": [38, 497, 511, 513, 732, 811, 1102, 1190, 1422, 1465, 1728, 1799, 1882, 1897, 1908], "byte": [38, 41, 47, 58, 242, 434, 555, 877, 971, 1012, 1014, 1016, 1018, 1116, 1189, 1261, 1298, 1299, 1658, 1667, 1739, 1862, 1863, 1864, 1876, 1905, 1917, 1919], "v_i": [38, 1229], "v_1": 38, "v_2": 38, "v1_i": 38, "v2_i": 38, "v1_1": 38, "v1_2": 38, "v2_1": 38, "v2_2": 38, "elem": [38, 1861], "customtyp": 38, "collate_customtype_fn": 38, "custotyp": 38, "default_convert": 38, "np": [38, 938, 1058, 1063, 1103, 1104, 1105, 1561, 1701, 1889, 1898, 1901, 1922, 1923, 1924], "workerinfo": [38, 1913], "random_split": 38, "floor": [38, 271, 644, 645, 765, 766, 1058, 1108, 1200, 1335, 1336, 1337, 1390, 1391, 1415, 1416, 1417, 1488, 1489, 1490, 1545, 1546, 1547, 1712, 1713, 1727, 1736, 1804, 1859, 1861, 1863, 1876, 1899, 1903, 1917], "frac": [38, 47, 279, 377, 646, 647, 684, 757, 769, 770, 771, 862, 919, 928, 958, 962, 1058, 1108, 1143, 1147, 1148, 1209, 1221, 1225, 1226, 1229, 1241, 1253, 1260, 1276, 1330, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1343, 1346, 1350, 1351, 1352, 1353, 1354, 1355, 1358, 1360, 1369, 1374, 1375, 1376, 1377, 1385, 1386, 1387, 1388, 1390, 1391, 1392, 1393, 1394, 1407, 1409, 1410, 1411, 1412, 1415, 1416, 1417, 1425, 1426, 1427, 1429, 1437, 1439, 1440, 1452, 1454, 1455, 1457, 1458, 1460, 1461, 1462, 1473, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1541, 1557, 1559, 1561, 1571, 1573, 1577, 1579, 1581, 1582, 1662, 1663, 1666, 1668, 1674, 1681, 1682, 1711, 1723, 1726, 1738, 1759, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1787, 1802, 1803, 1804, 1808, 1829, 1845, 1846, 1861, 1876, 1881, 1883, 1891, 1903, 1918], "robin": [38, 41], "generator1": 38, "manual_se": [38, 68, 89, 1858, 1861, 1876, 1894, 1898, 1901, 1903, 1912], "generator2": 38, "data_sourc": 38, "accedingsequencelengthsampl": 38, "argsort": [38, 1819, 1861, 1889, 1903], "tolist": [38, 352, 1863, 1903, 1919], "accedingsequencelengthbatchsampl": 38, "sequentialsampl": 38, "num_sampl": [38, 420, 1312, 1861], "drawn": [38, 174, 258, 286, 1312, 1650, 1714, 1718, 1719, 1881, 1924, 1925], "subsetrandomsampl": 38, "weightedrandomsampl": 38, "row": [38, 39, 46, 47, 209, 313, 315, 321, 582, 585, 690, 696, 874, 898, 900, 938, 958, 962, 1046, 1076, 1104, 1105, 1125, 1131, 1152, 1211, 1237, 1245, 1248, 1253, 1277, 1279, 1287, 1289, 1290, 1292, 1295, 1312, 1318, 1319, 1320, 1512, 1513, 1561, 1609, 1648, 1705, 1708, 1728, 1788, 1789, 1790, 1791, 1792, 1794, 1795, 1807, 1826, 1829, 1833, 1835, 1844, 1850, 1852, 1861, 1891, 1917, 1922], "05": [38, 45, 71, 114, 344, 691, 709, 710, 711, 712, 713, 714, 720, 721, 733, 734, 746, 748, 749, 750, 751, 905, 906, 942, 1077, 1179, 1205, 1206, 1276, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1465, 1467, 1469, 1491, 1522, 1531, 1535, 1602, 1680, 1686, 1687, 1693, 1765, 1766, 1771, 1860, 1861, 1904, 1914, 1924], "batchsampl": 38, "distributedsampl": [38, 1602], "num_replica": 38, "world_siz": [38, 39, 41, 42, 45, 49, 58, 59, 61, 63, 1602, 1887, 1906, 1913, 1914], "evenli": [38, 580, 581, 582, 692, 693, 1061, 1153, 1260, 1276, 1851], "set_epoch": 38, "is_distribut": [38, 1861, 1903], "start_epoch": 38, "n_epoch": 38, "vanilla": [39, 1870], "allreduc": [39, 41, 1602, 1886, 1887, 1903], "register_comm_hook": [39, 45, 63, 1602], "mainli": [39, 47, 824, 1345, 1505, 1926], "gradbucket": [39, 1602], "decompos": [39, 71, 1113, 1120, 1234, 1859, 1883, 1901], "get_per_parameter_tensor": 39, "_distributed_c10d": [39, 41], "1d": [39, 46, 47, 63, 699, 702, 735, 738, 769, 779, 949, 958, 962, 1046, 1060, 1151, 1152, 1167, 1187, 1245, 1246, 1291, 1319, 1327, 1331, 1335, 1345, 1350, 1353, 1358, 1361, 1362, 1366, 1390, 1414, 1415, 1427, 1429, 1474, 1480, 1483, 1486, 1488, 1496, 1499, 1507, 1513, 1542, 1545, 1708, 1709, 1712, 1804, 1829, 1847], "is_last": 39, "set_buff": 39, "stateless": [39, 68, 1879, 1894], "ddp_comm_hook": [39, 45], "default_hook": 39, "allreduce_hook": 39, "process_group": [39, 42, 43, 45, 63, 1461, 1602], "unaffect": [39, 497, 498, 1376], "ddp_model": [39, 41, 1602, 1887], "fp16_compress_hook": 39, "decompress": [39, 1857, 1872], "bf16_compress_hook": 39, "nccl": [39, 42, 43, 59, 63, 1602, 1892], "brain": [39, 1920, 1923], "fp16_compress_wrapp": 39, "powersgdst": 39, "matrix_approximation_rank": 39, "start_powersgd_it": 39, "powersgd_hook": 39, "bf16_compress_wrapp": 39, "wikipedia": [39, 1558, 1883, 1891, 1929], "wiki": [39, 1929], "bfloat16_float": 39, "point_format": 39, "vogel": 39, "et": [39, 47, 63, 1345, 1434, 1435, 1470, 1471, 1677, 1772, 1809, 1881], "al": [39, 47, 63, 1345, 1434, 1435, 1470, 1471, 1677, 1772, 1809, 1881], "neurip": [39, 47], "2019": [39, 47, 1020], "hyperparamet": [39, 63, 71, 1922], "1000": [39, 1078, 1083, 1109, 1110, 1330, 1365, 1471, 1709, 1736, 1756, 1822, 1883, 1899, 1901, 1922], "min_compression_r": 39, "use_error_feedback": 39, "warm_start": 39, "orthogonalization_epsilon": 39, "random_se": 39, "compression_stats_logging_frequ": 39, "batch_tensors_with_same_shap": 39, "stronger": 39, "threshold": [39, 71, 1244, 1247, 1383, 1453, 1458, 1579, 1585, 1691, 1756, 1861, 1882, 1886, 1903, 1922], "exponenti": [39, 258, 1073, 1241, 1267, 1268, 1269, 1277, 1344, 1364, 1510, 1858, 1863, 1903, 1904, 1918, 1925], "grid": [39, 1083, 1291, 1486, 1521, 1859, 1861, 1886, 1922], "satisfactori": 39, "appendix": [39, 1858], "defer": [39, 63, 1886, 1906], "hybrid": [39, 63, 219, 540, 580, 581, 582, 584, 585, 1154], "scheme": [39, 58, 477, 799, 816, 817, 818, 819, 822, 824, 1894], "trajectori": 39, "irrecover": 39, "num_row": 39, "num_col": 39, "1e": [39, 71, 114, 344, 691, 709, 710, 711, 712, 713, 714, 720, 721, 733, 734, 746, 748, 749, 750, 751, 752, 905, 906, 941, 942, 1179, 1205, 1206, 1256, 1340, 1341, 1342, 1357, 1376, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1408, 1431, 1436, 1461, 1465, 1467, 1469, 1470, 1491, 1503, 1518, 1522, 1523, 1531, 1535, 1557, 1560, 1564, 1587, 1610, 1643, 1660, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1678, 1691, 1699, 1752, 1860, 1861, 1888, 1894, 1901, 1904, 1918, 1924], "orthogon": [39, 1226, 1229, 1248, 1253, 1262, 1695, 1707, 1881, 1883, 1894, 1917], "epsilon": [39, 71, 816, 817, 818, 819, 822, 862, 1244, 1247, 1340, 1341, 1342, 1357, 1377, 1385, 1386, 1387, 1394, 1431, 1461, 1503, 1557, 1610, 1643, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1711, 1861, 1918], "bucket_cap_mb": [39, 1602, 1887], "memor": 39, "compens": 39, "apex": 39, "uncompress": [39, 1917], "pq": 39, "mq": [39, 1908, 1927], "tp": [39, 46], "comm": [39, 41, 1887], "handler": [39, 41, 51, 52, 1621, 1873, 1893, 1905, 1928], "batched_powersgd_hook": 39, "destroi": [39, 58, 1359, 1883, 1913], "squar": [39, 47, 548, 736, 737, 738, 739, 776, 782, 791, 962, 1050, 1052, 1187, 1221, 1223, 1225, 1226, 1227, 1230, 1231, 1235, 1237, 1239, 1241, 1243, 1247, 1249, 1250, 1252, 1253, 1257, 1270, 1279, 1328, 1332, 1336, 1337, 1351, 1352, 1354, 1355, 1370, 1371, 1383, 1391, 1413, 1416, 1417, 1420, 1453, 1465, 1488, 1497, 1500, 1516, 1517, 1521, 1530, 1532, 1552, 1575, 1590, 1609, 1662, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1738, 1797, 1831, 1844, 1861, 1903, 1917], "truncat": [39, 1108, 1837, 1878, 1881, 1890, 1897], "debugging_hook": 39, "noop_hook": 39, "noop": [39, 1602], "headroom": 39, "desynchron": [39, 41], "trainer": [39, 49, 51, 56, 59, 60, 1602, 1913], "__setstate__": 39, "__getstate__": 39, "reload": [39, 45, 1857], "sy": [39, 50, 59, 61, 1857, 1886, 1905], "tempfil": 39, "simplemodel": 39, "fc2": [39, 1593, 1906], "master_addr": [39, 41, 49, 59, 61, 1887, 1906, 1913, 1914], "localhost": [39, 41, 58, 59, 1887, 1906, 1913, 1914], "master_port": [39, 41, 49, 59, 61, 1887, 1906, 1913, 1914], "12355": 39, "init_process_group": [39, 41, 42, 45, 49, 59, 61, 1602, 1886, 1887, 1913], "cleanup": 39, "destroy_process_group": 39, "run_demo": 39, "demo_fn": 39, "mp": [39, 41, 42, 60, 1602, 1858, 1887, 1896, 1908, 1914, 1919, 1920, 1927], "nproc": [39, 41, 56, 57, 59, 1875, 1887, 1914], "demo_seri": 39, "gettempdir": 39, "device_id": [39, 41, 42, 45, 59, 63, 1261, 1359, 1461, 1586, 1602, 1887], "powersgd_st": 39, "lr": [39, 42, 45, 63, 1593, 1602, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678, 1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1886, 1887, 1894, 1904, 1914, 1922], "001": [39, 905, 906, 1199, 1660, 1664, 1665, 1674, 1678, 1690, 1887, 1901], "comm_hook": 39, "comm_hook_st": 39, "hook_stat": 39, "barrier": [39, 49, 58, 1903], "map_loc": [39, 1194, 1197, 1261, 1602, 1857, 1872, 1905], "n_gpu": 39, "device_count": [39, 41, 1858], "got": [39, 41, 888, 1888, 1924], "thank": [39, 47, 1888, 1906], "thij": 39, "par": 39, "home": [40, 1886], "brief": [41, 1602, 1875, 1913], "introduct": [41, 47, 998, 1602, 1858, 1860, 1864, 1876, 1884, 1894, 1901, 1913, 1917, 1922], "mpi": [41, 1602], "gloo": [41, 59, 1602, 1887, 1892, 1913], "recv": [41, 1602, 1903, 1914], "all_reduc": [41, 60, 1602], "all_gath": 41, "scatter": [41, 45, 63, 511, 513, 515, 1359, 1843, 1861, 1890, 1903, 1913], "reduce_scatt": [41, 1903], "all_to_al": 41, "v1": [41, 63, 1258, 1696, 1857, 1887, 1913], "init_method": [41, 1602, 1913], "adher": [41, 1863], "some_fil": 41, "machine_nam": 41, "share_folder_nam": 41, "tcpstore": [41, 58], "infiniband": [41, 1602, 1913], "interconnect": 41, "gpudirect": 41, "ethernet": 41, "ip": [41, 58], "ib": 41, "nccl_socket_ifnam": 41, "eth0": 41, "gloo_socket_ifnam": 41, "comma": [41, 1063, 1863, 1869], "eth1": 41, "eth2": 41, "eth3": 41, "imper": 41, "nccl_debug": 41, "nccl_debug_subsi": 41, "coll": 41, "hang": [41, 42, 45, 1602, 1887], "topologi": [41, 43, 46, 49], "socket": [41, 1875, 1913], "nccl_socket_nthread": 41, "nccl_nsocks_perthread": 41, "cloud": [41, 1917, 1922], "aw": [41, 50, 962], "primit": [41, 45, 58, 1261, 1859, 1860, 1862, 1864, 1885, 1895, 1901, 1913], "connect": [41, 49, 58, 1350, 1351, 1352, 1353, 1354, 1355, 1398, 1399, 1400, 1401, 1402, 1403, 1450, 1875, 1913], "redund": [41, 63, 1079, 1080, 1082, 1084, 1098, 1100, 1804], "averag": [41, 45, 732, 763, 764, 765, 766, 818, 819, 914, 916, 962, 1026, 1040, 1190, 1327, 1328, 1329, 1335, 1336, 1337, 1338, 1339, 1340, 1341, 1342, 1356, 1358, 1366, 1376, 1382, 1388, 1389, 1390, 1391, 1395, 1396, 1397, 1413, 1414, 1422, 1425, 1426, 1427, 1428, 1429, 1436, 1453, 1454, 1461, 1470, 1480, 1481, 1482, 1488, 1489, 1490, 1493, 1494, 1504, 1518, 1533, 1542, 1543, 1556, 1564, 1602, 1661, 1662, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1829, 1858, 1887, 1907], "thrash": 41, "recurr": [41, 757, 758, 1205, 1345, 1359, 1374, 1375, 1392, 1437, 1612, 1638, 1675, 1858, 1886], "use_distribut": 41, "datetim": [41, 1873], "timedelta": [41, 58, 1873], "1800": 41, "group_nam": [41, 55], "pg_option": 41, "url": [41, 58, 913, 1857, 1872, 1913], "discov": [41, 1913], "encod": [41, 49, 55, 58, 71, 1237, 1261, 1303, 1304, 1338, 1339, 1465, 1466, 1467, 1468, 1469, 1602, 1790, 1791, 1792, 1794, 1795, 1860, 1863, 1864, 1888, 1899, 1905, 1914, 1917], "ucc": 41, "lowercas": 41, "deadlock": [41, 1602], "job": [41, 49, 51, 52, 54, 55, 57, 58, 59, 60, 1602, 1683, 1689, 1893, 1907, 1922], "exchang": [41, 58, 967, 1051, 1886, 1901], "nccl_blocking_wait": 41, "nccl_async_error_handl": [41, 1886], "abort": [41, 1886], "crash": [41, 51, 58, 1875, 1883, 1913, 1915, 1922], "caught": [41, 1602, 1875], "watch": 41, "dog": 41, "processgroupopt": 41, "processgroupnccl": [41, 1887], "is_high_priority_stream": 41, "backend_nam": 41, "custom_backend": 41, "is_initi": [41, 1858], "is_mpi_avail": 41, "is_nccl_avail": 41, "is_gloo_avail": 41, "is_torchelastic_launch": 41, "elast": [41, 50, 51, 52, 53, 54, 55, 56, 57, 58, 60, 61, 1858], "torchelast": [41, 44, 49, 50, 51, 52, 55, 57, 58, 59, 60, 61], "torchelastic_run_id": [41, 59], "rendezv": [41, 44, 49, 55, 57, 61, 1887, 1913], "null": [41, 50, 52, 55], "discoveri": [41, 58, 1886, 1905], "reachabl": 41, "multicast": 41, "23456": 41, "clean": [41, 49, 71, 1002, 1857, 1875, 1905], "fcntl": 41, "nf": 41, "brand": 41, "unsuccess": 41, "mnt": 41, "sharedfil": 41, "port": [41, 49, 57, 58, 59, 1892], "backend_str": 41, "uppercas": 41, "classmethod": [41, 58, 729, 735, 736, 737, 742, 743, 753, 761, 789, 790, 791, 812, 813, 814, 821, 851, 966, 1365, 1366, 1461, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1658, 1863, 1864, 1888, 1908, 1913, 1919, 1928], "extended_api": 41, "instanti": [41, 45, 57, 58, 59, 71, 838, 1067, 1165, 1366, 1513, 1611, 1635, 1642, 1647, 1857, 1860, 1862, 1863, 1886, 1888, 1894, 1919], "3rd": [41, 47, 58, 614, 1691, 1884], "processgroup": [41, 43, 45, 63, 1602], "four": [41, 1235, 1351, 1888, 1891, 1913, 1915], "c10d": [41, 49, 57, 59, 61, 1602, 1887, 1903], "distributedbackendopt": 41, "get_backend": [41, 58], "get_rank": [41, 1461], "get_world_s": 41, "filestor": [41, 58], "hashstor": 41, "host_nam": 41, "hostnam": [41, 49, 58, 1907], "listen": 41, "is_mast": 41, "300": [41, 49, 1267, 1339, 1639, 1641, 1904], "wait_for_work": 41, "server_stor": 41, "127": [41, 791, 1877, 1908, 1922], "1234": [41, 58, 1167], "client_stor": 41, "first_kei": 41, "first_valu": 41, "hashmap": 41, "file_nam": [41, 1857, 1872, 1905], "store1": 41, "store2": 41, "prefixstor": 41, "quantiti": [41, 64, 69, 1225, 1226, 1253, 1388, 1619, 1620, 1622, 1623, 1625, 1628, 1629, 1630, 1631, 1691, 1889, 1891], "compare_set": 41, "arg2": 41, "expected_valu": 41, "desired_valu": 41, "second_valu": 41, "overload": [41, 71, 614, 1862, 1863, 1867], "bad_kei": 41, "num_kei": 41, "destruct": [41, 1873, 1913, 1915], "delete_kei": 41, "set_timeout": 41, "grain": [41, 855, 858, 1571, 1858, 1883, 1901], "plai": 41, "new_group": [41, 63, 1461], "use_local_synchron": 41, "enqueu": [41, 70, 967, 969, 970, 1886, 1914], "get_group_rank": 41, "global_rank": [41, 49], "get_global_rank": 41, "group_rank": [41, 49, 59], "get_process_group_rank": 41, "dst": [41, 1857, 1905], "destin": [41, 43, 52, 55, 63, 210, 415, 416, 600, 978, 979, 1132, 1190, 1296, 1297, 1422, 1656, 1657, 1861, 1913, 1914, 1919], "unspecifi": [41, 480, 817, 818, 819, 822, 905, 906, 1455, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1787, 1870, 1917, 1922], "sender": [41, 1915], "isend": 41, "irecv": 41, "is_complet": 41, "finish": [41, 43, 49, 55, 56, 58, 60, 70, 1120, 1886, 1887, 1900, 1907, 1913, 1915], "batch_isend_irecv": 41, "p2p_op_list": 41, "p2pop": 41, "op_list": 41, "send_tensor": 41, "recv_tensor": 41, "send_op": 41, "recv_op": 41, "req": 41, "pg": [41, 1602], "set_devic": [41, 43, 63, 1602, 1747, 1858, 1913, 1920], "p2p": [41, 58], "async_op": 41, "get_futur": [41, 1602], "add_": [41, 66, 68, 222, 1120, 1861, 1876, 1884, 1917], "101": [41, 1330], "overwrot": 41, "sent": [41, 43, 1002, 1863, 1875, 1896, 1913, 1914, 1915], "broadcast_object_list": 41, "object_list": 41, "picklabl": [41, 1190, 1422, 1905], "current_devic": [41, 43, 975, 983, 984, 991, 992, 1008, 1012, 1014, 1015, 1016, 1018, 1020, 1021, 1022, 1026, 1027, 1028, 1029, 1039, 1040, 1041, 1858, 1920], "insecur": [41, 1261], "malici": [41, 1261, 1905], "ineffici": [41, 1886, 1908], "redoptyp": 41, "bitwis": [41, 922, 924, 925, 927, 1864, 1897, 1909, 1925], "reduceop": 41, "int64": [41, 192, 209, 313, 321, 393, 862, 921, 934, 1064, 1077, 1078, 1115, 1504, 1635, 1718, 1722, 1723, 1743, 1790, 1791, 1792, 1794, 1795, 1886, 1917, 1919, 1920, 1923, 1929], "1j": [41, 695, 955, 956, 1186, 1731, 1732, 1847, 1883, 1891, 1899], "2j": [41, 695, 955, 956, 1731, 1732, 1759, 1847, 1883], "tensor_list": [41, 1878], "all_gather_into_tensor": 41, "output_tensor": 41, "accommod": [41, 1418, 1419, 1420], "ii": [41, 958, 1063, 1392, 1393], "tensor_in": 41, "tensor_out": 41, "tensor_out2": 41, "all_gather_object": 41, "obj": [41, 71, 877, 987, 1176, 1177, 1196, 1201, 1739, 1861, 1900, 1905], "pickabl": 41, "responsibl": 41, "gather_object": 41, "gather_list": 41, "object_gather_list": 41, "scatter_list": 41, "tensor_s": 41, "t_one": 41, "t_five": 41, "scatter_object_list": 41, "scatter_object_output_list": 41, "scatter_object_input_list": 41, "output_list": 41, "input_list": 41, "reduce_scatter_tensor": 41, "all_to_all_singl": 41, "output_split_s": 41, "input_split_s": 41, "15": [41, 71, 614, 1061, 1133, 1143, 1153, 1212, 1226, 1346, 1419, 1420, 1639, 1641, 1699, 1772, 1781, 1827, 1851, 1860, 1861, 1864, 1901, 1917], "uneven": [41, 42, 45, 1602], "21": [41, 47, 682, 940, 1046, 1248, 1707, 1829, 1860, 1917], "31": [41, 926, 1337, 1417, 1593, 1767, 1901], "33": [41, 735, 736, 737, 738, 739, 740, 769, 1190, 1350, 1351, 1352, 1354, 1355, 1420, 1422, 1496, 1498, 1499, 1501, 1860, 1901], "35": [41, 1248, 1341, 1342, 1386, 1387, 1461, 1707], "input_split": 41, "output_split": 41, "5j": 41, "6j": 41, "7j": 41, "8j": 41, "9j": 41, "10j": 41, "11j": 41, "12j": 41, "13j": 41, "14j": 41, "15j": 41, "16j": 41, "output_tensor_list": 41, "input_tensor_list": 41, "monitored_barri": [41, 1903], "wait_all_rank": 41, "band": 41, "bor": 41, "bxor": 41, "premul_sum": 41, "_make_nccl_premul_sum": 41, "all_reduce_multigpu": 41, "__members__": 41, "reduce_op": 41, "revisit": 41, "broadcast_multigpu": 41, "reduce_multigpu": 41, "all_gather_multigpu": 41, "reduce_scatter_multigpu": 41, "distributed_test": 41, "dev_idx": 41, "src_tensor": 41, "resid": [41, 63, 70, 197, 289, 337, 1261, 1602, 1886, 1906, 1913], "dst_tensor": 41, "cpp_extens": [41, 1858, 1888], "cpp_c10d_extens": 41, "torchrun": [41, 44, 50, 57, 61], "benefici": [41, 1894], "nproc_per_nod": [41, 50], "num_gpus_you_hav": 41, "your_training_script": [41, 57, 59], "arg3": 41, "192": [41, 614, 1901], "168": 41, "nnode": [41, 57, 59], "local_process_rank": 41, "local_rank": [41, 49, 51, 56, 59, 61, 1461], "argpars": [41, 59, 1886], "parser": [41, 59, 1886], "argumentpars": [41, 59, 1886], "add_argu": [41, 59, 1886], "parse_arg": [41, 50, 59, 61, 1886, 1901], "output_devic": [41, 45, 59, 1359, 1461, 1586, 1602], "adjust": [41, 43, 45, 47, 63, 1858, 1885, 1909], "launcher": [41, 59], "filesystem": [41, 43, 965, 1857, 1905], "12042": 41, "imagenet": [41, 1881], "inconsist": [41, 63, 862, 1723, 1888], "group_gloo": 41, "29501": 41, "monitoredbarri": 41, "transport": [41, 1913], "598": 41, "2401": 41, "db00": 41, "eef0": 41, "1100": 41, "3560": 41, "1c05": 41, "25d": 41, "8594": 41, "torch_cpp_log_level": 41, "twolinlayernet": 41, "i0607": 41, "739390": 41, "515217": 41, "logger": [41, 1655, 1926, 1927], "173": 41, "broadcast_buff": [41, 1602], "bucket_cap_byt": 41, "26214400": 41, "find_unused_paramet": [41, 1602, 1887], "gradient_as_bucket_view": [41, 1602], "is_multi_device_modul": 41, "num_parameter_tensor": 41, "total_parameter_size_byt": 41, "440": 41, "bucket_s": 41, "cuda_visible_devic": [41, 1032, 1602, 1886], "module_nam": [41, 71, 814, 851, 1905], "nccl_ib_timeout": 41, "nccl_nthread": 41, "085681": 41, "544067": 41, "344": 41, "unused_parameter_s": 41, "40838608": 41, "5983335": 41, "4326421": 41, "comp": [41, 47], "4207652": 41, "085693": 41, "544066": 41, "42850427": 41, "3885553": 41, "2357981": 41, "2234674": 41, "unus": [41, 45, 71, 904, 1002, 1016, 1195, 1201, 1384, 1602, 1660, 1860, 1862, 1863, 1886, 1887, 1892, 1905], "wasn": [41, 1261, 1860], "va": 41, "lue": 41, "indirectli": 41, "outstand": [41, 1913], "stuck": [41, 49, 60], "uninform": 41, "reveal": [41, 1887], "default_pg": 41, "longtensor": [41, 135, 136, 137, 315, 317, 319, 451, 470, 511, 513, 515, 871, 872, 1132, 1164, 1211, 1312, 1365, 1366, 1425, 1512, 1513, 1558, 1648, 1743, 1781, 1793, 1818, 1826, 1853, 1920, 1923], "set_debug_level": 41, "set_debug_level_from_env": 41, "get_debug_level": 41, "torch_show_cpp_stacktrac": 41, "distbackenderror": 41, "facilit": [42, 47, 68, 967, 1051, 1748, 1857, 1860, 1863, 1898], "joinabl": [42, 45, 1602, 1858], "joinhook": [42, 1858], "throw_on_early_termin": [42, 1602], "shadow": [42, 45, 1602, 1926, 1927], "notify_join_context": 42, "zeroredundancyoptim": [42, 45, 1602, 1858], "01": [42, 45, 60, 752, 777, 818, 819, 1064, 1106, 1408, 1536, 1537, 1593, 1659, 1661, 1663, 1665, 1675, 1676, 1683, 1689, 1709, 1763, 1765, 1766, 1771, 1772, 1859, 1861, 1881, 1893, 1901, 1904], "vacuou": 42, "inherit": [42, 1627, 1860, 1862, 1878, 1888, 1894, 1896], "join_hook": [42, 45, 1602], "join_devic": 42, "join_process_group": 42, "repeatedli": [42, 1886, 1917], "main_hook": 42, "post_hook": 42, "is_last_join": 42, "dcp": 43, "reshard": [43, 46, 63], "storage_read": 43, "coordinator_rank": 43, "no_dist": 43, "planner": 43, "spmd": 43, "fullfil": 43, "shardedtensor": [43, 63], "po": [43, 1901], "storageread": [43, 1858], "rank0": [43, 63], "mymodul": [43, 63, 71, 1194, 1195, 1196, 1200, 1201, 1207, 1423, 1424, 1432, 1433, 1860, 1862, 1863, 1890, 1899, 1913], "adagrad": [43, 1365, 1870, 1904, 1913], "model_state_dict": 43, "fs_storage_load": 43, "filesystemload": 43, "save_state_dict": [43, 1858], "storage_writ": 43, "storagewrit": [43, 1858], "fs_storage_writ": 43, "filesystemwrit": [43, 1858], "told": [43, 1862], "read_metadata": 43, "set_up_storage_read": 43, "prepare_local_plan": 43, "prepare_global_plan": 43, "read_data": 43, "central": [43, 1143, 1891, 1893], "loadplan": [43, 1858], "storage_data": 43, "loadplann": [43, 1858], "load_byt": 43, "bytesio": [43, 1197, 1200, 1261, 1739, 1901, 1908], "resolve_tensor": 43, "storagelay": 43, "is_coordin": 43, "set_up_storage_writ": 43, "write_data": 43, "recover": 43, "writeresult": 43, "saveplan": [43, 1858], "saveplann": [43, 1858], "resolve_data": 43, "writeitem": [43, 1858], "tensor_data": 43, "set_up_plann": 43, "create_local_plan": 43, "create_global_plan": 43, "commit_tensor": 43, "defaultloadplann": [43, 1858], "requit": 43, "intrincaci": 43, "renameplann": 43, "original_state_dict": 43, "foo_": [43, 1120], "v": [43, 55, 67, 71, 486, 541, 892, 899, 901, 902, 903, 934, 1119, 1129, 1131, 1187, 1203, 1225, 1229, 1253, 1257, 1262, 1428, 1470, 1471, 1512, 1557, 1571, 1641, 1646, 1675, 1677, 1697, 1730, 1789, 1793, 1808, 1809, 1850, 1858, 1860, 1861, 1862, 1863, 1873, 1883, 1891, 1900, 1905, 1917, 1922], "read_item": 43, "dest_index": 43, "fqn": [43, 46, 1927], "metamodelmateri": 43, "defaultsaveplann": [43, 1858], "empty_lik": [43, 1861, 1865, 1876, 1878, 1903, 1917], "global_plan": 43, "finish_plan": 43, "central_plan": 43, "readitem": [43, 1858], "planner_data": 43, "loaditemtyp": 43, "metadataindex": 43, "dest_offset": 43, "storage_index": 43, "storage_offset": [43, 139, 518, 614, 875, 1859, 1861, 1903], "tandem": 43, "fp16planner": 43, "write_item": 43, "writeitemtyp": 43, "byte_io": 43, "itertool": [43, 47, 936, 949], "islic": 43, "ddploadbalancingplann": 43, "all_plan": 43, "saveextradataplann": 43, "merged_data": 43, "new_plan": 43, "idempot": [43, 1913, 1915], "hi": [43, 1392, 1393, 1860, 1862, 1891], "late": [43, 58], "tensorwritedata": 43, "nonetyp": [43, 1861, 1863], "filesystemread": [43, 1858], "single_file_per_rank": 43, "sync_fil": 43, "thread_count": 43, "per_thread_copy_ahead": 43, "10000000": 43, "atom": [43, 58, 71, 1864], "distributedtensor": [43, 46], "flatten_state_dict": 43, "flatten_sharded_tensor": 43, "dedup_replicated_tensor": 43, "lookup_object": 43, "transform_object": 43, "lookup_tensor": 43, "transform_tensor": 43, "fault": [44, 49, 57, 58, 1116], "toler": [44, 49, 57, 58, 71, 691, 905, 906, 1179, 1205, 1206, 1244, 1247, 1262, 1660, 1667, 1860, 1924], "quickstart": 44, "agent": [44, 50, 51, 52, 55, 57, 59, 60, 1913], "expir": 44, "kubernet": 44, "distributedoptim": [45, 1602, 1858, 1913, 1914], "rref": [45, 1602, 1858, 1863, 1906, 1914], "optimizer_class": 45, "params_rref": 45, "get_gradi": [45, 1903, 1913, 1914], "multithread": [45, 917, 1886], "dist_autograd": [45, 1602, 1913, 1914], "rpc": [45, 70, 1602, 1858, 1863, 1906, 1914, 1915], "context_id": [45, 1602, 1913, 1914], "rref1": [45, 1913, 1914], "worker1": [45, 70, 1602, 1913, 1914], "rref2": [45, 1913, 1914], "to_her": [45, 1602, 1903, 1913, 1914, 1915], "dist_optim": [45, 1602, 1914], "postlocalsgdoptim": [45, 1858], "afer": 45, "modelaverag": 45, "localsgd": 45, "model_averag": 45, "post_localsgd_hook": 45, "postlocalsgdst": 45, "subgroup": 45, "start_localsgd_it": 45, "warmup_step": 45, "local_optim": 45, "periodicmodelaverag": 45, "intra": [45, 1885, 1887, 1906], "unnecessari": [45, 1642, 1863, 1883, 1886, 1888, 1899, 1905, 1921], "parameters_as_bucket_view": 45, "overlap_with_ddp": 45, "consumpt": [45, 67, 1647, 1917, 1922], "intact": [45, 1913], "ddp_zero_hook": 45, "disjointli": 45, "trail": [45, 1637, 1639, 1878, 1881, 1884, 1888], "wari": 45, "static_graph": [45, 1602, 1887], "third": [45, 47, 1062, 1063, 1279, 1330, 1337, 1352, 1355, 1417, 1689, 1858, 1860, 1886, 1889, 1894, 1905, 1907], "add_param_group": [45, 1614, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678], "param_group": [45, 63, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1671, 1674, 1675, 1676, 1677, 1678, 1685, 1688], "frozen": [45, 1194, 1199, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1864, 1900], "trainabl": [45, 1009, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1669, 1674, 1675, 1676, 1677, 1678, 1888], "consolidate_state_dict": 45, "consolid": [45, 63, 1906], "pertain": 45, "dtensor": 46, "rowwis": 46, "colwis": 46, "pairwis": [46, 47, 1382, 1431, 1470], "parallelize_modul": [46, 1858], "device_mesh": 46, "parallelize_plan": 46, "tp_mesh_dim": 46, "sub_modul": 46, "parallelstyl": 46, "devicemesh": 46, "mesh": [46, 1922], "prepar": [46, 71, 794, 836, 838, 854, 856, 858, 859, 860, 1129, 1199, 1864, 1901, 1926, 1927], "pairwiseparallel": [46, 1858], "granular": [46, 63, 1203, 1882], "rowwiseparallel": [46, 1858], "_prepare_input": 46, "make_input_shard_1d_last_dim": [46, 1858], "_prepare_output": 46, "make_output_tensor": [46, 1858], "colwiseparallel": [46, 1858], "make_input_replicate_1d": [46, 1858], "make_sharded_output_tensor": 46, "megatron": 46, "lm": 46, "arxiv": [46, 47, 1392, 1440, 1441, 1468, 1646, 1697, 1809, 1883], "1909": [46, 875], "08053": 46, "multihead": [46, 1428, 1467], "mlp": [46, 1593, 1908], "sequenceparallel": [46, 1858], "pdf": [46, 1345, 1440, 1772, 1883], "2205": 46, "05198": 46, "expectedli": 46, "make_input_reshard_repl": [46, 1858], "make_input_shard_1d": [46, 1858], "make_output_replicate_1d": [46, 1858], "make_output_reshard_tensor": [46, 1858], "make_output_shard_1d": [46, 1858], "multiheadattent": [46, 1465, 1467, 1469, 1908], "multihead_attent": 46, "swap": [46, 71, 614, 785, 786, 787, 790, 794, 861, 1279, 1470, 1471, 1587, 1588, 1828, 1861, 1864, 1886, 1908, 1917, 1919, 1926], "multihead_attention_tp": 46, "tensorparallelmultiheadattent": [46, 1858], "embed_dim": [46, 732, 1428], "num_head": [46, 732, 1428, 1861], "add_bias_kv": [46, 732, 1428], "add_zero_attn": [46, 732, 1428, 1861], "kdim": [46, 732, 1428], "vdim": [46, 732, 1428], "batch_first": [46, 731, 732, 757, 1374, 1392, 1428, 1437, 1438, 1465, 1467, 1469, 1636, 1638, 1639, 1641, 1861, 1890], "tp_size": 46, "self_attent": 46, "head": [46, 732, 1330, 1428, 1465, 1467, 1469], "fullyshardeddataparallel": [46, 1858], "enable_2d_with_fsdp": [46, 1858], "parameteriz": 47, "tensorflow": [47, 1675, 1883, 1922], "backpropag": [47, 906, 1676, 1707, 1890], "surrog": 47, "likelihood": [47, 1330, 1376, 1429, 1436, 1518, 1556, 1564], "reinforc": [47, 1451, 1574], "polici": [47, 49, 51, 63, 1683, 1689], "reparameter": [47, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632, 1633, 1634, 1646], "trick": [47, 901, 1339, 1523, 1883, 1891, 1893], "autoencod": 47, "whilst": [47, 1886], "densiti": [47, 301, 1151, 1152, 1772, 1861, 1918], "log_prob": [47, 1330, 1345, 1505, 1861], "theta": [47, 1486, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1861], "pi": [47, 174, 377, 695, 928, 1147, 1148, 1241, 1372, 1436, 1519, 1564, 1681, 1682, 1701, 1763, 1764, 1767, 1768, 1769, 1770, 1804, 1862, 1863, 1905, 1918], "reward": 47, "ascent": 47, "prob": [47, 1861], "policy_network": 47, "next_stat": 47, "rsampl": 47, "parameter": [47, 377, 453, 1196, 1879, 1917], "has_rsampl": 47, "batch_shap": 47, "event_shap": 47, "validate_arg": 47, "arg_constraint": 47, "cdf": 47, "cumul": [47, 1042, 1043, 1044, 1045, 1046, 1269, 1340, 1341, 1342, 1372, 1395, 1396, 1397, 1461, 1519], "mass": 47, "enumerate_support": 47, "discret": [47, 62, 480, 1079, 1080, 1081, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1092, 1093, 1098, 1100, 1523, 1772, 1922, 1925], "cardin": [47, 1291], "univari": 47, "singleton": [47, 254, 1394, 1842, 1884], "cartesian": [47, 936, 1291, 1701], "_instanc": 47, "icdf": 47, "perplex": 47, "sample_shap": 47, "sample_n": 47, "set_default_validate_arg": 47, "mimic": [47, 1689], "stddev": 47, "varianc": [47, 962, 1340, 1341, 1342, 1367, 1376, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1514, 1518, 1674, 1675, 1711, 1720, 1721, 1845, 1846, 1881, 1894], "exp_famili": 47, "famili": 47, "p_": [47, 940, 1281, 1677], "langl": 47, "rangl": 47, "denot": [47, 71, 962, 1210, 1229, 1235, 1248, 1258, 1350, 1351, 1388, 1611, 1614, 1677, 1790, 1791, 1792, 1794, 1795, 1847, 1891, 1911, 1914, 1917], "carrier": 47, "analyt": [47, 905, 906, 1512, 1917], "bregman": 47, "courtesi": 47, "frank": 47, "nielsen": 47, "richard": 47, "nock": 47, "logit": [47, 391, 1339, 1358, 1494, 1504, 1523, 1861, 1903, 1918], "70": [47, 1248, 1707, 1878], "lower_bound": 47, "upper_bound": 47, "has_enumerate_support": 47, "param_shap": 47, "concentration1": 47, "concentration0": 47, "concentr": 47, "1046": 47, "1st": [47, 1884], "2nd": [47, 614, 1430, 1456, 1559, 1884], "greaterthan": 47, "total_count": 47, "71": 47, "trial": 47, "integergreaterthan": 47, "ldot": [47, 1221, 1229, 1260, 1276, 1291, 1394, 1415, 1416, 1417, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "unnorm": [47, 1358, 1494, 1504, 1523], "likewis": [47, 1828], "25": [47, 494, 583, 584, 585, 938, 1151, 1257, 1262, 1368, 1425, 1427, 1430, 1593, 1602, 1639, 1641, 1667, 1689, 1708, 1844, 1860, 1918], "independentconstraint": 47, "simplex": 47, "loc": [47, 1261], "lorentz": 47, "3214": 47, "width": [47, 776, 782, 855, 1150, 1151, 1152, 1336, 1337, 1351, 1352, 1354, 1355, 1391, 1416, 1417, 1429, 1456, 1474, 1532, 1590, 1877], "df": 47, "chi": 47, "continuous_bernoulli": 47, "lim": [47, 1187], "499": 47, "501": 47, "2538": [47, 1221], "pervas": 47, "loaiza": 47, "ganem": 47, "cunningham": 47, "jp": 47, "1907": 47, "06845": 47, "8954": 47, "greaterthaneq": 47, "df1": 47, "df2": 47, "fisher": 47, "snedecor": 47, "2453": 47, "degre": [47, 962, 1040, 1047, 1190, 1227, 1228, 1422, 1431, 1470, 1602, 1715, 1735, 1802, 1803, 1845, 1846, 1861, 1891, 1903, 1917], "freedom": [47, 962, 1802, 1803, 1845, 1846, 1891], "0124": 47, "half_cauchi": 47, "half_norm": 47, "base_distribut": 47, "reinterpreted_batch_ndim": 47, "diagon": [47, 68, 225, 260, 592, 593, 594, 595, 929, 958, 962, 1050, 1051, 1052, 1054, 1063, 1076, 1124, 1125, 1135, 1219, 1231, 1233, 1236, 1248, 1252, 1561, 1571, 1788, 1827, 1831, 1832, 1833, 1834, 1835, 1861, 1888, 1903, 1921], "multivari": [47, 1918], "multivariate_norm": 47, "mvn": 47, "scale_tril": 47, "diag": [47, 69, 1123, 1124, 1125, 1225, 1226, 1253, 1697, 1788, 1808, 1809, 1861, 1903], "diagn": 47, "1729": [47, 1894], "lkj_choleski": 47, "lkj": 47, "matric": [47, 260, 683, 686, 918, 930, 931, 940, 941, 942, 943, 1051, 1135, 1210, 1219, 1220, 1221, 1223, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1239, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1252, 1253, 1254, 1262, 1270, 1279, 1281, 1294, 1373, 1431, 1486, 1520, 1609, 1614, 1695, 1697, 1707, 1756, 1782, 1785, 1786, 1808, 1809, 1831, 1832, 1834, 1861, 1876, 1891, 1897, 1917, 1923], "eta": [47, 1661, 1663, 1676], "proport": [47, 1390, 1391, 1428, 1469], "det": [47, 1227, 1228, 1249, 1270, 1861, 1903], "lkjcorr": 47, "onion": 47, "3x3": [47, 1046, 1829], "3516": 47, "9361": 47, "1899": [47, 1292], "4748": 47, "8593": 47, "vine": 47, "2009": [47, 1697, 1809], "lewandowski": 47, "dorota": 47, "kurowicka": 47, "harri": [47, 1772], "joe": 47, "journal": [47, 1714], "1016": 47, "jmva": 47, "04": [47, 1106, 1267, 1765, 1772], "008": 47, "corrcholeski": 47, "log_norm": [47, 1903], "lowrank_multivariate_norm": 47, "cov_factor": 47, "cov_diag": 47, "covari": [47, 931, 958, 962, 1340, 1341, 1342, 1461, 1697], "covariance_matrix": 47, "2102": 47, "5429": [47, 1831], "woodburi": 47, "lemma": 47, "capacit": 47, "precision_matrix": 47, "mixture_same_famili": 47, "mixture_distribut": 47, "component_distribut": 47, "rightmost": [47, 931, 1151, 1152, 1863], "gaussian": [47, 1372, 1376, 1451, 1518, 1519, 1574, 1771, 1918], "gmm": 47, "bivari": 47, "innermost": [47, 71, 1143, 1152, 1743], "1338": 47, "mathbf": [47, 1210, 1610, 1643, 1646, 1676], "sigma": [47, 174, 377, 757, 1339, 1373, 1374, 1375, 1392, 1393, 1451, 1452, 1520, 1574, 1610, 1643, 1766, 1802, 1803, 1845, 1846, 1861], "triangular": [47, 941, 942, 943, 1219, 1220, 1226, 1228, 1236, 1237, 1244, 1247, 1248, 1250, 1252, 1561, 1683, 1707, 1831, 1832, 1833, 1834, 1835], "positivedefinit": 47, "lowercholeski": 47, "negative_binomi": 47, "halfopeninterv": 47, "mu": [47, 377, 1675, 1677], "one_hot_categor": 47, "onehot": 47, "5623": 47, "nonneg": [47, 1471, 1697, 1809, 1918], "pmf": 47, "mathrm": [47, 920, 1227, 1228, 1229, 1230, 1241, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1431, 1436, 1461, 1609, 1664, 1665, 1666, 1676, 1711, 1883, 1918], "relaxed_bernoulli": 47, "temperatur": [47, 1523, 1858], "parametr": [47, 1119, 1611, 1618, 1643, 1644, 1879, 1888], "reparametriz": 47, "99": [47, 1201, 1675, 1860], "2951": [47, 1289], "3442": 47, "8918": 47, "9021": 47, "maddison": 47, "2017": [47, 1465, 1467, 1469, 1789, 1900], "reparametr": [47, 1523, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1626], "jang": 47, "relaxed_categor": 47, "1294": [47, 941], "2324": [47, 1190, 1422], "3859": 47, "2523": 47, "student": 47, "transformed_distribut": 47, "composit": [47, 68, 1123, 1237, 1609, 1860, 1863, 1889, 1894, 1901], "basedistribut": 47, "dx": [47, 1046, 1338, 1829, 1861, 1888, 1889, 1918], "dy": 47, "logist": [47, 1451, 1454, 1574, 1918], "sigmoidtransform": 47, "affinetransform": 47, "invert": [47, 71, 943, 1181, 1221, 1230, 1231, 1237, 1243, 1250, 1252, 1255, 1256, 1270, 1418, 1419, 1420, 1831, 1861, 1897, 1913], "3418": 47, "upper": [47, 182, 183, 184, 591, 792, 929, 934, 941, 942, 943, 945, 1077, 1078, 1150, 1151, 1219, 1220, 1226, 1228, 1236, 1237, 1248, 1252, 1440, 1561, 1569, 1570, 1683, 1689, 1707, 1722, 1743, 1831, 1834, 1835, 1861, 1881, 1903, 1918, 1924], "von_mis": 47, "circular": [47, 1350, 1351, 1352, 1398, 1399, 1400, 1559], "von": 47, "mise": 47, "unconstrain": [47, 1614], "angl": [47, 752, 881, 1047, 1270, 1408, 1701, 1715, 1759, 1858, 1861, 1903, 1917], "9777": 47, "radian": [47, 695, 881, 1047, 1715, 1861, 1903], "nichola": 47, "1979": 47, "152": [47, 614], "157": 47, "4784": [47, 1294], "symmetr": [47, 799, 817, 919, 928, 941, 942, 943, 1084, 1085, 1086, 1091, 1093, 1097, 1098, 1100, 1147, 1148, 1209, 1219, 1220, 1225, 1226, 1228, 1232, 1233, 1234, 1241, 1244, 1247, 1253, 1262, 1609, 1614, 1689, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1908, 1911], "x_ij": 47, "wu": [47, 1262], "chu": 47, "2018": [47, 1262, 1705], "sawyer": 47, "2007": 47, "anderson": 47, "w": [47, 69, 151, 757, 886, 888, 890, 896, 904, 919, 928, 962, 1121, 1132, 1147, 1148, 1187, 1229, 1328, 1329, 1336, 1337, 1339, 1341, 1342, 1346, 1351, 1352, 1358, 1362, 1363, 1365, 1366, 1367, 1374, 1386, 1387, 1394, 1405, 1406, 1416, 1417, 1427, 1428, 1429, 1434, 1435, 1456, 1472, 1473, 1475, 1476, 1486, 1494, 1512, 1513, 1521, 1556, 1562, 1563, 1610, 1643, 1646, 1861, 1876, 1877, 1881, 1883, 1888, 1891, 1904, 1905, 1922], "2003": 47, "ed": [47, 68, 1361, 1362, 1883, 1905, 1928], "odel": 47, "feiveson": 47, "1966": 47, "samplecovari": 47, "jasa": 47, "61": 47, "313": 47, "199": 47, "203": [47, 614], "ku": 47, "bloomfield": 47, "2010": [47, 1881], "ox": 47, "max_try_correct": 47, "bartlett": [47, 919], "singular": [47, 1221, 1235, 1236, 1242, 1244, 1246, 1247, 1253, 1254, 1262, 1270, 1279, 1610, 1614, 1697, 1808, 1809, 1897], "kl_diverg": 47, "kullback": [47, 1388, 1533], "leibler": [47, 1388, 1533], "register_kl": 47, "type_p": 47, "type_q": 47, "kl_normal_norm": 47, "ambigu": [47, 71, 1175, 1353, 1354, 1355, 1369, 1418, 1419, 1420, 1474, 1863], "runtimewarn": 47, "basep": 47, "derivedq": 47, "kl_version1": 47, "derivedp": 47, "baseq": 47, "kl_version2": 47, "tie": 47, "abstransform": 47, "event_dim": 47, "affin": [47, 471, 472, 473, 474, 475, 746, 748, 749, 750, 799, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1486, 1886, 1894], "cattransform": 47, "tseq": 47, "functor": [47, 1006, 1007], "submatrix": 47, "t0": [47, 1143, 1661, 1862], "exptransform": 47, "identity_transform": 47, "composetransform": 47, "corrcholeskytransform": 47, "uncontrain": 47, "euclidean": [47, 938, 1557], "x_i": [47, 68, 945, 1042, 1043, 1044, 1045, 1258, 1265, 1412, 1431, 1455, 1457, 1470, 1541, 1577, 1704, 1787, 1802, 1803, 1829, 1845, 1846, 1847, 1918], "stickbreakingtransform": 47, "r_i": 47, "tanh": [47, 574, 757, 762, 792, 882, 1372, 1374, 1375, 1392, 1393, 1421, 1437, 1439, 1463, 1519, 1551, 1583, 1859, 1861, 1876, 1877, 1881, 1903, 1910, 1917], "unsign": [47, 1911, 1920, 1923, 1924], "z_i": 47, "s_i": 47, "y_i": [47, 945, 1042, 1043, 1044, 1045, 1258, 1265, 1470, 1829, 1847, 1891], "sqrt": [47, 71, 377, 546, 670, 671, 757, 958, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1156, 1209, 1291, 1340, 1341, 1342, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1372, 1374, 1375, 1377, 1385, 1386, 1387, 1390, 1391, 1392, 1393, 1394, 1407, 1409, 1437, 1439, 1461, 1519, 1571, 1614, 1662, 1663, 1664, 1665, 1668, 1674, 1675, 1711, 1738, 1771, 1802, 1803, 1859, 1861, 1876, 1881, 1882, 1883, 1903, 1917, 1918, 1924], "cumulativedistributiontransform": 47, "copula": 47, "base_dist": 47, "independenttransform": 47, "base_transform": 47, "log_abs_det_jacobian": 47, "lowercholeskytransform": 47, "positivedefinitetransform": 47, "powertransform": 47, "expon": [47, 268, 269, 280, 467, 468, 1106, 1113, 1213, 1243, 1330, 1410, 1557, 1704, 1714, 1859, 1861, 1920, 1923], "reshapetransform": 47, "in_shap": 47, "out_shap": 47, "softplustransform": 47, "tanhtransform": 47, "softmaxtransform": 47, "biject": 47, "hmc": 47, "stacktransform": 47, "stick": 47, "primarili": [47, 70, 812, 813, 814, 820, 1322, 1873, 1908], "_call": 47, "_invers": 47, "codomain": [47, 1883], "iff": [47, 1428], "weaker": [47, 1886], "pseudoinvers": [47, 1230, 1247, 1255], "monoton": [47, 1421, 1551, 1743], "forward_shap": 47, "inverse_shap": 47, "corr_choleski": 47, "greater_than": 47, "greater_than_eq": 47, "integer_interv": 47, "less_than": 47, "lower_choleski": 47, "lower_triangular": 47, "nonnegative_integ": 47, "one_hot": [47, 1861, 1903], "positive_integ": 47, "positive_semidefinit": 47, "positive_definit": 47, "real_vector": 47, "unit_interv": 47, "is_discret": 47, "_cat": 47, "dependent_properti": 47, "_dependentproperti": 47, "_greaterthan": 47, "_greaterthaneq": 47, "_independentconstraint": 47, "_integerinterv": 47, "_interv": 47, "half_open_interv": 47, "_halfopeninterv": 47, "_lessthan": 47, "_multinomi": 47, "_stack": [47, 1903], "constraintregistri": 47, "biject_to": 47, "transform_to": 47, "overparameter": 47, "rotat": [47, 1735, 1808], "hamiltonian": 47, "mont": 47, "carlo": 47, "potential_energi": 47, "cheap": [47, 1330], "svi": 47, "fewer": [47, 68, 690, 692, 693, 696, 944, 1210, 1211, 1277, 1287, 1289, 1290, 1292, 1295, 1317, 1320, 1376, 1503, 1705, 1789, 1802, 1803, 1807, 1825, 1845, 1846, 1869, 1884, 1899, 1924], "my_constraint": 47, "my_transform": 47, "myconstraintclass": 47, "my_factori": 47, "mytransform": 47, "param1": [47, 1894], "param2": [47, 1894], "constraint_registri": 47, "my_registri": 47, "construct_transform": 47, "myconstraint": 47, "from_dlpack": [48, 877, 1858], "ext_tensor": [48, 1114], "extern": [48, 967, 1114, 1205, 1873, 1885, 1886, 1897, 1901], "immut": [48, 1114, 1863], "__dlpack__": [48, 1114], "capsul": [48, 877, 1114], "ndarrai": [48, 457, 876, 1114, 1115, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1901, 1922, 1924], "pycapsul": [48, 1114], "to_dlpack": [48, 1114, 1858], "dltensor": [48, 1114], "t3": [48, 1114, 1914], "legaci": [48, 59, 1523, 1907, 1920], "idiomat": 48, "plane": [49, 58, 735, 736, 737, 738, 739, 740, 763, 764, 765, 766, 769, 770, 771, 779, 780, 1051, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1370, 1371, 1390, 1391, 1394, 1410, 1415, 1416, 1417, 1480, 1481, 1482, 1483, 1484, 1485, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1516, 1517, 1539, 1542, 1543, 1545, 1546, 1547, 1646, 1712, 1713, 1735], "monitor": [49, 59, 60, 966, 1691, 1858, 1886, 1892], "unhealthi": 49, "tear": 49, "decentr": 49, "elasticag": 49, "quad": [49, 1338, 1339, 1358, 1389, 1413, 1429, 1471], "group_result": 49, "is_fail": [49, 50], "exit_cod": 49, "get_worker_group": 49, "workergroup": [49, 59], "mutabl": [49, 1205, 1860, 1905, 1922], "implementor": 49, "defens": 49, "retri": [49, 51, 60, 63, 1020, 1913, 1915], "max_restart": [49, 50, 59], "runresult": 49, "workerspec": [49, 50, 59, 60], "local_world_s": [49, 50, 59], "rdzv_handler": [49, 50, 58], "monitor_interv": [49, 50], "local_addr": [49, 58], "tee": [49, 56], "blueprint": 49, "spec": [49, 50, 60, 85, 790, 791, 816, 817, 818, 821, 822, 823, 1910], "homogen": [49, 59], "rendezvoushandl": [49, 50, 58, 59], "rdzv": [49, 57, 59], "consol": [49, 52, 55, 56, 59, 1922], "get_entrypoint_nam": 49, "__qualname__": 49, "workerst": 49, "unknown": [49, 1604, 1605, 1915], "unrecover": 49, "interrupt": [49, 1875], "termin": [49, 58, 60, 71, 1667, 1875, 1913], "uncaught": [49, 51], "unhandl": 49, "recov": [49, 892, 1084, 1249, 1281, 1602, 1635, 1804, 1882, 1890, 1891, 1909], "is_run": 49, "role_rank": [49, 59], "role_world_s": [49, 59], "pid": [49, 51, 59, 60, 1461, 1890, 1907], "local_elastic_ag": 49, "localelasticag": [49, 50, 60], "start_method": [49, 50, 56, 60, 1875], "exit_barrier_timeout": 49, "log_dir": [49, 56, 1873, 1922], "inter": [49, 51, 1140, 1754, 1885, 1887, 1906, 1913], "advis": [49, 541, 614, 862, 1896], "pipe": [49, 60, 1858, 1913], "torchelastic_enable_file_tim": 49, "torchelastic_timer_fil": 49, "shared_queu": 49, "get_context": [49, 60, 1896], "nproc_per_process": 49, "foobar": [49, 51, 55, 56], "other_param": [49, 60], "usr": [49, 56, 58, 1886], "simpleelasticag": 49, "scaffold": 49, "_assign_worker_rank": 49, "group_world_s": 49, "_exit_barri": 49, "_initialize_work": 49, "worker_group": 49, "fresh": [49, 1054, 1746, 1777, 1857], "start_work": 49, "_stop_work": 49, "optimist": 49, "deleg": 49, "_monitor_work": 49, "_rendezv": 49, "_restart_work": 49, "_shutdown": 49, "death_sig": 49, "sigterm": 49, "_start_work": 49, "gracefulli": [49, 59, 68, 1220, 1889], "meaningless": 49, "intention": [49, 1060, 1847, 1892, 1913], "ship": [50, 1120, 1885, 1913], "programmat": [50, 71, 1894], "my_launch": 50, "argv": [50, 61], "trainer_entrypoint_fn": 50, "fn_arg": 50, "run_result": 50, "myrendezvoushandl": 50, "elastic_ag": 50, "metrichandl": [50, 55], "mymetrichandl": 50, "metric_data": [50, 55], "metricdata": 50, "sink": [50, 55, 1873], "eventhandl": 50, "cloudwatch": 50, "nulleventhandl": 50, "myeventhandl": 50, "start_process": [51, 56, 1875], "torchelastic_error_fil": 51, "error_handl": 51, "sugar": [51, 1862], "get_error_handl": 51, "childfailederror": 51, "get_first_failur": 51, "dump_error_fil": 51, "error_fil": [51, 56], "exitcod": [51, 59], "nanni": 51, "diagnost": [51, 72, 77, 78, 79, 80, 81, 82, 83, 84, 1656, 1858, 1860], "torchelastic_ag": 51, "trainer_0": 51, "trainer_1": 51, "trainer_n": 51, "errorhandl": 51, "record_except": 51, "processfailur": 51, "test_ev": 52, "eventsourc": 52, "get_logging_handl": 52, "millisecond": [52, 55, 966, 1873], "eventmetadatavalu": 52, "telemetri": 55, "timeseri": 55, "metric_group": 55, "metric_nam": 55, "sensibl": 55, "my_modul": [55, 63, 71, 1860, 1905], "nullmetricshandl": 55, "consolemetricshandl": 55, "my_method": 55, "put_metr": 55, "calculate_lat": 55, "succinctli": 55, "baz": [55, 71, 851, 1905, 1924], "leaf_modul": 55, "classnam": [55, 1863], "threw": 55, "my_app": 55, "consolemetrichandl": 55, "stdout": [55, 56, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1693, 1901], "stdoutmetrichandl": 55, "1574213883": 55, "4182858": 55, "my_metr": 55, "1574213940": 55, "5237644": 55, "nullmetrichandl": 55, "class_nam": [55, 71], "def_nam": 55, "metric_valu": 55, "metric_group_nam": 55, "popen": 56, "stderr": [56, 1857, 1872], "err": 56, "echo": 56, "hello": [56, 68, 1862, 1901, 1905], "pcontext": 56, "multiprocesscontext": 56, "subprocesscontext": 56, "keyset": 56, "bitmask": 56, "mask": [56, 399, 400, 401, 402, 403, 541, 732, 905, 906, 1283, 1334, 1345, 1367, 1428, 1465, 1466, 1467, 1468, 1469, 1514, 1571, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1678, 1858, 1861, 1876, 1877, 1917], "bar0": 56, "bar1": 56, "file1": 56, "file2": 56, "caution": 56, "short": [56, 71, 731, 760, 1063, 1187, 1345, 1392, 1393, 1505, 1658, 1756, 1804, 1862, 1876, 1883, 1884, 1894, 1913, 1919, 1920, 1923], "ing": 56, "cmd": [56, 59], "forkserv": [56, 1602, 1875, 1896], "tee_stdout": 56, "tee_stderr": 56, "processcontext": [56, 1875], "superset": [56, 59], "runprocsresult": 56, "num_nod": [57, 59], "trainers_per_nod": 57, "num_allowed_failur": 57, "job_id": [57, 58, 59], "endpoint": [57, 58, 59], "host_node_addr": [57, 59], "min_siz": [57, 59], "num_allowed_failures_or_membership_chang": 57, "node1": [57, 59], "29400": [57, 59], "sidecar": [57, 58], "agre": [58, 1248, 1915], "resum": [58, 1683, 1689, 1691, 1913, 1915, 1922], "retryabl": 58, "lose": [58, 61, 63, 192, 209, 1877], "train_loop": [58, 859], "arriv": [58, 59, 1913, 1915], "dynamicrendezvoushandl": 58, "rendezvousbackend": 58, "c10drendezvousbackend": 58, "etcdrendezvousbackend": 58, "supersed": 58, "etcdrendezvoushandl": 58, "my_run_id": 58, "from_backend": 58, "run_id": [58, 59], "min_nod": 58, "max_nod": 58, "rendezvousparamet": 58, "admit": [58, 59, 1886], "get_as_bool": 58, "get_as_int": 58, "rendezvoushandlerregistri": 58, "create_handl": 58, "creator": [58, 1883, 1913, 1915], "get_run_id": 58, "is_clos": 58, "set_clos": 58, "next_rendezv": 58, "rendezvousclosederror": 58, "rendezvousconnectionerror": 58, "rendezvousstateerror": 58, "rendezvoustimeouterror": 58, "num_nodes_wait": 58, "shutdown": [58, 1913, 1914], "rendezvouserror": 58, "dynamic_rendezv": 58, "join_timeout": 58, "600": 58, "last_call_timeout": 58, "close_timeout": 58, "rendezvoustimeout": 58, "get_stat": [58, 89], "fenc": 58, "set_stat": [58, 89], "condition": [58, 1753], "last_cal": 58, "heartbeat": 58, "keep_al": 58, "c10d_rendezvous_backend": 58, "create_backend": 58, "store_typ": 58, "tcp": [58, 59, 1913], "read_timeout": 58, "60": [58, 60, 1376, 1693, 1819, 1824, 1873, 1913], "is_host": 58, "cname": 58, "fqdn": [58, 59], "etcd_rendezvous_backend": 58, "ssl_cert": 58, "ssl": 58, "certif": 58, "ssl_cert_kei": 58, "ca_cert": 58, "rool": 58, "key_prefix": 58, "ttl": 58, "hour": 58, "etcd_rendezv": 58, "rdzv_impl": 58, "etcdrendezv": 58, "etcd_address": 58, "min_work": 58, "max_work": 58, "noqa": 58, "w605": 58, "2379": [58, 1287], "etcd_prefix": 58, "etcdstor": 58, "etcd_stor": 58, "etcd_client": 58, "etcd_store_prefix": 58, "piggyback": 58, "num": [58, 742, 743, 757, 1312, 1374, 1377, 1392, 1428, 1437, 1465], "lookuperror": 58, "override_timeout": 58, "etcdserv": 58, "cumbersom": [58, 1863], "etcd_serv": 58, "data_dir": 58, "v3": [58, 59], "substitut": [58, 71, 1202, 1883, 1920], "torchelastic_etcd_binary_path": 58, "get_client": 58, "etcd_binary_path": 58, "migrat": [59, 64, 1291, 1911], "train_script": 59, "aforment": 59, "suffic": [59, 71], "compliant": [59, 61], "num_train": 59, "wors": [59, 1843], "port_k": 59, "etcd": 59, "v2": [59, 1258, 1696, 1857], "revis": 59, "localworkergroup": 59, "rdzv_id": 59, "rdzv_backend": [59, 61], "rdzv_endpoint": [59, 61], "max_nnod": 59, "torchelastic_restart_count": 59, "torchelastic_max_restart": 59, "python_exec": 59, "gang": 59, "departur": 59, "surviv": 59, "kill": [59, 60, 1875, 1890], "load_checkpoint": [59, 61], "checkpoint_path": [59, 61], "dataset": [59, 61, 795, 1330, 1339, 1388, 1858, 1890, 1893, 1900, 1904, 1908, 1909, 1922], "train_step": 59, "should_checkpoint": 59, "save_checkpoint": [59, 61], "acquir": [60, 71, 1894, 1915, 1917], "deadlin": 60, "message_queu": 60, "localtimerserv": 60, "max_interv": 60, "trainer_func": 60, "localtimercli": 60, "expiri": 60, "timer_cli": 60, "countdown": 60, "timefram": [60, 1913], "elig": [60, 1915], "reap": 60, "timerserv": 60, "mp_queue": 60, "daemon": [60, 1875], "filetimerserv": 60, "file_path": 60, "log_ev": [60, 1873], "filetimercli": 60, "fifo": 60, "watchdog": 60, "filetimerrequest": 60, "sigkil": 60, "named_pip": 60, "mkfifo": 60, "timercli": 60, "timerrequest": 60, "scope_id": 60, "expiration_tim": 60, "acquisit": 60, "request_queu": 60, "entiti": [60, 71], "clear_tim": 60, "get_expired_tim": 60, "register_tim": 60, "timer_request": 60, "use_env": 61, "expositori": 61, "worst": [61, 1888], "total_num_epoch": 61, "sharding_strategi": 63, "cpu_offload": 63, "auto_wrap_polici": 63, "backward_prefetch": 63, "backwardprefetch": [63, 1858], "backward_pr": [63, 1190, 1422], "mixed_precis": [63, 1602], "ignored_modul": 63, "param_init_fn": 63, "sync_module_st": 63, "forward_prefetch": 63, "limit_all_gath": 63, "use_orig_param": 63, "ignored_st": 63, "deepspe": 63, "shorten": 63, "sharded_modul": 63, "0001": [63, 71, 1044, 1234, 1410, 1539, 1661, 1691, 1861, 1904], "stale": 63, "dev_id": 63, "no_sync": [63, 1602], "offload": 63, "ping": 63, "77724": 63, "summon_full_param": 63, "shardingstrategi": [63, 1858], "shard_grad_op": 63, "unshard": 63, "full_shard": 63, "with_grad": 63, "reacquir": 63, "hybrid_shard": 63, "cpuoffload": [63, 1858], "_fsdppolici": 63, "modulewrappolici": 63, "nonwrapped_numel": 63, "subtre": 63, "size_based_auto_wrap_polici": 63, "exce": [63, 1267, 1886], "100m": 63, "numel": [63, 434, 443, 948, 962, 1094, 1175, 1861, 1876, 1883, 1903, 1917], "custom_auto_wrap_polici": 63, "min_num_param": 63, "1e8": 63, "my_auto_wrap_polici": 63, "functool": [63, 66, 838, 1888, 1924], "1e5": 63, "mixedprecis": [63, 1858], "is_meta": [63, 1903], "reset_paramet": 63, "torchdistx": 63, "deferred_init": 63, "materialize_modul": 63, "my_init_fn": 63, "fsdp_model": 63, "fullstatedictconfig": 63, "flight": 63, "named_paramet": [63, 65, 67, 1119, 1190, 1194, 1422, 1894, 1899], "flatparamet": 63, "ignored_paramet": 63, "norm_typ": [63, 742, 743, 1365, 1366, 1390, 1391, 1512, 1513, 1542, 1543, 1606, 1861], "infin": [63, 960, 1180, 1182, 1184, 1185, 1316, 1338, 1415, 1416, 1417, 1545, 1546, 1547, 1606, 1666, 1776, 1787, 1917, 1918], "no_shard": 63, "flatten_sharded_optim_state_dict": 63, "sharded_optim_state_dict": 63, "shard_full_optim_state_dict": 63, "unflatten": [63, 1861, 1876, 1877, 1903, 1921], "fsdp_modul": 63, "root_onli": 63, "full_optim_state_dict": 63, "optim_input": 63, "rank0_onli": 63, "convent": [63, 71, 335, 939, 1063, 1081, 1083, 1107, 1129, 1340, 1341, 1342, 1385, 1386, 1387, 1461, 1736, 1739, 1837, 1857, 1872, 1878, 1883, 1891, 1894, 1899], "load_optim_state_dict_pre_hook": 63, "optim_state_dict": 63, "namedoptim": 63, "optim_state_dict_to_load": 63, "named_buff": [63, 1190, 1422, 1894, 1899], "state_dict_typ": 63, "oom": [63, 1890], "unflattend": 63, "statedicttyp": 63, "fulloptimstatedictconfig": 63, "set_state_dict_typ": 63, "full_state_dict": 63, "save_a_checkpoint": 63, "load_a_checkpoint": 63, "optim_state_dict_post_hook": 63, "is_named_optim": 63, "load_directli": 63, "original_osd": 63, "keyedoptim": 63, "torchrec": [63, 1858], "gossipgrad": [63, 1602], "latter": [63, 684, 788, 1190, 1392, 1422, 1429, 1889, 1894, 1896, 1898], "rekey_optim_state_dict": 63, "optim_state_key_typ": 63, "loadabl": [63, 1857], "wrapped_model": 63, "wrapped_optim": 63, "full_osd": 63, "nonwrapped_model": 63, "nonwrapped_optim": 63, "rekeyed_osd": 63, "optimstatekeytyp": 63, "param_id": 63, "osd": 63, "param_nam": 63, "sharded_osd": 63, "scatter_full_optim_state_dict": 63, "new_model": 63, "new_optim": 63, "remap": [63, 89, 1194, 1197, 1261, 1282, 1857, 1872, 1912], "state_dict_config": 63, "optim_state_dict_config": 63, "descend": [63, 71, 137, 539, 873, 1190, 1253, 1254, 1422, 1781, 1808, 1861], "transpar": [63, 1887, 1906, 1913, 1915], "sharded_state_dict": 63, "shardedstatedictconfig": 63, "offload_to_cpu": 63, "optimstatedictconfig": 63, "param_state_dict": 63, "statedictconfig": 63, "statedictset": 63, "writeback": 63, "summon": 63, "discard": [63, 1187, 1247, 1612, 1857, 1862, 1873], "redundantli": [63, 1882], "materi": [63, 897, 955, 1604, 1605, 1678, 1731, 1732, 1888], "throughput": [63, 1860, 1885], "contend": 63, "backward_post": 63, "reorder": [63, 1083, 1245], "volum": [63, 1152], "_hybrid_shard_zero2": 63, "param_dtyp": 63, "reduce_dtyp": 63, "buffer_dtyp": 63, "keep_low_precision_grad": 63, "cast_forward_input": 63, "cast_root_forward_input": 63, "_module_classes_to_ignor": 63, "batchnorm": [63, 697, 698, 1128, 1190, 1199, 1422, 1461, 1602, 1871, 1883, 1894, 1904, 1906, 1908, 1910, 1911], "_batchnorm": 63, "permit": [63, 1917], "thereaft": 63, "upcast": 63, "offload_param": 63, "love": 64, "hear": 64, "arbitrarili": [64, 69, 511, 1193, 1486, 1863, 1883, 1889], "stock": [64, 69], "ensembl": [64, 67, 69, 1129], "maml": [64, 69], "vjp": [64, 67, 68, 886, 887, 1125, 1131, 1850, 1888, 1889], "whirlwind": 64, "tour": 64, "running_mean": [66, 1128, 1190, 1340, 1341, 1342, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1461, 1491, 1531, 1859, 1861, 1894, 1899], "running_var": [66, 1128, 1190, 1340, 1341, 1342, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1461, 1491, 1531, 1859, 1861, 1899], "groupnorm": [66, 1522], "anywher": [66, 1882], "batchnorm2d": [66, 710, 713, 715, 720, 811, 1199, 1359, 1396, 1491, 1871, 1883, 1894, 1908, 1910], "track_running_stat": [66, 748, 749, 750, 1128, 1340, 1341, 1342, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1899], "resnet": [66, 1857, 1860, 1862, 1894, 1905, 1922, 1926], "regnet": 66, "norm_lay": 66, "num_group": [66, 746, 1377, 1522, 1861], "fragil": 66, "replace_all_batch_norm_modules_": 66, "upstream": [67, 1900], "kept": [67, 71, 694, 776, 782, 1340, 1341, 1342, 1385, 1386, 1387, 1461, 1532, 1590, 1863, 1875, 1911], "jvp": [67, 68, 887, 891, 892, 893, 897, 1127, 1888], "jacfwd": [67, 68, 900, 1123, 1889], "make_functional_with_buff": 67, "hurri": 67, "emul": [67, 796, 1864, 1888], "fmodel": 67, "compute_loss": [67, 69, 1119, 1121], "predict": [67, 1330, 1339, 1376, 1504, 1904, 1922], "argnum": [67, 1121, 1122, 1123, 1124, 1125], "stack_module_st": 67, "num_model": [67, 1129], "in_featur": [67, 717, 725, 726, 729, 730, 753, 761, 1129, 1190, 1330, 1407, 1409, 1422, 1593, 1609, 1610, 1642, 1643, 1646, 1894], "out_featur": [67, 717, 725, 726, 729, 730, 753, 761, 1129, 1190, 1343, 1407, 1409, 1422, 1593, 1609, 1610, 1642, 1643, 1646, 1894], "base_model": 67, "deepcopi": [67, 1908, 1927], "clearer": [67, 1246, 1678, 1888, 1902], "call_single_model": 67, "stori": [67, 1891], "grad_x": [68, 1889], "has_aux": [68, 1121, 1122, 1124, 1125, 1126, 1130], "mental": [68, 1120], "absenc": 68, "unbind": [68, 1131, 1850, 1858, 1861, 1876, 1903, 1921], "lst": 68, "in_dim": [68, 69, 889, 1121, 1131, 1850, 1889], "batchedtensor": 68, "batched_tensor_input": 68, "new_": [68, 1886, 1923], "new_zero": [68, 1861, 1903], "new_empti": [68, 1861, 1903], "diag_emb": [68, 1053, 1225, 1226, 1253, 1808, 1861, 1903], "vec": [68, 108, 109, 423, 687, 1314, 1645, 1859, 1861, 1917], "copy_": [68, 222, 1120, 1474, 1860, 1861, 1876, 1886, 1919], "arithmet": [68, 923, 926, 940, 1245, 1733, 1864, 1873, 1876, 1877, 1897, 1908, 1920], "extra_arg": 68, "theoret": 68, "custom_dot": 68, "lax": 68, "cond": [68, 1897], "while_loop": 68, "is_nonzero": [68, 1861, 1903, 1917], "rag": 68, "unclear": [68, 614], "add_nois": 68, "prng": 68, "cos_x": [69, 1121], "neg_sin_x": [69, 1121], "hide": [69, 1131, 1850, 1889], "feature_s": [69, 1121, 1131, 1850], "feature_vec": [69, 1121, 1131, 1850], "mseloss": [69, 1121, 1383, 1453, 1552, 1886, 1887], "grad_weight_per_exampl": [69, 1121], "cotang": [69, 1130], "vjp_fn": [69, 1130], "out_tang": 69, "hessian0": 69, "hessian1": 69, "hess": [69, 1123], "rpc_async": [70, 1863, 1903, 1913, 1915], "add_done_callback": 70, "fut": [70, 1193, 1602, 1885, 1913], "set_result": [70, 1602, 1913], "haven": [70, 1894], "set_except": 70, "baseexcept": 70, "slow_set_futur": 70, "sleep": 70, "cb1": 70, "cb2": 70, "dedic": [70, 1886], "didn": [70, 1888, 1900, 1904], "cb_fut": 70, "chain_cb_fut": 70, "cb": [70, 1913], "collect_al": [70, 1858], "fut0": 70, "fut1": [70, 1913], "fut_list": 70, "wait_al": [70, 1858], "toolkit": 71, "clamp": [71, 187, 188, 796, 799, 946, 1196, 1338, 1376, 1521, 1532, 1590, 1859, 1861, 1871, 1876, 1901, 1903, 1908, 1910, 1911, 1918, 1924], "get_attr": 71, "theses": 71, "callsit": 71, "constitut": 71, "tracer_class": 71, "treatment": 71, "topk": [71, 1859, 1861, 1876, 1903], "linear_weight": 71, "add_1": [71, 1120], "linear_1": 71, "relu_1": 71, "topk_1": 71, "pose": [71, 1914], "explor": [71, 1857, 1883, 1894, 1905], "edit": [71, 1905, 1921], "lint": 71, "new_nod": 71, "tediou": 71, "unwieldi": 71, "machineri": [71, 1888], "imagin": [71, 1913], "requisit": 71, "relu_decomposit": 71, "decomposition_rul": 71, "constitu": [71, 1878], "new_graph": 71, "graphappendingtrac": 71, "proxy_arg": 71, "output_proxi": 71, "node_copi": 71, "ari": [71, 1901], "unari": [71, 1124, 1125, 1465, 1467, 1469, 1864, 1876], "organiz": 71, "shapeprop": 71, "named_modul": [71, 1190, 1422, 1894], "args_it": 71, "load_arg": 71, "map_arg": 71, "fetch_attr": 71, "target_atom": 71, "attr_itr": 71, "nonexist": [71, 1862, 1863], "self_obj": 71, "encompass": 71, "prove": [71, 1875], "disprov": 71, "led": 71, "auxiliari": [71, 1121, 1122, 1124, 1125, 1126, 1130, 1857, 1893], "unord": [71, 1423, 1432], "nondetermin": [71, 906, 1898], "dedupl": 71, "torchvis": [71, 1857, 1858, 1860, 1862, 1901, 1905, 1908, 1922, 1926], "transformed_resnet18": 71, "input_imag": 71, "224": [71, 858, 859, 1860, 1862, 1901], "margin": [71, 1356, 1382, 1414, 1425, 1427, 1470, 1471, 1502, 1529, 1544, 1553, 1587, 1588, 1861, 1922], "commut": 71, "toolbox": 71, "tradit": 71, "luckili": 71, "my_pass": 71, "my_module_transform": 71, "input_valu": 71, "prompt": [71, 1857, 1900], "set_trac": [71, 1195, 1201, 1207, 1860], "examin": [71, 1894, 1901, 1907], "undergon": 71, "subclassm": 71, "untrac": 71, "pre_trac": 71, "post_trac": 71, "sake": 71, "tabular": [71, 677, 1869], "transform_graph": 71, "session": 71, "luck": 71, "input_nod": 71, "stepwis": 71, "onlin": [71, 1663], "realpython": 71, "pycharm": 71, "vscode": 71, "graphic": [71, 1900], "parlanc": 71, "func_to_trac": 71, "dyn": 71, "155": 71, "__bool__": [71, 1861, 1863], "to_bool": 71, "traceerror": [71, 1908], "architectur": [71, 990, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1358, 1465, 1504, 1752, 1886, 1897, 1908], "hyper": [71, 1453, 1862, 1922], "do_activ": 71, "512": [71, 1465, 1466, 1467, 1468, 1469, 1886], "without_activ": 71, "with_activ": 71, "traced_without_activ": 71, "traced_with_activ": 71, "concrete_arg": 71, "truli": [71, 1901], "__torch_function__": [71, 1928], "161": 71, "len_1": 71, "sqrt_1": 71, "mycustomtrac": 71, "traced_graph": 71, "myspecialsubmodul": 71, "submod": 71, "neg_1": 71, "is_leaf_modul": [71, 1927], "sparse_coo_tensor": [71, 541, 578, 1789, 1861, 1865, 1903, 1917], "ones_lik": [71, 1124, 1125, 1130, 1861, 1878, 1886, 1889, 1894, 1903], "zeros_lik": [71, 895, 897, 1861, 1865, 1878, 1886, 1903, 1917], "viabl": [71, 1886], "torch_randn": 71, "gotcha": 71, "bake": [71, 1194, 1199, 1664, 1665, 1904], "dropoutrepro": 71, "assert_clos": [71, 1080, 1082, 1083, 1088, 1089, 1094, 1095, 1096, 1098, 1100, 1858, 1860, 1924], "greatest": [71, 1133, 1316, 1901, 1924], "6207983493804932": 71, "dropoutrepro2": 71, "pytre": [71, 1889], "overspeci": 71, "ph": 71, "shouldn": [71, 964, 1905, 1917, 1921], "fn_or_nam": 71, "callfunct": 71, "fn_to_be_trac": 71, "reassign": [71, 1886], "regener": 71, "unset": [71, 1897], "add_submodul": 71, "subpath": 71, "get_submodul": [71, 1190, 1422], "delete_all_unused_submodul": 71, "delete_submodul": 71, "print_read": 71, "print_output": 71, "date": [71, 1905], "pythoncod": 71, "fxmodul": 71, "pathlik": [71, 1261, 1739, 1905], "owning_modul": 71, "tracer_cl": 71, "tracer_extra": 71, "the_funct": 71, "type_expr": 71, "create_nod": 71, "method_nam": 71, "0th": [71, 1131, 1850], "inserting_befor": 71, "influenc": [71, 1655, 1901, 1917], "eliminate_dead_cod": 71, "topolog": [71, 1901], "attr_1": 71, "is_impur": 71, "erase_nod": 71, "to_eras": 71, "qualified_nam": 71, "graph_copi": 71, "val_map": 71, "return_output_nod": 71, "slice": [71, 604, 692, 693, 1340, 1341, 1342, 1455, 1457, 1461, 1577, 1578, 1728, 1745, 1746, 1777, 1787, 1838, 1859, 1860, 1864, 1878, 1901, 1903, 1917, 1918, 1921, 1923], "memory_format": [71, 156, 171, 173, 176, 179, 180, 181, 190, 196, 207, 210, 240, 267, 297, 325, 331, 393, 497, 498, 522, 577, 947, 1064, 1065, 1118, 1190, 1422, 1602, 1654, 1717, 1719, 1721, 1856, 1858, 1859, 1861, 1924], "layout": [71, 151, 192, 209, 342, 343, 434, 444, 445, 446, 447, 448, 457, 541, 578, 579, 580, 581, 582, 584, 585, 614, 686, 862, 890, 892, 919, 928, 979, 1064, 1065, 1066, 1076, 1081, 1099, 1117, 1118, 1147, 1148, 1209, 1260, 1276, 1284, 1294, 1322, 1538, 1653, 1654, 1678, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1785, 1786, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1828, 1833, 1835, 1855, 1856, 1857, 1858, 1859, 1860, 1861, 1862, 1865, 1878, 1886, 1903, 1905, 1917, 1922, 1923, 1924], "companion": 71, "__exit__": [71, 1863, 1864, 1905], "arg_transform": 71, "value_remap": 71, "_node_list": 71, "doubli": 71, "on_generate_cod": 71, "make_transform": 71, "transformcodefunc": 71, "insert_pdb": 71, "current_tran": 71, "default_valu": 71, "_not_": 71, "tabul": 71, "process_input": 71, "process_output": 71, "python_cod": 71, "root_modul": [71, 790, 1910], "set_codegen": 71, "return_typ": [71, 694, 1042, 1043, 1152, 1211, 1249, 1287, 1290, 1292, 1295, 1318, 1781, 1826, 1831], "all_input_nod": 71, "format_nod": 71, "placeholder_nam": 71, "maybe_return_typenam": 71, "autogener": [71, 1889], "impur": 71, "normalized_argu": 71, "arg_typ": 71, "kwarg_typ": 71, "normalize_to_only_use_kwarg": 71, "vararg": 71, "argskwargspair": 71, "bx": 71, "ax": [71, 1221, 1235, 1239, 1250, 1251, 1252, 1280, 1291, 1430, 1440, 1831, 1901], "prev": [71, 1676], "replace_with": 71, "delete_user_cb": 71, "propagate_meta": 71, "replace_input_with": 71, "old_input": 71, "new_input": 71, "create_proxi": 71, "record_stack_trac": 71, "update_arg": 71, "update_kwarg": 71, "autowrap_modul": 71, "autowrap_funct": 71, "create_arg": 71, "create_args_for_root": 71, "root_fn": 71, "is_modul": 71, "proxy_factory_fn": 71, "attr": [71, 151, 890, 1291, 1736], "attr_val": 71, "parameter_proxy_cach": 71, "module_qualified_nam": [71, 1927], "path_of_modul": 71, "some_hyperparamet": 71, "indexed_item": 71, "proxied_valu": 71, "garbage_collect_valu": 71, "run_nod": 71, "negsigmswapinterpret": 71, "call_self": 71, "args_tail": 71, "boxed_run": 71, "args_list": 71, "promptli": [71, 1262], "fetch_args_kwargs_from_env": 71, "map_nodes_to_valu": 71, "initial_env": 71, "enable_io_process": 71, "negsigmswapxform": 71, "w1": 71, "w2": 71, "m1": [71, 1848, 1849], "m2": [71, 1642, 1848, 1849, 1908], "despit": [71, 1205, 1206, 1891], "stack_1": 71, "stack_2": 71, "sum_2": 71, "max_1": 71, "max_2": 71, "add_2": 71, "onnx": [83, 86, 87, 88, 1636, 1637, 1655, 1656, 1657, 1658, 1659, 1660, 1858, 1877, 1908], "dynamo_export": [83, 1656, 1657, 1901], "opset_vers": [88, 1655, 1901, 1903], "g_cpu": 89, "g_cuda": 89, "bytetensor": [89, 995, 996, 1034, 1035, 1142, 1301, 1308, 1757, 1912, 1920, 1923], "2147483647": 89, "0x8000_0000_0000_0000": [89, 1282, 1912], "0xffff_ffff_ffff_ffff": [89, 1282, 1912], "random_devic": 89, "1516516984916": 89, "new_stat": [89, 1034, 1035, 1308, 1757, 1912], "void": [89, 965, 1007, 1886, 1893], "g_cpu_oth": 89, "abs_": [93, 1861, 1876, 1923], "acosh": [97, 123, 864, 1859, 1861, 1876, 1903], "batch1": [100, 101, 152, 153, 683, 918, 1861], "batch2": [100, 101, 152, 153, 170, 683, 918, 1861], "tensor1": [102, 103, 104, 105, 684, 685, 1284, 1733, 1861], "tensor2": [102, 103, 104, 105, 314, 404, 684, 685, 1284, 1733, 1861], "mat1": [106, 107, 551, 686, 1154, 1210, 1294, 1782, 1785, 1786, 1800, 1859, 1861], "mat2": [106, 107, 413, 551, 686, 930, 1154, 1210, 1294, 1782, 1785, 1786, 1800, 1859, 1861], "mat": [108, 109, 537, 687, 1314, 1714, 1779, 1782, 1800, 1861, 1922], "vec1": [110, 111, 688, 1861], "vec2": [110, 111, 288, 460, 688, 1136, 1696, 1861], "keepdim": [113, 115, 116, 117, 119, 135, 136, 354, 392, 407, 409, 410, 411, 414, 428, 429, 430, 431, 452, 469, 478, 552, 562, 612, 690, 692, 693, 694, 696, 871, 872, 1211, 1242, 1246, 1259, 1277, 1287, 1289, 1290, 1292, 1295, 1317, 1318, 1319, 1320, 1431, 1560, 1649, 1705, 1708, 1802, 1803, 1807, 1845, 1846, 1859, 1861, 1876, 1918], "rtol": [114, 344, 691, 905, 906, 1179, 1244, 1247, 1660, 1860, 1861, 1924], "atol": [114, 344, 691, 905, 906, 1179, 1244, 1247, 1256, 1660, 1860, 1861, 1888, 1924], "08": [114, 344, 691, 928, 1179, 1236, 1357, 1436, 1564, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1691, 1763, 1861], "equal_nan": [114, 344, 691, 1179, 1861, 1924], "arcco": [122, 1861, 1903, 1924], "acosh_": [124, 1861, 1876], "arccosh": [124, 1861, 1903], "arcsin": [126, 878, 1861, 1903, 1917], "arcsinh": [128, 1861, 1903], "atan2_": [131, 1861, 1876], "arctan2": [131, 1861, 1903], "arctan": [132, 1861, 1903], "arctanh": [134, 1861, 1903], "cl": [140, 1888, 1908, 1913, 1928], "asinh": [144, 866, 1859, 1861, 1876, 1903, 1917], "atan": [148, 628, 629, 867, 1859, 1861, 1876, 1903, 1917], "atanh": [150, 869, 1859, 1861, 1876, 1903, 1917], "wrt": [151, 905, 906], "60521": [151, 890], "issuecom": [151, 890], "867061780": [151, 890], "texttt": [154, 155, 691, 1179, 1330, 1924], "bernoulli": [155, 757, 1334, 1360, 1361, 1362, 1363, 1367, 1374, 1392, 1506, 1507, 1508, 1509, 1514, 1858, 1861, 1876, 1903, 1925], "preserve_format": [156, 171, 173, 176, 179, 180, 181, 190, 207, 210, 240, 267, 297, 325, 393, 522, 577, 947, 1065, 1118, 1654, 1717, 1719, 1721, 1856, 1920], "minlength": [157, 921, 1861], "bitwise_and": [159, 1859, 1861, 1903], "bitwise_left_shift": [161, 1861, 1903], "bitwise_not": [163, 1859, 1861, 1876, 1903], "bitwise_or": [165, 1859, 1861, 1903], "bitwise_right_shift": [167, 1861, 1903], "bitwise_xor": [169, 1859, 1861, 1903], "uint8": [173, 242, 614, 690, 696, 1115, 1706, 1709, 1710, 1733, 1908, 1919, 1920, 1922, 1923, 1929], "cauchi": [174, 1858, 1883, 1891, 1903, 1925], "dfrac": [174, 377, 605, 1357, 1503, 1610, 1643, 1646], "complex32": [180, 1350, 1351, 1352, 1496, 1497, 1498, 1658, 1923, 1924], "int8": [181, 447, 726, 922, 923, 924, 925, 926, 927, 1115, 1271, 1272, 1273, 1274, 1908, 1911, 1919, 1920, 1923, 1929], "input2": [184, 458, 459, 515, 757, 943, 1343, 1356, 1357, 1414, 1431, 1492, 1502, 1503, 1544, 1861, 1882, 1901], "clamp_": [189, 1861, 1876], "uncoalesc": [191, 328, 1793], "coo": [191, 323, 328, 342, 611, 1154, 1782, 1785, 1790, 1791, 1792, 1793, 1794, 1795, 1858, 1870, 1920, 1924], "inttensor": [192, 209, 1164, 1279, 1280, 1365, 1920, 1923], "csr": [192, 209, 343, 580, 585, 1366, 1782, 1785, 1786, 1792, 1795, 1870, 1924], "sparse_csr": [192, 209, 580, 585, 1785, 1786, 1788, 1792, 1795, 1917], "nnz": [192, 541, 580, 581, 582, 584, 585, 905, 1322, 1783, 1785, 1786, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1917], "mkl": [192, 209, 1858, 1885, 1900, 1903, 1917], "routin": [192, 209, 873, 942, 1262, 1781, 1808, 1917], "downcast": [192, 209], "to_sparse_csr": [192, 209, 581, 582, 1785, 1786, 1861, 1903, 1917], "conj_phys": [195, 955, 1859, 1861, 1903, 1917], "contiguous_format": [196, 331, 497, 498, 1064, 1602, 1920], "non_block": [197, 210, 577, 600, 1190, 1422, 1635, 1859, 1861, 1886, 1919], "copysign": [199, 1861, 1903], "fweight": [206, 962, 1861], "aweight": [206, 962, 1861], "sparse_dim": [219, 542, 543, 1782, 1785, 1789, 1793, 1861, 1903, 1917], "resize_": [222, 498, 1120, 1211, 1860, 1861, 1862, 1876, 1910, 1919], "resize_as_": [222, 1861, 1876, 1917], "set_": [222, 497, 1861], "transpose_": [222, 1861, 1917], "zero_": [222, 1235, 1512, 1861, 1876, 1877, 1894, 1917], "dim1": [226, 228, 229, 566, 589, 590, 1051, 1053, 1054, 1224, 1811, 1828, 1861], "dim2": [226, 228, 229, 1051, 1053, 1054, 1224, 1861], "digamma": [232, 1859, 1861, 1876, 1903, 1918], "rounding_mod": [235, 236, 237, 238, 1058, 1059, 1108, 1111, 1727, 1836, 1861], "split_size_or_sect": [241, 302, 616, 1796], "eq": [244, 1859, 1861, 1876, 1903], "erf": [247, 636, 637, 1859, 1861, 1876, 1903, 1917, 1918], "erfc": [249, 638, 639, 1859, 1861, 1876, 1903, 1918], "front": [254, 1262, 1425, 1877, 1889], "lambd": [258, 298, 1378, 1459, 1524, 1580, 1661, 1861], "fill_valu": [260, 445, 1117, 1118, 1345, 1859, 1861, 1886], "tall": [260, 1248, 1253, 1888], "start_dim": [263, 1102, 1368, 1861], "end_dim": [263, 1102, 1368, 1861], "float_pow": [269, 1861, 1903], "floor_divid": [273, 1058, 1861, 1903, 1917], "divisor": [276, 277, 487, 488, 765, 766, 1058, 1108, 1111, 1133, 1336, 1337, 1369, 1473, 1489, 1490, 1727, 1836], "fmod": [277, 1727, 1859, 1861, 1903], "mantissa": [280, 480, 1113, 1213, 1861, 1886, 1897], "gcd": [283, 1859, 1861, 1903], "ge": [285, 1145, 1283, 1379, 1380, 1525, 1526, 1859, 1861, 1876, 1903], "ordin": [289, 1790, 1791, 1792, 1794, 1795, 1920], "greater_equ": [294, 1861, 1903], "gt": [296, 1144, 1859, 1861, 1876, 1891, 1903], "hypot": [304, 1859, 1861, 1903], "i0": [306, 1209, 1771, 1861, 1903, 1918], "igamma": [308, 1859, 1861, 1903], "igammac": [310, 1859, 1861, 1903], "3100": [311, 482, 1160, 1725], "3553j": [311, 482, 1160, 1725], "5445": [311, 482, 1160, 1725], "7896j": [311, 482, 1160, 1725], "6492": [311, 482, 1160, 1725], "0633j": [311, 482, 1160, 1725], "0638": [311, 482, 1160, 1725], "8119j": [311, 482, 1160, 1725], "3553": [311, 1160], "7896": [311, 1160], "0633": [311, 1160, 1236, 1878], "8119": [311, 1160], "index_add_": [312, 895, 1161, 1162, 1861, 1898], "index_copy_": [314, 1861], "index_fill_": [316, 1861, 1876], "index_put_": [318, 1861], "include_self": [321, 514, 515, 1163, 1742, 1859, 1861], "identit": 321, "amax": [321, 515, 693, 694, 1785, 1859, 1861, 1903], "amin": [321, 515, 692, 694, 1785, 1859, 1861, 1903], "fill_": [321, 1190, 1215, 1422, 1728, 1861, 1876, 1894, 1919], "72": [321, 614, 1143], "uint8_t": [326, 1658], "retain_grad": [335, 1861, 1883, 1903], "n_fft": [351, 553, 1187, 1804, 1861], "hop_length": [351, 553, 1187, 1804, 1861], "win_length": [351, 553, 1187, 1804, 1861], "center": [351, 553, 776, 782, 1083, 1187, 1486, 1521, 1532, 1590, 1675, 1697, 1765, 1804, 1861, 1883, 1903, 1922], "onesid": [351, 553, 1187, 1804, 1859, 1861], "return_complex": [351, 553, 1187, 1804, 1861], "element_s": [353, 434, 1861, 1876, 1903, 1919], "lcm": [356, 1861, 1903], "ldexp": [358, 1113, 1861, 1903], "le": [360, 1217, 1379, 1380, 1525, 1526, 1859, 1861, 1876, 1903, 1924], "lerp": [362, 1861, 1903], "less_equ": [366, 1861, 1903], "lgamma": [368, 648, 649, 1859, 1861, 1903], "ln": [377, 1218, 1918], "logical_and": [383, 1859, 1861, 1903], "logical_not": [385, 1859, 1861, 1876, 1878, 1903], "logical_or": [387, 1859, 1861, 1903], "logical_xor": [389, 1861, 1903], "pivot": [396, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1279, 1280, 1281, 1707, 1861], "get_info": [396, 1279], "lu_data": [397, 1280, 1281, 1861], "lu_pivot": [397, 1280, 1281, 1861], "masked_fill_": [399, 1861, 1876, 1877], "booltensor": [400, 402, 732, 1283, 1465, 1853, 1920, 1923], "masked_scatter_": [401, 1861], "mvlgamma": [425, 1861, 1903], "posinf": [426, 427, 1316, 1861], "neginf": [426, 427, 1316, 1861], "nan_to_num": [427, 1861, 1903], "interpol": [430, 478, 782, 783, 784, 816, 1215, 1319, 1474, 1475, 1476, 1486, 1521, 1590, 1591, 1592, 1708, 1843, 1861, 1910], "ne": [438, 1610, 1643, 1651, 1859, 1861, 1876, 1903], "8182e": 444, "5765e": 444, "41": [444, 1066, 1248, 1593, 1642, 1707], "0545e": 444, "0949e": 444, "4842e": [444, 1066], "0000e": [444, 1066, 1106, 1267, 1276, 1316, 1642, 1763, 1765, 1766, 1771, 1772], "00": [444, 1066, 1106, 1267, 1276, 1316, 1642, 1659, 1763, 1765, 1766, 1771, 1772, 1860, 1901], "141592": [445, 1117], "1416": [445, 1047, 1117, 1822], "from_numpi": [447, 876, 877, 1822], "array_lik": [447, 876, 1790, 1791, 1792, 1793, 1794, 1795, 1822, 1878], "nextaft": [450, 1859, 1861, 1903], "fro": [452, 1221, 1242, 1246, 1259, 1620, 1629, 1649, 1861], "not_equ": [455, 1861, 1903], "resolve_conj": [457, 955, 1861, 1903], "resolve_neg": [457, 1861, 1903], "input3": [459, 1861], "transpos": [459, 590, 591, 614, 689, 738, 739, 740, 943, 1063, 1130, 1219, 1220, 1226, 1229, 1232, 1239, 1250, 1253, 1353, 1354, 1355, 1473, 1499, 1500, 1501, 1571, 1609, 1638, 1695, 1808, 1810, 1811, 1817, 1831, 1859, 1861, 1876, 1878, 1883, 1897, 1901, 1903, 1910, 1917, 1921, 1923], "polygamma": [465, 1861, 1903, 1918], "q_per_channel_axi": [472, 473, 1861, 1903], "zero_point": [473, 475, 735, 736, 737, 738, 739, 740, 741, 746, 747, 748, 749, 750, 751, 752, 753, 755, 756, 767, 769, 770, 771, 772, 774, 777, 778, 796, 799, 816, 817, 818, 819, 822, 849, 1077, 1078, 1709, 1710, 1711, 1712, 1713, 1861, 1908, 1909], "qtensor": [477, 1861], "uniform": [480, 605, 920, 1358, 1440, 1504, 1716, 1717, 1765, 1858, 1859, 1881, 1903, 1925], "queu": [485, 970, 1886], "life": [485, 967], "cycl": [485, 890, 967, 1683, 1689, 1883, 1907], "unexpectedli": [485, 1923], "maxnorm": [489, 490, 1728, 1861], "repeat_interleav": [491, 1843, 1861, 1903, 1910], "output_s": [492, 738, 739, 740, 763, 764, 1327, 1328, 1329, 1331, 1332, 1333, 1354, 1369, 1370, 1371, 1418, 1419, 1420, 1473, 1480, 1481, 1482, 1483, 1484, 1485, 1515, 1516, 1517, 1548, 1549, 1550, 1729, 1859, 1861, 1878], "is_leaf": [493, 1861, 1876, 1878, 1903], "saved_weight": 494, "loaded_weight": 494, "5503": 494, "4926": [494, 1894], "1158": 494, "8303": 494, "1007": 494, "9853": 494, "2316": 494, "6606": 494, "resiz": [497, 498, 521, 542, 543, 1115, 1116, 1120, 1474, 1521, 1532, 1859, 1861, 1876, 1903, 1919], "shift": [503, 923, 926, 1083, 1090, 1334, 1340, 1341, 1342, 1367, 1461, 1514, 1734, 1861, 1864], "decim": [505, 506, 1736, 1861, 1897, 1929], "scatter_": [510, 513, 1740, 1861], "scatter_add_": [511, 512, 1741, 1843, 1861], "scatter_reduce_": [511, 514, 1742, 1861], "4600": 511, "2300": 511, "scatter_reduc": [515, 1843, 1859, 1861, 1903], "sgn": [520, 1112, 1761, 1861, 1876, 1878, 1903, 1917], "int16": [522, 1115, 1272, 1919, 1920, 1923, 1929], "dense_dim": [540, 542, 543, 580, 581, 582, 584, 585, 1793, 1861, 1903, 1917], "nse": [541, 1917], "randint": [541, 921, 962, 1106, 1295, 1345, 1471, 1504, 1505, 1789, 1861, 1865, 1877, 1903, 1922, 1925], "6550": 541, "2397": 541, "1611": 541, "0779": [541, 1226, 1704, 1853], "2326": 541, "0558": 541, "4711": 541, "9678": 541, "5138": 541, "0411": 541, "9417": 541, "5158": 541, "0793": 541, "0036": [541, 1287], "2569": 541, "1055": 541, "sparse_coo": [541, 580, 1322, 1785, 1788, 1789, 1793, 1917, 1920], "split_siz": [544, 1796, 1861], "squeez": [550, 690, 692, 693, 694, 696, 1211, 1277, 1287, 1289, 1290, 1292, 1295, 1317, 1320, 1503, 1705, 1789, 1802, 1803, 1807, 1845, 1846, 1859, 1861, 1876, 1901, 1903, 1910, 1921], "pad_mod": [553, 1804, 1861], "typedstorag": [554, 1858, 1919], "untypedstorag": [554, 610, 1858, 1919], "untyped_storag": 554, "compute_uv": [564, 1253, 1254, 1808, 1861], "axis0": [565, 1810, 1861], "axis1": [565, 1810, 1861], "dim0": [566, 589, 590, 1811, 1828, 1861], "indices_or_sect": [575, 1061, 1153, 1823, 1851], "rep": 576, "5044": 577, "0005": [577, 1687, 1693], "3310": 577, "0584": [577, 1808], "cuda0": [577, 1886, 1892, 1923], "masked_grad": [578, 1861], "sparse_mask": [578, 1861, 1903], "mkldnn": [579, 1199, 1858, 1903], "sparsedim": 580, "blocksiz": [580, 581, 582, 1790, 1791, 1792, 1861, 1917], "sparse_csc": [580, 584, 1788, 1792, 1794, 1917], "sparse_bsr": [580, 582, 1791, 1792, 1917], "sparse_bsc": [580, 581, 1790, 1792, 1917], "bsr": [580, 582, 1791, 1792, 1924], "bsc": [580, 581, 1790, 1792, 1924], "csc": [580, 584, 1792, 1794, 1924], "minu": [580, 581, 582, 584, 585, 1918], "crow_indic": [580, 582, 585, 1783, 1785, 1786, 1788, 1791, 1792, 1795, 1861, 1903, 1917, 1924], "col_indic": [580, 582, 585, 1785, 1786, 1788, 1791, 1792, 1795, 1861, 1903, 1917, 1924], "sparsecsr": [580, 1828, 1917], "row_indic": [581, 584, 1790, 1794, 1861, 1903, 1917, 1924], "ccol_indic": [581, 584, 1790, 1794, 1861, 1903, 1917, 1924], "_nnz": [583, 584, 585, 1903], "012766935862600803": 586, "5415473580360413": 586, "08909505605697632": 586, "7729271650314331": 586, "unitriangular": [591, 1252, 1831, 1861], "tril": [593, 1571, 1861, 1903], "triu": [595, 1614, 1831, 1861, 1901, 1903], "trunc": [599, 674, 675, 684, 1058, 1101, 1108, 1111, 1736, 1859, 1861, 1876, 1903, 1917], "sizedim": 604, "return_invers": [606, 607, 1840, 1841, 1861], "return_count": [606, 607, 1840, 1841, 1861], "unsqueez": [609, 1083, 1210, 1250, 1365, 1441, 1614, 1825, 1859, 1861, 1888, 1903, 1910, 1917, 1921, 1922], "subspac": [614, 1253, 1428, 1697, 1808, 1809], "span": [614, 1024, 1025, 1358, 1808, 1907, 1913], "foral": 614, "proportion": [614, 782, 1474, 1590], "met": [614, 1229, 1236, 1237, 1248, 1262, 1469], "9482": [614, 1167], "0310": 614, "4999": 614, "5316": 614, "1520": 614, "7472": 614, "5617": 614, "8649": 614, "4724": [614, 1894], "0334": 614, "2976": 614, "8499": 614, "2109": 614, "9913": 614, "9607": 614, "6123": 614, "1064483442": 614, "1124191867": 614, "1069546515": 614, "1089989247": 614, "1105482831": 614, "1061112040": 614, "1057999968": 614, "1084397505": 614, "1071760287": 614, "1123489973": 614, "1097310419": 614, "1084649136": 614, "1101533110": 614, "1073668768": 614, "1082790149": 614, "1088634448": 614, "1000000000": 614, "0047": 614, "0310j": 614, "5316j": 614, "7472j": 614, "8649j": 614, "0334j": 614, "8499j": 614, "9913j": 614, "6123j": 614, "202": 614, "154": [614, 1900], "59": [614, 1833, 1835], "182": 614, "243": [614, 1187, 1808], "253": 614, "188": 614, "252": [614, 1900], "191": 614, "63": [614, 1900, 1908], "240": 614, "227": 614, "165": 614, "190": 614, "128": [614, 717, 725, 726, 753, 761, 791, 816, 817, 1343, 1357, 1384, 1409, 1431, 1470, 1471, 1503, 1571, 1877, 1878, 1908, 1910, 1911, 1913, 1920, 1923], "146": 614, "106": 614, "205": 614, "206": 614, "189": 614, "95": [614, 1685, 1688, 1689], "147": 614, "43": 614, "87": 614, "235": 614, "226": 614, "254": [614, 1900], "111": [614, 1659, 1901], "117": 614, "177": 614, "xlogi": [619, 1861, 1903, 1918], "aot_graph": [677, 1869], "aot_joint_graph": [677, 1869], "ddp_graph": [677, 1869], "graph_cod": [677, 1869], "toggl": [677, 1886], "supress": 677, "silenc": 677, "lowest": [677, 940, 1316, 1619, 1620, 1628, 1629, 1718, 1719, 1888, 1924], "notset": 677, "joint": [677, 1869], "ddpoptim": [677, 1869], "unregist": [677, 1869, 1873, 1901], "3348": 680, "5889": 680, "1584": 680, "2294": [680, 1289], "2004": 680, "3690": 680, "7298": [680, 1726], "hyperbol": [681, 879, 882, 960, 1462, 1776, 1821], "uniform_": [681, 882, 920, 1858, 1861, 1876, 1881, 1888, 1918, 1925], "3192": 681, "9915": 681, "9674": 681, "7151": 681, "7791": 681, "3120": [681, 957], "2979": 681, "1341": 681, "_i": [682, 683, 684, 685, 686, 918, 920, 923, 926, 930, 945, 1058, 1108, 1213, 1215, 1311, 1470, 1700, 1704, 1723, 1759, 1805, 1853, 1918], "0202": 682, "0985": 682, "3506": [682, 1279], "6056": 682, "3944": 682, "9732": 682, "3497": 682, "6245": [682, 1221], "4022": [682, 1045, 1808], "3743": 682, "7724": 682, "5811": 682, "8017": 682, "7695": 682, "3930": 682, "3672": [682, 963, 1222], "1450": [682, 1789], "6971": 682, "0736": [682, 1894], "0994": 682, "3216": 682, "7845": 682, "1610": 682, "1868": 682, "4090": 682, "9902": [682, 963, 1222], "3667": [682, 957], "3925": 682, "6147": 682, "sum_": [683, 1187, 1241, 1258, 1335, 1336, 1337, 1350, 1351, 1352, 1358, 1390, 1391, 1410, 1425, 1429, 1431, 1802, 1803, 1804, 1824, 1829, 1845, 1846, 1847, 1918], "mathbin": [683, 686, 687, 918, 930, 1786], "doubletensor": [683, 684, 685, 686, 687, 918, 1749, 1920, 1923], "tensorfloat32": [683, 686, 918, 930, 1284, 1294, 1350, 1351, 1352, 1353, 1354, 1355, 1409, 1496, 1497, 1498, 1499, 1500, 1501, 1538, 1751, 1886, 1897], "rocm": [683, 686, 918, 930, 1284, 1294, 1350, 1351, 1352, 1353, 1354, 1355, 1375, 1393, 1409, 1858], "6311": 683, "0503": 683, "9768": [683, 1894], "0362": 683, "1653": 683, "8185": 683, "4255": [683, 1311], "6760": 683, "9453": 683, "5743": 683, "8202": 683, "3691": 683, "0943": 683, "1109": [683, 1376, 1772], "4730": [683, 1824], "histor": [684, 1020, 1362, 1885, 1894, 1899], "t1": [684, 685, 877, 1143, 1602, 1862, 1913, 1914], "2312": [684, 1789], "6496": 684, "1312": 684, "0428": 684, "4292": 684, "1030": 684, "5369": 684, "9829": 684, "0430": 684, "8635": 685, "6391": 685, "6174": 685, "7617": 685, "5879": 685, "7388": 685, "8353": 685, "6249": 685, "6511": 685, "8716": 686, "4671": 686, "3746": 686, "7573": 686, "9555": 686, "8681": 686, "3768": 687, "5565": 687, "otim": [688, 1210, 1373, 1520], "conj": [689, 956, 1079, 1080, 1082, 1084, 1091, 1093, 1097, 1098, 1100, 1219, 1220, 1226, 1228, 1247, 1731, 1732, 1859, 1861, 1891, 1903, 1923], "mh": [689, 941, 1226, 1808, 1861, 1903, 1921, 1923], "lvert": [691, 1179, 1470, 1557, 1924], "rvert": [691, 1179, 1924], "leq": [691, 919, 920, 957, 1081, 1083, 1179, 1210, 1214, 1229, 1235, 1345, 1364, 1425, 1427, 1429, 1505, 1556, 1559, 1762, 1804, 1881, 1918], "elementwis": [691, 957, 979, 1006, 1007, 1106, 1108, 1326, 1385, 1386, 1387, 1459, 1580, 1844, 1863, 1878, 1891, 1918], "07": [691, 816, 817, 818, 819, 822, 941, 942, 1066, 1227, 1230, 1235, 1247, 1248, 1254, 1277, 1280, 1609, 1660, 1667, 1766, 1771, 1808, 1901], "09": [691, 1667, 1679, 1924], "8177": 692, "4878": 692, "2491": 692, "9130": 692, "7158": 692, "1775": 692, "0992": 692, "4817": 692, "0053": 692, "0164": 692, "3738": 692, "0507": [692, 1901], "9700": 692, "1106": 692, "0318": 692, "0816": [692, 1279], "6451": 693, "4866": 693, "2987": 693, "3312": 693, "5744": 693, "2980": [693, 1878], "8397": 693, "2713": 693, "9128": 693, "9214": 693, "7268": 693, "2995": 693, "9023": [693, 1220], "4853": 693, "9075": 693, "6165": 693, "180": [695, 1047, 1715], "14159": [695, 1822], "135": 695, "45": [695, 1341, 1342, 1386, 1387, 1461, 1642, 1901], "ao": [697, 698, 699, 700, 701, 702, 703, 704, 705, 706, 707, 708, 709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 720, 721, 722, 723, 724, 725, 726, 727, 728, 729, 730, 731, 732, 733, 734, 735, 736, 737, 738, 739, 740, 741, 742, 743, 744, 745, 746, 747, 748, 749, 750, 751, 752, 753, 754, 755, 756, 757, 758, 759, 760, 761, 762, 763, 764, 765, 766, 767, 768, 769, 770, 771, 772, 773, 774, 775, 776, 777, 778, 779, 780, 781, 782, 783, 784, 785, 786, 787, 788, 789, 790, 791, 792, 793, 794, 795, 796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 811, 812, 813, 814, 815, 816, 817, 818, 819, 820, 821, 822, 823, 824, 825, 826, 827, 828, 829, 830, 831, 832, 833, 834, 835, 836, 837, 838, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 854, 855, 856, 857, 858, 859, 860, 861, 1908, 1909, 1910], "batch_norm": [697, 698, 1199, 1861, 1903], "3d": [698, 701, 704, 732, 737, 740, 764, 766, 771, 776, 1291, 1329, 1333, 1337, 1340, 1342, 1352, 1355, 1362, 1363, 1369, 1371, 1385, 1387, 1417, 1428, 1474, 1482, 1485, 1486, 1490, 1498, 1501, 1509, 1515, 1517, 1532, 1547, 1559, 1590, 1878, 1897, 1908, 1917, 1922], "bn": [699, 700, 701, 702, 703, 704, 811, 857, 1063, 1199, 1899, 1904, 1908, 1909], "qat": [709, 710, 711, 712, 713, 714, 715, 716, 717, 718, 719, 727, 728, 729, 730, 789, 790, 843, 1908, 1909, 1910], "in_channel": [709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 1199, 1350, 1351, 1352, 1353, 1354, 1355, 1398, 1399, 1400, 1401, 1402, 1403], "out_channel": [709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 1199, 1350, 1351, 1352, 1353, 1354, 1355, 1398, 1399, 1400, 1401, 1402, 1403], "kernel_s": [709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 765, 766, 779, 780, 1190, 1199, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1370, 1371, 1390, 1391, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1418, 1419, 1420, 1422, 1473, 1488, 1489, 1490, 1499, 1500, 1501, 1515, 1516, 1517, 1542, 1543, 1545, 1546, 1547, 1548, 1549, 1550, 1589, 1712, 1713, 1859, 1861, 1922], "dilat": [709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 769, 770, 771, 779, 780, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1398, 1399, 1400, 1401, 1402, 1403, 1415, 1416, 1417, 1473, 1496, 1497, 1498, 1499, 1500, 1501, 1515, 1545, 1546, 1547, 1589, 1712, 1713, 1859, 1861, 1901], "padding_mod": [709, 710, 711, 712, 713, 714, 715, 716, 722, 723, 724, 727, 728, 735, 736, 737, 738, 739, 740, 769, 770, 771, 1350, 1351, 1352, 1353, 1354, 1355, 1398, 1399, 1400, 1401, 1402, 1403, 1521, 1859, 1861], "ep": [709, 710, 711, 712, 713, 714, 720, 721, 733, 734, 746, 748, 749, 750, 751, 792, 816, 817, 818, 819, 822, 823, 905, 906, 1199, 1275, 1326, 1340, 1341, 1342, 1357, 1376, 1377, 1385, 1386, 1387, 1394, 1395, 1396, 1397, 1404, 1405, 1406, 1431, 1436, 1461, 1465, 1467, 1469, 1470, 1491, 1503, 1518, 1522, 1523, 1531, 1535, 1557, 1560, 1564, 1587, 1610, 1643, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1678, 1691, 1711, 1859, 1861, 1888, 1891, 1918, 1929], "momentum": [709, 710, 711, 712, 713, 714, 720, 721, 733, 734, 748, 749, 750, 1340, 1341, 1342, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1461, 1491, 1531, 1668, 1675, 1677, 1683, 1689, 1691, 1859, 1861, 1894, 1904], "freeze_bn": [709, 710, 711, 712, 713, 714], "qconfig": [709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 730, 785, 786, 788, 791, 792, 793, 794, 835, 836, 837, 839, 840, 841, 842, 843, 844, 845, 846, 847, 848, 849, 850, 851, 852, 853, 855, 856, 858, 859, 1927], "batchnorm1d": [709, 712, 1395, 1461, 1491, 1899, 1910], "fakequant": [709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 730, 799, 859], "weight_fake_qu": [709, 710, 711, 712, 713, 714, 715, 716, 727, 728], "quant": [709, 710, 711, 712, 713, 714, 715, 716, 717, 727, 728, 729, 787, 789, 790, 835, 858, 859, 1077, 1078, 1908, 1909], "batchnorm3d": [711, 714, 716, 721, 1397, 1461, 1491, 1910], "num_featur": [720, 721, 733, 734, 748, 749, 750, 1190, 1340, 1341, 1342, 1385, 1386, 1387, 1395, 1396, 1397, 1404, 1405, 1406, 1422, 1461, 1523, 1894], "qint8": [725, 726, 753, 758, 761, 762, 769, 770, 771, 778, 789, 791, 796, 817, 838, 855, 856, 858, 859, 1658, 1709, 1710, 1908, 1910, 1911, 1919, 1923, 1924], "highlight": [727, 728, 1863], "from_float": [729, 735, 736, 737, 742, 743, 753, 761, 794, 814, 820, 823, 835, 1908], "qparams_dict": [729, 735, 736, 737, 761], "hidden_s": [731, 757, 758, 762, 1374, 1375, 1392, 1393, 1437, 1438, 1439, 1861], "num_lay": [731, 757, 1374, 1392, 1437, 1438, 1466, 1468, 1861, 1894], "bidirect": [731, 757, 1374, 1392, 1437, 1438, 1861], "_lstmlayer": 731, "nnqa": 731, "h0": [731, 757, 759, 1374, 1392, 1437], "hn": [731, 757, 759, 1374, 1375, 1392, 1437], "cn": [731, 759, 1190, 1392], "weight_ih": [731, 1375, 1393, 1439], "weight_hh": [731, 1375, 1393, 1439], "dequant": [732, 785, 787, 789, 790, 796, 798, 858, 1861, 1903, 1909, 1911, 1924, 1926], "mha": [732, 1428], "conver": 732, "key_padding_mask": [732, 1428, 1861], "need_weight": [732, 1428, 1861], "attn_mask": [732, 1428, 1571, 1861], "average_attn_weight": [732, 1428, 1861], "is_caus": [732, 1428, 1468, 1469, 1571, 1861], "attn_output_weight": [732, 1428], "unmask": [732, 1465], "causal": [732, 1428, 1466, 1467, 1468, 1469, 1571], "attn_weight": [732, 1428, 1571], "attn_output": [732, 1428], "quint8": [735, 736, 737, 738, 739, 740, 742, 743, 753, 769, 770, 771, 778, 789, 791, 796, 816, 817, 818, 819, 822, 824, 856, 858, 1658, 1709, 1710, 1711, 1712, 1713, 1908, 1910, 1911, 1919, 1923, 1924], "learnabl": [735, 736, 737, 738, 739, 740, 742, 743, 753, 757, 761, 1340, 1341, 1342, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1365, 1366, 1374, 1375, 1377, 1385, 1386, 1387, 1392, 1393, 1394, 1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1409, 1430, 1437, 1439, 1461, 1513, 1565, 1894], "q_input": [735, 736, 737, 738, 739, 740, 769, 770, 771], "quantize_per_tensor": [735, 736, 737, 738, 739, 740, 753, 754, 755, 769, 770, 771, 1711, 1712, 1713, 1861, 1903, 1908], "unequ": [736, 737, 738, 739, 740, 1351, 1352, 1354, 1355], "50": [736, 738, 739, 740, 769, 821, 1245, 1295, 1336, 1337, 1345, 1350, 1351, 1352, 1354, 1355, 1370, 1371, 1390, 1391, 1415, 1416, 1417, 1472, 1498, 1499, 1501, 1505, 1516, 1517, 1676, 1819, 1878], "output_pad": [738, 739, 740, 1353, 1354, 1355, 1401, 1402, 1403, 1499, 1500, 1501, 1859, 1861], "qnnpack": [738, 739, 753, 761, 852, 853, 856, 858, 859, 1908, 1910], "convtranspose2d": [738, 1402, 1500, 1843, 1910], "nnq": [738, 739, 740, 785, 786, 787, 861, 1908], "downsampl": [738, 739, 740, 1354, 1474, 1486, 1521, 1532], "upsampl": [738, 739, 740, 776, 783, 784, 816, 1354, 1475, 1476, 1486, 1521, 1532, 1591, 1592], "cubic": [740, 1371, 1517, 1521], "num_embed": [742, 743, 1365, 1366, 1513], "embedding_dim": [742, 743, 1365, 1366, 1394, 1512, 1513], "padding_idx": [742, 1365, 1366, 1512, 1513, 1859, 1861], "scale_grad_by_freq": [742, 743, 1365, 1366, 1512, 1513, 1859, 1861], "_embed": [742, 743], "_dim": [742, 743, 1365], "include_last_offset": [743, 1366, 1513, 1861], "embedding_bag": [743, 1861, 1903], "floatfunct": [744, 1908], "activation_post_process": [744, 796, 1908], "add_relu": [744, 745, 754, 1871, 1903, 1926], "add_scalar": [744, 745, 754, 1903, 1922, 1926], "mul_scalar": [744, 745, 754, 1903, 1926], "collector": 745, "f_add": 745, "num_channel": [746, 1377, 1877], "normalized_shap": [751, 1394, 1535, 1859, 1861, 1878], "elementwise_affin": [751, 1394], "negative_slop": [752, 777, 1408, 1536, 1537, 1859, 1861, 1881], "slope": [752, 777, 1408, 1453, 1881], "bias_": [753, 761], "_featur": [753, 761, 778, 1330, 1343, 1407, 1409, 1492, 1538], "from_refer": [753, 761], "ref_qlinear": [753, 761], "output_scal": [753, 756, 1711, 1861], "output_zero_point": [753, 756, 1711, 1861], "q_add": 754, "qint32": [754, 755, 1658, 1709, 1710, 1908, 1911, 1919, 1923, 1924], "x_0": [755, 1829], "gate": [757, 758, 1373, 1374, 1375, 1392, 1451, 1520, 1574], "r_t": [757, 1374, 1674], "w_": [757, 1328, 1329, 1332, 1333, 1336, 1337, 1339, 1347, 1348, 1349, 1351, 1352, 1354, 1355, 1358, 1370, 1371, 1374, 1375, 1391, 1392, 1393, 1416, 1417, 1419, 1420, 1429, 1434, 1435, 1437, 1439, 1443, 1444, 1445, 1446, 1447, 1448, 1474, 1475, 1476, 1477, 1478, 1479, 1517, 1521], "x_t": [757, 891, 893, 1340, 1341, 1342, 1374, 1385, 1386, 1387, 1392, 1437, 1461, 1662], "b_": [757, 1374, 1375, 1392, 1393, 1410, 1437, 1439, 1824, 1917], "hr": [757, 1374, 1375, 1392, 1891], "h_": [757, 1328, 1329, 1332, 1333, 1336, 1337, 1343, 1348, 1349, 1351, 1352, 1354, 1355, 1370, 1371, 1374, 1375, 1391, 1392, 1409, 1416, 1417, 1418, 1419, 1420, 1434, 1435, 1437, 1439, 1444, 1445, 1447, 1448, 1474, 1475, 1476, 1478, 1479, 1492, 1517, 1521], "z_t": [757, 1374], "iz": [757, 1374, 1375], "hz": [757, 975, 1374, 1375, 1922], "n_t": [757, 1374], "h_t": [757, 1374, 1392, 1437], "hadamard": [757, 1374, 1375, 1392, 1393], "multilay": [757, 1374, 1392], "_t": [757, 1374, 1392, 1675, 1677, 1888, 1904], "b_ih": [757, 1374, 1375, 1392, 1393, 1437, 1439, 1861], "b_hh": [757, 1374, 1375, 1392, 1393, 1437, 1439, 1861], "h_0": [757, 1374, 1392, 1393, 1437], "seq_len": [757, 1374, 1392, 1428, 1437], "pack_padded_sequ": [757, 1374, 1392, 1437, 1635, 1637, 1638, 1890], "num_direct": [757, 1374, 1392, 1437], "h_n": [757, 1374, 1392, 1437], "input1": [757, 1343, 1356, 1357, 1414, 1431, 1492, 1502, 1503, 1544, 1861, 1882, 1901], "_size": [757, 1327, 1328, 1329, 1331, 1332, 1333, 1335, 1336, 1337, 1350, 1351, 1352, 1353, 1354, 1355, 1369, 1370, 1371, 1374, 1375, 1390, 1391, 1392, 1393, 1415, 1416, 1417, 1418, 1419, 1420, 1437, 1439, 1473, 1517], "_layer": [757, 1374, 1392, 1437], "_direct": 757, "output1": [757, 1330, 1882, 1901], "output2": [757, 1330], "weight_ih_l": [757, 1374, 1392, 1437], "w_ir": [757, 1374], "w_iz": [757, 1374], "w_in": [757, 1374], "weight_hh_l": [757, 1374, 1392, 1437], "w_hr": [757, 1374], "w_hz": [757, 1374], "w_hn": [757, 1374], "bias_ih_l": [757, 1374, 1392, 1437], "b_ir": [757, 1374], "b_iz": [757, 1374], "b_in": [757, 1374], "bias_hh_l": [757, 1374, 1392, 1437], "b_hr": [757, 1374], "b_hz": [757, 1374], "b_hn": [757, 1374], "mathcal": [757, 1343, 1350, 1351, 1352, 1353, 1354, 1355, 1365, 1366, 1374, 1375, 1392, 1393, 1407, 1409, 1437, 1439, 1440, 1461, 1720, 1881, 1891], "subtli": [757, 1374, 1677], "gru": [758, 1375, 1861, 1886, 1903, 1908, 1910], "cell": [758, 760, 762, 1374, 1375, 1392, 1393, 1437, 1439], "hx": [758, 760, 762, 1375, 1393, 1439, 1861], "cx": [760, 1393, 1861], "nonlinear": [762, 1338, 1356, 1382, 1437, 1439, 1449, 1858, 1881, 1917], "elman": [762, 1437, 1439], "adaptiveavgpool2d": [763, 1481, 1843, 1910], "adaptiveavgpool3d": [764, 1482, 1843, 1910], "ceil_mod": [765, 766, 779, 780, 1335, 1336, 1337, 1390, 1391, 1415, 1416, 1417, 1488, 1489, 1490, 1542, 1543, 1545, 1546, 1547, 1712, 1713, 1859, 1861], "count_include_pad": [765, 766, 1335, 1336, 1337, 1488, 1489, 1490, 1859, 1861], "divisor_overrid": [765, 766, 1336, 1337, 1489, 1490, 1859, 1861], "kh": [765, 766, 770, 771, 1336, 1337, 1370, 1371, 1416, 1417, 1489, 1490, 1497, 1498, 1500, 1501, 1516, 1517, 1546, 1547], "kw": [765, 766, 770, 771, 1336, 1337, 1370, 1371, 1416, 1417, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1516, 1517, 1545, 1546, 1547], "sw": [765, 766, 769, 770, 771, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1545, 1546, 1547], "avgpool2d": [765, 1489, 1910], "_channel": [765, 766, 769, 770, 771, 1350, 1351, 1352, 1353, 1354, 1355, 1377, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1545, 1546, 1547, 1913], "ih": [765, 766, 770, 771, 1437, 1439, 1489, 1490, 1497, 1498, 1500, 1501, 1546, 1547], "iw": [765, 766, 769, 770, 771, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501, 1545, 1546, 1547], "padh": [765, 766, 770, 771, 1489, 1490, 1497, 1498, 1500, 1501], "padw": [765, 766, 769, 770, 771, 1488, 1489, 1490, 1496, 1497, 1498, 1499, 1500, 1501], "kd": [766, 771, 1337, 1417], "sd": [766, 771], "padd": [766, 771], "formul": [767, 1344, 1364, 1378, 1412, 1458, 1459, 1540, 1557, 1571, 1891, 1917], "min_": [768, 1225, 1226, 1235, 1253, 1808], "max_": [768, 1415, 1416, 1417, 1610, 1643], "convolv": [769, 770, 771, 1350, 1351, 1352, 1353, 1354, 1355, 1398, 1399, 1400, 1401, 1402, 1403, 1496, 1497, 1498, 1499, 1500, 1501], "dw": [769, 770, 771, 1496, 1497, 1498, 1499, 1500, 1501], "qf": [769, 770, 771], "dtype_input": [769, 770, 771], "dtype_filt": [769, 770, 771], "q_filter": [769, 770, 771], "dh": [770, 771, 1497, 1498, 1500, 1501], "dd": 771, "min_val": [775, 1381, 1527, 1528, 1859, 1861], "max_val": [775, 1381, 1527, 1528, 1859, 1861], "scale_factor": [776, 782, 783, 784, 1474, 1475, 1476, 1532, 1571, 1590, 1591, 1592, 1859, 1861], "nearest": [776, 782, 784, 1319, 1474, 1476, 1521, 1532, 1590, 1592, 1708, 1736, 1886], "align_corn": [776, 782, 783, 1474, 1475, 1486, 1521, 1532, 1590, 1591, 1859, 1861], "height": [776, 782, 1336, 1337, 1351, 1352, 1354, 1355, 1391, 1416, 1417, 1429, 1456, 1474, 1532, 1590, 1877], "spatial": [776, 782, 783, 784, 938, 1083, 1341, 1369, 1394, 1434, 1435, 1456, 1473, 1474, 1475, 1476, 1486, 1521, 1532, 1561, 1562, 1563, 1590, 1591, 1592], "pixel": [776, 782, 784, 1351, 1358, 1361, 1362, 1363, 1367, 1429, 1434, 1435, 1474, 1486, 1521, 1532, 1590, 1592], "corner": [776, 782, 929, 1474, 1486, 1521, 1532, 1590], "leakyrelu": [777, 1423, 1536, 1894, 1910], "_slope": [777, 1408, 1536, 1881], "xa": [778, 1239, 1250, 1251, 1252, 1409, 1538], "return_indic": [779, 780, 1331, 1332, 1333, 1370, 1371, 1415, 1416, 1417, 1418, 1419, 1420, 1483, 1484, 1485, 1516, 1517, 1545, 1546, 1547, 1861], "maxpool1d": [779, 1418, 1545, 1548, 1910], "maxpool2d": [780, 1419, 1423, 1546, 1549, 1901, 1910], "linearli": [782, 1127, 1248, 1474, 1590, 1686, 1707, 1890, 1904, 1911], "neighbour": [784, 1410, 1532, 1592], "stub": [785, 786, 1905], "calibr": [785, 786, 794, 835, 836, 854, 856, 858, 1882, 1908, 1909, 1911, 1927], "quantstub": [787, 1908], "dequantstub": [787, 1908], "quantwrapp": 788, "backend_config": [789, 790, 791, 792, 793, 814, 815, 856, 857, 858, 859, 1927], "acycl": [789, 1883], "backendpatternconfig": [789, 858], "dtypeconfig": [789, 790, 792, 858], "observationtyp": [789, 790, 858, 1910], "weighted_int8_dtype_config": [789, 858], "input_dtyp": [789, 791, 858, 1910], "output_dtyp": [789, 791, 858, 1859, 1910], "weight_dtyp": [789, 791, 858, 1910], "bias_dtyp": [789, 791, 1910], "fuse_conv2d_relu": 789, "is_qat": [789, 790], "convrelu2d": [789, 1910], "linear_config": 789, "set_observation_typ": [789, 790, 858], "output_use_different_observer_as_input": [789, 790, 793, 858, 1910], "add_dtype_config": [789, 790, 858], "set_root_modul": [789, 790], "set_qat_modul": [789, 790], "set_reference_quantized_modul": [789, 790], "conv_relu_config": 789, "set_fused_modul": [789, 790], "set_fuser_method": [789, 790], "fused_conv_relu_config": 789, "set_backend_pattern_config": [789, 858], "from_dict": [789, 790, 791, 812, 813, 814, 851], "backend_config_dict": [789, 1908], "set_nam": 789, "to_dict": [789, 790, 791, 812, 813, 814, 851], "backendconfig": [790, 815, 856, 858, 1911], "dtype_config": [790, 1910], "backend_pattern_config_dict": 790, "observation_typ": [790, 1910], "qat_modul": [790, 1910], "reference_quantized_modul": 790, "fused_modul": [790, 1910], "fuser_method": [790, 811, 1910], "pattern_complex_format": 790, "set_dtype_config": 790, "fuse_linear_relu": 790, "linearrelu": [790, 1910], "8bea7180a8ba3c279f2c9b050f2a69a6": 790, "understood": [790, 937], "output_share_observer_with_input": [790, 793, 1910], "quantdequantstub": 790, "set_pattern": 790, "is_dynam": [791, 823, 1910], "quant1": 791, "dequant1": 791, "fp32_linear": 791, "quant2": 791, "dequant2": 791, "bracket": [791, 1914], "dtype_config1": 791, "dtype_config2": 791, "dtypewithconstraint": [791, 1910], "quant_min_lower_bound": [791, 792, 1910], "quant_max_upper_bound": [791, 792, 1910], "255": [791, 799, 1077, 1078, 1116, 1521, 1532, 1590, 1908, 1910, 1922], "input_dtype_with_constraint": 791, "scale_min_lower_bound": [791, 792, 1910], "scale_max_upper_bound": [791, 792, 1910], "dtype_config_dict": 791, "bias_typ": [791, 858], "scale_exact_match": [792, 1910], "zero_point_exact_match": [792, 1910], "quant_min": [792, 796, 799, 816, 817, 818, 819, 822, 823, 1077, 1078, 1861, 1908], "quant_max": [792, 796, 799, 816, 817, 818, 819, 822, 823, 1077, 1078, 1861, 1908], "fixedqparamsobserv": 792, "fixedqparamsfakequant": 792, "input_output_not_observ": [793, 1910], "maxpool": [793, 1370, 1371, 1516, 1517, 1901], "remove_qconfig": 794, "is_refer": 794, "convert_custom_config_dict": [794, 812, 1908], "from_observ": [794, 812, 1908], "observed_to_quantized_custom_module_class": [794, 812, 1908], "observedcustommodul": [794, 812, 814, 835, 1908], "quantizedcustommodul": [794, 812], "calib_data": 795, "fake_quant": [796, 797, 798, 799, 800, 801, 802, 803, 804, 805, 806, 807, 808, 809, 810, 859, 1077, 1078, 1927], "movingaverageminmaxobserv": [796, 799, 819], "observer_kwarg": [796, 799], "x_out": [796, 799], "fake_quant_en": 796, "observer_en": 796, "calculate_qparam": [797, 816, 817, 821], "qscheme": [799, 816, 817, 818, 819, 822, 823, 824, 1861, 1903, 1908, 1911, 1924], "fake_qu": [800, 804, 805, 806, 1908], "default_fake_qu": 801, "default_per_channel_weight_fake_qu": 802, "default_weight_fake_qu": 803, "histogram": [804, 816, 828, 1150, 1152, 1861, 1903, 1922], "memoryless": [805, 806], "averaging_const": [805, 806, 818, 819, 1861], "modules_to_fus": 811, "fuser_func": 811, "fuse_known_modul": 811, "fuse_custom_config_dict": [811, 813], "convmodul": 811, "bnmodul": 811, "convbnmodul": 811, "additional_fuser_method_map": 811, "fuse_conv_bn": [811, 1910], "conv1": [811, 1201, 1422, 1450, 1860, 1908, 1922], "bn1": 811, "relu1": [811, 1450, 1593], "fused_m": 811, "custom_config": [812, 813, 814, 815], "convert_fx": [812, 1908, 1927], "convert_custom_config": [812, 856, 1908], "set_observed_to_quantized_map": 812, "set_preserved_attribut": [812, 813, 814], "attr1": [812, 813, 814, 1901], "attr2": [812, 813, 814, 1901], "floatcustommodul": [812, 814], "weight_onli": [812, 856, 1908], "preserved_attribut": [812, 813, 814], "observed_class": [812, 814], "quantized_class": 812, "quant_typ": [812, 814], "quanttyp": [812, 814], "fuse_fx": [813, 1908], "fuse_custom_config": [813, 857], "convertcustomconfig": [813, 856], "prepare_fx": [814, 837, 856, 859, 1908, 1927], "prepare_qat_fx": [814, 856, 1908], "prepare_custom_config": [814, 815, 858, 859, 1908], "set_standalone_module_nam": 814, "module1": [814, 851, 1886], "qconfig_map": [814, 815, 851, 852, 853, 856, 858, 859, 1908], "child_prepare_custom_config": 814, "set_standalone_module_class": 814, "mystandalonemodul": 814, "set_float_to_observed_map": 814, "set_non_traceable_module_nam": 814, "module2": [814, 851, 1886], "module3": [814, 1886], "set_non_traceable_module_class": 814, "nontraceablemodule1": 814, "nontraceablemodule2": 814, "set_input_quantized_index": 814, "set_output_quantized_index": 814, "prepare_custom_config_dict": [814, 835, 837, 1908], "standalone_module_nam": 814, "standalone_module_class": 814, "module_class": 814, "float_to_observed_custom_module_class": [814, 835, 1908], "non_traceable_module_nam": 814, "non_traceable_module_class": 814, "input_quantized_idx": 814, "output_quantized_idx": 814, "float_class": 814, "qconfigmap": [815, 852, 853, 856, 858, 1908, 1911], "preparecustomconfig": [815, 858], "2048": [816, 1465, 1467, 1469, 1886], "upsample_r": 816, "per_tensor_affin": [816, 817, 818, 1710, 1711, 1712, 1713, 1908, 1911], "reduce_rang": [816, 817, 818, 819, 822, 824, 1861, 1908, 1909], "factory_kwarg": [816, 817, 822], "1920928955078125e": [816, 817, 818, 819, 822], "finfo": [816, 817, 818, 819, 822, 1244, 1247, 1326, 1858, 1924], "minmaxobserv": [816, 818, 822, 838, 858, 859, 1911], "x_": [817, 818, 962, 1073, 1263, 1264, 1266, 1269, 1277, 1339, 1358, 1412, 1429, 1455, 1457, 1577, 1785, 1787, 1829, 1883, 1911, 1918], "q_": [817, 1911], "x_orig": 817, "reset_min_max_v": [817, 822], "ch_axi": [819, 822, 1861], "per_channel_affin": [819, 822, 1709, 1908, 1911], "custom_op_nam": [820, 823], "with_arg": [821, 838, 858, 859], "_callable_arg": 821, "_with_arg": 821, "foo_build": 821, "foo_instance1": 821, "foo_instance2": 821, "with_callable_arg": 821, "_with_callable_arg": 821, "cur_tim": 821, "get_time_func": 821, "dan": 821, "creation_tim": 821, "compute_dtyp": 823, "ptq": [828, 1908, 1909, 1911], "obs_dict": 834, "get_observer_state_dict": 834, "allow_list": [835, 1926], "observer_non_leaf_module_list": 835, "preemptiv": [835, 836, 1602], "custommodul": [835, 1908], "propagate_qconfig_": 837, "qconfig_dict": [837, 851], "my_qconfig": 838, "default_observ": 838, "default_qat_config": 844, "set_glob": [851, 856, 858, 1908], "set_object_typ": [851, 856, 858], "set_module_name_regex": 851, "regex": 851, "set_module_nam": [851, 856, 858], "set_module_name_object_type_ord": 851, "global_qconfig": 851, "qconfig1": 851, "qconfig2": 851, "qconfig3": 851, "object_typ": 851, "module_name_regex": 851, "module_name_object_type_ord": 851, "conv0": 851, "x86": [852, 853, 1752, 1908, 1910], "run_arg": [854, 860], "qconfig_spec": 855, "quantize_fx": [856, 857, 858, 859, 1908, 1927], "_remove_qconfig": 856, "qconfig_from_prepar": 856, "prepared_model": [856, 858, 859], "xnnpack": [856, 1871, 1908], "get_default_backend_config": [856, 858, 859], "quantized_model": 856, "fusion_pattern": 857, "fusecustomconfig": 857, "_equalization_config": 858, "get_default_qconfig_map": [858, 1908], "float_model": [858, 859, 1926], "data_load": [858, 859, 1683, 1689, 1896], "get_default_qconfig": [858, 859, 1908], "linear_pattern_config": 858, "suer": 858, "sample_inference_data": 858, "get_default_qat_qconfig_map": [859, 1908], "load_weight": 859, "train_data": 859, "get_default_qat_qconfig": [859, 1908], "custom_module_class_map": 861, "lceil": [862, 939], "rceil": [862, 939], "gap": [862, 1723, 1858, 1908], "adjac": [862, 929, 1361, 1362, 1363, 1367, 1723, 1917], "set_default_tensor_typ": [862, 919, 928, 1064, 1066, 1076, 1081, 1099, 1117, 1137, 1147, 1148, 1209, 1260, 1276, 1653, 1716, 1718, 1720, 1722, 1723, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1790, 1791, 1792, 1793, 1794, 1795, 1833, 1835, 1855], "get_default_dtyp": [862, 1260, 1276, 1658, 1723, 1919, 1920, 1929], "5000": [862, 877, 883, 884, 885, 921, 945, 1081, 1083, 1084, 1091, 1094, 1099, 1109, 1111, 1112, 1113, 1143, 1149, 1152, 1215, 1241, 1260, 1317, 1319, 1347, 1348, 1366, 1474, 1708, 1712, 1713, 1714, 1723, 1727, 1918, 1923], "3398": 871, "2663": [871, 1886], "2686": 871, "2450": 871, "7401": 871, "8805": 871, "3402": 871, "1936": 871, "4907": [871, 1277], "3948": [871, 957], "0691": 871, "3132": 871, "6092": 871, "5419": 871, "2993": [871, 1807], "3195": 871, "1139": 872, "2254": 872, "1381": [872, 1807], "3687": 872, "0100": [872, 1243, 1709], "1975": [872, 1878], "0102": 872, "4732": 872, "9240": 872, "1207": [872, 1311], "7506": 872, "0213": 872, "7809": 872, "2960": 872, "9384": 872, "1438": 872, "ascend": [873, 1083, 1226, 1228, 1257, 1310, 1743, 1781, 1840], "0785": 873, "5267": 873, "8521": 873, "4065": 873, "1598": 873, "0788": 873, "0745": 873, "2700": 873, "2208": 873, "0722": 873, "7064": 873, "2564": 873, "0669": 873, "2318": 873, "8229": 873, "9280": 873, "lexicograph": [874, 1648, 1863, 1917], "9039": 875, "6291": 875, "0795": [875, 1708, 1894], "1586": 875, "1939": 875, "4900": 875, "7503": 875, "9355": 875, "histori": [876, 877, 1129, 1667, 1822, 1870, 1878, 1888, 1890, 1914], "dlpack": [877, 1114, 1858], "frombuff": 877, "data_ptr": [877, 1876, 1919, 1921], "addbackward0": [877, 1894, 1899], "__array_interface__": 877, "5962": 878, "4985": 878, "4396": 878, "4525": [878, 1878], "6387": 878, "4552": 878, "sine": [879, 1764, 1774, 1776], "1606": 879, "4267": 879, "0899": 879, "0250": 879, "1599": 879, "1534": 879, "9435": 879, "8990": [879, 1058], "arctang": [880, 881], "2341": 880, "2539": 880, "6256": 880, "6448": 880, "2299": 880, "2487": 880, "5591": [880, 902], "5727": 880, "quadrant": 881, "9041": [881, 938], "0196": [881, 938], "3108": [881, 938], "4423": [881, 938], "9833": 881, "0811": 881, "9743": 881, "4151": 881, "tangent": [882, 892, 893, 1126, 1127, 1462, 1820, 1821], "9385": 882, "2968": 882, "8591": 882, "1871": 882, "7253": 882, "3060": 882, "2899": 882, "1893": 882, "needs_input_grad": [886, 1888], "setup_context": [887, 1889], "save_for_forward": [887, 1889], "grad_input": [888, 895, 897, 910, 1190, 1422, 1598, 1888, 1894], "underneath": 889, "generate_vmap_rul": [889, 1889], "out_dim": [889, 1131, 1850, 1861, 1877, 1889], "grad_tensor": [890, 904, 1861, 1886], "grad_vari": 890, "forward_ad": 891, "dual": [891, 892, 893, 1647, 1889], "make_du": [891, 893], "your_fn": 891, "unpack_du": [891, 892], "grad_aft": 891, "dual_level": [892, 893], "primal": [893, 1122, 1126, 1127, 1130], "x_npy": 894, "once_differenti": [894, 895, 896, 897, 1888], "g1": [895, 897, 1886, 1915], "g2": [895, 897, 1886, 1915], "oppos": [896, 1889], "weren": 896, "grad_out": [896, 1859, 1861, 1891], "gx": 896, "gy": 896, "gz": 896, "simplefunc": 897, "outer_jacobian_strategi": 898, "disconnect": [898, 899, 900, 901, 902, 903], "said": [898, 899, 900, 901, 902, 903, 1870, 1897], "cliff": [898, 900, 904], "_debug_only_display_vmap_fallback_warn": [898, 904], "pow_reduc": [898, 899, 902], "2265": 898, "8221": 898, "9456": [898, 920], "2550": 898, "viewbackward": [898, 900], "pow_adder_reduc": [898, 899, 902], "func_output": [899, 901, 902, 903], "1448": 899, "0239": 899, "6456": 899, "4988": 899, "4310": 899, "sumbackward0": [899, 902], "3030": 899, "vhp": 899, "batched_grad": 900, "exp_reduc": [900, 901, 903], "4917": 900, "4352": 900, "4369": 900, "3799": 900, "exp_add": 900, "8052": 900, "3963": 900, "3090": 901, "6742": 901, "9114": 901, "2106": 901, "sumbackward1": [901, 903], "squeezebackward1": 901, "adder": [901, 903], "2399": 901, "5005": 901, "0689": 902, "2431": 902, "0989": 902, "4456": 902, "8053": [902, 1738], "7817": 903, "2458": 903, "7830": 903, "7782": 903, "4458": 903, "3962": 903, "3042": [903, 1247], "6354": 903, "1288": [903, 1767], "0652": 903, "5483": 903, "5035": 903, "2046": [903, 957], "1292": 903, "1432": 903, "3059": 903, "3225": 903, "6652": 903, "7753": 903, "0152": 903, "4225": 903, "3340": 903, "only_input": 904, "allow_unus": [904, 1861], "is_grads_batch": 904, "materialize_grad": 904, "require_grad": [904, 1863, 1883], "06": [905, 906, 1230, 1235, 1236, 1247, 1248, 1253, 1376, 1431, 1470, 1473, 1518, 1587, 1662, 1676, 1808, 1861, 1924], "raise_except": [905, 906], "check_sparse_nnz": 905, "nondet_tol": [905, 906], "check_undefined_grad": [905, 906], "check_grad_dtyp": [905, 906], "check_batched_grad": [905, 906], "check_batched_forward_grad": 905, "check_forward_ad": 905, "check_backward_ad": 905, "fast_mod": [905, 906, 1891], "differenc": [905, 1888], "perturb": [905, 906, 1891], "sparsetensor": [905, 1793], "gradgradcheck": [905, 1888], "gen_non_contig_grad_output": 906, "check_fwd_over_rev": 906, "check_rev_over_rev": 906, "noncontigu": [906, 1006, 1924], "inaccuraci": 906, "clonebackward0": 908, "gi": [910, 911, 1894], "removablehandl": [910, 911, 1190, 1422, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1905], "eventlist": [913, 914], "group_by_stack_n": [914, 1907], "roof": 914, "functioneventavg": [914, 916], "window_length": [919, 928, 1147, 1148, 1209, 1861], "2n": [919, 1762], "trim": [919, 928, 1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1147, 1148, 1187], "_length": [919, 928, 1147, 1148, 1187, 1345, 1804], "sim": [920, 1436, 1564, 1700, 1720], "pseudorandom": [920, 1312, 1650, 1697, 1700, 1716, 1718, 1720, 1722, 1809], "1737": 920, "0950": [920, 1786], "3609": 920, "7148": 920, "0289": [920, 1832], "2676": 920, "8937": 920, "7202": 920, "2500": [921, 1081, 1083, 1084, 1094, 1099, 1260, 1474, 1714], "7500": [921, 1084, 1094, 1113, 1143, 1245, 1260, 1474, 1714, 1770], "AND": [922, 1271, 1863, 1883], "OR": [925, 1273, 1863], "xor": [927, 1274, 1863], "blackman": [928, 1772], "arrang": 929, "broadcast_tensor": [931, 1861, 1903], "out_int32": [934, 1743, 1861], "formal": [934, 1743, 1870, 1877], "tensor_a": [936, 949], "tensor_b": 936, "6580": 937, "0969": 937, "4614": 937, "1034": [937, 1063], "5790": 937, "1497": 937, "x2": [938, 1237, 1414, 1470, 1471, 1503, 1560, 1861], "compute_mod": 938, "use_mm_for_euclid_dist_if_necessari": 938, "distanc": [938, 1187, 1225, 1226, 1253, 1382, 1431, 1470, 1471, 1561, 1683, 1804, 1808, 1858], "infti": [938, 1187, 1241, 1338, 1390, 1391, 1453, 1561, 1674, 1918], "use_mm_for_euclid_dist": 938, "donot_use_mm_for_euclid_dist": 938, "minkowski": [938, 1561], "ham": [938, 1147, 1561, 1768], "closest": [938, 1561], "xn": [938, 1561], "4821": [938, 941], "059": 938, "0590": 938, "1763": [938, 1726], "4713": [938, 1726], "6986": [938, 1726], "3702": [938, 1726], "1193": [938, 1279], "0959": 938, "7138": 938, "8322": 938, "2830": [938, 1834], "3791": 938, "6341": 939, "4208": 939, "0900": 939, "5826": 939, "clr": [940, 1683], "3375": 940, "9790": 940, "1119": 940, "6577": 940, "5609": [940, 1512], "5095": 940, "2614": 940, "4038": 940, "3378": [940, 1834], "4982": 940, "2457": [940, 1292], "2561": 940, "4684": 940, "7163": 940, "9647": 940, "8917": [940, 1270], "3213": [940, 1266], "2284": [940, 1043], "8615": 940, "2816": 940, "tu": 941, "mt": [941, 942, 1219, 1226, 1228, 1232, 1233, 1234, 1239, 1248, 1707, 1808, 1861, 1870, 1903, 1921, 1923], "4112": 941, "7486": 941, "4551": 941, "3544": 941, "6724": 941, "5528": 941, "0592": [941, 1894], "9371": 941, "5487": 941, "7023": 941, "03": [941, 942, 1267, 1765, 1766, 1771], "3842e": [941, 1235], "dpotri": 942, "spotri": 942, "uu": 942, "9935": 942, "6353": 942, "5806": 942, "8769": 942, "7183": [942, 1241, 1894], "6618": 942, "9314": 942, "2251": [942, 963, 1222, 1264], "0889": 942, "4439": 942, "2122": 942, "1412": 942, "5894e": 942, "semidefinit": 943, "7747": 943, "9549": 943, "3086": 943, "4114": 943, "8733": 943, "6355": 943, "9891": 943, "1974": 943, "4706": 943, "4115": 943, "6225": 943, "1625": 943, "6097": 943, "8398": 943, "2387": [943, 958], "3771": [943, 1236], "4173": 943, "1626": [943, 963, 1222], "tensor_split": [944, 1061, 1153, 1851, 1861, 1903, 1921], "min_valu": [945, 1381], "max_valu": [945, 1381, 1861], "_valu": [945, 1330, 1607, 1793, 1888, 1903, 1917], "7120": 945, "1734": [945, 1164], "0478": [945, 1853], "0922": 945, "3333": [945, 1143, 1152, 1474, 1475, 1822], "hstack": [948, 1861, 1903, 1917], "with_replac": [949, 1861], "combinations_with_replac": 949, "_glibcxx_use_cxx11_abi": 951, "flip": [955, 1104, 1105, 1257, 1859, 1861, 1903, 1904], "writeabl": [955, 956], "is_conj": [955, 1731, 1861, 1903], "geq": [957, 1134, 1221, 1229, 1358, 1408, 1429, 1430, 1440, 1504, 1556, 1609, 1881, 1918], "signbit": [957, 1859, 1861, 1903, 1917], "2557": 957, "0026": 957, "5387": 957, "4740": 957, "9244": 957, "7079": 957, "2778": 957, "0249": [957, 1265], "5719": 957, "0059": 957, "2600": 957, "4475": 957, "9567": [957, 1225, 1807], "5757": 957, "1751": 957, "0742": 957, "2998": 957, "1054": 957, "2373": 957, "3190": [957, 1886], "1128": [957, 1247, 1392], "pearson": 958, "coeffici": [958, 1147, 1662, 1664, 1665, 1666, 1668, 1674, 1678, 1767, 1768, 1769, 1831], "r_": [958, 1824], "ij": [958, 1063, 1269, 1277, 1291, 1425, 1785], "c_": [958, 1350, 1351, 1352, 1353, 1354, 1355, 1392, 1434, 1435], "jj": 958, "hermitian": [958, 1079, 1080, 1082, 1084, 1085, 1086, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1219, 1220, 1225, 1226, 1228, 1232, 1233, 1234, 1244, 1247, 1253, 1861], "cov": [958, 1861, 1903], "2678": [958, 1365], "0908": 958, "3766": 958, "2780": 958, "5812": 958, "1535": [958, 1365], "2350": 958, "3582": 958, "4309": 959, "2706": 959, "8562": 959, "9796": [959, 1235], "1395": 959, "2957": 959, "6553": 959, "5574": 959, "1632": 960, "1835": 960, "6979": 960, "7325": [960, 1053], "0133": 960, "7860": 960, "2536": 960, "2805": 960, "sleef": [960, 1776], "unbias": [962, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1461, 1802, 1803, 1845, 1846, 1859, 1861], "_w": 962, "y_": [962, 1073, 1263, 1264, 1266, 1339, 1358, 1388, 1785, 1829, 1883, 1918], "w_i": [962, 1229], "mu_x": 962, "mu_i": [962, 1668], "whichev": [962, 1131, 1521, 1708, 1850, 1886], "w_ix_": 962, "bessel": [962, 1209, 1771, 1802, 1803, 1845, 1846, 1918], "corrcoef": [962, 1861, 1903], "6667": [962, 1152, 1474, 1475, 1728, 1762, 1899], "fw": 962, "4282": 962, "0255": [962, 1050], "4144": [962, 1886], "4169": 962, "3956": [963, 1222], "1455": [963, 1222, 1900], "6895": [963, 1222], "5849": [963, 1222], "3599": [963, 1222], "7180": [963, 1222], "0521": [963, 1222], "1339": [963, 1222], "0225": [963, 1222, 1235], "0257": [963, 1222], "4725": [963, 1222], "1479": [963, 1222], "7005": [963, 1222], "9757": [963, 1222], "3904": [963, 1222], "3726": [963, 1222], "1836": [963, 1222], "9688": [963, 1222], "7153": [963, 1222, 1918], "2159": [963, 1222], "0844": [963, 1222], "5281": [963, 1222], "6120": [963, 1222], "4490": [963, 1222], "5687": [963, 1222], "9792": [963, 1044, 1222], "8304": [963, 1222], "3037": [963, 1222, 1894], "5650": [963, 1222], "2329": [963, 1222], "9883": [963, 1222], "0551": [963, 1222], "capture_begin": [964, 1886], "make_graphed_cal": [964, 1886], "graph_pool_handl": [964, 998], "other_graph_inst": [964, 998], "capture_end": [964, 1886], "debug_dump": 964, "debug_path": 964, "enable_debug_mod": 964, "path_to_so_fil": 965, "alloc_fn_nam": 965, "free_fn_nam": 965, "ctype": 965, "change_current_alloc": [965, 1886], "ssize_t": [965, 1886], "cudastream_t": [965, 967, 1886], "ptr": [965, 1886], "size_t": 965, "oss": 965, "enable_tim": [966, 1886], "interprocess": 966, "marker": 966, "elapsed_tim": [966, 1886], "end_ev": [966, 1886], "elaps": [966, 1873], "from_ipc_handl": 966, "reconstruct": [966, 1279, 1338, 1339, 1891, 1899, 1905], "ipc": [966, 1002], "ipc_handl": 966, "proceed": [966, 1376, 1914, 1915], "cudaeventsynchron": 966, "cudastreamwaitev": [966, 967, 969], "stream_ptr": 967, "record_ev": [967, 969], "cudastreamsynchron": [967, 969], "wait_ev": [967, 969], "interoper": 971, "caching_allocator_delet": 971, "mem_ptr": 972, "caching_allocator_alloc": 972, "peer_devic": 973, "_cudaalloc": 974, "clock": 975, "sm": 975, "hertz": 975, "smi": [975, 988, 1016, 1022, 1026, 1040, 1041, 1886, 1890, 1892], "buffer_s": 977, "10485760": 977, "chunk_siz": [980, 1125, 1131, 1850], "cublashandle_t": 981, "unoccupi": [988, 1300], "pytorch_cuda_alloc_conf": [989, 1886], "cudamallocasync": [989, 1020, 1886], "_cudadeviceproperti": 993, "gencod": 994, "cuda_graph": 998, "ordinari": [1000, 1602, 1882], "code_str": [1006, 1007], "temp": 1006, "typenam": [1006, 1007], "my_kernel": [1006, 1007], "jitted_fn": [1006, 1007], "create_jit_fn": [1006, 1007], "util_fn": 1006, "gelu": [1006, 1451, 1465, 1467, 1469, 1574, 1859, 1861, 1878, 1903], "my_gelu": 1006, "my_lib": [1006, 1867, 1900], "impl": [1006, 1867], "num_output": 1007, "sample_arg": 1009, "num_warmup_it": 1009, "allow_unused_input": 1009, "datadistributedparallel": 1009, "manual_seed_al": 1010, "occupi": [1012, 1016, 1027, 1298, 1410, 1539, 1886, 1892, 1929], "reset_peak_memory_stat": [1012, 1014, 1027, 1028], "max_memory_reserv": [1013, 1886, 1892], "cudamemgetinfo": 1015, "memory_reserv": [1017, 1886, 1892], "snapshot": [1019, 1863, 1886, 1892], "large_pool": 1020, "small_pool": 1020, "allocated_byt": 1020, "cudamalloc": [1020, 1886], "reserved_byt": 1020, "active_byt": 1020, "inactive_split": 1020, "inactive_split_byt": 1020, "octob": 1020, "1mb": 1020, "num_alloc_retri": 1020, "num_oom": 1020, "assist": [1020, 1887], "max_split_s": 1020, "oversize_alloc": 1020, "oversize_seg": 1020, "requested_byt": 1020, "abbrevi": 1021, "msg": [1023, 1025, 1907, 1924], "instantan": [1023, 1907], "ascii": [1023, 1025, 1261, 1863, 1907], "sensor": [1026, 1040], "mw": 1026, "milliwatt": 1026, "fermi": 1026, "max_memory_alloc": [1027, 1886, 1892], "max_memory_cach": 1028, "memory_stat": [1029, 1886, 1892], "seed_al": 1030, "environment": 1032, "total_memori": [1033, 1307], "debug_mod": [1037, 1750], "streamcontext": [1038, 1858], "centigrad": 1040, "x_1": [1042, 1043, 1044, 1045, 1257, 1343, 1356, 1357, 1492, 1503, 1829], "x_2": [1042, 1043, 1044, 1045, 1257, 1343, 1356, 1357, 1492, 1503], "x_3": [1042, 1043, 1044, 1045, 1257], "3449": 1042, "5447": 1042, "0685": 1042, "5104": [1042, 1886], "1706": 1042, "2259": 1042, "4696": 1042, "3284": 1042, "9946": 1042, "8209": [1042, 1045], "6628": 1043, "0975": 1043, "2680": [1043, 1885], "3298": [1043, 1050], "4220": 1043, "3885": 1043, "1762": 1043, "9165": 1043, "6684": [1043, 1167], "6001": 1044, "2069": 1044, "1919": 1044, "6727": [1044, 1057], "0062": 1044, "4126": 1044, "2129": 1044, "4206": 1044, "1968": [1044, 1918], "1241": 1044, "0238": 1044, "0233": [1044, 1715], "0157": 1044, "0158": [1044, 1808], "0065": 1044, "0014": [1044, 1918], "0006": 1044, "8286": 1045, "4890": 1045, "5155": 1045, "8443": 1045, "1865": 1045, "1752": [1045, 1053], "0595": 1045, "1850": 1045, "1571": [1045, 1894, 1899], "4243": 1045, "3175": 1045, "8020": [1045, 1705], "0423": 1045, "2289": 1045, "0537": 1045, "0058": 1045, "9780": 1045, "trapezoid": [1046, 1830, 1861, 1903], "360": 1047, "2832": 1047, "diagflat": [1050, 1861, 1903], "5950": 1050, "0872": 1050, "4264": 1050, "1064": [1050, 1894], "8795": 1050, "2429": 1050, "1374": 1050, "1029": 1050, "6482": 1050, "6300": 1050, "5410": 1051, "2934": 1051, "1788": [1051, 1918], "5684": 1051, "0845": [1051, 1776, 1894], "3986": 1051, "2956": [1052, 1222], "9068": 1052, "1695": 1052, "2094": [1052, 1886], "3018": 1052, "1516": 1052, "9342": 1052, "0854": 1053, "1431": 1053, "8536": 1053, "0905": 1053, "0360": [1053, 1311], "6927": 1053, "3735": 1053, "4945": 1053, "2631": [1053, 1310, 1886], "3755": 1053, "5977": 1053, "8172": 1053, "1065": [1053, 1894], "0401": 1053, "2235": [1053, 1807], "7938": 1053, "3081": 1053, "6166": 1053, "2335": 1053, "0500": 1053, "7336": 1053, "3836": 1053, "1015": 1053, "emb": [1054, 1746, 1777], "5393": 1057, "8675": 1057, "5916": 1057, "6321": 1057, "0967": 1057, "0511": 1057, "6295": 1057, "8360": 1057, "6973": 1057, "6537": 1057, "dividend": [1058, 1108, 1111, 1727, 1836], "true_divid": [1058, 1861, 1903], "3810": [1058, 1151], "2774": 1058, "2972": 1058, "3719": 1058, "4637": 1058, "7620": 1058, "5548": 1058, "5944": 1058, "7438": 1058, "9274": 1058, "3711": 1058, "9353": 1058, "4605": 1058, "2917": 1058, "1815": [1058, 1270], "0111": [1058, 1765], "9805": 1058, "5923": 1058, "1062": 1058, "4581": [1058, 1229], "7759": 1058, "2344": 1058, "1830": 1058, "0313": 1058, "1908": 1058, "4757": 1058, "8032": 1058, "2930": 1058, "8113": 1058, "2308": 1058, "4620": [1058, 1853], "6051": 1058, "5676": 1058, "2639": 1058, "2260": 1058, "4509": [1058, 1243], "2086": 1058, "1322": 1058, "9764": 1058, "9564": 1058, "3484": 1058, "2278": 1058, "1068": [1058, 1164], "4678": 1058, "3938": [1058, 1817], "depthwis": [1061, 1062, 1350, 1351, 1352], "atleast_3d": [1062, 1861, 1903], "operand": [1063, 1863, 1864, 1888, 1917, 1920], "notat": [1063, 1388, 1756, 1864, 1894, 1923], "einstein": 1063, "summat": [1063, 1187, 1269, 1277, 1917], "subscript": [1063, 1864], "ik": [1063, 1262, 1785], "za": 1063, "alphabet": [1063, 1505, 1913], "arrow": [1063, 1915], "ki": 1063, "ellipsi": [1063, 1863, 1864, 1877], "fourth": 1063, "whitespac": [1063, 1864], "opt_einsum": [1063, 1858], "_the_": 1063, "disclaim": 1063, "52": 1063, "op1": [1063, 1863], "sublist1": 1063, "op2": [1063, 1863], "sublist2": 1063, "subslist_out": 1063, "2104": 1063, "7952": 1063, "2433": 1063, "4545": 1063, "1156": 1063, "2897": [1063, 1894], "3918": 1063, "4963": 1063, "3744": 1063, "9381": 1063, "2685": 1063, "6070": 1063, "7208": 1063, "8058": 1063, "4419": 1063, "0936": 1063, "1713": 1063, "4291": 1063, "5802": 1063, "7350": [1063, 1918], "5704": 1063, "4290": 1063, "9323": 1063, "4480": 1063, "bij": 1063, "bjk": 1063, "bik": 1063, "0564": 1063, "5904": 1063, "2023": 1063, "1271": 1063, "6706": [1063, 1708], "8097": 1063, "8025": 1063, "1183": 1063, "2239": [1063, 1249], "3107": 1063, "5756": 1063, "2354": 1063, "4558": 1063, "3460": 1063, "5087": 1063, "8530": [1063, 1347, 1477], "8153": 1063, "8787": 1063, "3839": [1063, 1849], "2112": [1063, 1832], "3728": 1063, "1131": [1063, 1705], "0921": 1063, "8305": 1063, "ji": 1063, "anm": 1063, "bm": 1063, "ba": 1063, "3430": [1063, 1270], "2405": 1063, "4494": 1063, "3311": 1063, "5201": 1063, "0356": 1063, "4064e": 1064, "8000e": 1064, "3493e": 1064, "5751e": 1064, "1428e": 1064, "5955e": 1064, "9683e": 1066, "1239e": 1066, "0705e": 1066, "set_grad_en": [1067, 1861, 1903, 1925], "parenthesi": [1067, 1165, 1647], "doubler": [1067, 1647], "elsewher": [1068, 1076, 1134, 1146, 1180, 1182, 1183, 1186, 1214, 1278, 1323, 1786, 1857], "_max": [1077, 1078, 1908], "_min": [1077, 1078, 1908], "nearbi": [1077, 1078], "_int": [1077, 1078], "_point": [1077, 1078], "2525": 1077, "0466": 1077, "3491": [1077, 1243], "2168": [1077, 1824], "5906": [1077, 1918], "6258": 1077, "6444": 1077, "0542": 1077, "0475": [1077, 1918], "0486": 1077, "3405": 1077, "6134": [1077, 1292], "6323": 1077, "0552": 1078, "9730": 1078, "3973": 1078, "0780": 1078, "4000": [1078, 1081, 1090, 1099, 1474, 1711, 1762], "6000": [1078, 1465, 1467, 1469, 1474, 1711, 1759, 1762], "fourier": [1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1187, 1772, 1804, 1858], "rfft": [1079, 1084, 1094, 1098, 1099, 1100], "compact": [1079, 1080, 1082, 1232, 1234, 1237, 1888, 1901, 1908], "chalf": [1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1094, 1095, 1096, 1861, 1903, 1923], "sm53": [1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100], "ortho": [1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1262], "orthonorm": [1079, 1080, 1082, 1084, 1085, 1086, 1087, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1100, 1253, 1609, 1808], "ifft": [1079, 1083, 1084, 1088, 1089, 1091, 1092, 1093, 1094, 1095, 1096], "fftn": [1080, 1083, 1089, 1092, 1100], "rfft2": [1080, 1095], "ifft2": [1080, 1092], "two_fft": [1080, 1082, 1092, 1098, 1100], "check_strid": [1080, 1082, 1083, 1088, 1089, 1094, 1095, 1096, 1098, 1100, 1924], "nyquist": [1081, 1083, 1091, 1093, 1097, 1098, 1099, 1100], "i_1": [1082, 1100, 1210], "i_n": [1082, 1100, 1131, 1210, 1824, 1850], "rfftn": [1082, 1086, 1092, 1096, 1098], "ifftn": [1082, 1088, 1093], "rearrang": [1083, 1090, 1346, 1434, 1435, 1562, 1563, 1877], "fftfreq": [1083, 1090, 1099], "9000": [1083, 1822], "8000": [1083, 1317, 1474, 1708, 1762], "uncent": 1083, "ifftshift": 1083, "x_center": 1083, "x_uncent": 1083, "fft_uncent": 1083, "fft_center": 1083, "x_centered_2": 1083, "ihfft": [1084, 1092, 1093], "irfft": [1084, 1096, 1097], "symmetri": [1084, 1086, 1804], "opposit": [1084, 1086, 1808, 1828], "transformed_dim_s": [1084, 1094], "0000j": [1084, 1091, 1094, 1219, 1220, 1225, 1226, 1228, 1701, 1759], "1250": [1084, 1310], "1720j": 1084, "0406j": 1084, "2809": 1084, "6250": [1084, 1094, 1113, 1474], "9691": 1084, "hfftn": [1085, 1093], "last_dim_s": [1085, 1086, 1095, 1096, 1859], "ihfft2": 1085, "roundtrip": [1085, 1086, 1094, 1095, 1096], "ihfftn": [1086, 1092], "irfftn": [1086, 1095, 1100], "fft2": [1088, 1098], "two_ifft": [1088, 1089, 1093], "fftshift": 1090, "hfft": 1091, "6882j": 1091, "1625j": 1091, "hfft2": 1092, "8602j": 1094, "2031j": 1094, "1562": 1094, "3511": 1094, "7812": 1094, "2114": 1094, "irfft2": 1098, "wider": [1106, 1860, 1863, 1904, 1917], "49": [1106, 1245, 1885], "2500e": 1106, "1000e": 1106, "7656e": 1106, "lfloor": [1107, 1112, 1330, 1335, 1336, 1337, 1350, 1351, 1352, 1369, 1390, 1391, 1415, 1416, 1417, 1473, 1474, 1475, 1476, 1490, 1559, 1723, 1804], "rfloor": [1107, 1112, 1330, 1335, 1336, 1337, 1350, 1351, 1352, 1369, 1390, 1391, 1415, 1416, 1417, 1473, 1474, 1475, 1476, 1490, 1559, 1723, 1804], "8166": 1107, "5308": 1107, "2530": 1107, "2091": 1107, "7000": [1109, 1366, 1761], "3000": [1110, 1365, 1761, 1886], "entrywis": [1111, 1727], "modulu": [1111, 1249, 1727], "operatornam": [1112, 1225, 1226, 1227, 1228, 1245, 1253, 1338, 1339, 1345, 1382, 1383, 1389, 1413, 1453, 1471, 1761], "8750": [1113, 1474], "char": [1116, 1658, 1876, 1919], "parameter_and_buffer_dict": 1119, "tie_weight": [1119, 1644], "submodule_nam": [1119, 1644], "parameter_nam": [1119, 1644], "ty": [1119, 1644], "foo_ti": [1119, 1644], "new_a": [1119, 1644], "mutlipl": 1119, "grad_weight": [1119, 1888], "detached_param": 1119, "parameters_and_buffer_dict": 1119, "reparamater": [1119, 1644], "paramat": 1119, "intermediate_upd": 1120, "mutations_and_view": 1120, "intermeid": 1120, "inpt": 1120, "out1": [1120, 1861], "out2": [1120, 1861], "f_trace": 1120, "f_no_mutations_trac": 1120, "f_no_mutations_and_views_trac": 1120, "a_1": [1120, 1210], "view_1": 1120, "view_copi": [1120, 1861, 1903, 1925], "view_copy_1": 1120, "as_strid": [1120, 1859, 1861, 1903, 1921], "writ": 1120, "native_funct": [1120, 1859], "yaml": [1120, 1859], "aux": [1121, 1122, 1124, 1125, 1126, 1130], "my_loss_func": 1121, "y_pred": [1121, 1886], "loss_per_sampl": 1121, "y_true": 1121, "autodiff": [1124, 1125, 1126, 1248], "jacobian_f": [1124, 1125], "f_x": [1124, 1125], "jacboian": [1124, 1125], "expectedx": [1124, 1125], "expectedi": [1124, 1125], "_preallocate_and_copi": 1125, "stand": [1126, 1130, 1862, 1905, 1915], "jvp_out": 1126, "jvp_fn": 1127, "requr": 1127, "optimiz": [1129, 1860], "l1": [1129, 1382, 1383, 1453, 1530, 1575, 1619, 1628, 1894, 1899], "l2": [1129, 1383, 1413, 1453, 1661, 1662, 1663, 1664, 1666, 1668, 1674, 1675, 1677, 1882], "vjpfunc": 1130, "unsuccessfulli": [1131, 1850], "rummag": [1131, 1850], "batched_dot": [1131, 1850], "imposs": [1131, 1850, 1882], "jacobian_row": [1131, 1850], "get_vjp": [1131, 1850], "n1": [1131, 1729, 1850], "n0": [1131, 1850], "batched_pow": [1131, 1850], "autobatch": [1131, 1850], "sparse_grad": [1132, 1859, 1861], "tau": [1135, 1229, 1523, 1663, 1677, 1694, 1695, 1765, 1861], "elementari": [1135, 1883, 1891], "reflector": [1135, 1609, 1695], "household": [1135, 1229, 1609, 1695], "householder_product": [1135, 1609, 1694], "gel": [1135, 1235], "set_default_dtyp": 1137, "set_deterministic_debug_mod": [1138, 1843], "edge_ord": [1143, 1861], "mathbb": [1143, 1219, 1221, 1225, 1226, 1227, 1228, 1229, 1230, 1235, 1236, 1239, 1241, 1248, 1250, 1252, 1253, 1358, 1429, 1609], "rightarrow": 1143, "interior": 1143, "theorem": 1143, "h_l": 1143, "h_r": 1143, "neighbor": [1143, 1187, 1474, 1476, 1804], "xi_1": 1143, "xi_2": 1143, "approx": [1143, 1809, 1891], "outermost": 1143, "80": [1143, 1245, 1687, 1756, 1886, 1904], "halv": 1143, "coord": 1143, "54": [1147, 1384, 1768], "46": [1147, 1767], "hann_window": [1147, 1804, 1861, 1865, 1903], "hann": [1148, 1768], "hist": [1151, 1152, 1861], "bin_edg": [1151, 1152, 1861], "9524": 1151, "leftmost": [1152, 1878], "leg": 1156, "triangl": [1156, 1922], "hypotenus": 1156, "4031": 1156, "gammainc": [1158, 1918], "gammaincc": [1159, 1918], "index_reduce_": [1163, 1861], "realloc": 1164, "1427": 1164, "0231": 1164, "5414": 1164, "0009": 1164, "4664": [1164, 1824], "2647": 1164, "1228": 1164, "6571": 1164, "7230": 1164, "6004": 1164, "inferencemod": [1165, 1883], "bump": 1165, "_version": [1165, 1903], "multidimension": [1167, 1259, 1385], "8173": 1167, "0874": 1167, "1784": 1167, "3279": 1167, "7894": 1167, "4682": 1167, "7159": 1167, "1506": 1167, "4034": 1167, "3657": 1167, "0387": 1167, "9892": 1167, "1774": 1167, "3261": 1167, "3917": 1167, "4537": [1167, 1593], "7493": 1167, "1724": 1167, "2291": 1167, "5749": 1167, "2267": 1167, "7920": 1167, "3607": 1167, "3701": 1167, "3666": 1167, "5850": [1167, 1220], "7242": 1167, "9837": 1167, "1560": 1167, "2907": 1167, "6785": 1167, "5671": [1167, 1221], "5452": 1167, "6912": 1167, "5509": 1167, "1782": 1167, "9843": 1167, "7366": 1167, "5672": [1167, 1650], "5115": 1167, "4864": 1167, "2476": 1167, "4337": 1167, "6347": 1167, "1748": 1167, "3567": [1167, 1220], "6558": 1167, "2469": [1167, 1894], "5787": [1167, 1270], "typecheck": [1177, 1903], "mypi": [1177, 1862, 1863], "warn_alwai": 1178, "set_warn_alwai": 1178, "nonfinit": 1179, "test_el": [1181, 1861], "assume_uniqu": [1181, 1861], "0j": [1186, 1847], "nola": 1187, "envelop": 1187, "hop": [1187, 1804], "shorter": [1187, 1901, 1913], "griffin": 1187, "ieee": [1187, 1376, 1772, 1897], "tran": 1187, "assp": 1187, "vol": [1187, 1376, 1772], "pp": [1187, 1376, 1772], "236": 1187, "apr": 1187, "1984": 1187, "slide": [1187, 1335, 1336, 1337, 1369, 1415, 1416, 1417, 1473, 1515, 1545, 1546, 1547, 1589, 1712, 1713, 1804], "fft_size": 1187, "scriptmodul": [1188, 1189, 1194, 1197, 1199, 1200, 1201, 1205, 1206, 1660, 1860, 1862, 1871, 1901], "implic": [1188, 1205, 1913, 1917], "attributemodul": 1188, "names_ag": 1188, "9223372036854775807": [1188, 1635, 1873], "get_debug_st": 1189, "graphexecutorst": 1189, "_extra_fil": [1189, 1190, 1197, 1200, 1893], "save_to_buff": 1189, "add_modul": [1190, 1422], "init_weight": [1190, 1422, 1894], "buf": [1190, 1422], "20l": [1190, 1422], "1l": [1190, 1422], "5l": [1190, 1422], "code_with_const": 1190, "constmap": 1190, "extra_repr": [1190, 1422, 1888], "get_buff": [1190, 1422], "attributeerror": [1190, 1422, 1888, 1908], "get_extra_st": [1190, 1422], "set_extra_st": [1190, 1422], "get_paramet": [1190, 1422], "net_b": [1190, 1422], "net_c": [1190, 1422], "inlined_graph": 1190, "ipu": [1190, 1422], "missing_kei": [1190, 1422], "unexpected_kei": [1190, 1422], "remove_dupl": [1190, 1422], "named_children": [1190, 1422, 1894], "conv4": [1190, 1422], "conv5": [1190, 1422], "register_backward_hook": [1190, 1422, 1598], "register_full_backward_hook": [1190, 1422, 1894], "register_buff": [1190, 1422, 1595, 1860, 1862, 1888, 1894], "register_forward_hook": [1190, 1422, 1596, 1894], "with_kwarg": [1190, 1422], "register_module_forward_hook": [1190, 1422, 1894], "register_forward_pre_hook": [1190, 1359, 1422, 1597, 1894], "forward_pr": [1190, 1422], "register_module_forward_pre_hook": [1190, 1422, 1894], "register_module_full_backward_hook": [1190, 1422, 1594, 1883, 1894], "register_full_backward_pre_hook": [1190, 1422, 1894], "register_module_full_backward_pre_hook": [1190, 1422, 1894], "register_load_state_dict_post_hook": [1190, 1422], "incompatible_kei": [1190, 1422], "register_modul": [1190, 1422, 1600], "register_paramet": [1190, 1422, 1601, 1888, 1894], "register_state_dict_pre_hook": [1190, 1422], "keep_var": [1190, 1422], "finetun": [1190, 1422], "gan": [1190, 1422, 1610, 1643], "share_memori": [1190, 1422, 1896], "share_memory_": [1190, 1422, 1875, 1919], "shallow": [1190, 1359, 1422, 1470, 1471], "channels_last": [1190, 1422, 1602, 1920], "4d": [1190, 1341, 1369, 1386, 1422, 1474, 1515, 1532, 1559, 1590, 1711], "1913": [1190, 1422], "3420": [1190, 1422], "5113": [1190, 1422, 1824], "2325": [1190, 1222, 1422], "gpu1": [1190, 1422], "1914": [1190, 1422], "5112": [1190, 1422, 1886], "3741": [1190, 1422], "2382": [1190, 1311, 1422], "5593": [1190, 1422], "4443": [1190, 1422], "6122": [1190, 1422], "1150": [1190, 1422], "to_empti": [1190, 1422], "dst_type": [1190, 1422], "xpu": [1190, 1422, 1907], "set_to_non": [1190, 1422, 1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678, 1886], "the_typ": 1191, "the_valu": 1191, "script_bar": 1193, "addmod": 1193, "preserved_attr": 1194, "optimize_numer": 1194, "run_frozen_optim": 1194, "scripted_modul": [1194, 1201, 1899], "frozen_modul": 1194, "modified_tensor": 1194, "mymodule2": 1194, "dump_alias_db": 1194, "pdb": [1195, 1201, 1207, 1860, 1862], "training_method": 1195, "target_typ": 1196, "refin": [1196, 1877], "testcod": [1196, 1862], "key1": 1196, "val1": 1196, "key2": 1196, "val2": 1196, "_restore_shap": 1197, "scriptfunct": [1197, 1201, 1202, 1205, 1901], "readlin": [1197, 1261, 1905], "seek": [1197, 1261, 1905, 1908], "retrac": 1197, "rb": [1197, 1261], "extra_fil": [1197, 1200], "other_method": 1199, "lesser": [1199, 1883, 1885], "extent": [1199, 1885, 1917], "frozen_mod": 1199, "offlin": 1200, "_frames_up": 1201, "_rcb": 1201, "scriptdict": 1201, "scriptlist": 1201, "test_sum": 1201, "scripted_fn": [1201, 1860], "conv2": [1201, 1422, 1450, 1860, 1908], "some_entry_point": 1201, "python_only_fn": 1201, "testnnmodul": 1201, "pdt_model": 1201, "scripted_model": [1201, 1905], "un": [1203, 1345, 1908], "unfus": 1203, "nb": 1203, "check_trac": [1205, 1206], "check_input": [1205, 1206, 1860], "check_toler": [1205, 1206], "_force_outplac": [1205, 1206], "_module_class": [1205, 1206], "_compilation_unit": [1205, 1206], "compilationunit": [1205, 1206], "example_kwarg_input": 1205, "_store_input": [1205, 1206], "trace_modul": [1205, 1860, 1863], "untrack": 1205, "checker": [1205, 1206, 1863, 1901], "diverg": [1205, 1206, 1388, 1533, 1858, 1863], "traced_foo": [1205, 1860], "example_weight": [1205, 1206], "example_forward_input": [1205, 1206], "example_inputs_is_kwarg": 1206, "method2": 1206, "example_method2_input": 1206, "weighted_kernel_sum": 1206, "use_memory_effici": 1207, "memory_effici": 1207, "scriptabl": 1207, "kaiser": [1209, 1465, 1467, 1469], "i_0": [1209, 1210, 1771, 1824, 1918], "zeroth": [1209, 1771, 1918], "out_i": 1209, "kroneck": 1210, "a_0": 1210, "a_n": 1210, "b_0": 1210, "b_1": 1210, "b_n": 1210, "k_0": [1210, 1824], "k_1": 1210, "k_n": 1210, "j_0": 1210, "j_1": 1210, "j_n": 1210, "k_t": 1210, "i_t": [1210, 1392, 1676], "b_t": 1210, "j_t": 1210, "bmatrix": 1210, "a_": [1210, 1281, 1410, 1824], "cdot": [1210, 1235, 1247, 1338, 1339, 1357, 1358, 1380, 1388, 1425, 1426, 1427, 1428, 1429, 1465, 1503, 1526, 1701, 1804, 1918, 1924], "vdot": [1210, 1257, 1258, 1861, 1903], "ddot": [1210, 1257], "kth": 1211, "full_lik": [1215, 1861, 1865, 1903], "logarithm": [1218, 1223, 1249, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1276, 1345, 1505, 1540, 1784, 1918], "gamma": [1218, 1340, 1341, 1342, 1377, 1385, 1386, 1387, 1394, 1461, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1677, 1679, 1683, 1684, 1687, 1692, 1693, 1711, 1858, 1861, 1901, 1903, 1904, 1918], "5724": [1218, 1918], "1208": [1218, 1918], "mathrlap": [1219, 1225, 1226, 1227, 1228, 1236, 1239, 1248, 1250, 1252, 1253, 1609], "qquad": [1219, 1221, 1225, 1226, 1227, 1228, 1229, 1236, 1239, 1248, 1250, 1252, 1253, 1609], "eigenvalu": [1219, 1225, 1226, 1227, 1228, 1241, 1244, 1247, 1252, 1253, 1262, 1697, 1861], "resp": [1219, 1226, 1228, 1252, 1253, 1270], "5266": 1219, "9586": 1219, "0626j": 1219, "4160": 1219, "5895": 1219, "2322": 1219, "2976j": 1219, "4928": [1219, 1824], "4692e": 1219, "8747e": 1219, "check_error": [1220, 1231, 1233, 1238, 1251, 1861], "performantli": 1220, "3792": 1220, "9831j": 1220, "8757": 1220, "5425": 1220, "6374j": 1220, "kappa": 1221, "_p": [1221, 1431], "frobeniu": [1221, 1235, 1242, 1246, 1649], "nuc": [1221, 1242, 1246, 1259, 1620, 1629, 1649], "nuclear": [1221, 1242, 1246, 1649], "sigma_1": [1221, 1235, 1244, 1247], "sigma_n": 1221, "kappa_2": 1221, "kappa_": 1221, "4142": [1221, 1246, 1649, 1701], "1623": [1221, 1242], "2426": [1221, 1246, 1649], "7071": [1221, 1764], "5917": 1221, "9941": 1222, "5132": 1222, "5681": 1222, "4653": 1222, "4507": 1222, "4119": 1222, "6163": 1222, "1073": 1222, "3957": 1222, "9666": [1222, 1512], "0840": 1222, "3357": 1222, "2139": 1222, "slogdet": [1223, 1270, 1861, 1903], "0934": 1223, "1990": [1223, 1270], "4099": [1223, 1270], "7386": [1223, 1270], "diagonaliz": [1225, 1227], "eigenvector": [1225, 1226, 1262, 1861], "neq": [1225, 1226, 1229, 1253, 1323, 1425, 1427, 1662, 1663, 1664, 1666, 1668, 1674, 1675, 1677, 1681, 1808], "phi": [1225, 1226, 1253, 1372, 1519, 1808], "shall": [1225, 1226, 1253, 1611, 1615], "lambda_i": [1225, 1226, 1241], "lambda_j": [1225, 1226], "eigval": [1225, 1861], "9828": [1225, 1832, 1894], "3889j": 1225, "4617": 1225, "3010j": 1225, "1662": 1225, "7435j": 1225, "6139": 1225, "0562j": 1225, "1226": [1225, 1227], "5738j": [1225, 1227], "7537": [1225, 1227], "1286j": [1225, 1227], "9218": 1225, "1882": 1225, "2220j": 1225, "0270": 1225, "3867j": 1225, "7119e": 1225, "2841e": 1225, "uplo": [1226, 1228, 1861], "unitari": [1226, 1229, 1248, 1253, 1609, 1695], "eigvalsh": [1226, 1244], "9228": [1226, 1228], "2029": [1226, 1228], "0862j": [1226, 1228], "3464": [1226, 1228], "3277": [1226, 1228], "9415": [1226, 1228], "0846": 1226, "9964": 1226, "9170": 1226, "3898j": 1226, "0331j": 1226, "1062e": 1226, "5423e": 1226, "polynomi": [1227, 1228, 1690], "_n": [1227, 1228, 1230, 1609, 1888], "4576e": [1227, 1254], "5797": 1228, "4629": 1228, "1605": 1228, "3780": 1228, "1113": [1228, 1894], "7381": 1228, "h_1h_2": 1229, "h_k": 1229, "h_i": [1229, 1456], "_m": [1229, 1609], "tau_i": 1229, "8034": 1229, "4184j": 1229, "2588": 1229, "0174j": 1229, "6853": 1229, "7953j": 1229, "0790": 1229, "5620j": 1229, "6989j": 1229, "5360": 1229, "1193j": 1229, "3877": 1229, "6691j": 1229, "3512": 1229, "3024j": 1229, "4766": 1229, "5783j": 1229, "0361": [1229, 1894], "6587j": 1229, "6396": [1229, 1894], "1612j": 1229, "3693": 1229, "4481j": 1229, "aa": 1230, "pinv": [1230, 1235, 1699], "moor": [1230, 1247], "penros": [1230, 1247], "ainv": [1230, 1231, 1251, 1255], "1921e": 1230, "9073e": [1230, 1473], "5107e": 1230, "ldl": [1232, 1234], "indefinit": 1232, "ld": [1232, 1233, 1234, 1861], "sytrf": [1232, 1233], "ldl_solv": 1232, "ldl_factor_ex": [1232, 1234], "2079": [1232, 1233, 1918], "2414": [1232, 1233], "9428": [1232, 1233], "4554": [1232, 1233], "3264": [1232, 1233], "3823": [1232, 1233], "5884": [1232, 1233], "9595": [1232, 1233, 1764], "2695": [1232, 1233], "8513": [1232, 1233], "1633": [1232, 1233], "ldl_factor": 1233, "rcond": [1235, 1247, 1699, 1861], "_f": 1235, "gelsi": 1235, "gelsd": 1235, "gelss": 1235, "tridiagon": 1235, "sigma_i": [1235, 1253, 1808], "residu": [1235, 1262, 1861, 1894], "singular_valu": [1235, 1861], "lh": 1235, "rh": [1235, 1280], "0838": [1235, 1894], "2275": [1235, 1310], "3844": 1235, "5499": 1235, "1175": 1235, "9102": 1235, "0870": 1235, "6772": 1235, "7758": 1235, "5109": 1235, "4382": 1235, "3769": 1235, "1818": 1235, "3450": 1235, "0806": [1235, 1894], "3967": 1235, "3994": 1235, "1521": 1235, "1473": 1235, "9194": 1235, "0458": 1235, "6705": [1235, 1294], "1802": 1235, "4086": 1235, "5152e": 1235, "5007": 1236, "9755": 1236, "0489": 1236, "9644": [1236, 1289], "9605e": 1236, "0376e": 1236, "lu_factor_ex": [1237, 1279], "lu_unpack": [1237, 1279, 1861, 1903], "b1": 1237, "b2": [1237, 1886, 1892], "a_factor": 1237, "getrf": [1238, 1251], "adjoint": [1239, 1861, 1903, 1921, 1923], "_exp": 1241, "3891": 1241, "8660": 1241, "ord": [1242, 1246, 1259, 1649, 1861, 1863, 1903], "la": [1242, 1246, 1259, 1894], "2829": 1242, "2627": 1242, "0756": 1243, "4980": 1243, "6617": 1243, "4994": 1243, "9980": 1243, "2731": 1243, "8001": 1243, "2640": 1243, "4571": 1243, "5511": 1243, "0163": [1243, 1289], "5292": 1243, "4899": 1243, "0822": 1243, "2773": [1243, 1878], "varepsilon": [1244, 1247], "tol": [1244, 1262, 1861], "fewest": 1245, "nd": [1245, 1897], "bc": [1245, 1904], "75000": 1245, "148": 1245, "vector_norm": [1246, 1649], "matrix_norm": [1246, 1259, 1610, 1649], "7460": [1246, 1649], "3485": 1246, "8570e": 1246, "8480": 1246, "2361": [1246, 1649, 1650], "7417": [1246, 1649], "computation": [1247, 1891], "5495": [1247, 1310], "0979": 1247, "4092": 1247, "4132": [1247, 1770], "1143": 1247, "3662": 1247, "6374": 1247, "9294": 1247, "3269": [1247, 1894], "5745": [1247, 1802, 1803, 1845, 1846], "0382": [1247, 1311], "5922": 1247, "6759": 1247, "0600": 1247, "1933": 1247, "2090": 1247, "0903": 1247, "0817": 1247, "4752": [1247, 1807], "7124": 1247, "1631": 1247, "2272": 1247, "1356": 1247, "3933": 1247, "5023": 1247, "0308": 1247, "1725": 1247, "5216": 1247, "apinv": 1247, "5633e": 1247, "0830e": 1247, "wide": [1248, 1253, 1609, 1766, 1885, 1888, 1894, 1904], "51": [1248, 1420, 1707], "167": [1248, 1707], "68": [1248, 1707, 1860, 1862], "8571": [1248, 1707], "3943": [1248, 1707], "3314": [1248, 1707], "4286": [1248, 1707], "9029": [1248, 1707], "0343": [1248, 1707], "2857": [1248, 1707], "1714": [1248, 1707, 1894], "9429": [1248, 1707], "175": [1248, 1707], "q2": 1248, "r2": [1248, 1461], "6099e": 1248, "2158e": 1248, "logabsdet": [1249, 1861], "0032": 1249, "1219": [1249, 1726], "6690": 1249, "1161": 1249, "4053": 1249, "6218": [1249, 1821], "9273": 1249, "0082": 1249, "7576": 1249, "logdet": [1249, 1861, 1903], "linalg_slogdet": [1249, 1861, 1903], "2776": 1249, "solve_triangular": [1250, 1831], "expand_a": [1250, 1861, 1888, 1903, 1921], "rectangular": [1252, 1253, 1281, 1881], "triu_": [1252, 1861], "tril_": [1252, 1861], "full_matric": [1253, 1254, 1614, 1808, 1859, 1861], "vh": [1253, 1614, 1808, 1859, 1861], "gesvdj": [1253, 1254, 1808], "jacobi": 1253, "gesvda": [1253, 1254], "gesvd": [1253, 1254, 1808], "u_k": 1253, "v_k": 1253, "sigma_j": [1253, 1808], "eigendecomposit": 1253, "0486e": 1253, "0957e": 1253, "5139": 1254, "1087": 1254, "1066": 1254, "ind": [1255, 1256, 1861, 1889], "tensorsolv": 1255, "atensorinv": 1255, "movedim": [1256, 1296, 1861, 1889, 1903, 1921], "tensorinv": 1256, "vandermond": [1257, 1844], "pmatrix": 1257, "x_n": [1257, 1338, 1339, 1382, 1383, 1389, 1413, 1453, 1829, 1883], "125": [1257, 1440, 1844, 1861], "overlin": [1258, 1847], "3223": 1258, "2815": 1258, "1944": [1258, 1894], "4345": 1259, "pickle_modul": [1261, 1739], "weights_onli": [1261, 1857, 1872], "pickle_load_arg": 1261, "register_packag": 1261, "binaryio": [1261, 1739, 1905], "untrust": [1261, 1857, 1872, 1905], "unsaf": [1261, 1611, 1614, 1861, 1886, 1905], "tamper": [1261, 1905], "ram": [1261, 1886], "surg": 1261, "decod": [1261, 1465, 1466, 1467, 1602, 1905], "utf": [1261, 1901, 1905], "unicodedecodeerror": 1261, "codec": 1261, "0x": 1261, "latin1": 1261, "byte_arrai": 1261, "niter": [1262, 1697, 1809], "ortho_iparam": 1262, "ortho_fparam": 1262, "ortho_bparam": 1262, "knyazev": 1262, "knyazev2001": 1262, "stathopoulosetal2002": 1262, "converg": [1262, 1453, 1609, 1664, 1665, 1689, 1882, 1894, 1897], "precondition": 1262, "eigenpair": 1262, "criterion": [1262, 1338, 1339, 1356, 1358, 1383, 1389, 1413, 1414, 1425, 1426, 1427, 1453, 1454, 1470, 1471, 1504, 1682, 1714, 1890], "fep": 1262, "eigenproblem": 1262, "iparam": 1262, "fparam": 1262, "bparam": 1262, "ivar": 1262, "fvar": 1262, "bvar": 1262, "tvar": 1262, "istep": 1262, "converged_count": 1262, "rerr": 1262, "force_stop": 1262, "2001": 1262, "precondit": 1262, "eigensolv": 1262, "siam": 1262, "sci": 1262, "517": 1262, "541": 1262, "epub": 1262, "doi": [1262, 1376, 1772], "1137": 1262, "s1064827500366124": 1262, "andrea": 1262, "stathopoulo": 1262, "kesheng": 1262, "2002": [1262, 1772], "2165": 1262, "2182": 1262, "s1064827500370883": 1262, "duerschetal2018": 1262, "jed": 1262, "duersch": 1262, "meiyu": 1262, "shao": 1262, "chao": 1262, "ming": 1262, "gu": 1262, "c655": 1262, "c676": 1262, "17m1129830": 1262, "log_": [1263, 1264, 1265, 1266, 1861, 1876], "7767": 1263, "3234": 1263, "2156": 1263, "2411": 1263, "5739": 1263, "5637": 1263, "4640": 1263, "1952": 1263, "4226": 1263, "5204": [1263, 1716], "5224": 1264, "9354": 1264, "7257": 1264, "1301": 1264, "2820": 1264, "0290": 1264, "1392": 1264, "8857": 1264, "6476": 1264, "0090": [1265, 1324, 1703, 1918], "9923": 1265, "5372": 1265, "2492": 1265, "8653": 1265, "7055": 1265, "7705": 1265, "2225": 1265, "8419": 1266, "8003": [1266, 1898], "9971": 1266, "5287": 1266, "0490": 1266, "2483": 1266, "0042": 1266, "9196": 1266, "3504": [1266, 1824], "logsumexp": [1267, 1861, 1876, 1903, 1918], "3069": 1267, "6867": 1267, "8731": 1267, "30000": 1267, "1269e": 1267, "log_2": 1268, "logaddexp": [1268, 1861, 1903], "limits_": 1269, "42296738": 1269, "04462666": 1269, "86278635": 1269, "94622083": 1269, "05277811": 1269, "39202815": 1269, "83525007": 1269, "84492621": 1269, "06084887": 1269, "06844475": 1269, "2611": [1270, 1821], "9254": 1270, "6213": [1270, 1894], "6843": 1270, "3242": 1270, "9665": 1270, "4539": 1270, "0887": [1270, 1918], "1336": 1270, "4025": 1270, "7089": [1270, 1365], "9032": 1270, "3031": 1270, "2589": 1276, "1135": 1276, "5481": [1276, 1289, 1894], "9566": 1276, "sum_j": [1277, 1412, 1455, 1457, 1577, 1787, 1918], "0593": [1277, 1894], "5696": 1277, "6859e": 1277, "compute_pivot": 1279, "transposit": [1279, 1828, 1917], "perm": 1279, "a_lu": 1279, "5558": 1279, "1684": 1279, "1551": 1279, "1940": 1279, "6189": 1279, "5497": 1279, "4526": 1279, "2526": 1279, "3285": 1279, "7988": 1279, "7175": 1279, "9701": 1279, "2634": 1279, "9255": 1279, "3459": 1279, "00000e": 1280, "8312": 1280, "unpack_data": [1281, 1861], "unpack_pivot": [1281, 1861], "l_": [1281, 1327, 1331, 1335, 1339, 1350, 1351, 1352, 1353, 1390, 1415], "u_": [1281, 1662, 1666], "3552": [1283, 1513], "3825": 1283, "8297": 1283, "3477": 1283, "2035": [1283, 1802, 1803, 1845, 1846], "2252": [1283, 1918], "5002": 1283, "6248": [1283, 1292], "1307": 1283, "0608": [1283, 1781], "1244": 1283, "0139": 1283, "6763": 1287, "7445": 1287, "2369": 1287, "argmax": [1287, 1330, 1415, 1545, 1546, 1547, 1819, 1859, 1861, 1903], "max_indic": 1287, "2360": 1287, "2942": 1287, "1222": [1287, 1894], "8475": 1287, "1949": 1287, "1127": 1287, "6702": 1287, "5717": 1287, "9207": 1287, "1297": 1287, "8768": 1287, "6172": 1287, "6060": 1287, "2432": 1287, "3288": 1289, "3367": 1289, "nanmean": [1289, 1861, 1903], "3841": 1289, "6320": 1289, "4254": 1289, "7384": 1289, "0131": 1289, "6549": [1289, 1764], "4279": 1289, "3350": 1289, "7694": 1289, "5600": [1289, 1474], "0842": 1289, "9580": 1289, "3623": 1289, "2343": [1289, 1878], "5085": 1289, "4599": 1289, "1807": 1289, "5219": 1290, "5212": 1290, "2202": 1290, "2505": 1290, "3982": 1290, "9948": 1290, "3518": 1290, "3131": 1290, "3180": [1290, 1917], "6993": 1290, "0436": 1290, "0438": 1290, "2270": 1290, "2751": 1290, "7303": 1290, "2192": 1290, "3321": 1290, "2488": 1290, "0778": 1290, "9510": 1290, "7048": 1290, "4742": [1290, 1837, 1918], "7125": [1290, 1789], "plot": [1291, 1885, 1907, 1922], "t_0": [1291, 1682], "s_0": 1291, "s_": [1291, 1328, 1329, 1368, 1472], "g_0": 1291, "g_": [1291, 1666, 1676, 1677], "g_i": 1291, "t_i": 1291, "0d": [1291, 1414], "xy": 1291, "50276": 1291, "cartesian_prod": [1291, 1861, 1903], "grid_x": 1291, "grid_i": 1291, "dstack": [1291, 1861, 1903, 1917], "matplotlib": [1291, 1922], "pyplot": [1291, 1922], "plt": 1291, "plot_surfac": 1291, "6750": 1292, "0857": [1292, 1834], "7197": [1292, 1853], "argmin": [1292, 1859, 1861, 1903], "min_indic": [1292, 1861], "1334": 1292, "2803": 1292, "4644": [1292, 1802, 1803, 1845, 1846], "2635": [1292, 1894], "3651": 1292, "0384": 1292, "0128": 1292, "7015": 1292, "1153": 1292, "9849": 1292, "1458": [1292, 1918], "5788": 1292, "deduc": [1294, 1917], "4851": 1294, "5037": 1294, "3633": 1294, "0760": 1294, "3362": [1296, 1297], "8437": [1296, 1297], "9627": [1296, 1297], "1727": [1296, 1297], "5173": [1296, 1297], "1398": [1296, 1297], "mpsalloc": [1298, 1299], "metal": [1299, 1307, 1871, 1895], "mpsgraph": 1299, "wait_until_complet": [1303, 1304], "signpost": [1303, 1304, 1305], "xcode": 1304, "recommendedmaxworkingsets": 1307, "unlimit": [1307, 1886], "1321": 1310, "4370": 1310, "1289": 1310, "0527": 1310, "3077": [1310, 1798], "0881": 1310, "1259": 1310, "0284": 1310, "2015": [1311, 1881, 1894], "6087": 1311, "1494": 1311, "5491": 1311, "260": 1311, "8663": 1311, "3137": 1311, "0700": 1311, "8378": 1311, "5146": 1311, "1216": 1311, "5244": 1311, "5767": 1311, "1363": 1311, "5877": 1311, "5083": 1311, "1614": 1311, "1645": 1311, "7021": 1311, "0085": 1311, "0367": 1311, "1567": 1311, "4312": 1311, "1019": 1311, "4394": 1311, "8753": 1311, "_sampl": 1312, "thtensorrandom": 1312, "320": [1312, 1448], "0404": 1314, "6361": 1314, "multigammaln": [1315, 1918], "4028e": 1316, "1400e": 1316, "isnan": [1317, 1859, 1861, 1903, 1917], "midpoint": [1319, 1708], "weakli": [1321, 1322, 1918], "to_spars": [1322, 1785, 1861, 1898, 1903, 1917], "2262": [1324, 1703], "0682": [1324, 1703], "2866": [1324, 1703], "3940": [1324, 1703], "5x7": [1328, 1332], "7x7": [1328, 1332], "10x7": [1328, 1332], "cube": [1329, 1333, 1714], "d_": [1329, 1333, 1337, 1349, 1352, 1355, 1417, 1420, 1445, 1448, 1474, 1479, 1521, 1832, 1833, 1834, 1835], "5x7x9": [1329, 1333], "7x7x7": [1329, 1333], "7x9x8": [1329, 1333], "n_class": 1330, "cutoff": [1330, 1881], "div_valu": 1330, "head_bia": 1330, "edouard": 1330, "grave": [1330, 1345], "armand": 1330, "joulin": 1330, "moustapha": 1330, "ciss\u00e9": 1330, "grangier": 1330, "herv\u00e9": 1330, "j\u00e9gou": 1330, "imbalanc": 1330, "zipf": 1330, "law": 1330, "1001": 1330, "1002": 1330, "_class": 1330, "maxunpool1d": [1331, 1415, 1548, 1843], "maxunpool2d": [1332, 1370, 1416, 1549, 1843], "maxunpool3d": [1333, 1371, 1417, 1550, 1843], "selu": [1334, 1367, 1514, 1861, 1881, 1901, 1903], "n_i": [1335, 1336, 1337, 1350, 1351, 1352, 1415, 1416, 1417, 1470, 1471], "c_j": [1335, 1336, 1337, 1415, 1416, 1417], "size_averag": [1338, 1339, 1356, 1358, 1382, 1388, 1389, 1413, 1414, 1425, 1426, 1427, 1429, 1436, 1453, 1454, 1470, 1493, 1494, 1502, 1504, 1529, 1533, 1534, 1544, 1552, 1553, 1554, 1555, 1556, 1564, 1575, 1576, 1587, 1861], "unreduc": [1338, 1339, 1358, 1383, 1389, 1413, 1429, 1453, 1471], "ell": [1338, 1339, 1358, 1382, 1383, 1389, 1413, 1429, 1453, 1471], "l_1": [1338, 1339, 1358, 1382, 1383, 1389, 1413, 1429, 1453, 1471], "l_n": [1338, 1339, 1358, 1382, 1383, 1389, 1413, 1429, 1453, 1471], "w_n": [1338, 1339, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772], "y_n": [1338, 1339, 1358, 1382, 1383, 1389, 1413, 1429, 1453, 1829, 1883], "lim_": [1338, 1883], "secondli": 1338, "straight": [1338, 1523], "rescal": [1338, 1339, 1358, 1426, 1427, 1429, 1455, 1457, 1493, 1494, 1504, 1556, 1614, 1643], "nbatch": [1338, 1339], "pos_weight": [1339, 1494, 1861], "classif": [1339, 1345, 1358, 1425, 1427, 1429, 1454, 1505, 1858, 1881, 1909], "ell_c": 1339, "l_c": 1339, "p_c": 1339, "pai": [1339, 1494, 1900, 1921], "spacial": [1339, 1494], "random_": [1339, 1358, 1429, 1494, 1861, 1876, 1925], "hat": [1340, 1341, 1342, 1385, 1386, 1387, 1461], "terminologi": [1340, 1341, 1342, 1461], "tempor": [1340, 1342, 1345, 1461, 1474, 1505, 1532, 1590], "5d": [1342, 1387, 1474, 1521, 1532, 1559, 1590], "volumetr": [1342, 1461, 1474, 1521, 1532, 1590, 1591, 1592], "spatio": [1342, 1461], "in1_featur": 1343, "in2_featur": 1343, "in1": [1343, 1492], "in2": [1343, 1492], "blank": [1345, 1505, 1861, 1864], "zero_infin": [1345, 1505, 1861], "connectionist": [1345, 1505], "unseg": 1345, "longest": [1345, 1636, 1638, 1639, 1890], "input_length": [1345, 1505, 1861, 1890], "target_length": [1345, 1505, 1861], "s_n": 1345, "target_n": 1345, "unbatch": [1345, 1358, 1369, 1374, 1385, 1392, 1428, 1437, 1465, 1515], "s_min": 1345, "toronto": 1345, "edu": [1345, 1714], "icml_2006": 1345, "256": [1345, 1704, 1886, 1901], "background": [1345, 1353, 1521, 1559, 1896, 1913], "channel_shuffl": [1346, 1861, 1903], "_left": [1347, 1348, 1349, 1443, 1444, 1445, 1446, 1447, 1448, 1477, 1478, 1479, 1559], "_right": [1347, 1348, 1349, 1443, 1444, 1445, 1446, 1447, 1448, 1477, 1478, 1479, 1559], "0491": [1347, 1477], "7152": [1347, 1477], "0749": [1347, 1477], "3287": [1347, 1477], "8966": [1347, 1477], "1466": [1347, 1477], "2771": [1347, 1477], "6616": [1347, 1477], "4523": [1347, 1477], "1255": [1347, 1477], "6372": [1347, 1477, 1808], "1182": [1347, 1477], "8652": [1347, 1477], "_top": [1348, 1349, 1444, 1445, 1447, 1448, 1478, 1479, 1559], "_bottom": [1348, 1349, 1444, 1445, 1447, 1448, 1478, 1479, 1559], "6585": 1348, "4320": [1348, 1817], "8701": 1348, "4649": 1348, "_front": [1349, 1445, 1448, 1479, 1559], "_back": [1349, 1445, 1448, 1479, 1559], "_j": [1350, 1351], "star": [1350, 1351, 1352, 1863], "\u00e0": [1350, 1351, 1352, 1353, 1354, 1355, 1369, 1473], "trou": [1350, 1351, 1352, 1353, 1354, 1355, 1369, 1473], "harder": [1350, 1351, 1352, 1353, 1354, 1355, 1369, 1416, 1417, 1473], "prod_": [1351, 1352, 1354, 1355, 1368, 1472, 1668], "out_j": 1352, "deconvolut": [1353, 1354, 1355, 1499, 1500, 1501], "_pad": [1353, 1354, 1355], "dissimilar": [1356, 1382], "semi": [1356, 1382, 1881], "supervis": [1356, 1382], "vert": [1357, 1431, 1503], "_2": [1357, 1503, 1610, 1643], "ast_1": [1357, 1373], "ast_2": [1357, 1373], "ignore_index": [1358, 1429, 1504, 1556, 1861], "label_smooth": [1358, 1504, 1861], "unbalanc": [1358, 1429], "d_1": [1358, 1429, 1504, 1556], "d_2": [1358, 1429, 1504, 1556], "d_k": [1358, 1429, 1504, 1556], "_index": [1358, 1429], "logsoftmax": [1358, 1429, 1455, 1540], "nllloss": [1358, 1455, 1556, 1577, 1843], "blend": 1358, "smooth": [1358, 1383, 1453, 1458, 1504, 1675], "w_c": 1358, "truth": [1358, 1504, 1870, 1922], "rethink": [1358, 1504], "incept": [1358, 1504], "spectral_norm": [1359, 1633], "neuron": 1360, "detector": 1360, "dropout1d": [1362, 1861], "_freez": 1365, "sparseadam": [1365, 1904], "0251": 1365, "6902": [1365, 1705], "7172": 1365, "6431": 1365, "0748": 1365, "6969": 1365, "4970": 1365, "3448": 1365, "9685": 1365, "3677": 1365, "7265": 1365, "1685": 1365, "4362": 1365, "4004": [1365, 1789], "9400": 1365, "9124": 1365, "3616": 1365, "1151": 1365, "0309": 1365, "9315": 1365, "1655": [1365, 1886], "9897": 1365, "0635": 1365, "7895": 1365, "0364": 1365, "6778": 1365, "5803": 1365, "bag": [1366, 1513], "per_sample_weight": [1366, 1513, 1861], "embedding_sum": 1366, "8861": 1366, "4350": 1366, "0523": 1366, "1306": 1366, "5798": 1366, "0044": 1366, "7082": [1366, 1513], "2145": [1366, 1513], "6251": [1366, 1513], "6500": 1366, "satur": [1367, 1514], "alphadropout": [1367, 1487], "160": [1368, 1904], "unfold": [1369, 1861, 1903, 1921], "prod_d": [1369, 1473], "neighborhood": [1369, 1473], "col2im": [1369, 1859, 1861, 1903], "fold_param": [1369, 1473], "input_on": [1369, 1473], "output_ratio": [1370, 1371, 1516, 1517, 1861], "_random_sampl": [1370, 1371, 1516, 1517, 1861], "ben": [1370, 1371, 1516, 1517], "graham": [1370, 1371, 1516, 1517], "oh": [1370, 1371, 1516, 1517], "ow": [1370, 1371, 1516, 1517], "_ratio": [1370, 1371, 1517], "13x12": [1370, 1516], "kt": [1371, 1490, 1498, 1501, 1517, 1547], "ot": [1371, 1517], "13x12x11": [1371, 1517], "044715": [1372, 1519], "pack_sequ": [1374, 1392, 1437, 1638, 1640], "bias_ih": [1375, 1393, 1439], "bias_hh": [1375, 1393, 1439], "const": [1376, 1893], "homoscedast": [1376, 1518], "heteroscedast": [1376, 1518], "nix": 1376, "weigend": 1376, "1994": 1376, "icnn": 1376, "94": 1376, "orlando": 1376, "fl": 1376, "usa": [1376, 1922], "374138": 1376, "instancenorm": [1377, 1910], "shrinkag": [1378, 1459, 1524, 1580], "mobilenetv3": [1380, 1526], "_val": 1381, "l1loss": [1383, 1453, 1534], "outlier": [1383, 1453, 1908, 1909], "huber": [1383, 1453], "smoothl1loss": [1383, 1575], "insensit": 1384, "unused_argument1": 1384, "unused_argument2": 1384, "ingredi": [1385, 1386, 1387], "styliz": [1385, 1386, 1387], "rgb": [1386, 1387, 1922], "log_target": [1388, 1533, 1861], "pred": [1388, 1602, 1859, 1895, 1904, 1913], "kl": [1388, 1533, 1858], "summaris": 1388, "loss_pointwis": 1388, "batchmean": [1388, 1533], "kl_loss": 1388, "mae": 1389, "f_t": [1392, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "hf": [1392, 1393], "g_t": [1392, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "ig": [1392, 1393], "hg": [1392, 1393], "o_t": 1392, "ho": [1392, 1393], "c_t": 1392, "odot": 1392, "forget": [1392, 1862, 1863], "proj_siz": [1392, 1438], "1402": 1392, "c_0": [1392, 1393], "proj": 1392, "c_n": 1392, "w_ii": 1392, "w_if": 1392, "w_ig": 1392, "w_io": 1392, "w_hi": 1392, "w_hf": 1392, "w_hg": 1392, "w_ho": 1392, "b_ii": 1392, "b_if": 1392, "b_ig": 1392, "b_io": 1392, "b_hi": 1392, "b_hf": 1392, "b_hg": 1392, "b_ho": 1392, "weight_hr_l": 1392, "_revers": 1392, "h_1": 1393, "c_1": 1393, "time_step": 1393, "_shape": 1394, "sentence_length": 1394, "lazymodulemixin": [1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407], "cls_to_becom": [1395, 1396, 1397, 1398, 1399, 1400, 1401, 1402, 1403, 1404, 1405, 1406, 1407, 1605], "convtranspose1d": [1401, 1499, 1843, 1910], "convtranspose3d": [1403, 1501, 1843, 1910], "instancenorm1d": [1404, 1531, 1910], "instancenorm2d": [1405, 1531, 1910], "instancenorm3d": [1406, 1531, 1910], "uninitializedparamet": [1407, 1593, 1858], "lrn": 1410, "signal_2d": 1410, "signal_4d": 1410, "output_2d": 1410, "output_4d": 1410, "x_j": [1412, 1455, 1457, 1577, 1787, 1891, 1918], "80827": [1418, 1419, 1420], "unpool": [1418, 1419, 1420], "maxpool3d": [1420, 1547, 1550, 1843, 1910], "unpooled_output": 1420, "t_destin": 1422, "lrelu": [1423, 1894], "hing": [1425, 1427], "sum_i": [1426, 1427, 1454], "nelement": [1426, 1454], "jointli": 1428, "concat": [1428, 1861, 1903], "head_1": 1428, "head_h": 1428, "head_i": 1428, "qw_i": 1428, "kw_i": 1428, "vw_i": 1428, "scaled_dot_product_attent": [1428, 1861, 1903], "inference_mod": [1428, 1469], "nestedtensor": [1428, 1469, 1878], "multihead_attn": 1428, "e_q": 1428, "e_k": 1428, "e_v": 1428, "_head": [1428, 1465], "merge_mask": 1428, "mask_typ": 1428, "merged_mask": 1428, "nll": 1429, "crossentropyloss": [1429, 1504], "num_paramet": 1430, "nchannel": 1430, "decai": [1430, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1677, 1680, 1684, 1686, 1687, 1690, 1691, 1693, 1765, 1904], "legitim": [1430, 1521, 1889], "vert_p": 1431, "fromkei": 1432, "popitem": [1432, 1903], "setdefault": [1432, 1903], "upscale_factor": [1434, 1562, 1861], "upscal": 1434, "shi": [1434, 1435], "2016": [1434, 1435, 1471], "_factor": [1434, 1435, 1474, 1475, 1476], "pixel_shuffl": [1434, 1861, 1903, 1910], "downscale_factor": [1435, 1563, 1861], "pixelshuffl": [1435, 1562, 1563, 1910], "downscal": 1435, "pixel_unshuffl": [1435, 1861, 1903, 1910], "log_input": [1436, 1564, 1861], "poisson": [1436, 1564, 1765, 1858, 1861, 1903], "stirl": [1436, 1564], "hh": [1437, 1439], "flatten_paramet": 1438, "3333333333333333": [1440, 1680, 1686, 1861], "leaki": [1440, 1569, 1881], "rectifi": [1440, 1441, 1566, 1881], "liner": 1440, "empir": 1440, "1505": 1440, "00853": 1440, "crelu": 1441, "1603": 1441, "05201": 1441, "480": 1448, "6732632423543772848170429916717": [1449, 1572], "0507009873554804934193349852946": [1449, 1572], "kaiming_norm": 1449, "kaiming_normal_": [1449, 1858, 1865, 1881], "initialis": 1449, "calculate_gain": [1449, 1858, 1865, 1881], "modulelist": [1450, 1894], "cascad": 1450, "relu2": [1450, 1593], "swish": [1451, 1574], "coin": [1451, 1574], "explod": 1453, "cnn": [1453, 1908], "ross": 1453, "girshick": 1453, "quadrat": [1453, 1890], "huberloss": [1453, 1530], "w_j": 1456, "soft": [1459, 1523, 1580], "softshrinkag": 1459, "convert_sync_batchnorm": 1461, "r1": 1461, "sync_bn_network": 1461, "ddp_sync_bn_network": 1461, "sync_bn_modul": 1461, "d_model": [1465, 1466, 1467, 1468, 1469], "nhead": [1465, 1466, 1467, 1468, 1469], "num_encoder_lay": 1465, "num_decoder_lay": 1465, "dim_feedforward": [1465, 1467, 1469], "custom_encod": 1465, "custom_decod": 1465, "layer_norm_ep": [1465, 1467, 1469], "norm_first": [1465, 1467, 1469], "ashish": [1465, 1467, 1469], "vaswani": [1465, 1467, 1469], "noam": [1465, 1467, 1469], "shazeer": [1465, 1467, 1469], "niki": [1465, 1467, 1469], "parmar": [1465, 1467, 1469], "jakob": [1465, 1467, 1469], "uszkoreit": [1465, 1467, 1469], "llion": [1465, 1467, 1469], "jone": [1465, 1467, 1469], "aidan": [1465, 1467, 1469], "gomez": [1465, 1467, 1469], "lukasz": [1465, 1467, 1469], "illia": [1465, 1467, 1469], "polosukhin": [1465, 1467, 1469], "6010": [1465, 1467, 1469], "feedforward": [1465, 1467, 1469, 1881], "transformer_model": 1465, "word_language_model": 1465, "src_mask": [1465, 1469], "tgt_mask": [1465, 1466, 1467], "memory_mask": [1465, 1466, 1467], "src_key_padding_mask": [1465, 1468, 1469], "tgt_key_padding_mask": [1465, 1466, 1467], "memory_key_padding_mask": [1465, 1466, 1467], "_mask": [1465, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1632], "_key_padding_mask": 1465, "generate_square_subsequent_mask": 1465, "sz": 1465, "decoder_lay": [1466, 1467], "transformerdecoderlay": 1466, "transformer_decod": 1466, "tgt_is_caus": [1466, 1467], "memory_is_caus": [1466, 1467], "attn": [1467, 1469], "encoder_lay": [1468, 1469], "enable_nested_tensor": 1468, "mask_check": 1468, "1810": 1468, "04805": 1468, "transformerencoderlay": 1468, "transformer_encod": 1468, "flashattent": [1469, 1571], "triplet": [1470, 1471], "x3": 1470, "balnta": [1470, 1471], "riba": [1470, 1471], "a_i": [1470, 1471, 1767], "p_i": [1470, 1471], "rm": [1470, 1471], "bf": [1470, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "rvert_p": [1470, 1557], "tripletmarginwithdistanceloss": [1470, 1588], "triplet_loss": [1470, 1471], "distance_funct": [1471, 1588], "l_i": 1471, "tripletmarginloss": [1471, 1587], "l_p": [1471, 1557], "pairwisedist": [1471, 1560], "penal": [1471, 1894], "distant": 1471, "anchor_id": 1471, "positive_id": 1471, "negative_id": 1471, "l_infin": 1471, "bmva": 1471, "bmvc": 1471, "paper119": 1471, "unflattened_s": 1472, "namedtensor": 1472, "namedshap": 1472, "u_1": 1472, "u_n": 1472, "u_i": 1472, "im2col": [1473, 1861, 1903], "fold": [1473, 1809, 1861, 1871, 1901, 1911, 1917], "2x3": 1473, "3x4": 1473, "inp_unf": 1473, "out_unf": 1473, "recompute_scale_factor": [1474, 1532], "bicub": [1474, 1521, 1532, 1590, 1843], "trilinear": [1474, 1521, 1532, 1590, 1843], "input_3x3": 1474, "4375": 1474, "8125": 1474, "9375": 1474, "2400": [1474, 1824], "1200": [1474, 1736, 1886], "8800": 1474, "4400": [1474, 1824], "7200": 1474, "0400": 1474, "2800": [1474, 1759], "3600": 1474, "5200": 1474, "6400": 1474, "1678": 1478, "4418": 1478, "9466": [1478, 1918], "9604": 1478, "4219": 1478, "5241": 1478, "9162": 1478, "5436": [1478, 1824], "6446": 1478, "adaptiveavgpool1d": [1480, 1910], "tripl": [1482, 1485], "adaptivemaxpool1d": 1483, "adaptivemaxpool2d": [1484, 1843], "adaptivemaxpool3d": 1485, "ill": [1486, 1897], "avgpool1d": [1488, 1910], "avgpool3d": [1490, 1843, 1910], "iT": [1490, 1498, 1501], "padt": [1490, 1498, 1501], "score": [1494, 1571, 1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629, 1858], "out_padw": [1499, 1500, 1501], "out_padh": [1500, 1501], "out_padt": 1501, "cosineembeddingloss": 1502, "ctcloss": [1505, 1843], "charact": [1505, 1756, 1860, 1863, 1877, 1913], "elu": [1511, 1861, 1901, 1903, 1910], "embedding_matrix": [1512, 1513], "8490": 1512, "9625": 1512, "6753": 1512, "7761": 1512, "6108": 1512, "6246": 1512, "9751": 1512, "3618": 1512, "4161": [1512, 1917], "2419": 1512, "7383": 1512, "0237": 1512, "7794": 1512, "0528": 1512, "3385": 1512, "8612": 1512, "1867": 1512, "5384": 1512, "8720": 1512, "6262": 1512, "7471": 1512, "embeddingbag": [1513, 1843, 1908, 1910, 1923], "3397": 1513, "5545": 1513, "5893": 1513, "4386": 1513, "5882": 1513, "featurealphadropout": 1514, "gaussiannllloss": 1518, "border": 1521, "affine_grid": [1521, 1861], "extrema": 1521, "pil": [1521, 1532], "overshoot": [1521, 1532, 1590], "gumbel": [1523, 1858], "y_hard": 1523, "y_soft": 1523, "hardtanh": [1528, 1859, 1861, 1871, 1903, 1910], "hingeembeddingloss": 1529, "use_input_stat": [1531, 1861], "antialia": 1532, "anti": 1532, "pillow": [1532, 1922], "buggi": 1532, "inter_nearest": 1532, "kldivloss": 1533, "batchsiz": [1533, 1790, 1791, 1792, 1794, 1795, 1917], "leaky_relu": [1537, 1859, 1861, 1881, 1903, 1910], "localresponsenorm": 1539, "_stacklevel": [1540, 1577, 1578, 1861], "lppool1d": 1542, "lppool2d": 1543, "marginrankingloss": 1544, "max_unpool1d": [1545, 1861], "multimarginloss": 1553, "multilabelmarginloss": 1554, "multilabelsoftmarginloss": 1555, "n_0": 1557, "n_": 1557, "n_k": 1557, "everywher": [1558, 1804, 1904], "constantpad2d": 1559, "reflectionpad2d": [1559, 1843], "replicationpad2d": [1559, 1843], "t4d": 1559, "p1d": 1559, "p2d": 1559, "p3d": 1559, "pixelunshuffl": [1563, 1910], "poissonnllloss": 1564, "rrelu": [1570, 1861, 1903], "dropout_p": [1571, 1861], "masked_fil": [1571, 1861, 1876, 1878, 1903], "ev": 1571, "legend": 1571, "softmarginloss": 1576, "module_kwarg": 1586, "upsample_trilinear": 1591, "fo": 1591, "spatia": 1592, "mixin": [1593, 1858], "dry": 1593, "lazymlp": 1593, "lazylinear": 1593, "lazy_mlp": 1593, "8832e": 1593, "5636e": 1593, "1598e": 1593, "5637e": 1593, "8788e": 1593, "0042e": 1593, "0019": 1593, "lazymodul": 1593, "full_mlp": 1593, "3837": [1593, 1705], "0907": 1593, "6708": 1593, "5223": 1593, "9028": 1593, "2851": 1593, "6813": 1593, "5766": 1593, "8678": 1593, "1320": 1593, "2938": 1593, "0679": [1593, 1834], "2793": [1593, 1650], "1088": 1593, "1795": 1593, "2301": 1593, "2807": 1593, "2479": 1593, "1091": 1593, "has_uninitialized_param": 1593, "initialize_paramet": 1593, "register_backward_pre_hook": 1599, "check_reduct": 1602, "delay_all_reduce_named_param": 1602, "param_to_hook_all_reduc": 1602, "optimizer_param": 1602, "loss_func": [1602, 1913], "consume_prefix_in_state_dict_if_pres": 1602, "nccl2": 1602, "dictat": [1602, 1863], "megabyt": 1602, "mb": [1602, 1886], "detach_": [1602, 1861, 1876, 1910, 1917], "ddp_logging_data": 1602, "can_set_static_graph": 1602, "model_ddp": 1602, "_get_ddp_logging_data": 1602, "divide_by_initial_world_s": 1602, "syncbatchnorm": 1602, "exhaust": 1602, "deplet": 1602, "pariti": 1602, "discrep": [1602, 1714, 1891], "another_input": 1602, "predivid": 1602, "encode_and_decod": 1602, "encoded_tensor": 1602, "decoded_tensor": 1602, "error_if_nonfinit": 1606, "foreach": [1606, 1607, 1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677, 1904], "clip_valu": 1607, "orthogonal_map": 1609, "use_trivi": 1609, "qq": 1609, "matrix_exp": [1609, 1861, 1903], "caylei": 1609, "thin": [1609, 1707], "manifold": 1609, "register_parametr": [1609, 1610, 1611, 1612, 1643, 1879], "orth_linear": 1609, "parametrizedlinear": [1609, 1610], "moduledict": [1609, 1610, 1862, 1894], "parametrizationlist": [1609, 1610, 1614], "_orthogon": 1609, "9332e": 1609, "n_power_iter": [1610, 1643], "sn": [1610, 1643], "discrimin": [1610, 1643], "adversari": [1610, 1643], "lipschitz": 1610, "reimplement": [1610, 1643], "_spectralnorm": 1610, "convtranspos": [1610, 1643], "snm": 1610, "0081": 1610, "amaxbackward0": 1610, "original0": [1611, 1614], "original1": [1611, 1614], "tensor_nam": [1611, 1613, 1614, 1615], "right_invers": [1611, 1614], "out_rnn": 1612, "rnn_cell": 1612, "simplic": [1614, 1914], "inbuilt": 1614, "unparametr": 1614, "rankon": 1614, "surject": 1614, "s0_sqrt": 1614, "linear_rank_on": 1614, "matrix_rank": 1614, "leave_parametr": 1615, "unparametris": 1615, "prune": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1917], "skeleton": 1616, "compute_mask": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623], "importance_scor": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1625, 1628, 1629], "apply_mask": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623], "pruned_tensor": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623], "default_mask": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623], "_orig": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1624, 1625, 1626, 1628, 1629, 1630, 1631, 1632], "undon": [1616, 1617, 1618, 1619, 1620, 1621, 1622, 1623, 1632], "unprun": [1619, 1620, 1622, 1623, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631], "indexerror": [1620, 1622], "basepruningmethod": [1621, 1627], "add_pruning_method": 1621, "pruning_typ": [1621, 1625], "unstructur": [1621, 1625], "ravel": [1621, 1861, 1903], "nonmask": 1621, "bias_mask": [1624, 1626], "pruning_method": 1625, "typeerror": [1625, 1888, 1906, 1924, 1928], "parameters_to_prun": 1625, "l1unstructur": 1625, "parameters_to_vector": 1625, "forward_pre_hook": [1627, 1894], "random_unstructur": [1627, 1632], "odict_kei": 1628, "weight_orig": 1628, "weight_mask": [1628, 1631], "columns_prun": 1630, "t_modul": [1633, 1634, 1643, 1646], "weight_norm": 1634, "sorted_indic": [1635, 1637, 1638, 1640], "unsorted_indic": [1635, 1637, 1638, 1640], "abc": [1635, 1863], "axbc": 1635, "throughout": [1635, 1891, 1894, 1908], "conform": [1635, 1894], "is_cuda": [1635, 1876, 1903, 1919], "enforce_sort": [1636, 1637, 1638], "unsort": [1636, 1637, 1743], "shortest": 1636, "uncondition": [1636, 1857, 1888, 1928], "pad_sequ": [1637, 1641, 1861, 1903], "padding_valu": [1638, 1639, 1861], "total_length": [1638, 1890], "seq_unpack": 1638, "lens_unpack": 1638, "packed_sequ": 1640, "unpacked_sequ": 1640, "padded_sequ": 1641, "unpad": 1641, "unstack": 1641, "as_tensor": [1641, 1822, 1861, 1878, 1888, 1903, 1922, 1923, 1924], "unpadded_sequ": 1641, "module_cl": [1642, 1913], "5846e": 1642, "29": [1642, 1772, 1901], "8307e": 1642, "5250e": 1642, "1210e": 1642, "4677e": 1642, "5915e": 1642, "4013e": 1642, "weight_u": 1643, "parameters_and_buff": 1644, "decoupl": [1646, 1665], "weight_g": [1646, 1861], "weight_v": 1646, "1602": 1646, "07868": 1646, "as_tupl": [1648, 1853], "complexfloat": [1649, 1658], "0425": 1650, "7969": 1650, "2925": 1650, "7229": 1650, "2134": 1650, "0505": 1650, "1408": 1650, "0563": 1650, "0566": 1650, "0732": [1650, 1824], "0687": 1650, "1177": 1650, "2303": 1650, "1552": 1650, "6148": 1650, "6535": 1650, "8318": 1650, "3987": 1650, "9544": [1650, 1715], "6048": 1650, "7909": 1650, "120": [1652, 1922], "op_level_debug": 1655, "model_proto": [1656, 1657], "input_adapt": 1656, "output_adapt": 1656, "diagnostic_context": 1656, "adapt_torch_inputs_to_onnx": 1656, "model_arg": [1656, 1901], "model_kwarg": [1656, 1901], "xdoctest": 1656, "torch_doctest_onnx": 1656, "func_with_nested_input_structur": 1656, "x_dict": 1656, "y_tupl": 1656, "y3": 1656, "export_output": [1656, 1657], "adapt_torch_outputs_to_onnx": 1656, "model_output": 1656, "func_returning_tupl": 1656, "pt_output": 1656, "diagnosticcontext": 1656, "modelproto": [1656, 1657], "protobuf": [1656, 1657, 1901], "exportoutput": [1657, 1901], "bufferediobas": 1657, "protobufexportoutputseri": 1657, "serializetostr": 1657, "exported_model": 1657, "from_valu": 1658, "onnx_typ": 1658, "tensorprotodatatyp": 1658, "torch_c_value_with_type_float": 1658, "from_dtyp": 1658, "jit_type_bas": 1658, "safer": [1658, 1870], "onnxexportererror": [1658, 1901], "symbolicvalueerror": 1658, "onnx_compat": 1658, "scalar_nam": 1658, "complexhalf": 1658, "complexdoubl": 1658, "torch_nam": 1658, "int8_t": 1658, "int64_t": 1658, "int16_t": 1658, "verif": [1659, 1660, 1901], "input_arg": [1659, 1901], "params_dict": 1659, "export_opt": [1659, 1901], "_excluded_node_kind": 1659, "frozenset": [1659, 1863], "scalarimplicit": [1659, 1903], "prim": [1659, 1860, 1901, 1903], "listconstruct": [1659, 1860], "all_mismatch_leaf_graph_info": 1659, "essential_node_count": 1659, "essential_node_kind": 1659, "export_repro": 1659, "repro_dir": 1659, "test_": 1659, "test_data_set_0": 1659, "input_0": [1659, 1901], "pb": [1659, 1901], "input_1": [1659, 1901], "output_0": 1659, "output_1": 1659, "find_mismatch": [1659, 1901], "verificationopt": [1659, 1901], "find_partit": 1659, "has_mismatch": 1659, "pretty_print_mismatch": 1659, "pretty_print_tre": 1659, "graph_info": [1659, 1901], "__2": [1659, 1901], "__1": [1659, 1901], "__3": [1659, 1901], "110": [1659, 1901], "verify_export": 1659, "onnx_graph": 1659, "onnx_out": 1659, "pt_out": 1659, "ignore_non": 1660, "check_shap": 1660, "check_dtyp": [1660, 1924], "onnxbackend": 1660, "onnx_runtime_cpu": 1660, "remained_onnx_input_idx": 1660, "acceptable_error_percentag": 1660, "percentag": [1660, 1689, 1765], "weight_decai": [1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1677, 1894], "1e6": 1661, "impair": [1661, 1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "register_step_post_hook": [1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678], "removeablehandl": [1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678], "register_step_pre_hook": [1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678], "new_arg": [1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678], "new_kwarg": [1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1674, 1675, 1676, 1677, 1678], "altogeth": [1661, 1662, 1663, 1664, 1665, 1666, 1667, 1668, 1673, 1674, 1675, 1676, 1677, 1678], "rho": 1662, "110mm": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "4pt": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "textbf": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "theta_0": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "v_0": [1662, 1664, 1665, 1668, 1674, 1675], "leftarrow": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "u_0": [1662, 1666], "hspace": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "5mm": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "nabla_": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "theta_": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "10mm": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "v_t": [1662, 1664, 1665, 1668, 1674, 1675], "v_": [1662, 1664, 1665, 1668, 1674, 1675, 1677], "2_t": [1662, 1663, 1664, 1665, 1668, 1674, 1675], "21mm": 1662, "u_t": [1662, 1666], "theta_t": [1662, 1663, 1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "lr_decai": 1663, "initial_accumulator_valu": 1663, "12mm": [1663, 1674], "_sum_0": 1663, "tild": [1663, 1675], "_sum_t": 1663, "_sum_": 1663, "subgradi": 1663, "999": [1664, 1665, 1666, 1668, 1674, 1678, 1899, 1904], "amsgrad": [1664, 1665], "beta_1": [1664, 1665, 1666, 1668, 1674], "beta_2": [1664, 1665, 1666, 1668, 1674], "13mm": [1664, 1665, 1666, 1668, 1674, 1675, 1676, 1677], "textit": [1664, 1665, 1677], "m_0": [1664, 1665, 1666, 1668, 1674], "widehat": [1664, 1665, 1668, 1674], "m_t": [1664, 1665, 1666, 1668, 1674], "m_": [1664, 1665, 1666, 1668, 1674], "ungraph": [1664, 1665], "002": [1666, 1668], "t_1": 1666, "2e": [1666, 1668], "max_it": 1667, "max_ev": 1667, "tolerance_grad": 1667, "tolerance_chang": 1667, "history_s": 1667, "line_search_fn": 1667, "bfg": 1667, "minfunc": 1667, "intens": [1667, 1897], "param_byt": 1667, "strong_wolf": 1667, "reevalu": [1667, 1672, 1678, 1904], "momentum_decai": 1668, "004": 1668, "gamma_t": 1668, "psi": [1668, 1918], "mu_t": 1668, "96": 1668, "mu_": 1668, "11mm": 1668, "incorpor": [1668, 1908], "nesterov": [1668, 1677], "4e": 1668, "weightdecai": 1674, "18mm": 1674, "rho_": 1674, "6mm": 1674, "rho_t": 1674, "t_2": 1674, "l_t": 1674, "adamw": [1674, 1904], "_0": [1675, 1889, 1905], "av": 1675, "8mm": 1675, "3mm": 1675, "lectur": 1675, "hinton": 1675, "step_siz": [1676, 1693], "resili": [1676, 1897], "eta_": [1676, 1681, 1682], "etaplu": 1676, "etaminu": 1676, "gamma_": [1676, 1918], "0_": 1676, "eta_0": 1676, "i_": [1676, 1824], "15mm": [1676, 1677], "eta_t": [1676, 1681, 1682], "dampen": 1677, "sutskev": 1677, "veloc": 1677, "conflat": 1678, "is_spars": [1678, 1876, 1903, 1917, 1919], "maskedtensor": [1678, 1917], "rig": 1678, "insist": 1678, "lr_schedul": [1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1691, 1692, 1693, 1904], "chainabl": [1679, 1689], "081": 1679, "729": [1679, 1692], "6561": [1679, 1848], "59049": 1679, "scheduler1": [1679, 1692, 1904], "constantlr": [1679, 1692], "total_it": [1679, 1680, 1686, 1690, 1692], "scheduler2": [1679, 1692, 1904], "exponentiallr": [1679, 1692, 1904], "get_last_lr": [1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693], "print_lr": [1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693], "is_verbos": [1679, 1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693], "__dict__": [1679, 1680, 1681, 1682, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693], "last_epoch": [1680, 1681, 1682, 1683, 1684, 1685, 1686, 1687, 1688, 1689, 1690, 1692, 1693], "mileston": [1680, 1686, 1687, 1692, 1904], "simultan": [1680, 1681, 1686, 1687, 1693, 1883, 1913], "025": [1680, 1686], "t_max": [1681, 1904], "eta_min": [1681, 1682], "anneal": [1681, 1682, 1689, 1904], "cur": [1681, 1682], "sgdr": [1681, 1682], "2k": 1681, "sole": 1681, "t_mult": 1682, "interleav": 1682, "base_lr": [1683, 1689], "max_lr": [1683, 1689], "step_size_up": 1683, "step_size_down": 1683, "scale_fn": 1683, "scale_mod": 1683, "cycle_momentum": [1683, 1689], "base_momentum": [1683, 1689], "max_momentum": [1683, 1689], "cyclic": 1683, "amplitud": [1683, 1689], "triangular2": 1683, "exp_rang": 1683, "bckenstler": 1683, "train_batch": [1683, 1689], "get_lr": 1683, "lr_lambda": [1685, 1688], "lambda1": 1685, "lambda2": 1685, "start_factor": 1686, "end_factor": 1686, "03125": 1686, "0375": 1686, "04375": 1686, "005": [1687, 1693], "lmbda": 1688, "total_step": 1689, "steps_per_epoch": 1689, "pct_start": 1689, "anneal_strategi": [1689, 1904], "div_factor": 1689, "final_div_factor": 1689, "three_phas": 1689, "1cycl": 1689, "fastai": 1689, "unpublish": 1689, "initial_lr": 1689, "min_lr": [1689, 1691], "1e4": 1689, "annihil": 1689, "00075": 1690, "00050": 1690, "00025": 1690, "patienc": 1691, "threshold_mod": 1691, "cooldown": 1691, "stagnat": 1691, "new_lr": 1691, "hasn": [1691, 1873, 1905], "optimum": 1691, "dynamic_threshold": 1691, "val_loss": 1691, "81": 1692, "mn": 1695, "pca": [1697, 1917], "overestim": [1697, 1809], "nathan": [1697, 1809], "halko": [1697, 1809], "gunnar": [1697, 1809], "martinsson": [1697, 1809], "tropp": [1697, 1809], "probabilist": [1697, 1809], "0909": [1697, 1809], "4061": [1697, 1809], "na": [1697, 1809], "cmath": [1701, 1861], "4142j": 1701, "4331": 1704, "2475": [1704, 1807], "6834": 1704, "2791": 1704, "1875": 1704, "5561": 1704, "4670": 1704, "5428": 1705, "5854": 1705, "5261": [1705, 1808], "1857": 1705, "2498": 1705, "1646": [1705, 1886], "0705": 1705, "0629": 1705, "2962": 1705, "0821": [1705, 1765], "1831": 1705, "type1": [1706, 1861], "type2": [1706, 1861], "2117": 1708, "9765": 1708, "1707": 1708, "4884": 1708, "5661": 1708, "5795": 1708, "5280": 1708, "9206": 1708, "quantization_schem": [1709, 1710, 1711, 1712, 1713], "int_repr": [1709, 1710, 1861, 1903], "nchw": [1711, 1922], "qx": [1711, 1712, 1713], "00001": 1711, "max_pool1d": [1712, 1861, 1903, 1910], "max_pool2d": [1713, 1861, 1903, 1910], "quasirandom": 1714, "scrambl": 1714, "sobol": 1714, "quasi": 1714, "21201": 1714, "web": 1714, "unsw": 1714, "au": [1714, 1905], "fkuo": 1714, "art": 1714, "owen": 1714, "niederreit": 1714, "xing": 1714, "466": 1714, "489": 1714, "decemb": 1714, "1998": 1714, "zh": 1714, "vychisl": 1714, "phy": 1714, "784": 1714, "802": 1714, "1967": 1714, "soboleng": 1714, "draw_base2": 1714, "base2": 1714, "fast_forward": 1714, "142": 1715, "283": 1715, "570": 1715, "359": 1715, "9894": 1715, "2503": 1716, "3525": 1716, "5673": 1716, "8237": 1716, "5781": 1716, "6879": 1716, "3816": 1716, "7249": 1716, "0998": 1716, "1436": 1720, "9966": 1720, "3426": 1720, "6366": 1720, "5954": 1720, "8929": 1720, "0923": 1720, "1719": 1720, "4709": 1720, "1996": 1720, "4595": 1726, "4314": 1726, "flat": [1729, 1772, 1861, 1878, 1901], "n2": 1729, "n3": 1729, "negat": [1732, 1816, 1863], "is_neg": [1732, 1861, 1903], "equidist": 1736, "inexact": 1736, "1234567": 1736, "1230": 1736, "vstack": [1737, 1861, 1903, 1917], "0370": 1738, "2970": 1738, "5420": 1738, "9105": 1738, "8351": 1738, "pickle_protocol": [1739, 1905], "default_protocol": 1739, "_use_new_zipfile_seri": 1739, "zipfil": [1739, 1905], "sorted_sequ": [1743, 1861], "sorter": [1743, 1861], "sorted_sequence_1d": 1743, "select_copi": [1745, 1861, 1903], "92701": [1747, 1920], "complaint": 1748, "bfloat16_3x": 1751, "denorm": [1752, 1897], "sse3": 1752, "323": 1752, "88131e": 1752, "324": 1752, "is_train": [1753, 1925], "interop": 1754, "intraop": 1755, "edgeitem": 1756, "linewidth": 1756, "sci_mod": 1756, "shamelessli": 1756, "repr": [1756, 1863], "sane": 1756, "_tensor_str": 1756, "_formatt": 1756, "12345": 1756, "1235": 1756, "excess": 1758, "24j": 1759, "8000j": 1759, "9600j": 1759, "4472": [1759, 1894], "8944j": 1759, "expit": [1760, 1918], "sym": [1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772], "2222": [1762, 1822], "4444": 1762, "8889": 1762, "4901e": 1763, "4000e": 1763, "0077e": 1763, "4923e": 1763, "waveform": [1764, 1765, 1766], "1564": 1764, "4540": 1764, "8910": 1764, "9877": 1764, "1423": [1764, 1786], "4154": 1764, "8413": [1764, 1918], "0302": 1765, "2231": 1765, "6065": 1765, "5400e": 1765, "3546e": 1765, "4788e": 1765, "8316e": 1765, "02": [1765, 1766, 1771], "3534e": 1765, "0065e": [1766, 1771], "1875e": [1766, 1771], "3937e": [1766, 1771], "2465e": [1766, 1771], "8250e": [1766, 1771], "9858e": [1766, 1771], "1365e": [1766, 1771], "8659e": [1766, 1771], "4658e": [1766, 1771], "3941e": [1766, 1771], "5400": 1767, "3376": 1767, "4200": 1767, "9136": 1767, "wit": [1767, 1860], "0955": [1767, 1768, 1770], "3455": [1767, 1768, 1770], "6545": [1767, 1768, 1770], "9045": [1767, 1768, 1770], "0800": [1768, 1769], "1876": [1768, 1769], "4601": [1768, 1769], "7700": [1768, 1769], "9723": [1768, 1769], "1679": 1769, "3979": 1769, "6821": 1769, "9121": 1769, "1170": 1770, "9698": 1770, "36358": 1772, "z_n": [1772, 1883], "48917": 1772, "2z_n": 1772, "13659": 1772, "3z_n": 1772, "01064": 1772, "4z_n": 1772, "\u03c0": 1772, "sidelob": 1772, "transact": 1772, "acoust": 1772, "speech": 1772, "84": 1772, "91": 1772, "feb": 1772, "1981": 1772, "tassp": 1772, "1163506": 1772, "heinzel": 1772, "spectrum": [1772, 1897], "dft": 1772, "comprehens": [1772, 1863, 1864, 1877, 1886, 1892, 1908], "februari": 1772, "holomet": 1772, "fnal": 1772, "gov": 1772, "gh_fft": 1772, "nutal": 1772, "general_ham": 1772, "6280e": 1772, "2698e": 1772, "1052e": 1772, "9826e": 1772, "5461": [1774, 1894], "1347": 1774, "7266": 1774, "2746": 1774, "5194": 1774, "1343": 1774, "4032": 1774, "2711": 1774, "5380": 1776, "8632": 1776, "1265": 1776, "9399": 1776, "5644": 1776, "9744": 1776, "1268": 1776, "2162": 1781, "6719": 1781, "3332": 1781, "5793": [1781, 1894], "0061": 1781, "6058": 1781, "9497": 1781, "5071": 1781, "3343": 1781, "9553": 1781, "0960": 1781, "derivati": [1782, 1785], "sparsr": 1783, "run_my_model": 1783, "prev_checks_en": 1783, "check_invari": [1783, 1790, 1791, 1792, 1793, 1794, 1795, 1917], "sparse_csr_tensor": [1783, 1861, 1903, 1917], "z_": [1785, 1883, 1918], "bigoplus_": 1785, "kj": 1785, "bigoplu": 1785, "sparseaddmmbackward0": 1785, "sparsemmreduceimplbackward0": 1785, "sparsiti": [1786, 1858, 1870, 1881], "spy": 1786, "2847": 1786, "7805": 1786, "1900": [1786, 1898], "to_dens": [1786, 1788, 1861, 1903, 1917], "3903": 1786, "x_k": 1787, "6438": 1789, "6467": 1789, "3411": 1789, "0918": 1789, "5348": 1789, "0634": 1789, "0494": 1789, "0646": 1789, "1844": 1789, "1276": 1789, "1874": 1789, "6334": 1789, "9682": 1789, "5340": 1789, "7483": 1789, "4512": 1789, "4073": 1789, "8901": 1789, "3183": 1789, "7539": 1789, "6596": 1789, "ncolblock": [1790, 1917], "array_list": [1790, 1791, 1792, 1794, 1795], "nrow": [1790, 1791, 1792, 1794, 1795, 1917], "ncol": [1790, 1791, 1792, 1794, 1795, 1917], "denses": [1790, 1791, 1792, 1794, 1795, 1917], "check_sparse_tensor_invari": [1790, 1791, 1792, 1793, 1794, 1795, 1917], "nrowblock": [1791, 1917], "compressed_indic": [1792, 1861, 1917], "plain_indic": [1792, 1861, 1917], "compressed_dim_s": [1792, 1917], "rdinat": 1793, "_indic": [1793, 1903, 1917], "0755": [1797, 1798], "0226": [1797, 1798], "0831": [1797, 1798], "4806": [1797, 1798], "0112": 1797, "2883": 1797, "6933": 1797, "0457": 1798, "0069": 1798, "2310": 1798, "2959": [1802, 1803, 1845, 1846], "8101": [1802, 1803, 1845, 1846], "5027": [1802, 1803, 1845, 1846], "3270": [1802, 1803, 1845, 1846], "5905": [1802, 1803, 1845, 1846], "6538": [1802, 1803, 1845, 1846, 1894], "3330": [1802, 1803, 1845, 1846], "5596": [1802, 1803, 1845, 1846], "6548": [1802, 1803, 1845, 1846], "1264": [1802, 1803, 1845, 1846], "5080": [1802, 1803, 1808, 1845, 1846, 1894], "6420": [1802, 1803, 1845, 1846], "1992": [1802, 1803, 1845, 1846], "0311": [1802, 1918], "7477": 1802, "2204": 1802, "9087": 1802, "2620": 1803, "0028": [1803, 1828], "0957": 1803, "6038": 1803, "0645": [1803, 1846], "4485": [1803, 1846], "8707": [1803, 1846], "0665": [1803, 1846], "librosa": 1804, "omega": 1804, "win": [1804, 1883], "_fft": [1804, 1861], "dimnsion": 1804, "1133": 1807, "2958": 1807, "5475": 1807, "0569": 1807, "0737": 1807, "3429": 1807, "9138": 1807, "9337": 1807, "6864": [1807, 1832], "1132": 1807, "7892": 1807, "1003": 1807, "5688": 1807, "3637": 1807, "9906": 1807, "5197": 1807, "4598": 1807, "3708": 1807, "6217": 1807, "435": 1807, "1335": 1807, "3135": 1807, "gesdd": 1808, "conquer": 1808, "gesvdjbatch": 1808, "fortran": 1808, "\u00b9": 1808, "2364": 1808, "7752": 1808, "7201": 1808, "7394": 1808, "0504": 1808, "3371": 1808, "5296": 1808, "3550": 1808, "5569": 1808, "2445": 1808, "1414": 1808, "4027": 1808, "0287": 1808, "5434": 1808, "1946": 1808, "8833": 1808, "3679": 1808, "4296": 1808, "2890": 1808, "6604": 1808, "2717": 1808, "2618": 1808, "4234": 1808, "2481": 1808, "4733": 1808, "3289": [1808, 1899], "0315": 1808, "7806": 1808, "0199": 1808, "8766": 1808, "4809": 1808, "4054": 1808, "7600": 1808, "8611": 1808, "2594": 1808, "4373": 1808, "6531e": 1808, "a_big": 1808, "6503e": 1808, "swapax": [1811, 1861, 1903, 1921], "1995": 1817, "4608": 1817, "7702": 1817, "4875": 1817, "9158": 1817, "5872": 1817, "6929": 1817, "6932": 1817, "take_along_axi": [1819, 1889], "max_idx": 1819, "sorted_idx": 1819, "2027": 1820, "7687": 1820, "4412": 1820, "3856": 1820, "5930": 1820, "9859": 1820, "4722": 1820, "3366": 1820, "8986": 1821, "7279": 1821, "1745": 1821, "7156": 1821, "8257": 1821, "2553": 1821, "11111": 1822, "222222": 1822, "3333333": 1822, "1111": 1822, "array_split": 1823, "i_d": 1824, "k_": 1824, "4532": 1824, "4874": 1824, "5018": 1824, "4796": [1824, 1898], "5162": 1824, "5306": 1824, "2922": 1824, "7556": 1824, "2741": 1824, "3161": 1824, "0704": 1824, "0187": 1824, "4079": 1824, "3126": 1824, "8744": 1824, "8223": 1824, "9445": 1824, "4117": 1824, "7780": 1824, "7193": 1824, "4867": 1824, "3204": 1824, "5513": 1824, "4737": [1824, 1849], "2850": 1824, "2573": 1824, "5997": 1824, "sparsebsr": 1828, "sparsecsc": 1828, "sparsebsc": 1828, "9893": 1828, "5809": 1828, "1669": 1828, "7299": 1828, "4942": [1828, 1894], "y_0": 1829, "y_1": 1829, "x_diff": 1829, "y_diff": 1829, "riemann": [1829, 1883, 1891, 1918], "badli": 1831, "cloned_coeffici": 1831, "1527": 1831, "0753": 1831, "7986": 1831, "0210": 1831, "3513": 1831, "5492": 1831, "7403": 1831, "0243": 1831, "7841": 1831, "9046": 1831, "5405": 1831, "9320": 1831, "9270": 1831, "2826": 1831, "lbrace": [1832, 1833, 1834, 1835], "rbrace": [1832, 1833, 1834, 1835], "0813": 1832, "8619": 1832, "7105": 1832, "0935": 1832, "1380": 1832, "3409": [1832, 1898], "2219": 1832, "5653": 1832, "2521": 1832, "2345": 1832, "2544": 1832, "3461": 1832, "4785": 1832, "4477": 1832, "6049": 1832, "6368": 1832, "8775": 1832, "7145": 1832, "1502": 1832, "2716": 1832, "1243": 1832, "5413": 1832, "3615": 1832, "0614": 1832, "7344": 1832, "3164": 1832, "7648": 1832, "4024": 1832, "0978": 1832, "col": [1833, 1835, 1861], "2309": 1834, "5207": 1834, "0049": 1834, "2072": 1834, "0680": 1834, "6602": 1834, "3480": 1834, "5211": 1834, "4573": 1834, "5876": 1834, "0794": [1834, 1918], "8373": 1834, "6654": 1834, "2604": 1834, "5235": 1834, "2447": 1834, "9556": 1834, "2919": 1834, "1768": 1834, "4333": 1834, "3146": [1834, 1894], "6576": 1834, "0432": 1834, "9348": [1834, 1918], "4410": 1834, "9888": 1834, "3337": 1834, "6556": 1834, "4798": 1834, "5466": 1837, "8008": 1837, "9079": 1837, "unique_consecut": [1840, 1861, 1903], "inverse_indic": [1840, 1841], "warn_onli": 1843, "alon": [1843, 1862, 1905], "put_": [1843, 1861], "index_add": [1843, 1861, 1903], "index_select": [1843, 1859, 1861, 1903, 1917], "fractionalmaxpool2d": 1843, "fractionalmaxpool3d": 1843, "reflectionpad1d": 1843, "reflectionpad3d": 1843, "replicationpad1d": 1843, "replicationpad3d": 1843, "histc": [1843, 1861, 1903], "bincount": [1843, 1861, 1903], "kthvalu": [1843, 1861, 1876, 1903], "cublasapi_reproduc": [1843, 1898], "avg_pool3d_backward_cuda": 1843, "alexandr": 1844, "theophil": 1844, "0631": 1845, "5590": 1845, "4893": 1845, "8258": 1845, "5926": 1846, "0056": 1846, "3646": 1846, "vecdot": 1847, "mi": [1848, 1849], "6116": 1848, "5772": [1848, 1918], "4606": 1848, "9120": 1848, "0786": 1848, "7497": 1848, "6623": 1848, "5772j": 1848, "9120j": 1848, "7497j": 1848, "6623j": 1848, "3839j": 1849, "2098": 1849, "6699j": 1849, "3470": 1849, "9451j": 1849, "5174": 1849, "3136j": 1849, "6699": 1849, "9451": 1849, "3136": 1849, "atleast_2d": [1852, 1861, 1903], "3139": 1853, "3898": 1853, "1657": 1853, "0383": 1853, "8785": 1853, "1089": 1853, "hubconf": 1857, "entrypoint_nam": 1857, "_resnet18": 1857, "underscor": [1857, 1877, 1913, 1923], "load_state_dict_from_url": [1857, 1872], "2gb": 1857, "relative_path_to_checkpoint": 1857, "pth": [1857, 1872, 1899], "dirnam": 1857, "5c106cde": [1857, 1872], "force_reload": 1857, "skip_valid": 1857, "trust_repo": 1857, "repo_own": 1857, "repo_nam": 1857, "torchhub": 1857, "owner": [1857, 1888, 1903, 1913, 1914], "github_token": 1857, "repo_or_dir": 1857, "mute": 1857, "resnet50_weight": 1857, "imagenet1k_v1": 1857, "download_url_to_fil": 1857, "hash_prefix": 1857, "temporary_fil": 1857, "sha256": [1857, 1872], "s3": [1857, 1872, 1900], "amazonaw": [1857, 1872, 1900], "model_dir": [1857, 1872], "check_hash": [1857, 1872], "hub_dir": [1857, 1872], "get_dir": [1857, 1872], "ext": [1857, 1872], "eight": [1857, 1872], "hash": [1857, 1861, 1863, 1872, 1903], "succinct": 1857, "set_dir": 1857, "path_to_hub_dir": 1857, "torch_hom": 1857, "xdg_cache_hom": [1857, 1886], "reiniti": 1857, "path_importer_cach": 1857, "subpackag": [1857, 1905], "classifi": [1858, 1863, 1901, 1904, 1908, 1922], "pypi": 1858, "conda": [1858, 1900], "hip": 1858, "breakdown": 1858, "_log": [1858, 1863], "javadoc": 1858, "uninitializedbuff": 1858, "anomali": 1858, "can_device_access_p": 1858, "current_blas_handl": 1858, "device_of": 1858, "get_arch_list": 1858, "get_device_cap": 1858, "get_device_nam": 1858, "get_device_properti": 1858, "get_gencode_flag": 1858, "get_sync_debug_mod": 1858, "ipc_collect": 1858, "memory_usag": 1858, "set_stream": 1858, "set_sync_debug_mod": 1858, "power_draw": 1858, "clock_rat": 1858, "outofmemoryerror": 1858, "jiter": 1858, "sanit": 1858, "get_rng_stat": [1858, 1912], "set_rng_stat": [1858, 1912], "empty_cach": [1858, 1886, 1892], "set_per_process_memory_fract": 1858, "current_allocated_memori": 1858, "driver_allocated_memori": 1858, "pathwis": 1858, "exponentialfamili": 1858, "binomi": [1858, 1861, 1903], "chi2": 1858, "continuousbernoulli": 1858, "dirichlet": 1858, "fishersnedecor": 1858, "halfcauchi": 1858, "halfnorm": 1858, "kumaraswami": 1858, "lkjcholeski": 1858, "laplac": 1858, "lognorm": 1858, "lowrankmultivariatenorm": 1858, "mixturesamefamili": 1858, "multinomi": [1858, 1861, 1903], "multivariatenorm": 1858, "negativebinomi": 1858, "onehotcategor": 1858, "relaxedbernoulli": 1858, "logitrelaxedbernoulli": 1858, "relaxedonehotcategor": 1858, "studentt": 1858, "transformeddistribut": 1858, "vonmis": 1858, "weibul": 1858, "wishart": 1858, "solver": [1858, 1897], "misc": 1858, "normal_": [1858, 1861, 1876, 1881, 1886, 1925], "constant_": [1858, 1881], "ones_": [1858, 1881], "zeros_": [1858, 1881], "eye_": [1858, 1865, 1881], "dirac_": [1858, 1865, 1881], "xavier_uniform_": [1858, 1881], "xavier_normal_": [1858, 1881, 1894], "kaiming_uniform_": [1858, 1881], "trunc_normal_": [1858, 1881], "orthogonal_": [1858, 1865, 1881, 1894], "sparse_": [1858, 1881], "alexnet": 1858, "preview": 1858, "swa": 1858, "ema": 1858, "powersgd": 1858, "remotemodul": 1858, "fork_rng": [1858, 1912], "doublestorag": [1858, 1919], "floatstorag": [1858, 1919], "halfstorag": [1858, 1919], "longstorag": [1858, 1919], "intstorag": [1858, 1919], "shortstorag": [1858, 1919], "charstorag": [1858, 1919], "bytestorag": [1858, 1919], "boolstorag": [1858, 1919], "bfloat16storag": [1858, 1919], "complexdoublestorag": [1858, 1919], "complexfloatstorag": [1858, 1919], "quint8storag": [1858, 1919], "qint8storag": [1858, 1919], "qint32storag": [1858, 1919], "quint4x2storag": [1858, 1919], "quint2x4storag": [1858, 1919], "make_tensor": [1858, 1924], "assert_allclos": [1858, 1924], "sampler": 1858, "mobile_optim": 1858, "optimize_for_mobil": [1858, 1871], "model_zoo": 1858, "load_url": [1858, 1872], "tensorboard": [1858, 1873, 1907], "summarywrit": [1858, 1873, 1922], "iinfo": 1858, "unifi": [1858, 1877], "__config__": [1858, 1885], "set_log": [1858, 1869], "torchdata": 1858, "torchserv": 1858, "torchtext": 1858, "_out": [1859, 1881, 1891], "_adaptive_avg_pool2d": [1859, 1903], "_adaptive_avg_pool2d_backward": 1859, "_log_softmax": [1859, 1903], "half_to_float": 1859, "_native_batch_norm_legit": [1859, 1903], "no_stat": 1859, "_softmax": [1859, 1903, 1918], "_to_copi": [1859, 1903], "scalartyp": 1859, "memoryformat": 1859, "start_step": 1859, "avg_pool2d": [1859, 1861, 1903, 1910], "avg_pool2d_backward": 1859, "constant_pad_nd": [1859, 1861, 1903], "convolution_backward": 1859, "bias_siz": 1859, "output_mask": 1859, "embedding_dense_backward": 1859, "num_weight": 1859, "interpolation_mod": [1859, 1861], "isinf": [1859, 1861, 1903, 1917], "max_pool2d_with_indic": [1859, 1861, 1903], "max_pool2d_with_indices_backward": 1859, "max_pool3d_with_indic": [1859, 1861, 1903], "native_batch_norm": [1859, 1861, 1903], "native_dropout": [1859, 1861, 1903], "native_group_norm": [1859, 1861, 1903], "hxw": [1859, 1861], "native_group_norm_backward": 1859, "rstd": 1859, "native_layer_norm": [1859, 1861, 1903], "native_layer_norm_backward": 1859, "tensor_scalar": 1859, "tensor_tensor": 1859, "scalar_tensor": [1859, 1861, 1903], "slice_scatt": [1859, 1861, 1903], "dim_intlist": 1859, "upsample_bilinear2d": [1859, 1861, 1903], "upsample_nearest2d": [1859, 1861, 1903], "convert_element_typ": [1859, 1903], "broadcast_in_dim": [1859, 1903], "bessel_i0": [1859, 1903], "bessel_i1": [1859, 1903], "bessel_j0": [1859, 1903, 1918], "bessel_j1": [1859, 1903, 1918], "cbrt": [1859, 1903], "erf_inv": [1859, 1903], "erfcx": [1859, 1903, 1918], "exp2": [1859, 1861, 1903, 1918, 1922], "isfinit": [1859, 1861, 1897, 1903], "ndtri": [1859, 1903, 1918], "spherical_bessel_j0": [1859, 1903, 1918], "fmax": [1859, 1861, 1903], "fmin": [1859, 1861, 1903], "shift_left": [1859, 1903], "shift_right_arithmet": [1859, 1903], "zeta": [1859, 1886, 1903, 1918], "broadcast_dimens": 1859, "collapse_view": [1859, 1903], "start_indic": 1859, "limit_indic": 1859, "slice_in_dim": [1859, 1903], "start_index": 1859, "limit_index": 1859, "split_dim": [1859, 1903], "outer_length": 1859, "view_of": [1859, 1903], "as_strided_scatt": [1859, 1861, 1903], "collaps": [1859, 1876, 1903], "rev": [1859, 1903], "device_put": [1859, 1903], "maximum_valu": [1859, 1903], "minimum_valu": [1859, 1903], "copy_strid": [1859, 1903], "copy_to": [1859, 1903], "xor_sum": [1859, 1903], "empty_permut": [1859, 1861, 1903], "physical_layout": [1859, 1861], "iota": [1859, 1903], "fft_r2c": [1859, 1903], "fft_c2c": [1859, 1903], "fft_c2r": [1859, 1903], "disadvantag": 1860, "gentl": 1860, "beam": 1860, "traced_bar": 1860, "myscriptmodul": 1860, "103": [1860, 1862], "939": [1860, 1862], "116": [1860, 1862], "779": [1860, 1862], "123": [1860, 1862], "my_script_modul": [1860, 1862], "ins": 1860, "pytorch_jit": 1860, "traced_fn": 1860, "disable_jit_exampl": 1860, "printer": 1860, "rv": 1860, "rv0": 1860, "rv1": 1860, "ssa": 1860, "block0": 1860, "block1": 1860, "loop_in_traced_fn": 1860, "input_tupl": 1860, "fill_row_zero": 1860, "tracerwarn": 1860, "disjoint": 1860, "nr": 1860, "09115803241729736": 1860, "6782537698745728": 1860, "cpu_model": 1860, "gpu_model": 1860, "sample_input_cpu": 1860, "sample_input_gpu": 1860, "traced_cpu": 1860, "traced_gpu": 1860, "use_gpu": 1860, "__constants__": [1860, 1862], "my_module_inst": 1860, "redeclar": 1860, "nn_module_inst": 1860, "my_scripted_model": 1860, "526": [1860, 1862, 1901], "script_method": 1860, "implicitly_compiled_method": 1860, "another_forward": 1860, "unused_method": 1860, "some_fn": 1860, "ever": [1860, 1919], "some_fn2": 1860, "some_fn3": 1860, "some_fn4": 1860, "my_dict": [1860, 1862], "my_int": [1860, 1862], "my_const": 1860, "make_dict": 1860, "nnc": 1860, "__and__": 1861, "__iand__": 1861, "__ilshift__": 1861, "__ior__": 1861, "__irshift__": 1861, "__ixor__": 1861, "__lshift__": 1861, "__or__": 1861, "__rshift__": 1861, "__xor__": 1861, "absolute_": 1861, "acos_": [1861, 1876], "addbmm_": 1861, "addcdiv_": 1861, "addcmul_": 1861, "addmv_": [1861, 1876], "addr_": 1861, "align_a": [1861, 1876, 1877, 1903], "align_to": [1861, 1876, 1877, 1903], "ellipsis_idx": 1861, "aminmax": [1861, 1903], "arccos_": 1861, "arccosh_": 1861, "arcsin_": [1861, 1917], "arcsinh_": 1861, "arctan2_": 1861, "arctan_": 1861, "arctanh_": 1861, "argwher": [1861, 1903], "as_strided_": 1861, "asin_": [1861, 1876, 1917], "asinh_": [1861, 1876], "atan_": [1861, 1876], "atanh_": [1861, 1876], "baddbmm_": 1861, "bernoulli_": [1861, 1876, 1925], "bitwise_and_": 1861, "bitwise_left_shift_": 1861, "bitwise_not_": [1861, 1876], "bitwise_or_": 1861, "bitwise_right_shift_": 1861, "bitwise_xor_": 1861, "broadcast_to": [1861, 1903], "cauchy_": [1861, 1876, 1925], "ceil_": [1861, 1876], "clamp_max": [1861, 1903], "clamp_max_": 1861, "clamp_min": [1861, 1903], "clamp_min_": 1861, "clip_": 1861, "conj_physical_": 1861, "copysign_": 1861, "cos_": [1861, 1876, 1883], "cosh_": [1861, 1876], "count_nonzero": [1861, 1903], "cummax": [1861, 1903], "cummin": [1861, 1903], "cumprod_": 1861, "cumsum_": 1861, "deg2rad": [1861, 1876, 1903, 1917], "deg2rad_": [1861, 1876, 1917], "outdim": 1861, "diagonal_scatt": [1861, 1903], "digamma_": [1861, 1876], "div_": [1861, 1876, 1917], "divide_": 1861, "dsplit": [1861, 1903], "eq_": 1861, "erf_": [1861, 1876], "erfc_": [1861, 1876], "erfinv_": [1861, 1876], "exp2_": 1861, "exp_": [1861, 1876], "expm1_": [1861, 1876], "exponential_": [1861, 1876, 1925], "fill_diagonal_": 1861, "fix_": 1861, "fliplr": [1861, 1903], "flipud": [1861, 1903], "float_power_": 1861, "floor_": [1861, 1876], "floor_divide_": [1861, 1917], "fmod_": 1861, "frac_": [1861, 1876], "frexp": [1861, 1903], "gcd_": 1861, "ge_": 1861, "geometric_": [1861, 1925], "ger": [1861, 1903], "get_devic": [1861, 1876, 1903, 1917, 1919, 1920], "greater_": 1861, "greater_equal_": 1861, "gt_": 1861, "hardshrink": [1861, 1903], "heavisid": [1861, 1903], "heaviside_": 1861, "hsplit": [1861, 1903, 1921], "hypot_": 1861, "i0_": 1861, "igamma_": 1861, "igammac_": 1861, "index_fil": [1861, 1876, 1903], "index_reduc": [1861, 1903], "is_coalesc": [1861, 1903, 1917], "is_complex": [1861, 1903, 1917, 1920], "is_contigu": [1861, 1876, 1903, 1921], "is_floating_point": [1861, 1876, 1903, 1917, 1920], "is_infer": [1861, 1903], "is_same_s": [1861, 1903, 1917], "is_set_to": [1861, 1903], "is_sign": [1861, 1876, 1903, 1917], "isclos": [1861, 1903], "isneginf": [1861, 1903, 1917], "isposinf": [1861, 1903, 1917], "isreal": [1861, 1903], "istft": [1861, 1903], "kron": [1861, 1903], "lcm_": 1861, "ldexp_": 1861, "le_": 1861, "lerp_": 1861, "less_": 1861, "less_equal_": 1861, "lgamma_": 1861, "log10_": [1861, 1876], "log1p_": [1861, 1876, 1917], "log2_": [1861, 1876], "log_normal_": [1861, 1876, 1925], "logaddexp2": [1861, 1903], "logcumsumexp": [1861, 1903], "logical_and_": 1861, "logical_not_": [1861, 1876], "logical_or_": 1861, "logical_xor_": 1861, "logit_": 1861, "lt_": 1861, "masked_scatt": [1861, 1903], "masked_select": [1861, 1876, 1903], "matrix_pow": [1861, 1903], "moveaxi": [1861, 1903], "msort": [1861, 1903], "multiply_": 1861, "mvlgamma_": 1861, "nan_to_num_": 1861, "nanmedian": [1861, 1876, 1903], "nansum": [1861, 1903], "narrow_copi": [1861, 1903, 1917], "ne_": 1861, "neg_": [1861, 1876, 1917], "negative_": [1861, 1917], "new_empty_strid": [1861, 1903], "new_ful": [1861, 1886, 1903], "new_on": [1861, 1903], "nextafter_": 1861, "nonzero_stat": [1861, 1903], "not_equal_": 1861, "output_nr": [1861, 1903], "polygamma_": 1861, "pow_": [1861, 1876], "q_per_channel_scal": [1861, 1903], "q_per_channel_zero_point": [1861, 1903], "q_scale": [1861, 1903], "q_zero_point": [1861, 1903], "rad2deg": [1861, 1876, 1903, 1917], "rad2deg_": [1861, 1876, 1917], "reciprocal_": [1861, 1876], "record_stream": [1861, 1886, 1903], "refine_nam": [1861, 1876, 1877, 1903], "relu_": [1861, 1910], "remainder_": 1861, "rename_": [1861, 1876, 1877], "renorm_": 1861, "reshape_a": [1861, 1878, 1903, 1921], "resize_a": [1861, 1903], "the_templ": 1861, "resize_as_sparse_": 1861, "retains_grad": [1861, 1903], "roll": [1861, 1903], "rot90": [1861, 1903], "round_": [1861, 1876], "rsqrt_": [1861, 1876], "select_scatt": [1861, 1903], "sgn_": [1861, 1876], "sigmoid_": [1861, 1876, 1910], "sign_": [1861, 1876], "sinc_": 1861, "sinh_": [1861, 1876], "smm": [1861, 1903, 1917], "sparse_resize_": 1861, "sparse_resize_and_clear_": 1861, "split_with_s": [1861, 1903, 1921], "sqrt_": [1861, 1876], "square_": 1861, "squeeze_": [1861, 1910], "sspaddmm": [1861, 1903, 1917], "sub_": [1861, 1876, 1917], "subtract_": 1861, "sum_to_s": [1861, 1903], "swapaxes_": 1861, "swapdim": [1861, 1903, 1921], "swapdims_": 1861, "take_along_dim": [1861, 1903], "tan_": [1861, 1876], "tanh_": [1861, 1876, 1910], "tensor_indices_or_sect": 1861, "to_mkldnn": [1861, 1903], "to_padded_tensor": [1861, 1878, 1903], "to_sparse_bsc": [1861, 1903], "to_sparse_bsr": [1861, 1903, 1917], "to_sparse_csc": [1861, 1903, 1917], "true_divide_": 1861, "trunc_": [1861, 1876], "type_a": [1861, 1876, 1903], "out0": [1861, 1899], "unsafe_chunk": [1861, 1903], "unsafe_split": [1861, 1903], "unsafe_split_with_s": [1861, 1903], "unsqueeze_": [1861, 1910], "view_a": [1861, 1903, 1921], "vsplit": [1861, 1903, 1921], "xlogy_": 1861, "adaptive_avg_pool2d": [1861, 1888, 1903, 1910], "adaptive_max_pool1d_with_indic": [1861, 1888], "adaptive_max_pool2d_with_indic": 1861, "adaptive_max_pool3d_with_indic": 1861, "alpha_dropout": [1861, 1903], "assert_int_or_pair": 1861, "arg_nam": 1861, "binary_cross_entropi": [1861, 1903], "binary_cross_entropy_with_logit": [1861, 1903], "celu": [1861, 1903], "dropout2d": 1861, "dropout3d": 1861, "feature_alpha_dropout": [1861, 1903], "fractional_max_pool2d_with_indic": 1861, "fractional_max_pool3d_with_indic": 1861, "gaussian_nll_loss": 1861, "glu": [1861, 1903], "gumbel_softmax": 1861, "hardsigmoid": [1861, 1903, 1910], "hardswish": [1861, 1903, 1910], "huber_loss": [1861, 1903], "instance_norm": [1861, 1903, 1910], "local_response_norm": 1861, "lp_pool1d": 1861, "lp_pool2d": 1861, "max_pool1d_with_indic": [1861, 1903], "mish": [1861, 1903], "multi_head_attention_forward": 1861, "embed_dim_to_check": 1861, "in_proj_weight": 1861, "in_proj_bia": 1861, "bias_k": 1861, "bias_v": 1861, "out_proj_weight": 1861, "out_proj_bia": 1861, "use_separate_proj_weight": 1861, "q_proj_weight": 1861, "k_proj_weight": 1861, "v_proj_weight": 1861, "static_k": 1861, "static_v": 1861, "multilabel_soft_margin_loss": 1861, "relu6": [1861, 1903, 1910], "silu": [1861, 1878, 1903], "softsign": 1861, "tanhshrink": 1861, "adaptive_avg_pool1d": [1861, 1888, 1903, 1910], "adaptive_max_pool1d": [1861, 1888, 1903], "affine_grid_gener": [1861, 1903], "alias_copi": [1861, 1903], "align_tensor": [1861, 1903], "alpha_dropout_": 1861, "as_strided_copi": [1861, 1903], "atleast_1d": [1861, 1903], "avg_pool1d": [1861, 1903, 1910], "bartlett_window": [1861, 1865, 1903], "cudnn_en": 1861, "batch_norm_backward_elemt": 1861, "invstd": 1861, "mean_di": 1861, "mean_dy_xmu": 1861, "batch_norm_backward_reduc": 1861, "input_g": 1861, "bias_g": 1861, "out3": 1861, "batch_norm_elemt": [1861, 1903], "batch_norm_gather_stat": [1861, 1903], "batch_norm_gather_stats_with_count": [1861, 1903], "batch_norm_stat": [1861, 1903], "batch_norm_update_stat": [1861, 1903], "blackman_window": [1861, 1865, 1903], "block_diag": [1861, 1903], "can_cast": [1861, 1903], "ccol_indices_copi": [1861, 1903], "celu_": 1861, "choose_qparams_optim": [1861, 1903], "n_bin": 1861, "bit_width": 1861, "col_indices_copi": [1861, 1903], "column_stack": [1861, 1903], "conv_tbc": [1861, 1903], "crow_indices_copi": [1861, 1903], "cudnn_affine_grid_gener": [1861, 1903], "cudnn_batch_norm": [1861, 1903], "exponential_average_factor": 1861, "cudnn_convolut": [1861, 1903], "cudnn_convolution_add_relu": [1861, 1903], "cudnn_convolution_relu": [1861, 1903], "cudnn_convolution_transpos": [1861, 1903], "cudnn_grid_sampl": [1861, 1903], "cudnn_is_accept": [1861, 1903], "cumulative_trapezoid": [1861, 1903], "diagonal_copi": [1861, 1903], "dropout_": [1861, 1871], "embedding_renorm_": 1861, "empty_quant": [1861, 1903], "anyenumtyp": 1861, "expand_copi": [1861, 1903], "fake_quantize_per_channel_affin": [1861, 1903], "fbgemm_linear_fp16_weight": [1861, 1903], "packed_weight": 1861, "fbgemm_linear_fp16_weight_fp32_activ": [1861, 1903], "fbgemm_linear_int8_weight": [1861, 1903], "col_offset": 1861, "weight_scal": 1861, "weight_zero_point": 1861, "fbgemm_linear_int8_weight_fp32_activ": [1861, 1903], "fbgemm_linear_quantize_weight": [1861, 1903], "fbgemm_pack_gemm_matrix_fp16": [1861, 1903], "fbgemm_pack_quantized_matrix": [1861, 1903], "feature_alpha_dropout_": 1861, "feature_dropout": [1861, 1903], "feature_dropout_": 1861, "frobenius_norm": [1861, 1903], "from_fil": [1861, 1903, 1919], "fused_moving_avg_obs_fake_qu": [1861, 1903], "observer_on": 1861, "fake_quant_on": 1861, "running_min": 1861, "running_max": 1861, "per_row_fake_qu": 1861, "symmetric_qu": 1861, "has_bias": 1861, "gru_cel": [1861, 1903], "w_ih": 1861, "w_hh": 1861, "hamming_window": [1861, 1865, 1903], "histogramdd": [1861, 1903], "hspmm": [1861, 1903, 1917], "indices_copi": [1861, 1903], "is_autocast_cpu_en": [1861, 1903], "is_autocast_en": [1861, 1903], "is_grad_en": [1861, 1903], "is_vulkan_avail": [1861, 1903], "isin": [1861, 1903], "kaiser_window": [1861, 1903], "lstm_cell": [1861, 1903], "meshgrid": [1861, 1903], "miopen_batch_norm": [1861, 1903], "miopen_convolut": [1861, 1903], "miopen_convolution_add_relu": [1861, 1903], "miopen_convolution_relu": [1861, 1903], "miopen_convolution_transpos": [1861, 1903], "miopen_depthwise_convolut": [1861, 1903], "miopen_rnn": [1861, 1903], "weight_stride0": 1861, "dropout_st": 1861, "out4": 1861, "mkldnn_adaptive_avg_pool2d": [1861, 1903], "mkldnn_convolut": [1861, 1903], "mkldnn_linear_backward_weight": 1861, "bias_defin": 1861, "mkldnn_max_pool2d": [1861, 1903], "mkldnn_max_pool3d": [1861, 1903], "mkldnn_rnn_layer": [1861, 1903], "weight0": 1861, "weight1": 1861, "weight2": 1861, "weight3": 1861, "hx_": 1861, "cx_": 1861, "save_mean": 1861, "save_invstd": 1861, "native_channel_shuffl": [1861, 1903], "native_norm": [1861, 1903, 1917], "norm_except_dim": [1861, 1903], "nuclear_norm": [1861, 1903], "pairwise_dist": [1861, 1903], "permute_copi": [1861, 1903], "promote_typ": [1861, 1903, 1924], "quantize_per_channel": [1861, 1903, 1908], "quantize_per_tensor_dynam": [1861, 1903, 1908], "quantized_batch_norm": [1861, 1903], "quantized_gru_cel": [1861, 1903], "packed_ih": 1861, "packed_hh": 1861, "col_offsets_ih": 1861, "col_offsets_hh": 1861, "scale_ih": 1861, "scale_hh": 1861, "zero_point_ih": 1861, "zero_point_hh": 1861, "quantized_lstm_cel": [1861, 1903], "quantized_max_pool1d": [1861, 1903], "quantized_max_pool2d": [1861, 1903], "quantized_max_pool3d": [1861, 1903], "quantized_rnn_relu_cel": [1861, 1903], "quantized_rnn_tanh_cel": [1861, 1903], "randint_lik": [1861, 1865, 1903, 1925], "randn_lik": [1861, 1865, 1878, 1903, 1925], "randperm": [1861, 1865, 1903, 1925], "result_typ": [1861, 1903], "scalar1": 1861, "scalar2": 1861, "rnn_relu": [1861, 1903], "rnn_relu_cel": [1861, 1903], "rnn_tanh": [1861, 1903], "rnn_tanh_cel": [1861, 1903], "row_indices_copi": [1861, 1903], "row_stack": [1861, 1903], "rrelu_": 1861, "rsub": [1861, 1903], "searchsort": [1861, 1903], "segment_reduc": [1861, 1903], "selu_": 1861, "slice_copi": [1861, 1903], "sparse_bsc_tensor": [1861, 1903, 1917], "sparse_bsr_tensor": [1861, 1903, 1917], "sparse_compressed_tensor": [1861, 1903, 1917], "sparse_csc_tensor": [1861, 1903, 1917], "split_copi": [1861, 1903], "split_with_sizes_copi": [1861, 1903], "squeeze_copi": [1861, 1903], "std_mean": [1861, 1876, 1903], "t_copi": [1861, 1903], "threshold_": 1861, "transpose_copi": [1861, 1903], "trapz": [1861, 1903], "tril_indic": [1861, 1865, 1903], "triu_indic": [1861, 1865, 1903], "unbind_copi": [1861, 1903], "unfold_copi": [1861, 1903], "unsqueeze_copi": [1861, 1903], "values_copi": [1861, 1903], "vander": [1861, 1865, 1903], "var_mean": [1861, 1876, 1903], "view_as_complex_copi": [1861, 1903], "view_as_real_copi": [1861, 1903], "_nn": 1861, "adaptive_max_pool2d": [1861, 1903], "conv_depthwise3d": [1861, 1903], "cross_entropy_loss": [1861, 1903], "input_scal": 1861, "elu_": 1861, "flatten_dense_tensor": [1861, 1903], "random_sampl": 1861, "gelu_": 1861, "hardsigmoid_": [1861, 1910], "hardswish_": 1861, "hardtanh_": [1861, 1910], "leaky_relu_": 1861, "log_sigmoid": [1861, 1903], "mish_": 1861, "mkldnn_linear": [1861, 1903], "mkldnn_reorder_conv2d_weight": [1861, 1903], "mkldnn_reorder_conv3d_weight": [1861, 1903], "nll_loss2d": [1861, 1903], "nll_loss_nd": [1861, 1903], "reflection_pad3d": [1861, 1903], "relu6_": 1861, "rrelu_with_nois": [1861, 1903], "rrelu_with_noise_": 1861, "silu_": 1861, "slow_conv3d": [1861, 1903], "slow_conv_dilated2d": [1861, 1903], "slow_conv_dilated3d": [1861, 1903], "slow_conv_transpose2d": [1861, 1903], "slow_conv_transpose3d": [1861, 1903], "softshrink": [1861, 1903], "thnn_conv2d": [1861, 1903], "unflatten_dense_tensor": [1861, 1903], "upsample_bicubic2d": [1861, 1903], "scales_h": 1861, "scales_w": 1861, "upsample_linear1d": [1861, 1903], "upsample_nearest1d": [1861, 1903], "upsample_nearest3d": [1861, 1903], "scales_d": 1861, "upsample_trilinear3d": [1861, 1903], "fft_fftfreq": [1861, 1903], "fft_fftshift": [1861, 1903], "fft_hfft2": [1861, 1903], "fft_hfftn": [1861, 1903], "fft_ifftshift": [1861, 1903], "fft_ihfft2": [1861, 1903], "fft_ihfftn": [1861, 1903], "fft_rfftfreq": [1861, 1903], "_linalg": 1861, "linalg_cross": [1861, 1903], "linalg_det": [1861, 1903], "linalg_diagon": [1861, 1903], "eigvec": 1861, "linalg_ldl_factor": [1861, 1903], "linalg_ldl_factor_ex": [1861, 1903], "linalg_ldl_solv": [1861, 1903], "linalg_lu": [1861, 1903], "linalg_lu_factor": [1861, 1903], "linalg_lu_factor_ex": [1861, 1903], "linalg_lu_solv": [1861, 1903], "linalg_matmul": [1861, 1903], "linalg_matrix_exp": [1861, 1903], "linalg_matrix_pow": [1861, 1903], "linalg_multi_dot": [1861, 1903], "linalg_norm": [1861, 1903], "linalg_pinv": [1861, 1903], "linalg_solve_ex": [1861, 1903], "linalg_solve_triangular": [1861, 1903], "linalg_vand": [1861, 1903], "linalg_vecdot": [1861, 1903], "linalg_vector_norm": [1861, 1903], "_nest": 1861, "nested_to_padded_tensor": [1861, 1903], "_spars": 1861, "sparse_sampled_addmm": [1861, 1903], "_special": 1861, "special_airy_ai": [1861, 1903], "special_bessel_j0": [1861, 1903], "special_bessel_j1": [1861, 1903], "special_bessel_y0": [1861, 1903], "special_bessel_y1": [1861, 1903], "special_chebyshev_polynomial_t": [1861, 1903], "special_chebyshev_polynomial_u": [1861, 1903], "special_chebyshev_polynomial_v": [1861, 1903], "special_chebyshev_polynomial_w": [1861, 1903], "special_digamma": [1861, 1903], "special_entr": [1861, 1903], "special_erf": [1861, 1903], "special_erfc": [1861, 1903], "special_erfcx": [1861, 1903], "special_erfinv": [1861, 1903], "special_exp2": [1861, 1903], "special_expit": [1861, 1903], "special_expm1": [1861, 1903], "special_gammainc": [1861, 1903], "special_gammaincc": [1861, 1903], "special_gammaln": [1861, 1903], "special_hermite_polynomial_h": [1861, 1903], "special_i0": [1861, 1903], "special_i1": [1861, 1903], "special_laguerre_polynomial_l": [1861, 1903], "special_legendre_polynomial_p": [1861, 1903], "special_log1p": [1861, 1903], "special_log_ndtr": [1861, 1903], "special_log_softmax": [1861, 1903], "special_logit": [1861, 1903], "special_logsumexp": [1861, 1903], "special_modified_bessel_i0": [1861, 1903], "special_modified_bessel_i1": [1861, 1903], "special_modified_bessel_k0": [1861, 1903], "special_modified_bessel_k1": [1861, 1903], "special_multigammaln": [1861, 1903], "special_ndtr": [1861, 1903], "special_ndtri": [1861, 1903], "special_polygamma": [1861, 1903], "special_psi": [1861, 1903], "special_round": [1861, 1903], "special_scaled_modified_bessel_k0": [1861, 1903], "special_scaled_modified_bessel_k1": [1861, 1903], "special_shifted_chebyshev_polynomial_t": [1861, 1903], "special_shifted_chebyshev_polynomial_u": [1861, 1903], "special_shifted_chebyshev_polynomial_v": [1861, 1903], "special_shifted_chebyshev_polynomial_w": [1861, 1903], "special_sinc": [1861, 1903], "special_softmax": [1861, 1903], "special_spherical_bessel_j0": [1861, 1903], "special_xlog1pi": [1861, 1903], "special_xlogi": [1861, 1903], "special_zeta": [1861, 1903], "tval": 1861, "is_accept": 1861, "rect": 1861, "__complex__": 1861, "__float__": 1861, "__int__": 1861, "hex": [1861, 1863, 1903], "__hex__": 1861, "oct": [1861, 1903], "__oct__": 1861, "divmod": [1861, 1863, 1903], "chr": [1861, 1863, 1903], "int_float": 1861, "float_int": 1861, "fab": [1861, 1903], "int_int": 1861, "float_float": 1861, "complex_complex": 1861, "int_complex": 1861, "complex_int": 1861, "float_complex": 1861, "complex_float": [1861, 1919], "scalar_scalar": 1861, "int_to_int": 1861, "modf": [1861, 1903], "mathremaind": [1861, 1903], "programm": [1862, 1863], "tn": 1862, "subtyp": 1862, "an_error": 1862, "noreturn": [1862, 1863], "classvar": [1862, 1863], "anystr": [1862, 1863], "nomin": 1862, "newtyp": [1862, 1863], "tup": [1862, 1863], "emptydatastructur": 1862, "my_list": 1862, "aug_add_x": 1862, "inc": [1862, 1863], "assign_x": [1862, 1863], "polymorph": 1862, "sum_pair": 1862, "red": [1862, 1863], "enum_fn": [1862, 1863], "my_variable_nam": 1862, "top_level_method": 1862, "other_help": 1862, "ten": [1862, 1922], "my_paramet": 1862, "my_submodul": 1862, "tuple_or_list": 1862, "a_tupl": 1862, "de": [1862, 1905, 1908], "is_script": [1862, 1863, 1903], "unsupported_linear_op": 1862, "is_trac": [1862, 1863], "univers": 1862, "typing_extens": 1862, "a_dict": 1862, "some_dict": 1862, "delimit": [1863, 1864], "tstype": 1863, "tsmoduletyp": 1863, "tsalltyp": 1863, "tsmetatyp": 1863, "tsprimitivetyp": 1863, "tsstructuraltyp": 1863, "tsnominaltyp": 1863, "myclass": [1863, 1905], "printabl": [1863, 1905], "sortabl": 1863, "nevertheless": [1863, 1915], "inc_first_el": 1863, "cpufloattyp": 1863, "tstupl": 1863, "tsnamedtupl": 1863, "tslist": 1863, "tsdict": 1863, "tsoption": 1863, "tsunion": 1863, "tsfutur": 1863, "tsrref": 1863, "tsawait": 1863, "await": [1863, 1864, 1913], "keytyp": 1863, "_await": 1863, "mytupl": 1863, "scripted_inc": 1863, "_annotatednamedtupl": 1863, "_namedtupleannot": 1863, "_unannotatednamedtupl": 1863, "nameerror": 1863, "remedi": 1863, "tsbuiltinclass": 1863, "tscustomclass": 1863, "tsenum": 1863, "tstensor": 1863, "subtensor": [1863, 1888, 1928], "subwithtorchfunct": 1863, "script_g": 1863, "tsclassdef": 1863, "methoddefinit": 1863, "__torch__": [1863, 1901], "class2": 1863, "tsenumdef": 1863, "tsenumtyp": 1863, "memberidentifi": 1863, "intenum": 1863, "intflag": 1863, "basecolor": 1863, "compli": [1863, 1905], "classbodydefinit": 1863, "moduleobj": 1863, "testmodul": 1863, "mymodel": [1863, 1882, 1896], "dosometh": 1863, "strateg": 1863, "congruent": 1863, "python3": 1863, "unannot": 1863, "python3annot": 1863, "paramannot": 1863, "returnannot": 1863, "funcormethodbodi": 1863, "mypyannot": 1863, "localvarannot": 1863, "setval": 1863, "moduletyp": [1863, 1905], "classidentifi": 1863, "instanceattridentifi": 1863, "offset_": 1863, "tsstructualtyp": 1863, "grammar": 1863, "chapter": [1863, 1891], "floattyp": 1863, "inttyp": 1863, "stringtyp": 1863, "devicetyp": 1863, "bullet": 1863, "tupletyp": 1863, "listtyp": 1863, "enclosur": 1863, "parenth_form": 1863, "list_displai": 1863, "dict_displai": 1863, "legal": 1863, "stringliter": 1863, "floatnumb": 1863, "expression_list": 1863, "list_comprehens": 1863, "comp_for": 1863, "target_list": 1863, "or_expr": 1863, "key_datum_list": 1863, "dict_comprehens": 1863, "key_datum": 1863, "ongo": [1863, 1901, 1911, 1913], "enclos": 1863, "datum": [1863, 1927], "attributeref": 1863, "slice_list": 1863, "slice_item": 1863, "proper_slic": 1863, "argument_list": 1863, "u_expr": 1863, "tightli": [1863, 1894], "m_expr": 1863, "a_expr": 1863, "shift_expr": 1863, "and_expr": 1863, "xor_expr": 1863, "comp_oper": 1863, "__contains__": 1863, "or_test": 1863, "and_test": 1863, "not_test": 1863, "conditional_express": 1863, "starred_item": 1863, "expression_stmt": 1863, "starred_express": 1863, "assignment_express": 1863, "assignment_stmt": 1863, "augmented_assignment_stmt": 1863, "augtarget": 1863, "augop": 1863, "annotated_assignment_stmt": 1863, "raise_stmt": 1863, "assert_stmt": 1863, "return_stmt": 1863, "del_stmt": 1863, "pass_stmt": 1863, "print_stmt": 1863, "break_stmt": 1863, "continue_stmt": 1863, "if_stmt": 1863, "while_stmt": 1863, "for_stmt": 1863, "with_stmt": 1863, "with_item": 1863, "__enter__": 1863, "suppress": [1863, 1912], "tuple_stmt": 1863, "getattr_stmt": 1863, "hasattr_stmt": 1863, "zip_stmt": 1863, "iterable1": 1863, "iterable2": 1863, "enumerate_stmt": 1863, "add_stat_valu": 1863, "sugaredvalu": 1863, "unrecogn": 1863, "honor": 1863, "__abs__": 1863, "bytearrai": 1863, "delattr": 1863, "exec": 1863, "__index__": 1863, "isint": 1863, "issubclass": [1863, 1888], "ndigit": 1863, "setattr": 1863, "__import__": [1863, 1905], "rpc_sync": [1863, 1903, 1913, 1914, 1915], "synonym": 1863, "_fork": [1863, 1885], "_wait": [1863, 1885], "lexic": 1864, "indent": 1864, "coroutin": 1864, "__del__": [1864, 1883], "__bytes__": 1864, "__slots__": 1864, "metaclass": 1864, "mro": 1864, "__r": 1864, "nonloc": 1864, "bytesliter": 1864, "imagnumb": 1864, "parenthes": 1864, "ifs": 1864, "compound": 1864, "exc_typ": 1864, "exc_valu": 1864, "adaptivelogsoftmaxwithloss": 1865, "enable_grad": [1865, 1925], "overload_nam": 1867, "handi": [1867, 1883, 1886], "spotti": 1867, "googl": 1867, "keynam": 1867, "alias_analysi": 1867, "op_nam": 1867, "opoverload": 1867, "div_cpu": 1867, "off_by_default": 1869, "_registr": 1869, "born": 1870, "citizen": 1870, "afterthought": 1870, "unlock": 1870, "intuit": 1870, "alik": 1870, "grai": 1870, "systemat": 1870, "onboard": 1870, "maskedarrai": 1870, "masked_tensor": 1870, "blocklist": [1871, 1905], "mobileoptimizertyp": 1871, "conv_bn_fus": 1871, "correspondingli": 1871, "prepack": [1871, 1903], "insert_fold_prepack_op": 1871, "arm": [1871, 1908], "remove_dropout": 1871, "hoist": 1871, "hoist_conv_packed_param": 1871, "fuse_add_relu": 1871, "vulkan": 1871, "vulkan_automatic_gpu_transf": 1871, "freeze_modul": 1871, "script_modul": 1871, "optimization_blocklist": 1871, "preserved_method": 1871, "_mobileoptimizertyp": 1871, "recursivescriptmodul": [1871, 1899], "infrequ": 1873, "window_s": 1873, "max_sampl": 1873, "cap": 1873, "_monitor": 1873, "data_value_t": 1873, "eventhandlerhandl": 1873, "register_event_handl": 1873, "unregister_event_handl": 1873, "tensorboardeventhandl": 1873, "writer": [1873, 1894, 1922], "shared_memori": 1875, "abruptli": 1875, "get_all_sharing_strategi": 1875, "get_sharing_strategi": 1875, "set_sharing_strategi": 1875, "new_strategi": 1875, "abnorm": [1875, 1896], "fatal": [1875, 1896], "forev": [1875, 1887], "asap": 1875, "queue_2": 1875, "x_clone": 1875, "shm_open": 1875, "mmap": 1875, "destructor": [1875, 1915], "torch_shm_manag": 1875, "unnot": 1875, "spawncontext": 1875, "has_nam": 1876, "is_shar": [1876, 1919], "is_sparse_csr": [1876, 1903, 1919], "is_tensor": [1876, 1917], "items": [1876, 1903], "unifies_names_from_input_tensor": 1876, "nbyte": [1876, 1903, 1919], "ndimens": 1876, "position": [1876, 1877], "unnam": [1876, 1877], "misalign": 1876, "inher": 1876, "disappear": 1876, "img": [1877, 1922], "renamed_img": 1877, "coexist": 1877, "scale_channel": 1877, "more_img": 1877, "named_tensor": 1877, "named_img": 1877, "flat_img": 1877, "named_flat_img": 1877, "unflattened_img": 1877, "unflattened_named_img": 1877, "grad_loss": 1877, "8107": 1877, "6357": 1877, "0783": 1877, "untest": 1877, "rename_map": 1877, "greedili": 1877, "unment": 1877, "49152": 1877, "datastructur": 1878, "seamless": 1878, "nested_tensor": 1878, "nt": 1878, "vein": 1878, "as_nested_tensor": 1878, "irregular": 1878, "indistinguish": 1878, "2286": 1878, "4842": 1878, "7827": 1878, "6745": [1878, 1918], "0658": 1878, "1247": 1878, "4078": 1878, "8083": 1878, "2871": 1878, "5559": 1878, "9885": 1878, "4074": 1878, "4855": 1878, "0733": 1878, "8285": 1878, "6858": 1878, "7030": 1878, "3481": 1878, "0236": 1878, "fake_grad": 1878, "6862": 1878, "1282": 1878, "1031": 1878, "0464": 1878, "3276": 1878, "9967": 1878, "0054": 1878, "8972": 1878, "9174": 1878, "4995": 1878, "8546": 1878, "7194": 1878, "2918": 1878, "1846": 1878, "8793": 1878, "5183": 1878, "6447": 1878, "8009": 1878, "8468": 1878, "9832": 1878, "5272": 1878, "pt_infer": 1878, "pt_larg": 1878, "pt_small": 1878, "bitwidth": [1879, 1894, 1908], "asymmetr": [1879, 1908, 1911], "sacrific": [1881, 1886], "dirac": 1881, "glorot": 1881, "bengio": 1881, "fan": 1881, "_in": 1881, "fan_in": 1881, "delv": 1881, "surpass": 1881, "he": 1881, "_mode": 1881, "fan_out": 1881, "redrawn": 1881, "sax": 1881, "2013": 1881, "marten": 1881, "walkthrough": 1882, "clip_grad_value_": 1882, "optimizer2": 1882, "batch_per_it": 1882, "iters_to_accumul": 1882, "num_proc": 1882, "grad_param": 1882, "grad_norm": 1882, "scaled_grad_param": 1882, "inv_scal": 1882, "optimizer0": 1882, "optimizer1": 1882, "output0": 1882, "model0": 1882, "model1": 1882, "loss0": 1882, "loss1": 1882, "imped": 1882, "poor": [1882, 1883], "dp_model": 1882, "imported_funct": 1882, "mymm": 1882, "myfloat32func": 1882, "fwd_output": 1882, "cleaner": 1883, "mapsto": 1883, "educ": 1883, "_save": 1883, "_saved_self": 1883, "convex": 1883, "concav": 1883, "togglabl": 1883, "drawback": 1883, "0011": 1883, "dirti": 1883, "hogwild": 1883, "train_fn": 1883, "graphtask": 1883, "copyslic": 1883, "mutex": 1883, "gotten": 1883, "curiou": 1883, "\u2102": 1883, "yj": 1883, "holomorph": 1883, "theori": 1883, "homomorph": 1883, "mathematician": 1883, "im": 1883, "studi": [1883, 1907], "beauti": 1883, "somewhat": [1883, 1886, 1917], "counterintuit": 1883, "0906": 1883, "4835": 1883, "audio": [1883, 1922], "\u211d": 1883, "_output": 1883, "vj": 1883, "selfdeletingtempfil": 1883, "tmp_dir": 1883, "uuid": 1883, "uuid4": 1883, "temp_fil": 1883, "forbidden": 1883, "savedtensor": 1883, "_raw_saved_": 1883, "_raw_saved_self": 1883, "save_on_disk_threshold": 1883, "tensor_or_sctf": 1883, "_saved_oth": 1883, "4th": 1884, "backcompat": 1884, "broadcast_warn": 1884, "userwarn": 1884, "compute_z": 1885, "w_z": 1885, "w_y": 1885, "tbb": 1885, "aten_thread": 1885, "omp": 1885, "mkl_thread": 1885, "bla": 1885, "mkldnn_cpu_runtim": 1885, "use_mkldnn": 1885, "use_tbb": 1885, "use_openmp": 1885, "ON": [1885, 1892, 1893], "set_num_interop_thread": 1885, "get_num_interop_thread": 1885, "set_num_thread": 1885, "get_num_thread": 1885, "omp_num_thread": 1885, "mkl_num_thread": 1885, "1024": [1885, 1886], "e5": 1885, "oversubscript": 1885, "irrespect": 1886, "spread": 1886, "cuda2": [1886, 1892], "a_ful": 1886, "10240": 1886, "b_full": 1886, "ab_ful": 1886, "7277": 1886, "ab_tf32": 1886, "016": 1886, "ga100": 1886, "1747": 1886, "relative_error": 1886, "0022": 1886, "ab_fp32": 1886, "0031": 1886, "000039": 1886, "7x": 1886, "globalcontext": 1886, "setallowtf32cubla": 1886, "setallowtf32cudnn": 1886, "bench_gemm_transform": 1886, "allow_fp16_reduc": 1886, "4048": 1886, "1634": 1886, "1639": 1886, "4056": 1886, "1670": 1886, "1661": 1886, "4080": 1886, "1664": 1886, "1658": 1886, "1651": 1886, "4104": 1886, "1677": 1886, "1674": 1886, "4128": 1886, "1796": [1886, 1894], "2519": 1886, "5096": 1886, "2144": 1886, "2149": 1886, "2766": 1886, "5120": 1886, "2142": 1886, "9728": 1886, "3875": 1886, "5779": 1886, "6182": 1886, "9656": 1886, "setallowfp16reductioncubla": 1886, "instabl": 1886, "setallowbf16reductioncubla": 1886, "start_ev": 1886, "elapsed_time_m": 1886, "exploit": 1886, "paragraph": [1886, 1891], "initial_grad": 1886, "memory_alloc": [1886, 1892], "memory_snapshot": [1886, 1892], "memcheck": 1886, "pytorch_no_cuda_memory_cach": [1886, 1892], "option2": 1886, "value2": 1886, "max_split_size_mb": 1886, "borderlin": 1886, "memory_summari": 1886, "resort": [1886, 1891, 1905], "roundup_power2_divis": 1886, "cudacachingalloc": 1886, "1280": 1886, "1536": 1886, "1792": 1886, "256mb": 1886, "512mb": 1886, "1gb": 1886, "roundup_bypass_threshold_mb": 1886, "garbage_collection_threshold": 1886, "release_cached_block": 1886, "unfavor": 1886, "cuda_runtime_api": 1886, "iostream": 1886, "fpic": 1886, "my_malloc": 1886, "cout": 1886, "endl": [1886, 1893], "my_fre": 1886, "cudafre": 1886, "cudapluggablealloc": 1886, "new_alloc": 1886, "_cuda_clearcublasworkspac": 1886, "kib": 1886, "lru": 1886, "geometri": 1886, "1023": 1886, "use_pytorch_kernel_cach": 1886, "pytorch_kernel_cache_path": 1886, "store_tru": 1886, "disable_cuda": 1886, "assess": 1886, "cudagetdevicecount": 1886, "cuinit": 1886, "pytorch_nvml_based_cuda_check": 1886, "nvml": 1886, "nvmldevicegetcount_v2": 1886, "poison": 1886, "aforement": [1886, 1896], "train_load": 1886, "x_cpu": 1886, "x_gpu": 1886, "x_cpu_long": 1886, "y_cpu": 1886, "y_gpu": 1886, "y_cpu_long": 1886, "new_tensor": 1886, "overus": 1886, "cudagraphlaunch": 1886, "elid": 1886, "versatil": 1886, "static_input": 1886, "static_output": 1886, "realist": 1886, "sophist": [1886, 1904], "violat": [1886, 1889], "prohibit": [1886, 1899], "virtual": 1886, "d_in": 1886, "d_out": 1886, "640": 1886, "static_target": 1886, "static_y_pr": 1886, "static_loss": 1886, "real_target": 1886, "refil": 1886, "dag": 1886, "rejoin": 1886, "cuda_work": 1886, "nsight": 1886, "reorgan": 1886, "graphabl": 1886, "econom": 1886, "static_out_1": 1886, "g1_workload": 1886, "static_in_1": 1886, "static_out_2": 1886, "g2_workload": 1886, "static_in_2": 1886, "real_data_1": 1886, "real_data_2": 1886, "29500": [1887, 1906, 1913, 1914], "prerequisit": 1887, "grad0": 1887, "grad1": 1887, "bucket1": 1887, "bucket0": 1887, "hurt": 1887, "earliest": 1887, "unreadi": 1887, "absent": 1887, "hpp": 1887, "processgroupgloo": 1887, "processgroupmpi": 1887, "_sync_param": 1887, "autograd_hook": 1887, "prepare_for_backward": 1887, "_after_": 1887, "optimize_ddp": 1887, "mark_dirti": 1888, "mark_non_differenti": [1888, 1889], "set_materialize_grad": 1888, "linearfunct": 1888, "grad_bia": 1888, "mulconst": 1888, "mycub": [1888, 1889], "grad_dx": [1888, 1889], "my_cub": [1888, 1889], "input_featur": 1888, "output_featur": 1888, "duck": [1888, 1905], "__array_function__": 1888, "nep": 1888, "0018": 1888, "scalartensor": 1888, "handled_funct": 1888, "mandat": 1888, "update_wrapp": 1888, "ensure_tensor": 1888, "metadatatensor": 1888, "__add__": 1888, "subtensor2": 1888, "othersubtensor": 1888, "loggingtensor": 1888, "permiss": 1888, "_metadata": 1888, "ndata": 1888, "ret": [1888, 1913], "ministri": 1888, "silli": 1888, "superclass": 1888, "troublesom": 1888, "_get_overridable_funct": 1888, "overriden": 1888, "get_overridable_funct": [1888, 1928], "func_dict": 1888, "nn_func": 1888, "labori": 1888, "_get_testing_overrid": 1888, "get_testing_overrid": [1888, 1928], "override_dict": 1888, "dummy_add": 1888, "get_ignored_funct": [1888, 1928], "custom_vjp": 1889, "custom_jvp": 1889, "to_numpi": 1889, "numpysort": 1889, "ind_inv": 1889, "_1": [1889, 1905], "numpytak": 1889, "numpy_sort": 1889, "saniti": 1889, "ggx": 1889, "vmappabl": 1889, "x_bdim": 1889, "ind_bdim": 1889, "ind_inv_bdim": 1889, "expanded_x": 1889, "expanded_ind": 1889, "expanded_ind_inv": 1889, "new_dim": 1889, "logical_dim": 1889, "maybe_expand_bdim_at_front": 1889, "pseudocod": 1889, "rapidli": 1890, "abridg": 1890, "total_loss": 1890, "extrud": 1890, "phenomenon": 1890, "plenti": 1890, "bptt": 1890, "repackag": 1890, "nm": 1890, "blow": 1890, "elf": 1890, "grep": 1890, "run_model": 1890, "recoveri": 1890, "data_parallel": 1890, "pad_packed_sequ": 1890, "padded_input": 1890, "packed_input": 1890, "packed_output": 1890, "my_lstm": 1890, "dp_m": 1890, "padding_input": 1890, "ur": 1891, "rewritten": 1891, "j_f": 1891, "calculu": 1891, "cw": 1891, "bigger": 1891, "articl": 1891, "58eb23378f2a376565a66ac32c93a316c45b6131": 1891, "l99": 1891, "l105": 1891, "ds_dx": 1891, "compute_gradi": 1891, "ds_dy": 1891, "conj_w_d": 1891, "w_d": 1891, "d_idx": 1891, "albeit": 1891, "wonder": 1891, "amd": 1892, "dialect": 1892, "portabl": 1892, "rocmdoc": 1892, "programming_guid": 1892, "hip_api_guid": 1892, "cuda_vers": 1892, "cudaruntimegetvers": 1892, "cudadrivergetvers": 1892, "hip_vers": 1892, "hipruntimegetvers": 1892, "hipdrivergetvers": 1892, "11000": 1892, "use_rocm": 1892, "rocm_vers": 1892, "40300": 1892, "cmake": [1892, 1900], "drocm_force_enable_gpu_assert": 1892, "addglobalcallback": 1893, "recordfunct": 1893, "ivalu": 1893, "threadlocaldebuginfo": 1893, "debuginfoguard": 1893, "recordfunctioncallback": 1893, "onfunctionent": 1893, "onfunctionexit": 1893, "needsinput": 1893, "samplingprob": 1893, "enablerecordfunct": 1893, "cerr": 1893, "broader": [1893, 1925], "inject": 1893, "setapiusagehandl": 1893, "setapiusagelogg": 1893, "event_nam": 1893, "c10_log_api_usage_onc": 1893, "my_api": 1893, "_log_api_usage_onc": 1893, "archiv": 1893, "bundl": 1893, "akin": 1893, "jpeg": 1893, "camera": [1893, 1922], "setexportmoduleextrafileshook": 1893, "extrafilesmap": 1893, "producer_info": 1893, "getenv": 1893, "getsourc": 1893, "precompil": 1893, "pyc": 1893, "loos": 1893, "elabor": 1894, "tpu": 1894, "mylinear": 1894, "sample_input": 1894, "0413": 1894, "2057": 1894, "0597": 1894, "8247": 1894, "1045": 1894, "4299": 1894, "5457": 1894, "4793": 1894, "3634": 1894, "8525": 1894, "6749": 1894, "l0": [1894, 1899], "bignet": 1894, "big_net": 1894, "dynamicnet": 1894, "dynamic_net": 1894, "2051": 1894, "7601": 1894, "1963": 1894, "4354": 1894, "6598": 1894, "4446": 1894, "4628": 1894, "8774": 1894, "6848": 1894, "5458": 1894, "4647": 1894, "5310": 1894, "0609": 1894, "0940": 1894, "1266": 1894, "0623": 1894, "3508": 1894, "0550": 1894, "5317": 1894, "5562": 1894, "4028": 1894, "6942": 1894, "0140": 1894, "0329": 1894, "1160": 1894, "0434": 1894, "3889": 1894, "1613": 1894, "6340": 1894, "3887": 1894, "9979": 1894, "0767": 1894, "3526": 1894, "8756": 1894, "5847": 1894, "6016": 1894, "1608": 1894, "0829": 1894, "6338": 1894, "9239": 1894, "6943": 1894, "5034": 1894, "0268": 1894, "4489": 1894, "9403": 1894, "2509": 1894, "5052": 1894, "3088": 1894, "4951": 1894, "3381": 1894, "5166": 1894, "boilerpl": [1894, 1905], "beginn": 1894, "examples_nn": 1894, "polynomial_modul": 1894, "teach": 1894, "0013": [1894, 1918], "0030": 1894, "0008": 1894, "modalmodul": 1894, "6614": 1894, "2669": 1894, "0617": 1894, "4519": 1894, "two_layer_net_optim": 1894, "blitz": 1894, "neural_networks_tutori": 1894, "autograd_tutori": 1894, "new_net": 1894, "runningmean": 1894, "1041": 1894, "0647": 1894, "1515": 1894, "m_load": 1894, "unserialized_th": 1894, "statefulmodul": 1894, "param3": 1894, "param_list": 1894, "parameterlist": 1894, "param_dict": 1894, "parameterdict": 1894, "buffer1": 1894, "buffer2": 1894, "buffer3": 1894, "0322": 1894, "9066": 1894, "1409": 1894, "4852": 1894, "6949": 1894, "2911": 1894, "1044": 1894, "4202": 1894, "1953": 1894, "5299": 1894, "8747": 1894, "6289": 1894, "4898": 1894, "6434": 1894, "5187": 1894, "0346": 1894, "4077": 1894, "4324": 1894, "7022": 1894, "3915": 1894, "6176": 1894, "6062": 1894, "5992": 1894, "4452": 1894, "2843": 1894, "3710": 1894, "3947": 1894, "saving_loading_model": 1894, "what_is_state_dict": 1894, "skip_init": 1894, "skip_param_init": 1894, "new_grad_input": 1894, "5059": 1894, "8158": 1894, "2390": 1894, "0043": 1894, "addmmbackward": 1894, "forward_pre_hook_handl": 1894, "5752": 1894, "7421": 1894, "forward_hook_handl": 1894, "0980": 1894, "4666": 1894, "0256": 1894, "4497": 1894, "5046": 1894, "combat": 1894, "shader": 1895, "mps_devic": 1895, "yourfavoritenet": 1895, "a3c": 1896, "set_start_method": 1896, "simplequeu": 1896, "cope": 1896, "eleg": 1896, "num_process": 1896, "modern": 1897, "754": 1897, "1e20": 1897, "4142e": 1897, "struggl": 1897, "benign": 1897, "v_dot2": 1897, "mfma": 1897, "fp64": 1897, "rocbla": 1897, "miopen": 1897, "rocblas_internal_fp16_alt_impl": 1897, "miopen_debug_convolution_attrib_fp16_alt_impl": 1897, "_convbackend": 1897, "slownd": 1897, "slownd_transpos": 1897, "slownd_dil": 1897, "slownd_dilated_transpos": 1897, "convbackend": 1897, "miopendepthwis": 1897, "miopentranspos": 1897, "svd_lowrank": [1898, 1917], "22modul": 1898, "20determin": 1898, "index_add_cuda_": 1898, "1509": 1898, "8027": 1898, "0333": 1898, "1444": 1898, "rese": 1898, "seed_work": 1898, "worker_se": 1898, "train_dataset": 1898, "tensor_dict": 1899, "loaded_numb": 1899, "loaded_even": 1899, "scene": [1899, 1922], "loaded_smal": 1899, "num_batches_track": 1899, "bn_state_dict": 1899, "new_bn": 1899, "out0_relu": 1899, "1400": 1899, "4563": 1899, "0271": 1899, "4406": 1899, "2827": 1899, "4588": 1899, "2031": 1899, "0300": 1899, "1316": 1899, "6533": 1899, "3413": 1899, "1112": 1899, "m_state_dict": 1899, "new_m": 1899, "original_nam": 1899, "controlflowmodul": 1899, "controlflowmodule_trac": 1899, "3793": 1899, "controlflowmodule_script": 1899, "rem": 1900, "7z": 1900, "curl": 1900, "ossci": 1900, "mkl_2020": 1900, "aoa": 1900, "omkl": 1900, "cuda_prefix": 1900, "cuda102": 1900, "magma_2": 1900, "4_": 1900, "omagma": 1900, "cmake_include_path": 1900, "magma_hom": 1900, "studio": 1900, "pip": [1900, 1901, 1922], "cmake_gener": 1900, "ffi": 1900, "create_extens": 1900, "_ext": 1900, "define_macro": 1900, "relative_to": 1900, "c99": 1900, "x86_x64": 1900, "packagesnotfounderror": 1900, "anaconda": 1900, "noarch": 1900, "continuum": 1900, "pkg": 1900, "pro": [1900, 1922], "msys2": 1900, "importerror": [1900, 1905], "dll": 1900, "vc2017": 1900, "redistribut": 1900, "vc": 1900, "vs2017_runtim": 1900, "mkl_fft": 1900, "intel_openmp": 1900, "vs2017": 1900, "openbla": 1900, "forg": 1900, "bootstrap": 1900, "forgotten": 1900, "idiom": 1900, "freeze_support": 1900, "forkingpickl": 1900, "brokenpipeerror": 1900, "errno": 1900, "couldn": [1900, 1901], "torch_14808_1591070686": 1900, "thalloc": 1900, "tdr": 1900, "thcudacheck": 1900, "storageshar": 1900, "dummy_input": 1901, "input_nam": 1901, "actual_input_1": 1901, "learned_": 1901, "output_nam": 1901, "learned_0": 1901, "learned_1": 1901, "learned_2": 1901, "learned_3": 1901, "learned_14": 1901, "learned_15": 1901, "kernel_shap": 1901, "9216": 1901, "transb": 1901, "check_model": 1901, "printable_graph": 1901, "onnxruntim": 1901, "ort": 1901, "ort_sess": 1901, "inferencesess": 1901, "astyp": 1901, "seq_length": 1901, "real_seq_length": 1901, "experienc": 1901, "new_data": 1901, "symbolic_opset": 1901, "symbolic_opset9": 1901, "_variablefunct": 1901, "pyi": 1901, "___torch_mangle_0": 1901, "alpha_f": 1901, "myrelu": 1901, "value_t": 1901, "pythonop": [1901, 1903], "mylogexp": 1901, "operator_export_typ": 1901, "onnx_fallthrough": 1901, "onnx_aten_fallback": 1901, "onnxscript": 1901, "onnx_opset": 1901, "opset15": 1901, "custom_opset": 1901, "67326": 1901, "alphax": 1901, "castlik": 1901, "gammax": 1901, "settyp": 1901, "custom_selu": 1901, "jit_util": 1901, "graphcontext": 1901, "onnxscript_op": 1901, "register_custom_op_symbol": 1901, "symbolic_nam": 1901, "symbolic_fn": 1901, "symbolic_help": 1901, "symbolic_foo_forward": 1901, "custom_domain": 1901, "attr1_f": 1901, "attr2_i": 1901, "foo_forward": 1901, "foomodel": 1901, "example_input1": 1901, "caffe2": [1901, 1922], "torch_script_graph": 1901, "unconvertible_op": 1901, "dynamic_ax": 1901, "export_param": 1901, "trainingmod": 1901, "operatorexporttyp": 1901, "do_constant_fold": 1901, "keep_initializers_as_input": 1901, "export_modules_as_funct": 1901, "OF": 1901, "WITH": 1901, "input_i": 1901, "input_z": 1901, "fileno": 1901, "untrain": 1901, "doc_str": 1901, "onnx_aten": 1901, "build_caffe2": 1901, "summodul": 1901, "dim_valu": 1901, "my_custom_axis_nam": 1901, "dim_param": 1901, "sum_dynamic_axes_1": 1901, "predefin": 1901, "checkererror": 1901, "unsupportedoperatorerror": 1901, "export_to_pretty_str": 1901, "export_typ": 1901, "google_print": 1901, "add_node_nam": 1901, "nodeproto": 1901, "debugstr": 1901, "contrib": 1901, "test_aten_embedding_2": 1901, "test_oper": 1901, "unregister_custom_op_symbol": 1901, "select_model_mode_for_export": 1901, "is_in_onnx_export": 1901, "middl": 1901, "enable_log": 1901, "disable_log": 1901, "graphinfo": 1901, "incorrect_relu_symbolic_funct": 1901, "2328854203224182": 1901, "699536174352349": 1901, "rapid": 1901, "exportopt": 1901, "my_nn_modul": 1901, "my_nn_module_attribut": 1901, "underdevelop": 1902, "parsabl": 1902, "sarif": 1902, "diagsys0001": 1902, "fxe0001": 1902, "fxe0002": 1902, "fxe0003": 1902, "fxe0004": 1902, "fxe0005": 1902, "fxe0006": 1902, "atenlib": 1902, "fxe0007": 1902, "fxe0008": 1902, "fxe0009": 1902, "fxe0010": 1902, "fxe0011": 1902, "fxe0012": 1902, "poe0001": 1902, "poe0002": 1902, "poe0003": 1902, "poe0004": 1902, "_intern": [1902, 1919], "exportdiagnost": 1902, "frames_to_skip": 1902, "cpp_stack": 1902, "record_cpp_call_stack": 1902, "constantchunk": 1903, "__and_": 1903, "__contains_": 1903, "__derive_index": 1903, "__getitem_": 1903, "__interpol": 1903, "__is_": 1903, "__isnot_": 1903, "__lshift_": 1903, "__not_": 1903, "__or_": 1903, "__range_length": 1903, "__rshift_": 1903, "__xor_": 1903, "_cast_byt": 1903, "_cast_char": 1903, "_cast_doubl": 1903, "_cast_float": 1903, "_cast_half": 1903, "_cast_int": 1903, "_cast_long": 1903, "_cast_short": 1903, "_conj": 1903, "_convolution_mod": 1903, "_dim_arang": 1903, "_pack_padded_sequ": 1903, "_pad_packed_sequ": 1903, "_reshape_from_tensor": 1903, "_sample_dirichlet": 1903, "_set_item": 1903, "_shape_as_tensor": 1903, "_standard_gamma": 1903, "_uniqu": 1903, "_unique2": 1903, "_weight_norm": 1903, "conv1d_relu": 1903, "conv2d_relu": 1903, "embedding_renorm": 1903, "floordiv": [1903, 1910], "nonzero_numpi": 1903, "numpy_t": 1903, "unchecked_cast": 1903, "unique_dim": 1903, "_quantiz": 1903, "conv2d_prepack": 1903, "conv3d_prepack": 1903, "conv3d_relu": 1903, "conv_transpose1d_prepack": 1903, "conv_transpose2d_prepack": 1903, "conv_transpose3d_prepack": 1903, "linear_dynam": 1903, "linear_prepack": 1903, "linear_prepack_fp16": 1903, "linear_prepack_fp16_legaci": 1903, "linear_prepack_legaci": 1903, "_test": 1903, "get_first": 1903, "compleximplicit": 1903, "floatimplicit": 1903, "intimplicit": 1903, "__iand_": 1903, "__ilshift_": 1903, "__ior_": 1903, "__irshift_": 1903, "__ixor_": 1903, "__round_to_zero_floordiv": 1903, "__upsampl": 1903, "__upsample_bilinear": 1903, "__upsample_nearest": 1903, "_adaptive_avg_pool3d": 1903, "_add_batch_dim": 1903, "_add_relu": 1903, "_addmm_activ": 1903, "_aminmax": 1903, "_amp_foreach_non_finite_check_and_unscal": 1903, "_amp_update_scal": 1903, "_assert_async": 1903, "_assert_tensor_metadata": 1903, "_autocast_to_full_precis": 1903, "_autocast_to_reduced_precis": 1903, "_batch_norm_impl_index": 1903, "_cdist_forward": 1903, "_cholesky_solve_help": 1903, "_choose_qparams_per_tensor": 1903, "_chunk_grad_outputs_efficient_attent": 1903, "_coalesc": 1903, "_compute_linear_combin": 1903, "_conj_copi": 1903, "_conj_phys": 1903, "_conv_depthwise2d": 1903, "_convert_indices_from_coo_to_csr": 1903, "_convert_indices_from_csr_to_coo": 1903, "_copy_from": 1903, "_copy_from_and_res": 1903, "_ctc_loss": 1903, "_cudnn_ctc_loss": 1903, "_cudnn_init_dropout_st": 1903, "_cudnn_rnn": 1903, "_cudnn_rnn_flatten_weight": 1903, "_cufft_clear_plan_cach": 1903, "_cufft_get_plan_cache_max_s": 1903, "_cufft_get_plan_cache_s": 1903, "_cufft_set_plan_cache_max_s": 1903, "_cummax_help": 1903, "_cummin_help": 1903, "_debug_has_internal_overlap": 1903, "_dimi": 1903, "_dimv": 1903, "_dirichlet_grad": 1903, "_efficient_attention_forward": 1903, "_efficientzerotensor": 1903, "_embedding_bag": 1903, "_embedding_bag_forward_onli": 1903, "_empty_affine_quant": 1903, "_empty_per_channel_affine_quant": 1903, "_euclidean_dist": 1903, "_fake_quantize_learnable_per_channel_affin": 1903, "_fake_quantize_learnable_per_tensor_affin": 1903, "_fake_quantize_per_tensor_affine_cachemask_tensor_qparam": 1903, "_fft_c2c": 1903, "_fft_c2r": 1903, "_fft_r2c": 1903, "_flash_attention_forward": 1903, "_foreach_ab": 1903, "_foreach_aco": 1903, "_foreach_add": 1903, "_foreach_addcdiv": 1903, "_foreach_addcmul": 1903, "_foreach_asin": 1903, "_foreach_atan": 1903, "_foreach_ceil": 1903, "_foreach_clamp_max": 1903, "_foreach_clamp_min": 1903, "_foreach_co": 1903, "_foreach_cosh": 1903, "_foreach_div": 1903, "_foreach_erf": 1903, "_foreach_erfc": 1903, "_foreach_exp": 1903, "_foreach_expm1": 1903, "_foreach_floor": 1903, "_foreach_frac": 1903, "_foreach_lerp": 1903, "_foreach_lgamma": 1903, "_foreach_log": 1903, "_foreach_log10": 1903, "_foreach_log1p": 1903, "_foreach_log2": 1903, "_foreach_maximum": 1903, "_foreach_minimum": 1903, "_foreach_mul": 1903, "_foreach_neg": 1903, "_foreach_norm": 1903, "_foreach_pow": 1903, "_foreach_reciproc": 1903, "_foreach_round": 1903, "_foreach_sigmoid": 1903, "_foreach_sin": 1903, "_foreach_sinh": 1903, "_foreach_sqrt": 1903, "_foreach_sub": 1903, "_foreach_tan": 1903, "_foreach_tanh": 1903, "_foreach_trunc": 1903, "_foreach_zero": 1903, "_fused_adam": 1903, "_fused_adamw": 1903, "_fused_dropout": 1903, "_fused_moving_avg_obs_fq_help": 1903, "_fused_moving_avg_obs_fq_helper_funct": 1903, "_fused_sdp_choic": 1903, "_fw_primal": 1903, "_fw_primal_copi": 1903, "_get_cpu_cap": 1903, "_get_tracing_st": 1903, "_grad_sum_to_s": 1903, "_has_compatible_shallow_copy_typ": 1903, "_has_same_storage_numel": 1903, "_histogramdd_bin_edg": 1903, "_histogramdd_from_bin_ct": 1903, "_histogramdd_from_bin_tensor": 1903, "_index_put_impl": 1903, "_indices_copi": 1903, "_infer_s": 1903, "_int_mm": 1903, "_is_all_tru": 1903, "_is_any_tru": 1903, "_is_zerotensor": 1903, "_linalg_check_error": 1903, "_linalg_det": 1903, "_linalg_eigh": 1903, "_linalg_slogdet": 1903, "_linalg_solve_ex": 1903, "_linalg_svd": 1903, "_list_to_tensor": 1903, "_local_scalar_dens": 1903, "_logcumsumexp": 1903, "_lstm_mp": 1903, "_make_du": 1903, "_make_dual_copi": 1903, "_make_per_channel_quantized_tensor": 1903, "_make_per_tensor_quantized_tensor": 1903, "_masked_scal": 1903, "_masked_softmax": 1903, "_mkldnn_reshap": 1903, "_mkldnn_transpos": 1903, "_mps_convolut": 1903, "_mps_convolution_transpos": 1903, "_native_batch_norm_legit_funct": 1903, "_native_batch_norm_legit_no_train": 1903, "_native_multi_head_attent": 1903, "_ncf_unsqueez": 1903, "_ncf_view": 1903, "_neg_view": 1903, "_neg_view_copi": 1903, "_nested_from_pad": 1903, "_nested_from_padded_and_nested_exampl": 1903, "_nested_tensor_from_mask": 1903, "_nested_tensor_from_mask_left_align": 1903, "_nested_tensor_from_tensor_list": 1903, "_nested_tensor_s": 1903, "_nested_tensor_softmax_with_shap": 1903, "_nested_tensor_storage_offset": 1903, "_nested_tensor_strid": 1903, "_nested_view_from_buff": 1903, "_nested_view_from_buffer_copi": 1903, "_new_zeros_with_same_feature_meta": 1903, "_nnpack_avail": 1903, "_nnpack_spatial_convolut": 1903, "_no_grad_embedding_renorm": 1903, "_no_grad_fil": 1903, "_no_grad_norm": 1903, "_no_grad_uniform": 1903, "_no_grad_zero": 1903, "_pack_sequ": 1903, "_pad_circular": 1903, "_pad_enum": 1903, "_pdist_forward": 1903, "_pin_memori": 1903, "_prelu_kernel": 1903, "_propagate_xla_data": 1903, "_remove_batch_dim": 1903, "_reshape_alia": 1903, "_reshape_alias_copi": 1903, "_reshape_copi": 1903, "_resize_output": 1903, "_rowwise_prun": 1903, "_saturate_weight_to_fp16": 1903, "_scaled_dot_product_attent": 1903, "_scaled_dot_product_attention_math": 1903, "_scaled_dot_product_efficient_attent": 1903, "_scaled_dot_product_flash_attent": 1903, "_size_if_not_equ": 1903, "_slow_conv2d_forward": 1903, "_sobol_engine_draw": 1903, "_sobol_engine_ff": 1903, "_sobol_engine_initialize_st": 1903, "_sobol_engine_scrambl": 1903, "_sparse_addmm": 1903, "_sparse_broadcast_to": 1903, "_sparse_broadcast_to_copi": 1903, "_sparse_bsc_tensor_unsaf": 1903, "_sparse_bsr_tensor_unsaf": 1903, "_sparse_compressed_tensor_unsaf": 1903, "_sparse_coo_tensor_unsaf": 1903, "_sparse_coo_tensor_with_dim": 1903, "_sparse_coo_tensor_with_dims_and_tensor": 1903, "_sparse_csc_tensor_unsaf": 1903, "_sparse_csr_prod": 1903, "_sparse_csr_sum": 1903, "_sparse_csr_tensor_unsaf": 1903, "_sparse_log_softmax": 1903, "_sparse_mm": 1903, "_sparse_mm_reduce_impl": 1903, "_sparse_softmax": 1903, "_sparse_sparse_matmul": 1903, "_sparse_sum": 1903, "_spdiag": 1903, "_standard_gamma_grad": 1903, "_structured_sparse_linear": 1903, "_tensor_to_list": 1903, "_test_ambiguous_default": 1903, "_test_autograd_multiple_dispatch": 1903, "_test_autograd_multiple_dispatch_view": 1903, "_test_autograd_multiple_dispatch_view_copi": 1903, "_test_check_tensor": 1903, "_test_functorch_fallback": 1903, "_test_optional_filled_intlist": 1903, "_test_optional_floatlist": 1903, "_test_optional_intlist": 1903, "_test_serialization_subcmul": 1903, "_test_string_default": 1903, "_test_warn_in_autograd": 1903, "_thnn_fused_gru_cel": 1903, "_thnn_fused_lstm_cel": 1903, "_to_cpu": 1903, "_to_dens": 1903, "_transform_bias_rescale_qkv": 1903, "_transformer_encoder_layer_fwd": 1903, "_trilinear": 1903, "_triton_multi_head_attent": 1903, "_triton_scaled_dot_attent": 1903, "_unpack_du": 1903, "_unsafe_index": 1903, "_unsafe_index_put": 1903, "_unsafe_view": 1903, "_unwrap_opt": 1903, "_upsample_bicubic2d_aa": 1903, "_upsample_bilinear2d_aa": 1903, "_upsample_nearest_exact1d": 1903, "_upsample_nearest_exact2d": 1903, "_upsample_nearest_exact3d": 1903, "_use_cudnn_ctc_loss": 1903, "_use_cudnn_rnn_flatten_weight": 1903, "_validate_compressed_sparse_indic": 1903, "_validate_sparse_bsc_tensor_arg": 1903, "_validate_sparse_bsr_tensor_arg": 1903, "_validate_sparse_compressed_tensor_arg": 1903, "_validate_sparse_coo_tensor_arg": 1903, "_validate_sparse_csc_tensor_arg": 1903, "_validate_sparse_csr_tensor_arg": 1903, "_values_copi": 1903, "_weight_norm_interfac": 1903, "capit": 1903, "confirmed_by_own": [1903, 1913], "convolution_overrid": 1903, "copy_sparse_to_spars": 1903, "endswith": 1903, "expandtab": 1903, "fake_quantize_per_channel_affine_cachemask": 1903, "fake_quantize_per_tensor_affine_cachemask": 1903, "fill_diagon": 1903, "glu_jvp": 1903, "has_torch_funct": [1903, 1928], "is_non_overlapping_and_dens": 1903, "is_own": 1903, "is_strides_like_format": 1903, "isalnum": 1903, "isalpha": 1903, "isdecim": 1903, "isdigit": 1903, "isidentifi": 1903, "islow": 1903, "isnumer": 1903, "isprint": 1903, "isspac": 1903, "istitl": 1903, "isupp": 1903, "lift_fresh": 1903, "lift_fresh_copi": 1903, "ljust": 1903, "local_valu": [1903, 1906], "log_sigmoid_forward": 1903, "lstrip": 1903, "matrix_h": 1903, "nll_loss2d_forward": 1903, "nll_loss_forward": 1903, "normal_funct": 1903, "owner_nam": 1903, "percentformat": 1903, "quantized_gru": 1903, "quantized_lstm": 1903, "resize_as_spars": 1903, "rfind": 1903, "rindex": 1903, "rjust": 1903, "rpartit": 1903, "rsplit": 1903, "rstrip": 1903, "set_data": 1903, "slow_conv3d_forward": 1903, "sparse_res": 1903, "sparse_resize_and_clear": 1903, "splitlin": 1903, "startswith": 1903, "swapcas": 1903, "sym_numel": 1903, "sym_siz": 1903, "sym_storage_offset": 1903, "sym_strid": 1903, "unique_dim_consecut": 1903, "zfill": 1903, "_allgather_bas": 1903, "_reduce_scatter_bas": 1903, "allgath": 1903, "allgather_coalesc": 1903, "allgather_into_tensor_coalesc": 1903, "allreduce_coalesc": 1903, "alltoal": 1903, "alltoall_bas": 1903, "recv_any_sourc": 1903, "debugprim": 1903, "load_tensor": 1903, "_mkl_linear": 1903, "_mkl_reorder_linear_weight": 1903, "_convolution_pointwis": 1903, "_convolution_transpose_pointwis": 1903, "_is_mkldnn_bf16_support": 1903, "_linear_pointwis": 1903, "_reorder_convolution_transpose_weight": 1903, "_reorder_linear_weight": 1903, "mkldnn_prepack": 1903, "conv2d_run": 1903, "nvprim": 1903, "conv2d_clamp_prepack": 1903, "conv2d_clamp_run": 1903, "conv2d_transpose_clamp_prepack": 1903, "conv2d_transpose_clamp_run": 1903, "linear_clamp_prepack": 1903, "linear_clamp_run": 1903, "unpack_prepacked_sizes_conv2d": 1903, "unpack_prepacked_sizes_linear": 1903, "addstatvalu": 1903, "autogradadd": 1903, "autogradallnonzero": 1903, "autogradallzero": 1903, "autogradanynonzero": 1903, "autogradzero": 1903, "bailouttempl": 1903, "broadcastmkldnntensor": 1903, "broadcasts": 1903, "chunksiz": 1903, "constantmkldnntensor": 1903, "differentiablegraph": 1903, "enumnam": 1903, "enumvalu": 1903, "fallbackgraph": 1903, "fusedconcat": 1903, "fusiongroup": 1903, "ifthenels": 1903, "ignoredpythonop": 1903, "mkldnnclamp": 1903, "mkldnnhardsigmoid": 1903, "mkldnnhardswish": 1903, "mkldnnhardtanh": 1903, "mkldnnlayernorm": 1903, "mkldnnscalarmul": 1903, "mmbatchsid": 1903, "mmtreereduc": 1903, "modulecontainerindex": 1903, "numtotensor": 1903, "raiseexcept": 1903, "reductions": 1903, "requiresgradcheck": 1903, "staticruntimecopyout": 1903, "staticsubgraph": 1903, "stringindex": 1903, "tensorexprdynamicgroup": 1903, "tensorexprdynamicguard": 1903, "tensorexprgroup": 1903, "timepoint": 1903, "tupleindex": 1903, "tupleunpack": 1903, "varconcat": 1903, "varstack": 1903, "awaitable_nowait": 1903, "awaitable_wait": 1903, "is_cpu": 1903, "is_ipu": 1903, "is_mkldnn": 1903, "is_mp": 1903, "is_nest": 1903, "is_ort": 1903, "is_quant": 1903, "is_vulkan": 1903, "is_xpu": 1903, "onednnfusiongroup": 1903, "onednnfusionguard": 1903, "profile_ivalu": 1903, "rangelist": 1903, "rpc_remot": 1903, "unchecked_unwrap_opt": 1903, "_call_end_callbacks_on_jit_fut": 1903, "_record_function_ent": 1903, "_record_function_enter_new": 1903, "_record_function_exit": 1903, "_bfloat16quantizedtofloat": 1903, "_floattobfloat16quant": 1903, "add_out": 1903, "add_relu_out": 1903, "add_scalar_out": 1903, "add_scalar_relu": 1903, "add_scalar_relu_out": 1903, "batch_norm1d": 1903, "batch_norm1d_relu": 1903, "batch_norm2d": 1903, "batch_norm2d_relu": 1903, "batch_norm3d": 1903, "batch_norm3d_relu": 1903, "batch_norm_relu": 1903, "cat_out": 1903, "cat_relu": 1903, "cat_relu_out": 1903, "conv1d_dynam": 1903, "conv1d_prepack": 1903, "conv1d_unpack": 1903, "conv2d_add": 1903, "conv2d_add_relu": 1903, "conv2d_dil": 1903, "conv2d_dynam": 1903, "conv2d_group": 1903, "conv2d_output_pad": 1903, "conv2d_pad": 1903, "conv2d_strid": 1903, "conv2d_transpos": 1903, "conv2d_unpack": 1903, "conv2d_unpack_s": 1903, "conv3d_dil": 1903, "conv3d_dynam": 1903, "conv3d_group": 1903, "conv3d_output_pad": 1903, "conv3d_pad": 1903, "conv3d_strid": 1903, "conv3d_transpos": 1903, "conv3d_unpack": 1903, "conv_prepack": 1903, "conv_transpose1d_dynam": 1903, "conv_transpose1d_unpack": 1903, "conv_transpose2d_dil": 1903, "conv_transpose2d_dynam": 1903, "conv_transpose2d_group": 1903, "conv_transpose2d_output_pad": 1903, "conv_transpose2d_pad": 1903, "conv_transpose2d_strid": 1903, "conv_transpose2d_transpos": 1903, "conv_transpose2d_unpack": 1903, "conv_transpose3d_dil": 1903, "conv_transpose3d_dynam": 1903, "conv_transpose3d_group": 1903, "conv_transpose3d_output_pad": 1903, "conv_transpose3d_pad": 1903, "conv_transpose3d_strid": 1903, "conv_transpose3d_transpos": 1903, "conv_transpose3d_unpack": 1903, "conv_unpack": 1903, "embedding_4bit": 1903, "embedding_bag_2bit_prepack": 1903, "embedding_bag_2bit_rowwise_offset": 1903, "embedding_bag_2bit_unpack": 1903, "embedding_bag_4bit": 1903, "embedding_bag_4bit_prepack": 1903, "embedding_bag_4bit_rowwise_offset": 1903, "embedding_bag_4bit_unpack": 1903, "embedding_bag_byt": 1903, "embedding_bag_byte_prepack": 1903, "embedding_bag_byte_rowwise_offset": 1903, "embedding_bag_byte_unpack": 1903, "embedding_bag_prepack": 1903, "embedding_bag_unpack": 1903, "embedding_byt": 1903, "linear_dynamic_fp16": 1903, "linear_leaky_relu": 1903, "linear_relu": [1903, 1910], "linear_relu_dynam": 1903, "linear_relu_dynamic_fp16": 1903, "linear_tanh": 1903, "linear_unpack": 1903, "linear_unpack_fp16": 1903, "linear_with_input_q_dq_qweight_dq_output_fp32": 1903, "linear_with_input_q_dq_qweight_dq_relu_output_fp32": 1903, "make_quantized_cell_param": 1903, "make_quantized_cell_params_dynam": 1903, "make_quantized_cell_params_fp16": 1903, "mul_out": 1903, "mul_relu": 1903, "mul_relu_out": 1903, "mul_scalar_out": 1903, "mul_scalar_relu": 1903, "mul_scalar_relu_out": 1903, "quantized_gru_cell_dynam": 1903, "quantized_lstm_cell_dynam": 1903, "quantized_rnn_relu_cell_dynam": 1903, "quantized_rnn_tanh_cell_dynam": 1903, "rngprim": 1903, "philox_rand": 1903, "qlinear": 1903, "qlinear_dynam": 1903, "qlinear_prepack": 1903, "qlinear_relu": 1903, "qlinear_relu_dynam": 1903, "qlinear_unpack": 1903, "static_runtim": 1903, "vartupleunpack": 1903, "clamp_nan_to_num": 1903, "create_owned_ref": 1903, "dequantize_copi": 1903, "dict_unpack": 1903, "expand_dims_copi": 1903, "flatten_copi": 1903, "fused_equally_split": 1903, "reshape_copi": 1903, "select_tensor": 1903, "signed_log1p": 1903, "to_copi": 1903, "to_maybe_copy_out": 1903, "var1": 1904, "var2": 1904, "lbfg": 1904, "adadelta": 1904, "adamax": 1904, "asgd": 1904, "nadam": 1904, "radam": 1904, "rmsprop": 1904, "rprop": 1904, "reducelronplateau": 1904, "multisteplr": 1904, "upgrad": [1904, 1924], "swa_util": 1904, "averagedmodel": 1904, "swalr": 1904, "update_bn": 1904, "optima": 1904, "polyak": 1904, "averaged_model": 1904, "multi_avg_fn": 1904, "get_ema_multi_avg_fn": 1904, "textrm": 1904, "update_paramet": 1904, "avg_fn": 1904, "_foreach": 1904, "ema_model": 1904, "ema_avg": 1904, "averaged_model_paramet": 1904, "model_paramet": 1904, "num_averag": 1904, "swa_schedul": 1904, "anneal_epoch": 1904, "swa_lr": 1904, "swa_model": 1904, "cosineannealinglr": 1904, "swa_start": 1904, "test_input": 1904, "secur": 1905, "unpackag": 1905, "exercis": 1905, "unzip": 1905, "my_packag": 1905, "freeli": 1905, "94304870911616": 1905, "94304900784016": 1905, "extern_modul": 1905, "model_1": 1905, "pkl": 1905, "myzip": 1905, "file_byt": 1905, "writestr": 1905, "new_file_byt": 1905, "vim": 1905, "vimrc": 1905, "bufreadcmd": 1905, "brows": 1905, "amatch": 1905, "vi": 1905, "packageimport": 1905, "queryabl": 1905, "glob": 1905, "packageexport": 1905, "pe": 1905, "save_pickl": 1905, "has_fil": 1905, "importer_file_structur": 1905, "package_a": 1905, "get_rdep": 1905, "all_path": 1905, "dependency_graph_str": 1905, "save_text": 1905, "save_binari": 1905, "my_resourc": 1905, "config_stuff": 1905, "raw_data": 1905, "my_byt": 1905, "complementari": [1905, 1918], "load_pickl": 1905, "load_text": 1905, "load_binari": 1905, "my_tensor": 1905, "__reduce_package__": 1905, "my_str": 1905, "time_import": 1905, "time_export": 1905, "pickler": 1905, "persistent_id": 1905, "persistent_load": 1905, "generated_module_nam": 1905, "get_unique_id": 1905, "clock_gettim": 1905, "unpackage_foo": 1905, "depickl": 1905, "foo_1": 1905, "foo_2": 1905, "foo_packag": 1905, "foo_collect": 1905, "foo1": 1905, "foo2": 1905, "imported_foo": 1905, "9857706": 1905, "650140837": 1905, "652698385": 1905, "__torch_package__": 1905, "is_in_packag": 1905, "userexcept": 1905, "unpackageableexcept": 1905, "loaded_modul": 1905, "import_modul": 1905, "save_source_str": 1905, "save_modul": 1905, "textwrap": 1905, "dedent": 1905, "my_funct": 1905, "is_packag": 1905, "importlib": 1905, "my_pickl": 1905, "get_my_resourc": 1905, "read_text": 1905, "torch_package_import": 1905, "get_my_pickl": 1905, "is_from_packag": 1905, "stdlib": 1905, "my_test": 1905, "f2": [1905, 1906], "sys_import": 1905, "script_model": 1905, "mixed_model": 1905, "python_model_with_scripted_submodul": 1905, "loaded_script": 1905, "loaded_mix": 1905, "convention": 1905, "94286146172688": 1905, "94286146172784": 1905, "essai": 1905, "another_packag": 1905, "pickletool": 1905, "ast": 1905, "deni": 1905, "my_export": 1905, "my_interned_modul": 1905, "package_export": 1905, "my_externed_modul": 1905, "my_mocked_modul": 1905, "unwant": [1905, 1922], "hodg": 1905, "podg": 1905, "bazel": 1905, "buck": 1905, "my_class_inst": 1905, "imported_myclass": 1905, "okai": 1905, "torch_package_0": 1905, "handle_me_this_wai": 1905, "inadvert": 1905, "pun": 1905, "packagingerror": 1905, "dependency_graph": 1905, "emptymatcherror": 1905, "allow_empti": 1905, "_sysimport": 1905, "hermet": 1905, "scan": 1905, "orderedimport": 1905, "add_depend": 1905, "graphviz": 1905, "lang": 1905, "denied_modul": 1905, "my_subpackag": 1905, "digraph": 1905, "externed_modul": 1905, "interned_modul": 1905, "mocked_modul": 1905, "register_extern_hook": 1905, "register_intern_hook": 1905, "register_mock_hook": 1905, "myobject": 1905, "save_source_fil": 1905, "file_or_directori": 1905, "my_subsubpackag": 1905, "file_or_buff": 1905, "module_allow": 1905, "pytorchfileread": 1905, "python_vers": 1905, "is_dir": 1905, "gpipe": 1906, "suffer": 1906, "microbatch": 1906, "bubbl": 1906, "except_last": 1906, "deferred_batch_norm": 1906, "torchgpip": 1906, "withdevic": 1906, "micro": 1906, "fc": [1906, 1908], "init_rpc": [1906, 1913, 1914], "output_rref": 1906, "fed": [1906, 1922], "nochunk": 1906, "resnext": 1906, "till": 1906, "skippabl": 1906, "perfectli": 1906, "1to3": 1906, "layer1": 1906, "f1": 1906, "layer2": 1906, "layer3": 1906, "skip_1to3": 1906, "f3": 1906, "alic": 1906, "bob": 1906, "carol": 1906, "stashstashpop": 1906, "f_alic": 1906, "f_bob": 1906, "verify_skipp": 1906, "unmatch": [1906, 1927], "fairscal": 1906, "_kinetoprofil": 1907, "profileract": 1907, "add_metadata": 1907, "add_metadata_json": 1907, "unaggreg": 1907, "export_chrome_trac": 1907, "export_memory_timelin": 1907, "gzip": 1907, "export_stack": 1907, "self_cuda_time_tot": 1907, "flamegraph": 1907, "brendangregg": 1907, "pl": 1907, "countnam": 1907, "perf_viz": 1907, "svg": 1907, "on_trace_readi": 1907, "record_and_sav": 1907, "tensorboard_trace_handl": 1907, "dir_nam": 1907, "logdir": [1907, 1922], "code_to_profil": 1907, "row_limit": 1907, "trace_handl": 1907, "test_trace_": 1907, "step_num": 1907, "code_iteration_to_profil": 1907, "mtia": 1907, "skip_first": 1907, "worker_nam": [1907, 1913], "use_gzip": 1907, "range_push": 1907, "range_pop": 1907, "4x": 1908, "broadli": 1908, "domin": 1908, "previous_layer_fp32": 1908, "linear_fp32": 1908, "activation_fp32": 1908, "next_layer_fp32": 1908, "linear_weight_fp32": 1908, "linear_int8_w_fp32_inp": 1908, "linear_weight_int8": 1908, "ptdq": 1908, "model_fp32": 1908, "model_int8": 1908, "quantize_dynam": 1908, "input_fp32": 1908, "previous_layer_int8": 1908, "linear_with_activation_int8": 1908, "next_layer_int8": 1908, "ptsq": 1908, "minmax": 1908, "l2norm": 1908, "model_fp32_fus": 1908, "fuse_modul": [1908, 1909], "model_fp32_prepar": 1908, "fq": 1908, "prepare_qat": 1908, "training_loop": 1908, "requant": 1908, "linear1": 1908, "custom_qconfig": 1908, "fxptq": 1908, "model_fp": 1908, "usermodel": 1908, "model_to_quant": 1908, "default_dynamic_qconfig": 1908, "model_prepar": 1908, "model_quant": 1908, "model_fus": 1908, "per_tensor_symmetr": [1908, 1911], "per_channel_symmetr": [1908, 1911], "per_channel_scal": 1908, "per_channel_zero_point": 1908, "quantized_tensor": 1908, "qengin": 1908, "in4": 1908, "fx2trt": 1908, "float_modul": [1908, 1926], "staticquantcustommodul": 1908, "observed_modul": 1908, "default_qconfig": [1908, 1927], "test_quantized_op": 1908, "testquantizedop": 1908, "test_custom_module_lstm": 1908, "test_quantize_fx": 1908, "testquantizefx": 1908, "test_static_lstm": 1908, "some_oper": 1908, "e2": 1908, "thnn_conv2d_forward": 1908, "quantizedcpu": 1908, "some_qconfig": 1908, "linearpackedparam": 1908, "_modul": 1908, "prepare_orig": 1908, "quantized_orig": 1908, "scripted_quant": 1908, "fp32_op": 1909, "int8_op": 1909, "cooperlak": 1909, "audit": 1909, "op_fp32": 1909, "op_int8": 1909, "_numeric_suit": 1909, "_numeric_suite_fx": 1909, "0x7f62a1a106c0": 1910, "0x7f628d8a91f0": 1910, "0x7f628d8a9280": 1910, "num_tensor_args_to_observation_typ": 1910, "convbn1d": 1910, "0x7f628ccb4790": 1910, "reference_quantized_module_for_root": 1910, "fuse_convtranspose_bn": 1910, "0x7f628ccb4940": 1910, "linearbn1d": 1910, "fuse_linear_bn": 1910, "0x7f628ccb48b0": 1910, "convbn2d": 1910, "convbn3d": 1910, "bnrelu2d": 1910, "bnrelu3d": 1910, "input_type_to_index": 1910, "conv_fus": 1910, "convbnrelu1d": 1910, "convbnrelu2d": 1910, "convbnrelu3d": 1910, "convrelu1d": 1910, "convrelu3d": 1910, "0x7f628d8a9310": 1910, "0x7f628d8a9940": 1910, "quint4x2": [1910, 1919, 1923, 1924], "embedding_op": 1910, "0x7f628d8ab820": 1910, "00390625": 1910, "0x7f628d8ab160": 1910, "0x7f628d8ab310": 1910, "0x7f628d8a9820": 1910, "0x7f628d8ab700": 1910, "0x7f628d820ee0": 1910, "0x7f628d8ab790": 1910, "0x7f628d8a9af0": 1910, "linear_fus": 1910, "_sequential_wrapper2": 1910, "0x7f62a8b5d430": 1910, "0x7f628d8a9700": 1910, "0x7f628ab80280": 1910, "fuse_conv_bn_relu": 1910, "0x7f628ccb4820": 1910, "0x7f628ab80310": 1910, "0x7f628ab803a0": 1910, "0x7f628ab80430": 1910, "0x7f628ab804c0": 1910, "0x7f628ab80550": 1910, "0x7f628ab805e0": 1910, "0x7f628ab80670": 1910, "0x7f628ab80700": 1910, "0x7f628ab80790": 1910, "0x7f628ab80820": 1910, "0x7f628d8a98b0": 1910, "0078125": 1910, "customconfig": 1911, "custom_module_config": 1911, "_caller": 1912, "_devices_kw": 1912, "slowli": 1912, "unind": 1912, "deivc": 1912, "privateuse1": 1912, "shortcom": 1913, "stitch": 1913, "rpc_backend_opt": 1913, "trainer3": 1913, "parameterserver2": 1913, "dash": [1913, 1915], "backendtyp": 1913, "rpcbackendopt": 1913, "rpcagent": 1913, "transmit": 1913, "calle": [1913, 1915], "_set_rpc_timeout": 1913, "5678": 1913, "worker0": 1913, "my_script_add": 1913, "wire": 1913, "fut2": 1913, "meth": 1913, "grace": 1913, "userrref": [1913, 1915], "async_execut": 1913, "paus": 1913, "outmost": 1913, "async_add_chain": 1913, "worker2": 1913, "script_add": 1913, "async_add": 1913, "asyncexecutionclass": 1913, "static_async_add": 1913, "class_async_add": 1913, "ret_fut": 1913, "bound_async_add": 1913, "rpc_timeout": 1913, "incid": [1913, 1915], "nvlink": 1913, "multiplex": 1913, "tensorpiperpcbackendopt": 1913, "num_worker_thread": 1913, "device_map": 1913, "_transport": 1913, "tensorpipeag": 1913, "set_device_map": 1913, "intermitt": 1913, "remote_modul": 1913, "forward_async": 1913, "remote_devic": 1913, "workernam": 1913, "trainer0": 1913, "ps0": 1913, "remote_linear_modul": 1913, "get_module_rref": 1913, "remote_paramet": 1913, "my_add": [1914, 1928], "t4": 1914, "t5": 1914, "autograd_message_id": 1914, "autograd_context_id": 1914, "send1": 1914, "kickoff": 1914, "recv2": 1914, "heard": 1914, "send2": 1914, "recv1": 1914, "dist_autograd_simpl": 1914, "random_tensor": 1914, "_run_process": 1914, "dst_rank": 1914, "dst_name": 1914, "run_process": 1914, "rrefid": 1915, "ownerrref": 1915, "transient": 1915, "udf": 1915, "deliveri": 1915, "knowledg": 1915, "danger": 1915, "ancestor": 1915, "trickier": 1915, "forkid": 1915, "ack": 1915, "solid": 1915, "gc": 1915, "followup": 1915, "lil": 1917, "stark": 1917, "9093": 1917, "1411": 1917, "7568": 1917, "9589": 1917, "2794": 1917, "catastroph": 1917, "9900": 1917, "000": 1917, "400": 1917, "s2": 1917, "plain_dim_s": 1917, "lp64": 1917, "280": 1917, "310": 1917, "sp": 1917, "9078": 1917, "conception": 1917, "lobpcg": 1917, "geneig": 1917, "pca_lowrank": 1917, "kindli": 1917, "airy_ai": 1918, "airi": 1918, "onward": 1918, "9635": 1918, "entr": 1918, "3466": 1918, "int_": 1918, "8427": 1918, "0561": 1918, "4769": 1918, "9213": 1918, "8858": 1918, "7683": 1918, "7481": 1918, "2920": 1918, "int_0": 1918, "gammaln": 1918, "a1": 1918, "a2": 1918, "3528": 1918, "5665": 1918, "6472": 1918, "4335": 1918, "2650": 1918, "2661": 1918, "2796": 1918, "8808": 1918, "3019": 1918, "4658": 1918, "3085": 1918, "2430": 1918, "2070": 1918, "i1": 1918, "5652": 1918, "9534": 1918, "7595": 1918, "2153": 1918, "log_ndtr": 1918, "_ndtr": 1918, "6077": 1918, "7832": 1918, "841": 1918, "6931": 1918, "1728": 1918, "023": 1918, "9331": 1918, "6486": 1918, "1523": 1918, "6516": 1918, "6352": 1918, "6131": 1918, "7169": 1918, "6261": 1918, "displaystyl": 1918, "undefiend": 1918, "6835": 1918, "8474": 1918, "1929": 1918, "7162": 1918, "4180": 1918, "3928": 1918, "4007": 1918, "7586": 1918, "3901": 1918, "5049": 1918, "ndtr": 1918, "0228": 1918, "1587": 1918, "9772": 1918, "9987": 1918, "2p": 1918, "64493": 1918, "4041": 1918, "8288": 1918, "4939": 1918, "97": 1918, "4091": 1918, "8863": 1918, "771": 1918, "scaled_modified_bessel_k0": 1918, "scaled_modified_bessel_k1": 1918, "2948": 1918, "0267": 1918, "1566": 1918, "9186": 1918, "8631": 1918, "0259": 1918, "1300": 1918, "spheric": 1918, "xlog1pi": 1918, "3863": 1918, "1972": 1918, "6094": 1918, "2189": 1918, "8283": 1918, "7726": 1918, "0986": 1918, "1589": 1918, "hurwitz": 1918, "6449": 1918, "0823": 1918, "untyp": 1919, "wrap_storag": 1919, "complex_doubl": 1919, "from_buff": 1919, "pickle_storage_typ": 1919, "byteswap": 1919, "quint2x4": [1919, 1924], "twelv": 1920, "halftensor": [1920, 1923], "bfloat16tensor": [1920, 1923], "chartensor": [1920, 1923], "shorttensor": [1920, 1923], "binary16": [1920, 1923], "significand": [1920, 1923], "float_tensor": 1920, "double_tensor": 1920, "complex_float_tensor": 1920, "complex_double_tensor": 1920, "int_tensor": 1920, "long_tensor": 1920, "uint_tensor": 1920, "bool_tensor": 1920, "long_zerodim": 1920, "int_zerodim": 1920, "set_default_devic": 1920, "cuda1": 1920, "nhwc": [1920, 1922], "channels_last_3d": 1920, "ndhwc": 1920, "blogpost": 1921, "totensor": 1922, "trainset": 1922, "mnist": 1922, "mnist_train": 1922, "trainload": 1922, "grayscal": 1922, "make_grid": 1922, "add_imag": 1922, "add_graph": 1922, "clutter": 1922, "n_iter": 1922, "purge_step": 1922, "max_queu": 1922, "flush_sec": 1922, "filename_suffix": 1922, "current_datetime_hostnam": 1922, "exp1": 1922, "suffix": [1922, 1923], "global_step": 1922, "purg": 1922, "event_file_writ": 1922, "eventfilewrit": 1922, "may04_22": 1922, "54_": 1922, "macbook": 1922, "my_experi": 1922, "lr_0": 1922, "1_batch_16": 1922, "locallr_0": 1922, "scalar_valu": 1922, "walltim": 1922, "new_styl": 1922, "double_precis": 1922, "blobnam": 1922, "simple_valu": 1922, "main_tag": 1922, "tag_scalar_dict": 1922, "run_14h": 1922, "xsinx": 1922, "xcosx": 1922, "tanx": 1922, "add_histogram": 1922, "max_bin": 1922, "fd": 1922, "img_tensor": 1922, "dataformat": 1922, "chw": 1922, "hwc": 1922, "hw": 1922, "wh": 1922, "3xhxw": 1922, "img_hwc": 1922, "my_imag": 1922, "my_image_hwc": 1922, "img_batch": 1922, "my_image_batch": 1922, "add_figur": 1922, "add_video": 1922, "vid_tensor": 1922, "fp": 1922, "moviepi": 1922, "add_audio": 1922, "snd_tensor": 1922, "sample_r": 1922, "44100": 1922, "add_text": 1922, "text_str": 1922, "input_to_model": 1922, "use_strict_trac": 1922, "add_embed": 1922, "label_img": 1922, "metadata_head": 1922, "projector": 1922, "kwlist": 1922, "add_pr_curv": 1922, "num_threshold": 1922, "pr_curv": 1922, "add_custom_scalar": 1922, "chart": 1922, "categorynam": 1922, "chartnam": 1922, "listofproperti": 1922, "multilin": 1922, "taiwan": 1922, "twse": 1922, "0050": 1922, "2330": 1922, "dow": 1922, "aaa": 1922, "bbb": 1922, "ccc": 1922, "nasdaq": 1922, "add_mesh": 1922, "config_dict": 1922, "threej": 1922, "vertex": 1922, "number_of_vertic": 1922, "vertices_tensor": 1922, "colors_tensor": 1922, "faces_tensor": 1922, "my_mesh": 1922, "add_hparam": 1922, "hparam_dict": 1922, "metric_dict": 1922, "hparam_domain_discret": 1922, "run_nam": 1922, "hparam": 1922, "bsize": 1922, "_like": 1923, "allow_subclass": 1924, "check_devic": 1924, "check_layout": 1924, "6e": 1924, "3e": 1924, "assert_equ": 1924, "000000000000001e": 1924, "1e0": 1924, "argh": 1924, "nfooter": 1924, "66": 1924, "footer": 1924, "exclude_zero": 1924, "1205": 1924, "2282": 1924, "6380": 1924, "default_gener": 1925, "data_dependent_output": 1925, "dynamic_output_shap": 1925, "inplace_view": 1925, "nondeterministic_bitwis": 1925, "nondeterministic_seed": 1925, "compare_weight": 1926, "float_dict": 1926, "quantized_dict": 1926, "wt_compare_dict": 1926, "qmodel": 1926, "compute_error": 1926, "weight_dict": 1926, "get_logger_dict": 1926, "shadowlogg": 1926, "outputlogg": [1926, 1927], "target_dict": 1926, "q_modul": 1926, "logger_cl": [1926, 1927], "prepare_model_with_stub": 1926, "module_swap_list": 1926, "q_model": 1926, "ob_dict": 1926, "compare_model_stub": 1926, "quantizablebasicblock": 1926, "get_matching_activ": 1926, "act_dict": 1926, "prepare_model_output": 1926, "compare_model_output": 1926, "act_compare_dict": 1926, "weight_comparison": 1927, "extract_weight": 1927, "sqnr": 1927, "extend_logger_results_with_comparison": 1927, "compute_sqnr": 1927, "mp_n": 1927, "mq_n": 1927, "add_logg": 1927, "act_comparison": 1927, "extract_logger_info": 1927, "mp_shadows_mq": 1927, "add_shadow_logg": 1927, "shadow_act_comparison": 1927, "extract_shadow_logger_info": 1927, "ref_node_nam": 1927, "prev_node_nam": 1927, "model_nam": 1927, "ref_nam": 1927, "prev_node_target_typ": 1927, "ref_node_target_typ": 1927, "results_typ": 1927, "index_within_arg": 1927, "index_of_arg": 1927, "qconfig_str": 1927, "outputcomparisonlogg": 1927, "x_ref": 1927, "nstracer": 1927, "skipped_module_nam": 1927, "skipped_module_class": 1927, "model_name_a": 1927, "model_a": 1927, "model_name_b": 1927, "model_b": 1927, "base_name_to_sets_of_related_op": 1927, "unmatchable_types_map": 1927, "op_to_type_to_weight_extraction_fn": 1927, "nsresultstyp": 1927, "name_a": 1927, "name_b": 1927, "should_log_input": 1927, "model_a_with_logg": 1927, "model_b_with_logg": 1927, "model_name_to_use_for_layer_nam": 1927, "node_type_to_io_type_map": 1927, "model_a_shadows_b": 1927, "model_name_1": 1927, "model_name_2": 1927, "comparison_fn": 1927, "comparison_nam": 1927, "prepare_n_shadows_model": 1927, "qconfig_multi_map": 1927, "custom_prepare_fn": 1927, "custom_prepare_kwarg": 1927, "custom_trac": 1927, "args_kwargs_m": 1927, "op_m": 1927, "output_m": 1927, "op_m_n": 1927, "log_m_n": 1927, "log_m_0": 1927, "qconfig_n": 1927, "args_m": 1927, "op_m_prepared_with_qconfig_n": 1927, "out_m_n": 1927, "kwargs_m": 1927, "docblock": 1927, "loggers_set_en": 1927, "loggers_set_save_activ": 1927, "save_activ": 1927, "convert_n_shadows_model": 1927, "custom_convert_fn": 1927, "custom_convert_kwarg": 1927, "extract_results_n_shadows_model": 1927, "print_comparisons_n_shadows_model": 1927, "compute_normalized_l2_error": 1927, "compute_cosine_similar": 1927, "as_subclass": 1928, "resolve_nam": 1928, "handle_torch_funct": 1928, "public_api": 1928, "relevant_arg": 1928, "has_torch_function_unari": 1928, "is_tensor_lik": 1928, "notatensor": 1928, "tensorlik": 1928, "is_tensor_method_or_properti": 1928, "__get__": 1928, "__module__": 1928, "slot": 1928, "wrap_torch_funct": 1928, "smallest_norm": 1929, "subnorm": 1929, "denormal_numb": 1929}, "objects": {"": [[1925, 0, 0, "-", "torch"], [1860, 7, 1, "-", "PYTORCH_JIT"]], "torch": [[1919, 1, 1, "", "BFloat16Storage"], [1919, 1, 1, "", "BoolStorage"], [1919, 1, 1, "", "ByteStorage"], [1919, 1, 1, "", "CharStorage"], [1919, 1, 1, "", "ComplexDoubleStorage"], [1919, 1, 1, "", "ComplexFloatStorage"], [1919, 1, 1, "", "DoubleStorage"], [1919, 1, 1, "", "FloatStorage"], [89, 1, 1, "", "Generator"], [1919, 1, 1, "", "HalfStorage"], [1919, 1, 1, "", "IntStorage"], [1919, 1, 1, "", "LongStorage"], [1919, 1, 1, "", "QInt32Storage"], [1919, 1, 1, "", "QInt8Storage"], [1919, 1, 1, "", "QUInt2x4Storage"], [1919, 1, 1, "", "QUInt4x2Storage"], [1919, 1, 1, "", "QUInt8Storage"], [1919, 1, 1, "", "ShortStorage"], [1925, 1, 1, "", "SymBool"], [1925, 1, 1, "", "SymFloat"], [1925, 1, 1, "", "SymInt"], [1925, 1, 1, "", "Tag"], [1923, 1, 1, "", "Tensor"], [1919, 1, 1, "", "TypedStorage"], [1919, 1, 1, "", "UntypedStorage"], [31, 0, 0, "-", "__config__"], [621, 5, 1, "", "_assert"], [0, 0, 0, "-", "_dynamo"], [622, 5, 1, "", "_foreach_abs"], [623, 5, 1, "", "_foreach_abs_"], [624, 5, 1, "", "_foreach_acos"], [625, 5, 1, "", "_foreach_acos_"], [626, 5, 1, "", "_foreach_asin"], [627, 5, 1, "", "_foreach_asin_"], [628, 5, 1, "", "_foreach_atan"], [629, 5, 1, "", "_foreach_atan_"], [630, 5, 1, "", "_foreach_ceil"], [631, 5, 1, "", "_foreach_ceil_"], [632, 5, 1, "", "_foreach_cos"], [633, 5, 1, "", "_foreach_cos_"], [634, 5, 1, "", "_foreach_cosh"], [635, 5, 1, "", "_foreach_cosh_"], [636, 5, 1, "", "_foreach_erf"], [637, 5, 1, "", "_foreach_erf_"], [638, 5, 1, "", "_foreach_erfc"], [639, 5, 1, "", "_foreach_erfc_"], [640, 5, 1, "", "_foreach_exp"], [641, 5, 1, "", "_foreach_exp_"], [642, 5, 1, "", "_foreach_expm1"], [643, 5, 1, "", "_foreach_expm1_"], [644, 5, 1, "", "_foreach_floor"], [645, 5, 1, "", "_foreach_floor_"], [646, 5, 1, "", "_foreach_frac"], [647, 5, 1, "", "_foreach_frac_"], [648, 5, 1, "", "_foreach_lgamma"], [649, 5, 1, "", "_foreach_lgamma_"], [650, 5, 1, "", "_foreach_log"], [651, 5, 1, "", "_foreach_log10"], [652, 5, 1, "", "_foreach_log10_"], [653, 5, 1, "", "_foreach_log1p"], [654, 5, 1, "", "_foreach_log1p_"], [655, 5, 1, "", "_foreach_log2"], [656, 5, 1, "", "_foreach_log2_"], [657, 5, 1, "", "_foreach_log_"], [658, 5, 1, "", "_foreach_neg"], [659, 5, 1, "", "_foreach_neg_"], [660, 5, 1, "", "_foreach_reciprocal"], [661, 5, 1, "", "_foreach_reciprocal_"], [662, 5, 1, "", "_foreach_round"], [663, 5, 1, "", "_foreach_round_"], [664, 5, 1, "", "_foreach_sigmoid"], [665, 5, 1, "", "_foreach_sigmoid_"], [666, 5, 1, "", "_foreach_sin"], [667, 5, 1, "", "_foreach_sin_"], [668, 5, 1, "", "_foreach_sinh"], [669, 5, 1, "", "_foreach_sinh_"], [670, 5, 1, "", "_foreach_sqrt"], [671, 5, 1, "", "_foreach_sqrt_"], [672, 5, 1, "", "_foreach_tan"], [673, 5, 1, "", "_foreach_tan_"], [674, 5, 1, "", "_foreach_trunc"], [675, 5, 1, "", "_foreach_trunc_"], [676, 5, 1, "", "_foreach_zero_"], [1869, 0, 0, "-", "_logging"], [678, 5, 1, "", "abs"], [679, 5, 1, "", "absolute"], [680, 5, 1, "", "acos"], [681, 5, 1, "", "acosh"], [682, 5, 1, "", "add"], [683, 5, 1, "", "addbmm"], [684, 5, 1, "", "addcdiv"], [685, 5, 1, "", "addcmul"], [686, 5, 1, "", "addmm"], [687, 5, 1, "", "addmv"], [688, 5, 1, "", "addr"], [689, 5, 1, "", "adjoint"], [690, 5, 1, "", "all"], [691, 5, 1, "", "allclose"], [692, 5, 1, "", "amax"], [693, 5, 1, "", "amin"], [694, 5, 1, "", "aminmax"], [1, 0, 0, "-", "amp"], [695, 5, 1, "", "angle"], [696, 5, 1, "", "any"], [1908, 0, 0, "-", "ao"], [862, 5, 1, "", "arange"], [863, 5, 1, "", "arccos"], [864, 5, 1, "", "arccosh"], [865, 5, 1, "", "arcsin"], [866, 5, 1, "", "arcsinh"], [867, 5, 1, "", "arctan"], [868, 5, 1, "", "arctan2"], [869, 5, 1, "", "arctanh"], [870, 5, 1, "", "are_deterministic_algorithms_enabled"], [871, 5, 1, "", "argmax"], [872, 5, 1, "", "argmin"], [873, 5, 1, "", "argsort"], [874, 5, 1, "", "argwhere"], [875, 5, 1, "", "as_strided"], [876, 5, 1, "", "as_tensor"], [877, 5, 1, "", "asarray"], [878, 5, 1, "", "asin"], [879, 5, 1, "", "asinh"], [880, 5, 1, "", "atan"], [881, 5, 1, "", "atan2"], [882, 5, 1, "", "atanh"], [883, 5, 1, "", "atleast_1d"], [884, 5, 1, "", "atleast_2d"], [885, 5, 1, "", "atleast_3d"], [1, 1, 1, "", "autocast"], [1925, 0, 0, "-", "autograd"], [3, 0, 0, "-", "backends"], [918, 5, 1, "", "baddbmm"], [919, 5, 1, "", "bartlett_window"], [920, 5, 1, "", "bernoulli"], [921, 5, 1, "", "bincount"], [922, 5, 1, "", "bitwise_and"], [923, 5, 1, "", "bitwise_left_shift"], [924, 5, 1, "", "bitwise_not"], [925, 5, 1, "", "bitwise_or"], [926, 5, 1, "", "bitwise_right_shift"], [927, 5, 1, "", "bitwise_xor"], [928, 5, 1, "", "blackman_window"], [929, 5, 1, "", "block_diag"], [930, 5, 1, "", "bmm"], [931, 5, 1, "", "broadcast_shapes"], [932, 5, 1, "", "broadcast_tensors"], [933, 5, 1, "", "broadcast_to"], [934, 5, 1, "", "bucketize"], [935, 5, 1, "", "can_cast"], [936, 5, 1, "", "cartesian_prod"], [937, 5, 1, "", "cat"], [938, 5, 1, "", "cdist"], [939, 5, 1, "", "ceil"], [940, 5, 1, "", "chain_matmul"], [941, 5, 1, "", "cholesky"], [942, 5, 1, "", "cholesky_inverse"], [943, 5, 1, "", "cholesky_solve"], [944, 5, 1, "", "chunk"], [945, 5, 1, "", "clamp"], [946, 5, 1, "", "clip"], [947, 5, 1, "", "clone"], [948, 5, 1, "", "column_stack"], [949, 5, 1, "", "combinations"], [950, 5, 1, "", "compile"], [951, 5, 1, "", "compiled_with_cxx11_abi"], [952, 5, 1, "", "complex"], [953, 5, 1, "", "concat"], [954, 5, 1, "", "concatenate"], [955, 5, 1, "", "conj"], [956, 5, 1, "", "conj_physical"], [1925, 0, 0, "-", "contrib"], [957, 5, 1, "", "copysign"], [958, 5, 1, "", "corrcoef"], [959, 5, 1, "", "cos"], [960, 5, 1, "", "cosh"], [961, 5, 1, "", "count_nonzero"], [962, 5, 1, "", "cov"], [1, 0, 0, "-", "cpu"], [963, 5, 1, "", "cross"], [34, 0, 0, "-", "cuda"], [1042, 5, 1, "", "cummax"], [1043, 5, 1, "", "cummin"], [1044, 5, 1, "", "cumprod"], [1045, 5, 1, "", "cumsum"], [1046, 5, 1, "", "cumulative_trapezoid"], [1047, 5, 1, "", "deg2rad"], [1048, 5, 1, "", "dequantize"], [1049, 5, 1, "", "det"], [1920, 1, 1, "", "device"], [1050, 5, 1, "", "diag"], [1051, 5, 1, "", "diag_embed"], [1052, 5, 1, "", "diagflat"], [1053, 5, 1, "", "diagonal"], [1054, 5, 1, "", "diagonal_scatter"], [1055, 5, 1, "", "diff"], [1056, 5, 1, "", "digamma"], [1057, 5, 1, "", "dist"], [41, 0, 0, "-", "distributed"], [47, 0, 0, "-", "distributions"], [1058, 5, 1, "", "div"], [1059, 5, 1, "", "divide"], [1060, 5, 1, "", "dot"], [1061, 5, 1, "", "dsplit"], [1062, 5, 1, "", "dstack"], [1920, 1, 1, "", "dtype"], [1063, 5, 1, "", "einsum"], [1064, 5, 1, "", "empty"], [1065, 5, 1, "", "empty_like"], [1066, 5, 1, "", "empty_strided"], [1067, 1, 1, "", "enable_grad"], [1068, 5, 1, "", "eq"], [1069, 5, 1, "", "equal"], [1070, 5, 1, "", "erf"], [1071, 5, 1, "", "erfc"], [1072, 5, 1, "", "erfinv"], [1073, 5, 1, "", "exp"], [1074, 5, 1, "", "exp2"], [1075, 5, 1, "", "expm1"], [1076, 5, 1, "", "eye"], [1077, 5, 1, "", "fake_quantize_per_channel_affine"], [1078, 5, 1, "", "fake_quantize_per_tensor_affine"], [62, 0, 0, "-", "fft"], [1101, 5, 1, "", "fix"], [1102, 5, 1, "", "flatten"], [1103, 5, 1, "", "flip"], [1104, 5, 1, "", "fliplr"], [1105, 5, 1, "", "flipud"], [1106, 5, 1, "", "float_power"], [1107, 5, 1, "", "floor"], [1108, 5, 1, "", "floor_divide"], [1109, 5, 1, "", "fmax"], [1110, 5, 1, "", "fmin"], [1111, 5, 1, "", "fmod"], [1112, 5, 1, "", "frac"], [1113, 5, 1, "", "frexp"], [1114, 5, 1, "", "from_dlpack"], [1115, 5, 1, "", "from_numpy"], [1116, 5, 1, "", "frombuffer"], [1117, 5, 1, "", "full"], [1118, 5, 1, "", "full_like"], [65, 0, 0, "-", "func"], [70, 0, 0, "-", "futures"], [71, 0, 0, "-", "fx"], [1132, 5, 1, "", "gather"], [1133, 5, 1, "", "gcd"], [1134, 5, 1, "", "ge"], [1135, 5, 1, "", "geqrf"], [1136, 5, 1, "", "ger"], [1137, 5, 1, "", "get_default_dtype"], [1138, 5, 1, "", "get_deterministic_debug_mode"], [1139, 5, 1, "", "get_float32_matmul_precision"], [1140, 5, 1, "", "get_num_interop_threads"], [1141, 5, 1, "", "get_num_threads"], [1142, 5, 1, "", "get_rng_state"], [1143, 5, 1, "", "gradient"], [1144, 5, 1, "", "greater"], [1145, 5, 1, "", "greater_equal"], [1146, 5, 1, "", "gt"], [1147, 5, 1, "", "hamming_window"], [1148, 5, 1, "", "hann_window"], [1149, 5, 1, "", "heaviside"], [1150, 5, 1, "", "histc"], [1151, 5, 1, "", "histogram"], [1152, 5, 1, "", "histogramdd"], [1153, 5, 1, "", "hsplit"], [1154, 5, 1, "", "hspmm"], [1155, 5, 1, "", "hstack"], [1857, 0, 0, "-", "hub"], [1156, 5, 1, "", "hypot"], [1157, 5, 1, "", "i0"], [1158, 5, 1, "", "igamma"], [1159, 5, 1, "", "igammac"], [1160, 5, 1, "", "imag"], [1161, 5, 1, "", "index_add"], [1162, 5, 1, "", "index_copy"], [1163, 5, 1, "", "index_reduce"], [1164, 5, 1, "", "index_select"], [1165, 1, 1, "", "inference_mode"], [1166, 5, 1, "", "initial_seed"], [1167, 5, 1, "", "inner"], [1168, 5, 1, "", "inverse"], [1169, 5, 1, "", "is_complex"], [1170, 5, 1, "", "is_conj"], [1171, 5, 1, "", "is_deterministic_algorithms_warn_only_enabled"], [1172, 5, 1, "", "is_floating_point"], [1173, 5, 1, "", "is_grad_enabled"], [1174, 5, 1, "", "is_inference_mode_enabled"], [1175, 5, 1, "", "is_nonzero"], [1176, 5, 1, "", "is_storage"], [1177, 5, 1, "", "is_tensor"], [1178, 5, 1, "", "is_warn_always_enabled"], [1179, 5, 1, "", "isclose"], [1180, 5, 1, "", "isfinite"], [1181, 5, 1, "", "isin"], [1182, 5, 1, "", "isinf"], [1183, 5, 1, "", "isnan"], [1184, 5, 1, "", "isneginf"], [1185, 5, 1, "", "isposinf"], [1186, 5, 1, "", "isreal"], [1187, 5, 1, "", "istft"], [1860, 0, 0, "-", "jit"], [1209, 5, 1, "", "kaiser_window"], [1210, 5, 1, "", "kron"], [1211, 5, 1, "", "kthvalue"], [1920, 1, 1, "", "layout"], [1212, 5, 1, "", "lcm"], [1213, 5, 1, "", "ldexp"], [1214, 5, 1, "", "le"], [1215, 5, 1, "", "lerp"], [1216, 5, 1, "", "less"], [1217, 5, 1, "", "less_equal"], [1218, 5, 1, "", "lgamma"], [1868, 0, 0, "-", "linalg"], [1260, 5, 1, "", "linspace"], [1261, 5, 1, "", "load"], [1262, 5, 1, "", "lobpcg"], [1263, 5, 1, "", "log"], [1264, 5, 1, "", "log10"], [1265, 5, 1, "", "log1p"], [1266, 5, 1, "", "log2"], [1267, 5, 1, "", "logaddexp"], [1268, 5, 1, "", "logaddexp2"], [1269, 5, 1, "", "logcumsumexp"], [1270, 5, 1, "", "logdet"], [1271, 5, 1, "", "logical_and"], [1272, 5, 1, "", "logical_not"], [1273, 5, 1, "", "logical_or"], [1274, 5, 1, "", "logical_xor"], [1275, 5, 1, "", "logit"], [1276, 5, 1, "", "logspace"], [1277, 5, 1, "", "logsumexp"], [1278, 5, 1, "", "lt"], [1279, 5, 1, "", "lu"], [1280, 5, 1, "", "lu_solve"], [1281, 5, 1, "", "lu_unpack"], [1282, 5, 1, "", "manual_seed"], [1870, 0, 0, "-", "masked"], [1283, 5, 1, "", "masked_select"], [1284, 5, 1, "", "matmul"], [1285, 5, 1, "", "matrix_exp"], [1286, 5, 1, "", "matrix_power"], [1287, 5, 1, "", "max"], [1288, 5, 1, "", "maximum"], [1289, 5, 1, "", "mean"], [1290, 5, 1, "", "median"], [1920, 1, 1, "", "memory_format"], [1291, 5, 1, "", "meshgrid"], [1292, 5, 1, "", "min"], [1293, 5, 1, "", "minimum"], [1294, 5, 1, "", "mm"], [1295, 5, 1, "", "mode"], [1873, 0, 0, "-", "monitor"], [1296, 5, 1, "", "moveaxis"], [1297, 5, 1, "", "movedim"], [1874, 0, 0, "-", "mps"], [1310, 5, 1, "", "msort"], [1311, 5, 1, "", "mul"], [1312, 5, 1, "", "multinomial"], [1313, 5, 1, "", "multiply"], [1875, 0, 0, "-", "multiprocessing"], [1314, 5, 1, "", "mv"], [1315, 5, 1, "", "mvlgamma"], [1316, 5, 1, "", "nan_to_num"], [1317, 5, 1, "", "nanmean"], [1318, 5, 1, "", "nanmedian"], [1319, 5, 1, "", "nanquantile"], [1320, 5, 1, "", "nansum"], [1321, 5, 1, "", "narrow"], [1322, 5, 1, "", "narrow_copy"], [1323, 5, 1, "", "ne"], [1324, 5, 1, "", "neg"], [1325, 5, 1, "", "negative"], [1878, 0, 0, "-", "nested"], [1326, 5, 1, "", "nextafter"], [1879, 0, 0, "-", "nn"], [1647, 1, 1, "", "no_grad"], [1648, 5, 1, "", "nonzero"], [1649, 5, 1, "", "norm"], [1650, 5, 1, "", "normal"], [1651, 5, 1, "", "not_equal"], [1652, 5, 1, "", "numel"], [1653, 5, 1, "", "ones"], [1654, 5, 1, "", "ones_like"], [1901, 0, 0, "-", "onnx"], [1904, 0, 0, "-", "optim"], [1694, 5, 1, "", "orgqr"], [1695, 5, 1, "", "ormqr"], [1696, 5, 1, "", "outer"], [1905, 0, 0, "-", "package"], [1697, 5, 1, "", "pca_lowrank"], [1698, 5, 1, "", "permute"], [1699, 5, 1, "", "pinverse"], [1700, 5, 1, "", "poisson"], [1701, 5, 1, "", "polar"], [1702, 5, 1, "", "polygamma"], [1703, 5, 1, "", "positive"], [1704, 5, 1, "", "pow"], [1705, 5, 1, "", "prod"], [1907, 0, 0, "-", "profiler"], [1706, 5, 1, "", "promote_types"], [1707, 5, 1, "", "qr"], [1708, 5, 1, "", "quantile"], [1911, 0, 0, "-", "quantization"], [1709, 5, 1, "", "quantize_per_channel"], [1710, 5, 1, "", "quantize_per_tensor"], [1711, 5, 1, "", "quantized_batch_norm"], [1712, 5, 1, "", "quantized_max_pool1d"], [1713, 5, 1, "", "quantized_max_pool2d"], [1715, 5, 1, "", "rad2deg"], [1716, 5, 1, "", "rand"], [1717, 5, 1, "", "rand_like"], [1718, 5, 1, "", "randint"], [1719, 5, 1, "", "randint_like"], [1720, 5, 1, "", "randn"], [1721, 5, 1, "", "randn_like"], [1912, 0, 0, "-", "random"], [1722, 5, 1, "", "randperm"], [1723, 5, 1, "", "range"], [1724, 5, 1, "", "ravel"], [1725, 5, 1, "", "real"], [1726, 5, 1, "", "reciprocal"], [1727, 5, 1, "", "remainder"], [1728, 5, 1, "", "renorm"], [1729, 5, 1, "", "repeat_interleave"], [1730, 5, 1, "", "reshape"], [1731, 5, 1, "", "resolve_conj"], [1732, 5, 1, "", "resolve_neg"], [1733, 5, 1, "", "result_type"], [1734, 5, 1, "", "roll"], [1735, 5, 1, "", "rot90"], [1736, 5, 1, "", "round"], [1737, 5, 1, "", "row_stack"], [1738, 5, 1, "", "rsqrt"], [1739, 5, 1, "", "save"], [1740, 5, 1, "", "scatter"], [1741, 5, 1, "", "scatter_add"], [1742, 5, 1, "", "scatter_reduce"], [1743, 5, 1, "", "searchsorted"], [1744, 5, 1, "", "seed"], [1745, 5, 1, "", "select"], [1746, 5, 1, "", "select_scatter"], [1747, 5, 1, "", "set_default_device"], [1748, 5, 1, "", "set_default_dtype"], [1749, 5, 1, "", "set_default_tensor_type"], [1750, 5, 1, "", "set_deterministic_debug_mode"], [1751, 5, 1, "", "set_float32_matmul_precision"], [1752, 5, 1, "", "set_flush_denormal"], [1753, 1, 1, "", "set_grad_enabled"], [1754, 5, 1, "", "set_num_interop_threads"], [1755, 5, 1, "", "set_num_threads"], [1756, 5, 1, "", "set_printoptions"], [1757, 5, 1, "", "set_rng_state"], [1758, 5, 1, "", "set_warn_always"], [1759, 5, 1, "", "sgn"], [1760, 5, 1, "", "sigmoid"], [1761, 5, 1, "", "sign"], [1916, 0, 0, "-", "signal"], [1773, 5, 1, "", "signbit"], [1774, 5, 1, "", "sin"], [1775, 5, 1, "", "sinc"], [1776, 5, 1, "", "sinh"], [1777, 5, 1, "", "slice_scatter"], [1778, 5, 1, "", "slogdet"], [1779, 5, 1, "", "smm"], [1780, 5, 1, "", "softmax"], [1781, 5, 1, "", "sort"], [1917, 0, 0, "-", "sparse"], [1790, 5, 1, "", "sparse_bsc_tensor"], [1791, 5, 1, "", "sparse_bsr_tensor"], [1792, 5, 1, "", "sparse_compressed_tensor"], [1793, 5, 1, "", "sparse_coo_tensor"], [1794, 5, 1, "", "sparse_csc_tensor"], [1795, 5, 1, "", "sparse_csr_tensor"], [1918, 0, 0, "-", "special"], [1796, 5, 1, "", "split"], [1797, 5, 1, "", "sqrt"], [1798, 5, 1, "", "square"], [1799, 5, 1, "", "squeeze"], [1800, 5, 1, "", "sspaddmm"], [1801, 5, 1, "", "stack"], [1802, 5, 1, "", "std"], [1803, 5, 1, "", "std_mean"], [1804, 5, 1, "", "stft"], [1805, 5, 1, "", "sub"], [1806, 5, 1, "", "subtract"], [1807, 5, 1, "", "sum"], [1808, 5, 1, "", "svd"], [1809, 5, 1, "", "svd_lowrank"], [1810, 5, 1, "", "swapaxes"], [1811, 5, 1, "", "swapdims"], [1812, 5, 1, "", "sym_float"], [1813, 5, 1, "", "sym_int"], [1814, 5, 1, "", "sym_max"], [1815, 5, 1, "", "sym_min"], [1816, 5, 1, "", "sym_not"], [1817, 5, 1, "", "t"], [1818, 5, 1, "", "take"], [1819, 5, 1, "", "take_along_dim"], [1820, 5, 1, "", "tan"], [1821, 5, 1, "", "tanh"], [1822, 5, 1, "", "tensor"], [1823, 5, 1, "", "tensor_split"], [1824, 5, 1, "", "tensordot"], [1924, 0, 0, "-", "testing"], [1825, 5, 1, "", "tile"], [1826, 5, 1, "", "topk"], [1827, 5, 1, "", "trace"], [1828, 5, 1, "", "transpose"], [1829, 5, 1, "", "trapezoid"], [1830, 5, 1, "", "trapz"], [1831, 5, 1, "", "triangular_solve"], [1832, 5, 1, "", "tril"], [1833, 5, 1, "", "tril_indices"], [1834, 5, 1, "", "triu"], [1835, 5, 1, "", "triu_indices"], [1836, 5, 1, "", "true_divide"], [1837, 5, 1, "", "trunc"], [1838, 5, 1, "", "unbind"], [1839, 5, 1, "", "unflatten"], [1840, 5, 1, "", "unique"], [1841, 5, 1, "", "unique_consecutive"], [1842, 5, 1, "", "unsqueeze"], [1843, 5, 1, "", "use_deterministic_algorithms"], [1925, 0, 0, "-", "utils"], [1844, 5, 1, "", "vander"], [1845, 5, 1, "", "var"], [1846, 5, 1, "", "var_mean"], [1847, 5, 1, "", "vdot"], [1848, 5, 1, "", "view_as_complex"], [1849, 5, 1, "", "view_as_real"], [1850, 5, 1, "", "vmap"], [1851, 5, 1, "", "vsplit"], [1852, 5, 1, "", "vstack"], [1853, 5, 1, "", "where"], [1854, 5, 1, "", "xlogy"], [1855, 5, 1, "", "zeros"], [1856, 5, 1, "", "zeros_like"]], "torch.BFloat16Storage": [[1919, 2, 1, "", "dtype"]], "torch.BoolStorage": [[1919, 2, 1, "", "dtype"]], "torch.ByteStorage": [[1919, 2, 1, "", "dtype"]], "torch.CharStorage": [[1919, 2, 1, "", "dtype"]], "torch.ComplexDoubleStorage": [[1919, 2, 1, "", "dtype"]], "torch.ComplexFloatStorage": [[1919, 2, 1, "", "dtype"]], "torch.DoubleStorage": [[1919, 2, 1, "", "dtype"]], "torch.FloatStorage": [[1919, 2, 1, "", "dtype"]], "torch.Generator": [[89, 2, 1, "", "device"], [89, 3, 1, "", "get_state"], [89, 3, 1, "", "initial_seed"], [89, 3, 1, "", "manual_seed"], [89, 3, 1, "", "seed"], [89, 3, 1, "", "set_state"]], "torch.HalfStorage": [[1919, 2, 1, "", "dtype"]], "torch.IntStorage": [[1919, 2, 1, "", "dtype"]], "torch.LongStorage": [[1919, 2, 1, "", "dtype"]], "torch.QInt32Storage": [[1919, 2, 1, "", "dtype"]], "torch.QInt8Storage": [[1919, 2, 1, "", "dtype"]], "torch.QUInt2x4Storage": [[1919, 2, 1, "", "dtype"]], "torch.QUInt4x2Storage": [[1919, 2, 1, "", "dtype"]], "torch.QUInt8Storage": [[1919, 2, 1, "", "dtype"]], "torch.ShortStorage": [[1919, 2, 1, "", "dtype"]], "torch.Tag": [[1925, 4, 1, "", "name"]], "torch.Tensor": [[1923, 2, 1, "", "H"], [1923, 2, 1, "", "T"], [90, 3, 1, "", "abs"], [91, 3, 1, "", "abs_"], [92, 3, 1, "", "absolute"], [93, 3, 1, "", "absolute_"], [94, 3, 1, "", "acos"], [95, 3, 1, "", "acos_"], [96, 3, 1, "", "acosh"], [97, 3, 1, "", "acosh_"], [98, 3, 1, "", "add"], [99, 3, 1, "", "add_"], [100, 3, 1, "", "addbmm"], [101, 3, 1, "", "addbmm_"], [102, 3, 1, "", "addcdiv"], [103, 3, 1, "", "addcdiv_"], [104, 3, 1, "", "addcmul"], [105, 3, 1, "", "addcmul_"], [106, 3, 1, "", "addmm"], [107, 3, 1, "", "addmm_"], [108, 3, 1, "", "addmv"], [109, 3, 1, "", "addmv_"], [110, 3, 1, "", "addr"], [111, 3, 1, "", "addr_"], [112, 3, 1, "", "adjoint"], [1877, 3, 1, "", "align_as"], [1877, 3, 1, "", "align_to"], [113, 3, 1, "", "all"], [114, 3, 1, "", "allclose"], [115, 3, 1, "", "amax"], [116, 3, 1, "", "amin"], [117, 3, 1, "", "aminmax"], [118, 3, 1, "", "angle"], [119, 3, 1, "", "any"], [120, 3, 1, "", "apply_"], [121, 3, 1, "", "arccos"], [122, 3, 1, "", "arccos_"], [123, 3, 1, "", "arccosh"], [124, 3, 1, "", "arccosh_"], [125, 3, 1, "", "arcsin"], [126, 3, 1, "", "arcsin_"], [127, 3, 1, "", "arcsinh"], [128, 3, 1, "", "arcsinh_"], [129, 3, 1, "", "arctan"], [130, 3, 1, "", "arctan2"], [131, 3, 1, "", "arctan2_"], [132, 3, 1, "", "arctan_"], [133, 3, 1, "", "arctanh"], [134, 3, 1, "", "arctanh_"], [135, 3, 1, "", "argmax"], [136, 3, 1, "", "argmin"], [137, 3, 1, "", "argsort"], [138, 3, 1, "", "argwhere"], [139, 3, 1, "", "as_strided"], [140, 3, 1, "", "as_subclass"], [141, 3, 1, "", "asin"], [142, 3, 1, "", "asin_"], [143, 3, 1, "", "asinh"], [144, 3, 1, "", "asinh_"], [145, 3, 1, "", "atan"], [146, 3, 1, "", "atan2"], [147, 3, 1, "", "atan2_"], [148, 3, 1, "", "atan_"], [149, 3, 1, "", "atanh"], [150, 3, 1, "", "atanh_"], [151, 3, 1, "", "backward"], [152, 3, 1, "", "baddbmm"], [153, 3, 1, "", "baddbmm_"], [154, 3, 1, "", "bernoulli"], [155, 3, 1, "", "bernoulli_"], [156, 3, 1, "", "bfloat16"], [157, 3, 1, "", "bincount"], [158, 3, 1, "", "bitwise_and"], [159, 3, 1, "", "bitwise_and_"], [160, 3, 1, "", "bitwise_left_shift"], [161, 3, 1, "", "bitwise_left_shift_"], [162, 3, 1, "", "bitwise_not"], [163, 3, 1, "", "bitwise_not_"], [164, 3, 1, "", "bitwise_or"], [165, 3, 1, "", "bitwise_or_"], [166, 3, 1, "", "bitwise_right_shift"], [167, 3, 1, "", "bitwise_right_shift_"], [168, 3, 1, "", "bitwise_xor"], [169, 3, 1, "", "bitwise_xor_"], [170, 3, 1, "", "bmm"], [171, 3, 1, "", "bool"], [172, 3, 1, "", "broadcast_to"], [173, 3, 1, "", "byte"], [174, 3, 1, "", "cauchy_"], [175, 3, 1, "", "ccol_indices"], [176, 3, 1, "", "cdouble"], [177, 3, 1, "", "ceil"], [178, 3, 1, "", "ceil_"], [179, 3, 1, "", "cfloat"], [180, 3, 1, "", "chalf"], [181, 3, 1, "", "char"], [182, 3, 1, "", "cholesky"], [183, 3, 1, "", "cholesky_inverse"], [184, 3, 1, "", "cholesky_solve"], [185, 3, 1, "", "chunk"], [186, 3, 1, "", "clamp"], [187, 3, 1, "", "clamp_"], [188, 3, 1, "", "clip"], [189, 3, 1, "", "clip_"], [190, 3, 1, "", "clone"], [191, 3, 1, "", "coalesce"], [192, 3, 1, "", "col_indices"], [193, 3, 1, "", "conj"], [194, 3, 1, "", "conj_physical"], [195, 3, 1, "", "conj_physical_"], [196, 3, 1, "", "contiguous"], [197, 3, 1, "", "copy_"], [198, 3, 1, "", "copysign"], [199, 3, 1, "", "copysign_"], [200, 3, 1, "", "corrcoef"], [201, 3, 1, "", "cos"], [202, 3, 1, "", "cos_"], [203, 3, 1, "", "cosh"], [204, 3, 1, "", "cosh_"], [205, 3, 1, "", "count_nonzero"], [206, 3, 1, "", "cov"], [207, 3, 1, "", "cpu"], [208, 3, 1, "", "cross"], [209, 3, 1, "", "crow_indices"], [210, 3, 1, "", "cuda"], [211, 3, 1, "", "cummax"], [212, 3, 1, "", "cummin"], [213, 3, 1, "", "cumprod"], [214, 3, 1, "", "cumprod_"], [215, 3, 1, "", "cumsum"], [216, 3, 1, "", "cumsum_"], [217, 3, 1, "", "data_ptr"], [218, 3, 1, "", "deg2rad"], [219, 3, 1, "", "dense_dim"], [220, 3, 1, "", "dequantize"], [221, 3, 1, "", "det"], [222, 3, 1, "", "detach"], [223, 3, 1, "", "detach_"], [224, 2, 1, "", "device"], [225, 3, 1, "", "diag"], [226, 3, 1, "", "diag_embed"], [227, 3, 1, "", "diagflat"], [228, 3, 1, "", "diagonal"], [229, 3, 1, "", "diagonal_scatter"], [230, 3, 1, "", "diff"], [231, 3, 1, "", "digamma"], [232, 3, 1, "", "digamma_"], [233, 3, 1, "", "dim"], [234, 3, 1, "", "dist"], [235, 3, 1, "", "div"], [236, 3, 1, "", "div_"], [237, 3, 1, "", "divide"], [238, 3, 1, "", "divide_"], [239, 3, 1, "", "dot"], [240, 3, 1, "", "double"], [241, 3, 1, "", "dsplit"], [242, 3, 1, "", "element_size"], [243, 3, 1, "", "eq"], [244, 3, 1, "", "eq_"], [245, 3, 1, "", "equal"], [246, 3, 1, "", "erf"], [247, 3, 1, "", "erf_"], [248, 3, 1, "", "erfc"], [249, 3, 1, "", "erfc_"], [250, 3, 1, "", "erfinv"], [251, 3, 1, "", "erfinv_"], [252, 3, 1, "", "exp"], [253, 3, 1, "", "exp_"], [254, 3, 1, "", "expand"], [255, 3, 1, "", "expand_as"], [256, 3, 1, "", "expm1"], [257, 3, 1, "", "expm1_"], [258, 3, 1, "", "exponential_"], [259, 3, 1, "", "fill_"], [260, 3, 1, "", "fill_diagonal_"], [261, 3, 1, "", "fix"], [262, 3, 1, "", "fix_"], [263, 3, 1, "", "flatten"], [264, 3, 1, "", "flip"], [265, 3, 1, "", "fliplr"], [266, 3, 1, "", "flipud"], [267, 3, 1, "", "float"], [268, 3, 1, "", "float_power"], [269, 3, 1, "", "float_power_"], [270, 3, 1, "", "floor"], [271, 3, 1, "", "floor_"], [272, 3, 1, "", "floor_divide"], [273, 3, 1, "", "floor_divide_"], [274, 3, 1, "", "fmax"], [275, 3, 1, "", "fmin"], [276, 3, 1, "", "fmod"], [277, 3, 1, "", "fmod_"], [278, 3, 1, "", "frac"], [279, 3, 1, "", "frac_"], [280, 3, 1, "", "frexp"], [281, 3, 1, "", "gather"], [282, 3, 1, "", "gcd"], [283, 3, 1, "", "gcd_"], [284, 3, 1, "", "ge"], [285, 3, 1, "", "ge_"], [286, 3, 1, "", "geometric_"], [287, 3, 1, "", "geqrf"], [288, 3, 1, "", "ger"], [289, 3, 1, "", "get_device"], [290, 2, 1, "", "grad"], [291, 3, 1, "", "greater"], [292, 3, 1, "", "greater_"], [293, 3, 1, "", "greater_equal"], [294, 3, 1, "", "greater_equal_"], [295, 3, 1, "", "gt"], [296, 3, 1, "", "gt_"], [297, 3, 1, "", "half"], [298, 3, 1, "", "hardshrink"], [299, 3, 1, "", "heaviside"], [300, 3, 1, "", "histc"], [301, 3, 1, "", "histogram"], [302, 3, 1, "", "hsplit"], [303, 3, 1, "", "hypot"], [304, 3, 1, "", "hypot_"], [305, 3, 1, "", "i0"], [306, 3, 1, "", "i0_"], [307, 3, 1, "", "igamma"], [308, 3, 1, "", "igamma_"], [309, 3, 1, "", "igammac"], [310, 3, 1, "", "igammac_"], [311, 2, 1, "", "imag"], [312, 3, 1, "", "index_add"], [313, 3, 1, "", "index_add_"], [314, 3, 1, "", "index_copy"], [315, 3, 1, "", "index_copy_"], [316, 3, 1, "", "index_fill"], [317, 3, 1, "", "index_fill_"], [318, 3, 1, "", "index_put"], [319, 3, 1, "", "index_put_"], [320, 3, 1, "", "index_reduce"], [321, 3, 1, "", "index_reduce_"], [322, 3, 1, "", "index_select"], [323, 3, 1, "", "indices"], [324, 3, 1, "", "inner"], [325, 3, 1, "", "int"], [326, 3, 1, "", "int_repr"], [327, 3, 1, "", "inverse"], [328, 3, 1, "", "is_coalesced"], [329, 3, 1, "", "is_complex"], [330, 3, 1, "", "is_conj"], [331, 3, 1, "", "is_contiguous"], [332, 2, 1, "", "is_cuda"], [333, 3, 1, "", "is_floating_point"], [334, 3, 1, "", "is_inference"], [335, 2, 1, "", "is_leaf"], [336, 2, 1, "", "is_meta"], [337, 3, 1, "", "is_pinned"], [338, 2, 1, "", "is_quantized"], [339, 3, 1, "", "is_set_to"], [340, 3, 1, "", "is_shared"], [341, 3, 1, "", "is_signed"], [342, 2, 1, "", "is_sparse"], [343, 2, 1, "", "is_sparse_csr"], [344, 3, 1, "", "isclose"], [345, 3, 1, "", "isfinite"], [346, 3, 1, "", "isinf"], [347, 3, 1, "", "isnan"], [348, 3, 1, "", "isneginf"], [349, 3, 1, "", "isposinf"], [350, 3, 1, "", "isreal"], [351, 3, 1, "", "istft"], [352, 3, 1, "", "item"], [353, 2, 1, "", "itemsize"], [354, 3, 1, "", "kthvalue"], [355, 3, 1, "", "lcm"], [356, 3, 1, "", "lcm_"], [357, 3, 1, "", "ldexp"], [358, 3, 1, "", "ldexp_"], [359, 3, 1, "", "le"], [360, 3, 1, "", "le_"], [361, 3, 1, "", "lerp"], [362, 3, 1, "", "lerp_"], [363, 3, 1, "", "less"], [364, 3, 1, "", "less_"], [365, 3, 1, "", "less_equal"], [366, 3, 1, "", "less_equal_"], [367, 3, 1, "", "lgamma"], [368, 3, 1, "", "lgamma_"], [369, 3, 1, "", "log"], [370, 3, 1, "", "log10"], [371, 3, 1, "", "log10_"], [372, 3, 1, "", "log1p"], [373, 3, 1, "", "log1p_"], [374, 3, 1, "", "log2"], [375, 3, 1, "", "log2_"], [376, 3, 1, "", "log_"], [377, 3, 1, "", "log_normal_"], [378, 3, 1, "", "logaddexp"], [379, 3, 1, "", "logaddexp2"], [380, 3, 1, "", "logcumsumexp"], [381, 3, 1, "", "logdet"], [382, 3, 1, "", "logical_and"], [383, 3, 1, "", "logical_and_"], [384, 3, 1, "", "logical_not"], [385, 3, 1, "", "logical_not_"], [386, 3, 1, "", "logical_or"], [387, 3, 1, "", "logical_or_"], [388, 3, 1, "", "logical_xor"], [389, 3, 1, "", "logical_xor_"], [390, 3, 1, "", "logit"], [391, 3, 1, "", "logit_"], [392, 3, 1, "", "logsumexp"], [393, 3, 1, "", "long"], [394, 3, 1, "", "lt"], [395, 3, 1, "", "lt_"], [396, 3, 1, "", "lu"], [397, 3, 1, "", "lu_solve"], [1923, 2, 1, "", "mH"], [1923, 2, 1, "", "mT"], [398, 3, 1, "", "map_"], [399, 3, 1, "", "masked_fill"], [400, 3, 1, "", "masked_fill_"], [401, 3, 1, "", "masked_scatter"], [402, 3, 1, "", "masked_scatter_"], [403, 3, 1, "", "masked_select"], [404, 3, 1, "", "matmul"], [405, 3, 1, "", "matrix_exp"], [406, 3, 1, "", "matrix_power"], [407, 3, 1, "", "max"], [408, 3, 1, "", "maximum"], [409, 3, 1, "", "mean"], [410, 3, 1, "", "median"], [411, 3, 1, "", "min"], [412, 3, 1, "", "minimum"], [413, 3, 1, "", "mm"], [414, 3, 1, "", "mode"], [415, 3, 1, "", "moveaxis"], [416, 3, 1, "", "movedim"], [417, 3, 1, "", "msort"], [418, 3, 1, "", "mul"], [419, 3, 1, "", "mul_"], [420, 3, 1, "", "multinomial"], [421, 3, 1, "", "multiply"], [422, 3, 1, "", "multiply_"], [423, 3, 1, "", "mv"], [424, 3, 1, "", "mvlgamma"], [425, 3, 1, "", "mvlgamma_"], [1877, 2, 1, "", "names"], [426, 3, 1, "", "nan_to_num"], [427, 3, 1, "", "nan_to_num_"], [428, 3, 1, "", "nanmean"], [429, 3, 1, "", "nanmedian"], [430, 3, 1, "", "nanquantile"], [431, 3, 1, "", "nansum"], [432, 3, 1, "", "narrow"], [433, 3, 1, "", "narrow_copy"], [434, 2, 1, "", "nbytes"], [435, 2, 1, "", "ndim"], [436, 3, 1, "", "ndimension"], [437, 3, 1, "", "ne"], [438, 3, 1, "", "ne_"], [439, 3, 1, "", "neg"], [440, 3, 1, "", "neg_"], [441, 3, 1, "", "negative"], [442, 3, 1, "", "negative_"], [443, 3, 1, "", "nelement"], [444, 3, 1, "", "new_empty"], [445, 3, 1, "", "new_full"], [446, 3, 1, "", "new_ones"], [447, 3, 1, "", "new_tensor"], [448, 3, 1, "", "new_zeros"], [449, 3, 1, "", "nextafter"], [450, 3, 1, "", "nextafter_"], [451, 3, 1, "", "nonzero"], [452, 3, 1, "", "norm"], [453, 3, 1, "", "normal_"], [454, 3, 1, "", "not_equal"], [455, 3, 1, "", "not_equal_"], [456, 3, 1, "", "numel"], [457, 3, 1, "", "numpy"], [458, 3, 1, "", "orgqr"], [459, 3, 1, "", "ormqr"], [460, 3, 1, "", "outer"], [461, 3, 1, "", "permute"], [462, 3, 1, "", "pin_memory"], [463, 3, 1, "", "pinverse"], [464, 3, 1, "", "polygamma"], [465, 3, 1, "", "polygamma_"], [466, 3, 1, "", "positive"], [467, 3, 1, "", "pow"], [468, 3, 1, "", "pow_"], [469, 3, 1, "", "prod"], [470, 3, 1, "", "put_"], [471, 3, 1, "", "q_per_channel_axis"], [472, 3, 1, "", "q_per_channel_scales"], [473, 3, 1, "", "q_per_channel_zero_points"], [474, 3, 1, "", "q_scale"], [475, 3, 1, "", "q_zero_point"], [476, 3, 1, "", "qr"], [477, 3, 1, "", "qscheme"], [478, 3, 1, "", "quantile"], [479, 3, 1, "", "rad2deg"], [480, 3, 1, "", "random_"], [481, 3, 1, "", "ravel"], [482, 2, 1, "", "real"], [483, 3, 1, "", "reciprocal"], [484, 3, 1, "", "reciprocal_"], [485, 3, 1, "", "record_stream"], [1877, 3, 1, "", "refine_names"], [486, 3, 1, "", "register_hook"], [487, 3, 1, "", "remainder"], [488, 3, 1, "", "remainder_"], [1877, 3, 1, "", "rename"], [1877, 3, 1, "", "rename_"], [489, 3, 1, "", "renorm"], [490, 3, 1, "", "renorm_"], [491, 3, 1, "", "repeat"], [492, 3, 1, "", "repeat_interleave"], [493, 2, 1, "", "requires_grad"], [494, 3, 1, "", "requires_grad_"], [495, 3, 1, "", "reshape"], [496, 3, 1, "", "reshape_as"], [497, 3, 1, "", "resize_"], [498, 3, 1, "", "resize_as_"], [499, 3, 1, "", "resolve_conj"], [500, 3, 1, "", "resolve_neg"], [501, 3, 1, "", "retain_grad"], [502, 2, 1, "", "retains_grad"], [503, 3, 1, "", "roll"], [504, 3, 1, "", "rot90"], [505, 3, 1, "", "round"], [506, 3, 1, "", "round_"], [507, 3, 1, "", "row_indices"], [508, 3, 1, "", "rsqrt"], [509, 3, 1, "", "rsqrt_"], [510, 3, 1, "", "scatter"], [511, 3, 1, "", "scatter_"], [512, 3, 1, "", "scatter_add"], [513, 3, 1, "", "scatter_add_"], [514, 3, 1, "", "scatter_reduce"], [515, 3, 1, "", "scatter_reduce_"], [516, 3, 1, "", "select"], [517, 3, 1, "", "select_scatter"], [518, 3, 1, "", "set_"], [519, 3, 1, "", "sgn"], [520, 3, 1, "", "sgn_"], [521, 3, 1, "", "share_memory_"], [522, 3, 1, "", "short"], [523, 3, 1, "", "sigmoid"], [524, 3, 1, "", "sigmoid_"], [525, 3, 1, "", "sign"], [526, 3, 1, "", "sign_"], [527, 3, 1, "", "signbit"], [528, 3, 1, "", "sin"], [529, 3, 1, "", "sin_"], [530, 3, 1, "", "sinc"], [531, 3, 1, "", "sinc_"], [532, 3, 1, "", "sinh"], [533, 3, 1, "", "sinh_"], [534, 3, 1, "", "size"], [535, 3, 1, "", "slice_scatter"], [536, 3, 1, "", "slogdet"], [537, 3, 1, "", "smm"], [538, 3, 1, "", "softmax"], [539, 3, 1, "", "sort"], [540, 3, 1, "", "sparse_dim"], [541, 3, 1, "", "sparse_mask"], [542, 3, 1, "", "sparse_resize_"], [543, 3, 1, "", "sparse_resize_and_clear_"], [544, 3, 1, "", "split"], [545, 3, 1, "", "sqrt"], [546, 3, 1, "", "sqrt_"], [547, 3, 1, "", "square"], [548, 3, 1, "", "square_"], [549, 3, 1, "", "squeeze"], [550, 3, 1, "", "squeeze_"], [551, 3, 1, "", "sspaddmm"], [552, 3, 1, "", "std"], [553, 3, 1, "", "stft"], [554, 3, 1, "", "storage"], [555, 3, 1, "", "storage_offset"], [556, 3, 1, "", "storage_type"], [557, 3, 1, "", "stride"], [558, 3, 1, "", "sub"], [559, 3, 1, "", "sub_"], [560, 3, 1, "", "subtract"], [561, 3, 1, "", "subtract_"], [562, 3, 1, "", "sum"], [563, 3, 1, "", "sum_to_size"], [564, 3, 1, "", "svd"], [565, 3, 1, "", "swapaxes"], [566, 3, 1, "", "swapdims"], [567, 3, 1, "", "t"], [568, 3, 1, "", "t_"], [569, 3, 1, "", "take"], [570, 3, 1, "", "take_along_dim"], [571, 3, 1, "", "tan"], [572, 3, 1, "", "tan_"], [573, 3, 1, "", "tanh"], [574, 3, 1, "", "tanh_"], [575, 3, 1, "", "tensor_split"], [576, 3, 1, "", "tile"], [577, 3, 1, "", "to"], [578, 3, 1, "", "to_dense"], [579, 3, 1, "", "to_mkldnn"], [580, 3, 1, "", "to_sparse"], [581, 3, 1, "", "to_sparse_bsc"], [582, 3, 1, "", "to_sparse_bsr"], [583, 3, 1, "", "to_sparse_coo"], [584, 3, 1, "", "to_sparse_csc"], [585, 3, 1, "", "to_sparse_csr"], [586, 3, 1, "", "tolist"], [587, 3, 1, "", "topk"], [588, 3, 1, "", "trace"], [589, 3, 1, "", "transpose"], [590, 3, 1, "", "transpose_"], [591, 3, 1, "", "triangular_solve"], [592, 3, 1, "", "tril"], [593, 3, 1, "", "tril_"], [594, 3, 1, "", "triu"], [595, 3, 1, "", "triu_"], [596, 3, 1, "", "true_divide"], [597, 3, 1, "", "true_divide_"], [598, 3, 1, "", "trunc"], [599, 3, 1, "", "trunc_"], [600, 3, 1, "", "type"], [601, 3, 1, "", "type_as"], [602, 3, 1, "", "unbind"], [603, 3, 1, "", "unflatten"], [604, 3, 1, "", "unfold"], [605, 3, 1, "", "uniform_"], [606, 3, 1, "", "unique"], [607, 3, 1, "", "unique_consecutive"], [608, 3, 1, "", "unsqueeze"], [609, 3, 1, "", "unsqueeze_"], [610, 3, 1, "", "untyped_storage"], [611, 3, 1, "", "values"], [612, 3, 1, "", "var"], [613, 3, 1, "", "vdot"], [614, 3, 1, "", "view"], [615, 3, 1, "", "view_as"], [616, 3, 1, "", "vsplit"], [617, 3, 1, "", "where"], [618, 3, 1, "", "xlogy"], [619, 3, 1, "", "xlogy_"], [620, 3, 1, "", "zero_"]], "torch.TypedStorage": [[1919, 3, 1, "", "bfloat16"], [1919, 3, 1, "", "bool"], [1919, 3, 1, "", "byte"], [1919, 3, 1, "", "char"], [1919, 3, 1, "", "clone"], [1919, 3, 1, "", "complex_double"], [1919, 3, 1, "", "complex_float"], [1919, 3, 1, "", "copy_"], [1919, 3, 1, "", "cpu"], [1919, 3, 1, "", "cuda"], [1919, 3, 1, "", "data_ptr"], [1919, 4, 1, "", "device"], [1919, 3, 1, "", "double"], [1919, 2, 1, "", "dtype"], [1919, 3, 1, "", "element_size"], [1919, 3, 1, "", "fill_"], [1919, 3, 1, "", "float"], [1919, 3, 1, "", "from_buffer"], [1919, 3, 1, "", "from_file"], [1919, 3, 1, "", "get_device"], [1919, 3, 1, "", "half"], [1919, 3, 1, "", "int"], [1919, 4, 1, "", "is_cuda"], [1919, 3, 1, "", "is_pinned"], [1919, 3, 1, "", "is_shared"], [1919, 2, 1, "", "is_sparse"], [1919, 3, 1, "", "long"], [1919, 3, 1, "", "nbytes"], [1919, 3, 1, "", "pickle_storage_type"], [1919, 3, 1, "", "pin_memory"], [1919, 3, 1, "", "resize_"], [1919, 3, 1, "", "share_memory_"], [1919, 3, 1, "", "short"], [1919, 3, 1, "", "size"], [1919, 3, 1, "", "tolist"], [1919, 3, 1, "", "type"], [1919, 3, 1, "", "untyped"]], "torch.UntypedStorage": [[1919, 3, 1, "", "bfloat16"], [1919, 3, 1, "", "bool"], [1919, 3, 1, "", "byte"], [1919, 3, 1, "", "byteswap"], [1919, 3, 1, "", "char"], [1919, 3, 1, "", "clone"], [1919, 3, 1, "", "complex_double"], [1919, 3, 1, "", "complex_float"], [1919, 3, 1, "", "copy_"], [1919, 3, 1, "", "cpu"], [1919, 3, 1, "", "cuda"], [1919, 3, 1, "", "data_ptr"], [1919, 2, 1, "", "device"], [1919, 3, 1, "", "double"], [1919, 3, 1, "", "element_size"], [1919, 3, 1, "", "fill_"], [1919, 3, 1, "", "float"], [1919, 3, 1, "", "from_buffer"], [1919, 3, 1, "", "from_file"], [1919, 3, 1, "", "get_device"], [1919, 3, 1, "", "half"], [1919, 3, 1, "", "int"], [1919, 4, 1, "", "is_cuda"], [1919, 3, 1, "", "is_pinned"], [1919, 3, 1, "", "is_shared"], [1919, 2, 1, "", "is_sparse"], [1919, 2, 1, "", "is_sparse_csr"], [1919, 3, 1, "", "long"], [1919, 3, 1, "", "mps"], [1919, 3, 1, "", "nbytes"], [1919, 3, 1, "", "new"], [1919, 3, 1, "", "pin_memory"], [1919, 3, 1, "", "resize_"], [1919, 3, 1, "", "share_memory_"], [1919, 3, 1, "", "short"], [1919, 3, 1, "", "size"], [1919, 3, 1, "", "tolist"], [1919, 3, 1, "", "type"], [1919, 3, 1, "", "untyped"]], "torch.__config__": [[31, 5, 1, "", "parallel_info"], [31, 5, 1, "", "show"]], "torch._dynamo": [[0, 1, 1, "", "OptimizedModule"], [0, 5, 1, "", "allow_in_graph"], [0, 5, 1, "", "disable"], [0, 5, 1, "", "disallow_in_graph"], [0, 5, 1, "", "export"], [0, 5, 1, "", "forbid_in_graph"], [0, 5, 1, "", "graph_break"], [0, 5, 1, "", "list_backends"], [0, 5, 1, "", "mark_dynamic"], [0, 5, 1, "", "mark_static"], [0, 5, 1, "", "optimize"], [0, 5, 1, "", "optimize_assert"], [0, 5, 1, "", "register_backend"], [0, 5, 1, "", "reset"], [0, 5, 1, "", "run"]], "torch._logging": [[677, 5, 1, "", "set_logs"]], "torch.ao": [[1908, 0, 0, "-", "nn"], [1908, 0, 0, "-", "ns"], [1908, 0, 0, "-", "pruning"], [1908, 0, 0, "-", "quantization"]], "torch.ao.nn": [[1911, 0, 0, "-", "intrinsic"], [1911, 0, 0, "-", "qat"], [1908, 0, 0, "-", "quantizable"], [1908, 0, 0, "-", "quantized"], [1908, 0, 0, "-", "sparse"]], "torch.ao.nn.intrinsic": [[697, 1, 1, "", "BNReLU2d"], [698, 1, 1, "", "BNReLU3d"], [699, 1, 1, "", "ConvBn1d"], [700, 1, 1, "", "ConvBn2d"], [701, 1, 1, "", "ConvBn3d"], [702, 1, 1, "", "ConvBnReLU1d"], [703, 1, 1, "", "ConvBnReLU2d"], [704, 1, 1, "", "ConvBnReLU3d"], [705, 1, 1, "", "ConvReLU1d"], [706, 1, 1, "", "ConvReLU2d"], [707, 1, 1, "", "ConvReLU3d"], [708, 1, 1, "", "LinearReLU"], [1911, 0, 0, "-", "modules"], [1911, 0, 0, "-", "qat"], [1911, 0, 0, "-", "quantized"]], "torch.ao.nn.intrinsic.qat": [[709, 1, 1, "", "ConvBn1d"], [710, 1, 1, "", "ConvBn2d"], [711, 1, 1, "", "ConvBn3d"], [712, 1, 1, "", "ConvBnReLU1d"], [713, 1, 1, "", "ConvBnReLU2d"], [714, 1, 1, "", "ConvBnReLU3d"], [715, 1, 1, "", "ConvReLU2d"], [716, 1, 1, "", "ConvReLU3d"], [717, 1, 1, "", "LinearReLU"], [718, 1, 1, "", "freeze_bn_stats"], [1911, 0, 0, "-", "modules"], [719, 1, 1, "", "update_bn_stats"]], "torch.ao.nn.intrinsic.quantized": [[720, 1, 1, "", "BNReLU2d"], [721, 1, 1, "", "BNReLU3d"], [722, 1, 1, "", "ConvReLU1d"], [723, 1, 1, "", "ConvReLU2d"], [724, 1, 1, "", "ConvReLU3d"], [725, 1, 1, "", "LinearReLU"], [1911, 0, 0, "-", "dynamic"], [1911, 0, 0, "-", "modules"]], "torch.ao.nn.intrinsic.quantized.dynamic": [[726, 1, 1, "", "LinearReLU"], [1911, 0, 0, "-", "modules"]], "torch.ao.nn.qat": [[727, 1, 1, "", "Conv2d"], [728, 1, 1, "", "Conv3d"], [729, 1, 1, "", "Linear"], [1911, 0, 0, "-", "dynamic"], [1911, 0, 0, "-", "modules"]], "torch.ao.nn.qat.Linear": [[729, 3, 1, "", "from_float"]], "torch.ao.nn.qat.dynamic": [[730, 1, 1, "", "Linear"], [1911, 0, 0, "-", "modules"]], "torch.ao.nn.quantizable": [[731, 1, 1, "", "LSTM"], [732, 1, 1, "", "MultiheadAttention"], [1908, 0, 0, "-", "modules"]], "torch.ao.nn.quantizable.MultiheadAttention": [[732, 3, 1, "", "dequantize"], [732, 3, 1, "", "forward"]], "torch.ao.nn.quantized": [[733, 1, 1, "", "BatchNorm2d"], [734, 1, 1, "", "BatchNorm3d"], [735, 1, 1, "", "Conv1d"], [736, 1, 1, "", "Conv2d"], [737, 1, 1, "", "Conv3d"], [738, 1, 1, "", "ConvTranspose1d"], [739, 1, 1, "", "ConvTranspose2d"], [740, 1, 1, "", "ConvTranspose3d"], [741, 1, 1, "", "ELU"], [742, 1, 1, "", "Embedding"], [743, 1, 1, "", "EmbeddingBag"], [744, 1, 1, "", "FXFloatFunctional"], [745, 1, 1, "", "FloatFunctional"], [746, 1, 1, "", "GroupNorm"], [747, 1, 1, "", "Hardswish"], [748, 1, 1, "", "InstanceNorm1d"], [749, 1, 1, "", "InstanceNorm2d"], [750, 1, 1, "", "InstanceNorm3d"], [751, 1, 1, "", "LayerNorm"], [752, 1, 1, "", "LeakyReLU"], [753, 1, 1, "", "Linear"], [754, 1, 1, "", "QFunctional"], [755, 1, 1, "", "ReLU6"], [756, 1, 1, "", "Sigmoid"], [1911, 0, 0, "-", "dynamic"], [1911, 0, 0, "-", "functional"], [1911, 0, 0, "-", "modules"], [1908, 0, 0, "-", "reference"]], "torch.ao.nn.quantized.Conv1d": [[735, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Conv2d": [[736, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Conv3d": [[737, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Embedding": [[742, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.EmbeddingBag": [[743, 3, 1, "", "from_float"]], "torch.ao.nn.quantized.Linear": [[753, 3, 1, "", "from_float"], [753, 3, 1, "", "from_reference"]], "torch.ao.nn.quantized.dynamic": [[757, 1, 1, "", "GRU"], [758, 1, 1, "", "GRUCell"], [759, 1, 1, "", "LSTM"], [760, 1, 1, "", "LSTMCell"], [761, 1, 1, "", "Linear"], [762, 1, 1, "", "RNNCell"], [1911, 0, 0, "-", "modules"]], "torch.ao.nn.quantized.dynamic.Linear": [[761, 3, 1, "", "from_float"], [761, 3, 1, "", "from_reference"]], "torch.ao.nn.quantized.functional": [[763, 1, 1, "", "adaptive_avg_pool2d"], [764, 1, 1, "", "adaptive_avg_pool3d"], [765, 1, 1, "", "avg_pool2d"], [766, 1, 1, "", "avg_pool3d"], [767, 1, 1, "", "celu"], [768, 1, 1, "", "clamp"], [769, 1, 1, "", "conv1d"], [770, 1, 1, "", "conv2d"], [771, 1, 1, "", "conv3d"], [772, 1, 1, "", "elu"], [773, 1, 1, "", "hardsigmoid"], [774, 1, 1, "", "hardswish"], [775, 1, 1, "", "hardtanh"], [776, 1, 1, "", "interpolate"], [777, 1, 1, "", "leaky_relu"], [778, 1, 1, "", "linear"], [779, 1, 1, "", "max_pool1d"], [780, 1, 1, "", "max_pool2d"], [781, 1, 1, "", "threshold"], [782, 1, 1, "", "upsample"], [783, 1, 1, "", "upsample_bilinear"], [784, 1, 1, "", "upsample_nearest"]], "torch.ao.nn.quantized.reference": [[1908, 0, 0, "-", "modules"]], "torch.ao.nn.sparse": [[1908, 0, 0, "-", "quantized"]], "torch.ao.nn.sparse.quantized": [[1908, 0, 0, "-", "dynamic"]], "torch.ao.ns": [[1926, 0, 0, "-", "_numeric_suite"], [1927, 0, 0, "-", "_numeric_suite_fx"], [1908, 0, 0, "-", "fx"]], "torch.ao.ns._numeric_suite": [[1926, 1, 1, "", "Logger"], [1926, 1, 1, "", "OutputLogger"], [1926, 1, 1, "", "Shadow"], [1926, 1, 1, "", "ShadowLogger"], [1926, 5, 1, "", "compare_model_outputs"], [1926, 5, 1, "", "compare_model_stub"], [1926, 5, 1, "", "compare_weights"], [1926, 5, 1, "", "get_logger_dict"], [1926, 5, 1, "", "get_matching_activations"], [1926, 5, 1, "", "prepare_model_outputs"], [1926, 5, 1, "", "prepare_model_with_stubs"]], "torch.ao.ns._numeric_suite.Logger": [[1926, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.OutputLogger": [[1926, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite.Shadow": [[1926, 3, 1, "", "add"], [1926, 3, 1, "", "add_relu"], [1926, 3, 1, "", "add_scalar"], [1926, 3, 1, "", "cat"], [1926, 3, 1, "", "forward"], [1926, 3, 1, "", "mul"], [1926, 3, 1, "", "mul_scalar"]], "torch.ao.ns._numeric_suite.ShadowLogger": [[1926, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite_fx": [[1927, 1, 1, "", "NSTracer"], [1927, 1, 1, "", "OutputComparisonLogger"], [1927, 1, 1, "", "OutputLogger"], [1927, 5, 1, "", "add_loggers"], [1927, 5, 1, "", "add_shadow_loggers"], [1927, 5, 1, "", "convert_n_shadows_model"], [1927, 5, 1, "", "extend_logger_results_with_comparison"], [1927, 5, 1, "", "extract_logger_info"], [1927, 5, 1, "", "extract_results_n_shadows_model"], [1927, 5, 1, "", "extract_shadow_logger_info"], [1927, 5, 1, "", "extract_weights"], [1927, 5, 1, "", "loggers_set_enabled"], [1927, 5, 1, "", "loggers_set_save_activations"], [1927, 5, 1, "", "prepare_n_shadows_model"], [1927, 5, 1, "", "print_comparisons_n_shadows_model"]], "torch.ao.ns._numeric_suite_fx.NSTracer": [[1927, 3, 1, "", "is_leaf_module"]], "torch.ao.ns._numeric_suite_fx.OutputComparisonLogger": [[1927, 3, 1, "", "forward"]], "torch.ao.ns._numeric_suite_fx.OutputLogger": [[1927, 3, 1, "", "forward"]], "torch.ao.ns.fx.utils": [[1927, 5, 1, "", "compute_cosine_similarity"], [1927, 5, 1, "", "compute_normalized_l2_error"], [1927, 5, 1, "", "compute_sqnr"]], "torch.ao.pruning": [[1908, 0, 0, "-", "scheduler"], [1908, 0, 0, "-", "sparsifier"]], "torch.ao.quantization": [[785, 1, 1, "", "DeQuantStub"], [786, 1, 1, "", "QuantStub"], [787, 1, 1, "", "QuantWrapper"], [788, 1, 1, "", "add_quant_dequant"], [1908, 0, 0, "-", "backend_config"], [794, 1, 1, "", "convert"], [795, 1, 1, "", "default_eval_fn"], [811, 1, 1, "", "fuse_modules"], [1908, 0, 0, "-", "fx"], [835, 1, 1, "", "prepare"], [836, 1, 1, "", "prepare_qat"], [837, 1, 1, "", "propagate_qconfig_"], [854, 1, 1, "", "quantize"], [855, 1, 1, "", "quantize_dynamic"], [860, 1, 1, "", "quantize_qat"], [861, 1, 1, "", "swap_module"]], "torch.ao.quantization.backend_config": [[789, 1, 1, "", "BackendConfig"], [790, 1, 1, "", "BackendPatternConfig"], [791, 1, 1, "", "DTypeConfig"], [792, 1, 1, "", "DTypeWithConstraints"], [793, 1, 1, "", "ObservationType"]], "torch.ao.quantization.backend_config.BackendConfig": [[789, 4, 1, "", "configs"], [789, 3, 1, "", "from_dict"], [789, 3, 1, "", "set_backend_pattern_config"], [789, 3, 1, "", "set_backend_pattern_configs"], [789, 3, 1, "", "set_name"], [789, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.BackendPatternConfig": [[790, 3, 1, "", "add_dtype_config"], [790, 3, 1, "", "from_dict"], [790, 3, 1, "", "set_dtype_configs"], [790, 3, 1, "", "set_fused_module"], [790, 3, 1, "", "set_fuser_method"], [790, 3, 1, "", "set_observation_type"], [790, 3, 1, "", "set_pattern"], [790, 3, 1, "", "set_qat_module"], [790, 3, 1, "", "set_reference_quantized_module"], [790, 3, 1, "", "set_root_module"], [790, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.DTypeConfig": [[791, 3, 1, "", "from_dict"], [791, 3, 1, "", "to_dict"]], "torch.ao.quantization.backend_config.ObservationType": [[793, 2, 1, "", "INPUT_OUTPUT_NOT_OBSERVED"], [793, 2, 1, "", "OUTPUT_SHARE_OBSERVER_WITH_INPUT"], [793, 2, 1, "", "OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT"]], "torch.ao.quantization.fake_quantize": [[796, 1, 1, "", "FakeQuantize"], [797, 1, 1, "", "FakeQuantizeBase"], [798, 1, 1, "", "FixedQParamsFakeQuantize"], [799, 1, 1, "", "FusedMovingAvgObsFakeQuantize"], [800, 2, 1, "", "default_fake_quant"], [801, 2, 1, "", "default_fused_act_fake_quant"], [802, 2, 1, "", "default_fused_per_channel_wt_fake_quant"], [803, 2, 1, "", "default_fused_wt_fake_quant"], [804, 2, 1, "", "default_histogram_fake_quant"], [805, 2, 1, "", "default_per_channel_weight_fake_quant"], [806, 2, 1, "", "default_weight_fake_quant"], [807, 1, 1, "", "disable_fake_quant"], [808, 1, 1, "", "disable_observer"], [809, 1, 1, "", "enable_fake_quant"], [810, 1, 1, "", "enable_observer"]], "torch.ao.quantization.fx.custom_config": [[812, 1, 1, "", "ConvertCustomConfig"], [813, 1, 1, "", "FuseCustomConfig"], [814, 1, 1, "", "PrepareCustomConfig"], [815, 1, 1, "", "StandaloneModuleConfigEntry"]], "torch.ao.quantization.fx.custom_config.ConvertCustomConfig": [[812, 3, 1, "", "from_dict"], [812, 3, 1, "", "set_observed_to_quantized_mapping"], [812, 3, 1, "", "set_preserved_attributes"], [812, 3, 1, "", "to_dict"]], "torch.ao.quantization.fx.custom_config.FuseCustomConfig": [[813, 3, 1, "", "from_dict"], [813, 3, 1, "", "set_preserved_attributes"], [813, 3, 1, "", "to_dict"]], "torch.ao.quantization.fx.custom_config.PrepareCustomConfig": [[814, 3, 1, "", "from_dict"], [814, 3, 1, "", "set_float_to_observed_mapping"], [814, 3, 1, "", "set_input_quantized_indexes"], [814, 3, 1, "", "set_non_traceable_module_classes"], [814, 3, 1, "", "set_non_traceable_module_names"], [814, 3, 1, "", "set_output_quantized_indexes"], [814, 3, 1, "", "set_preserved_attributes"], [814, 3, 1, "", "set_standalone_module_class"], [814, 3, 1, "", "set_standalone_module_name"], [814, 3, 1, "", "to_dict"]], "torch.ao.quantization.observer": [[816, 1, 1, "", "HistogramObserver"], [817, 1, 1, "", "MinMaxObserver"], [818, 1, 1, "", "MovingAverageMinMaxObserver"], [819, 1, 1, "", "MovingAveragePerChannelMinMaxObserver"], [820, 1, 1, "", "NoopObserver"], [821, 1, 1, "", "ObserverBase"], [822, 1, 1, "", "PerChannelMinMaxObserver"], [823, 1, 1, "", "PlaceholderObserver"], [824, 1, 1, "", "RecordingObserver"], [825, 2, 1, "", "default_debug_observer"], [826, 2, 1, "", "default_dynamic_quant_observer"], [827, 2, 1, "", "default_float_qparams_observer"], [828, 2, 1, "", "default_histogram_observer"], [829, 2, 1, "", "default_observer"], [830, 2, 1, "", "default_per_channel_weight_observer"], [831, 2, 1, "", "default_placeholder_observer"], [832, 2, 1, "", "default_weight_observer"], [833, 1, 1, "", "get_observer_state_dict"], [834, 1, 1, "", "load_observer_state_dict"]], "torch.ao.quantization.observer.MinMaxObserver": [[817, 3, 1, "", "calculate_qparams"], [817, 3, 1, "", "forward"], [817, 3, 1, "", "reset_min_max_vals"]], "torch.ao.quantization.observer.ObserverBase": [[821, 3, 1, "", "with_args"], [821, 3, 1, "", "with_callable_args"]], "torch.ao.quantization.observer.PerChannelMinMaxObserver": [[822, 3, 1, "", "reset_min_max_vals"]], "torch.ao.quantization.qconfig": [[838, 1, 1, "", "QConfig"], [839, 2, 1, "", "default_activation_only_qconfig"], [840, 2, 1, "", "default_debug_qconfig"], [841, 2, 1, "", "default_dynamic_qconfig"], [842, 2, 1, "", "default_per_channel_qconfig"], [843, 2, 1, "", "default_qat_qconfig"], [844, 2, 1, "", "default_qat_qconfig_v2"], [845, 2, 1, "", "default_qconfig"], [846, 2, 1, "", "default_weight_only_qconfig"], [847, 2, 1, "", "float16_dynamic_qconfig"], [848, 2, 1, "", "float16_static_qconfig"], [849, 2, 1, "", "float_qparams_weight_only_qconfig"], [850, 2, 1, "", "per_channel_dynamic_qconfig"]], "torch.ao.quantization.qconfig_mapping": [[851, 1, 1, "", "QConfigMapping"], [852, 1, 1, "", "get_default_qat_qconfig_mapping"], [853, 1, 1, "", "get_default_qconfig_mapping"]], "torch.ao.quantization.qconfig_mapping.QConfigMapping": [[851, 3, 1, "", "from_dict"], [851, 3, 1, "", "set_global"], [851, 3, 1, "", "set_module_name"], [851, 3, 1, "", "set_module_name_object_type_order"], [851, 3, 1, "", "set_module_name_regex"], [851, 3, 1, "", "set_object_type"], [851, 3, 1, "", "to_dict"]], "torch.ao.quantization.quantize_fx": [[856, 1, 1, "", "convert_fx"], [857, 1, 1, "", "fuse_fx"], [858, 1, 1, "", "prepare_fx"], [859, 1, 1, "", "prepare_qat_fx"]], "torch.autograd": [[2, 1, 1, "", "Function"], [890, 5, 1, "", "backward"], [2, 1, 1, "", "detect_anomaly"], [904, 5, 1, "", "grad"], [905, 5, 1, "", "gradcheck"], [906, 5, 1, "", "gradgradcheck"], [2, 1, 1, "", "set_detect_anomaly"], [917, 1, 1, "", "set_multithreading_enabled"]], "torch.autograd.Function": [[886, 3, 1, "", "backward"], [887, 3, 1, "", "forward"], [888, 3, 1, "", "jvp"], [889, 3, 1, "", "vmap"]], "torch.autograd.forward_ad": [[891, 1, 1, "", "dual_level"], [892, 5, 1, "", "make_dual"], [893, 5, 1, "", "unpack_dual"]], "torch.autograd.function.FunctionCtx": [[894, 3, 1, "", "mark_dirty"], [895, 3, 1, "", "mark_non_differentiable"], [896, 3, 1, "", "save_for_backward"], [897, 3, 1, "", "set_materialize_grads"]], "torch.autograd.functional": [[898, 5, 1, "", "hessian"], [899, 5, 1, "", "hvp"], [900, 5, 1, "", "jacobian"], [901, 5, 1, "", "jvp"], [902, 5, 1, "", "vhp"], [903, 5, 1, "", "vjp"]], "torch.autograd.graph.Node": [[907, 3, 1, "", "metadata"], [908, 3, 1, "", "name"], [909, 4, 1, "", "next_functions"], [910, 3, 1, "", "register_hook"], [911, 3, 1, "", "register_prehook"]], "torch.autograd.graph": [[2, 1, 1, "", "allow_mutation_on_saved_tensors"], [2, 1, 1, "", "disable_saved_tensors_hooks"], [2, 1, 1, "", "register_multi_grad_hook"], [2, 1, 1, "", "save_on_cpu"], [2, 1, 1, "", "saved_tensors_hooks"]], "torch.autograd.profiler": [[2, 1, 1, "", "emit_itt"], [2, 1, 1, "", "emit_nvtx"], [912, 5, 1, "", "load_nvprof"], [2, 1, 1, "", "profile"]], "torch.autograd.profiler.profile": [[913, 3, 1, "", "export_chrome_trace"], [914, 3, 1, "", "key_averages"], [915, 4, 1, "", "self_cpu_time_total"], [916, 3, 1, "", "total_average"]], "torch.backends": [[3, 0, 0, "-", "cpu"], [3, 0, 0, "-", "cuda"], [3, 0, 0, "-", "cudnn"], [3, 0, 0, "-", "mkl"], [3, 0, 0, "-", "mkldnn"], [3, 0, 0, "-", "mps"], [3, 0, 0, "-", "openmp"], [3, 0, 0, "-", "opt_einsum"], [3, 0, 0, "-", "quantized"], [3, 0, 0, "-", "xeon"], [3, 0, 0, "-", "xnnpack"]], "torch.backends.cpu": [[3, 5, 1, "", "get_cpu_capability"]], "torch.backends.cuda": [[3, 1, 1, "", "SDPBackend"], [3, 2, 1, "", "cufft_plan_cache"], [3, 5, 1, "", "enable_flash_sdp"], [3, 5, 1, "", "enable_math_sdp"], [3, 5, 1, "", "enable_mem_efficient_sdp"], [3, 5, 1, "", "flash_sdp_enabled"], [3, 5, 1, "", "is_built"], [3, 5, 1, "", "math_sdp_enabled"], [3, 5, 1, "", "mem_efficient_sdp_enabled"], [3, 5, 1, "", "preferred_linalg_library"], [3, 5, 1, "", "sdp_kernel"]], "torch.backends.cuda.cufft_plan_cache": [[3, 3, 1, "", "clear"], [3, 2, 1, "", "max_size"], [3, 2, 1, "", "size"]], "torch.backends.cuda.matmul": [[3, 2, 1, "", "allow_bf16_reduced_precision_reduction"], [3, 2, 1, "", "allow_fp16_reduced_precision_reduction"], [3, 2, 1, "", "allow_tf32"]], "torch.backends.cudnn": [[3, 2, 1, "", "allow_tf32"], [3, 2, 1, "", "benchmark"], [3, 2, 1, "", "benchmark_limit"], [3, 2, 1, "", "deterministic"], [3, 2, 1, "", "enabled"], [3, 5, 1, "", "is_available"], [3, 5, 1, "", "version"]], "torch.backends.mkl": [[3, 5, 1, "", "is_available"], [3, 1, 1, "", "verbose"]], "torch.backends.mkldnn": [[3, 5, 1, "", "is_available"], [3, 1, 1, "", "verbose"]], "torch.backends.mps": [[3, 5, 1, "", "is_available"], [3, 5, 1, "", "is_built"]], "torch.backends.openmp": [[3, 5, 1, "", "is_available"]], "torch.backends.opt_einsum": [[3, 2, 1, "", "enabled"], [3, 5, 1, "", "get_opt_einsum"], [3, 5, 1, "", "is_available"], [3, 2, 1, "", "strategy"]], "torch.cpu": [[1, 0, 0, "-", "amp"]], "torch.cpu.amp": [[1, 1, 1, "", "autocast"]], "torch.cuda": [[964, 1, 1, "", "CUDAGraph"], [965, 1, 1, "", "CUDAPluggableAllocator"], [966, 1, 1, "", "Event"], [967, 1, 1, "", "ExternalStream"], [968, 6, 1, "", "OutOfMemoryError"], [969, 1, 1, "", "Stream"], [970, 1, 1, "", "StreamContext"], [35, 0, 0, "-", "_sanitizer"], [1, 0, 0, "-", "amp"], [971, 5, 1, "", "caching_allocator_alloc"], [972, 5, 1, "", "caching_allocator_delete"], [973, 5, 1, "", "can_device_access_peer"], [974, 5, 1, "", "change_current_allocator"], [975, 5, 1, "", "clock_rate"], [981, 5, 1, "", "current_blas_handle"], [982, 5, 1, "", "current_device"], [983, 5, 1, "", "current_stream"], [984, 5, 1, "", "default_stream"], [985, 1, 1, "", "device"], [986, 5, 1, "", "device_count"], [987, 1, 1, "", "device_of"], [988, 5, 1, "", "empty_cache"], [989, 5, 1, "", "get_allocator_backend"], [990, 5, 1, "", "get_arch_list"], [991, 5, 1, "", "get_device_capability"], [992, 5, 1, "", "get_device_name"], [993, 5, 1, "", "get_device_properties"], [994, 5, 1, "", "get_gencode_flags"], [995, 5, 1, "", "get_rng_state"], [996, 5, 1, "", "get_rng_state_all"], [997, 5, 1, "", "get_sync_debug_mode"], [998, 1, 1, "", "graph"], [999, 5, 1, "", "graph_pool_handle"], [1000, 5, 1, "", "init"], [1001, 5, 1, "", "initial_seed"], [1002, 5, 1, "", "ipc_collect"], [1003, 5, 1, "", "is_available"], [1004, 5, 1, "", "is_current_stream_capturing"], [1005, 5, 1, "", "is_initialized"], [1008, 5, 1, "", "list_gpu_processes"], [1009, 5, 1, "", "make_graphed_callables"], [1010, 5, 1, "", "manual_seed"], [1011, 5, 1, "", "manual_seed_all"], [1012, 5, 1, "", "max_memory_allocated"], [1013, 5, 1, "", "max_memory_cached"], [1014, 5, 1, "", "max_memory_reserved"], [1015, 5, 1, "", "mem_get_info"], [1016, 5, 1, "", "memory_allocated"], [1017, 5, 1, "", "memory_cached"], [1018, 5, 1, "", "memory_reserved"], [1019, 5, 1, "", "memory_snapshot"], [1020, 5, 1, "", "memory_stats"], [1021, 5, 1, "", "memory_summary"], [1022, 5, 1, "", "memory_usage"], [1026, 5, 1, "", "power_draw"], [1027, 5, 1, "", "reset_max_memory_allocated"], [1028, 5, 1, "", "reset_max_memory_cached"], [1029, 5, 1, "", "reset_peak_memory_stats"], [1030, 5, 1, "", "seed"], [1031, 5, 1, "", "seed_all"], [1032, 5, 1, "", "set_device"], [1033, 5, 1, "", "set_per_process_memory_fraction"], [1034, 5, 1, "", "set_rng_state"], [1035, 5, 1, "", "set_rng_state_all"], [1036, 5, 1, "", "set_stream"], [1037, 5, 1, "", "set_sync_debug_mode"], [1038, 5, 1, "", "stream"], [1039, 5, 1, "", "synchronize"], [1040, 5, 1, "", "temperature"], [1041, 5, 1, "", "utilization"]], "torch.cuda.CUDAGraph": [[964, 3, 1, "", "capture_begin"], [964, 3, 1, "", "capture_end"], [964, 3, 1, "", "debug_dump"], [964, 3, 1, "", "enable_debug_mode"], [964, 3, 1, "", "pool"], [964, 3, 1, "", "replay"], [964, 3, 1, "", "reset"]], "torch.cuda.Event": [[966, 3, 1, "", "elapsed_time"], [966, 3, 1, "", "from_ipc_handle"], [966, 3, 1, "", "ipc_handle"], [966, 3, 1, "", "query"], [966, 3, 1, "", "record"], [966, 3, 1, "", "synchronize"], [966, 3, 1, "", "wait"]], "torch.cuda.ExternalStream": [[967, 3, 1, "", "query"], [967, 3, 1, "", "record_event"], [967, 3, 1, "", "synchronize"], [967, 3, 1, "", "wait_event"], [967, 3, 1, "", "wait_stream"]], "torch.cuda.Stream": [[969, 3, 1, "", "query"], [969, 3, 1, "", "record_event"], [969, 3, 1, "", "synchronize"], [969, 3, 1, "", "wait_event"], [969, 3, 1, "", "wait_stream"]], "torch.cuda._sanitizer": [[35, 5, 1, "", "enable_cuda_sanitizer"]], "torch.cuda.amp": [[1, 1, 1, "", "GradScaler"], [1, 1, 1, "", "autocast"], [1, 5, 1, "", "custom_bwd"], [1, 5, 1, "", "custom_fwd"]], "torch.cuda.amp.GradScaler": [[1, 3, 1, "", "get_backoff_factor"], [1, 3, 1, "", "get_growth_factor"], [1, 3, 1, "", "get_growth_interval"], [1, 3, 1, "", "get_scale"], [1, 3, 1, "", "is_enabled"], [1, 3, 1, "", "load_state_dict"], [1, 3, 1, "", "scale"], [1, 3, 1, "", "set_backoff_factor"], [1, 3, 1, "", "set_growth_factor"], [1, 3, 1, "", "set_growth_interval"], [1, 3, 1, "", "state_dict"], [1, 3, 1, "", "step"], [1, 3, 1, "", "unscale_"], [1, 3, 1, "", "update"]], "torch.cuda.comm": [[976, 5, 1, "", "broadcast"], [977, 5, 1, "", "broadcast_coalesced"], [978, 5, 1, "", "gather"], [979, 5, 1, "", "reduce_add"], [980, 5, 1, "", "scatter"]], "torch.cuda.jiterator": [[1006, 5, 1, "", "_create_jit_fn"], [1007, 5, 1, "", "_create_multi_output_jit_fn"]], "torch.cuda.nvtx": [[1023, 5, 1, "", "mark"], [1024, 5, 1, "", "range_pop"], [1025, 5, 1, "", "range_push"]], "torch.distributed": [[41, 1, 1, "", "Backend"], [41, 1, 1, "", "DistBackendError"], [41, 1, 1, "", "FileStore"], [39, 1, 1, "", "GradBucket"], [41, 1, 1, "", "HashStore"], [41, 1, 1, "", "P2POp"], [41, 1, 1, "", "PrefixStore"], [41, 1, 1, "", "ReduceOp"], [41, 1, 1, "", "Store"], [41, 1, 1, "", "TCPStore"], [41, 0, 0, "-", "algorithms"], [41, 5, 1, "", "all_gather"], [41, 5, 1, "", "all_gather_into_tensor"], [41, 5, 1, "", "all_gather_multigpu"], [41, 5, 1, "", "all_gather_object"], [41, 5, 1, "", "all_reduce"], [41, 5, 1, "", "all_reduce_multigpu"], [41, 5, 1, "", "all_to_all"], [41, 5, 1, "", "all_to_all_single"], [1913, 0, 0, "-", "autograd"], [41, 5, 1, "", "barrier"], [41, 5, 1, "", "batch_isend_irecv"], [41, 5, 1, "", "broadcast"], [41, 5, 1, "", "broadcast_multigpu"], [41, 5, 1, "", "broadcast_object_list"], [43, 0, 0, "-", "checkpoint"], [41, 0, 0, "-", "elastic"], [63, 0, 0, "-", "fsdp"], [41, 5, 1, "", "gather"], [41, 5, 1, "", "gather_object"], [41, 5, 1, "", "get_backend"], [41, 5, 1, "", "get_global_rank"], [41, 5, 1, "", "get_group_rank"], [41, 5, 1, "", "get_process_group_ranks"], [41, 5, 1, "", "get_rank"], [41, 5, 1, "", "get_world_size"], [41, 5, 1, "", "init_process_group"], [41, 5, 1, "", "irecv"], [41, 5, 1, "", "is_available"], [41, 5, 1, "", "is_gloo_available"], [41, 5, 1, "", "is_initialized"], [41, 5, 1, "", "is_mpi_available"], [41, 5, 1, "", "is_nccl_available"], [41, 5, 1, "", "is_torchelastic_launched"], [41, 5, 1, "", "isend"], [41, 0, 0, "-", "launch"], [41, 0, 0, "-", "launcher"], [41, 5, 1, "", "monitored_barrier"], [41, 5, 1, "", "new_group"], [41, 0, 0, "-", "nn"], [45, 0, 0, "-", "optim"], [41, 0, 0, "-", "pipeline"], [41, 5, 1, "", "recv"], [41, 5, 1, "", "reduce"], [41, 5, 1, "", "reduce_multigpu"], [41, 1, 1, "", "reduce_op"], [41, 5, 1, "", "reduce_scatter"], [41, 5, 1, "", "reduce_scatter_multigpu"], [41, 5, 1, "", "reduce_scatter_tensor"], [1913, 0, 0, "-", "rpc"], [59, 0, 0, "-", "run"], [41, 5, 1, "", "scatter"], [41, 5, 1, "", "scatter_object_list"], [41, 5, 1, "", "send"], [41, 0, 0, "-", "tensor"]], "torch.distributed.Backend": [[41, 3, 1, "", "register_backend"]], "torch.distributed.GradBucket": [[39, 5, 1, "", "buffer"], [39, 5, 1, "", "gradients"], [39, 5, 1, "", "index"], [39, 5, 1, "", "is_last"], [39, 5, 1, "", "parameters"], [39, 5, 1, "", "set_buffer"]], "torch.distributed.Store": [[41, 5, 1, "", "add"], [41, 5, 1, "", "compare_set"], [41, 5, 1, "", "delete_key"], [41, 5, 1, "", "get"], [41, 5, 1, "", "num_keys"], [41, 5, 1, "", "set"], [41, 5, 1, "", "set_timeout"], [41, 5, 1, "", "wait"]], "torch.distributed.algorithms": [[42, 1, 1, "", "Join"], [42, 1, 1, "", "JoinHook"], [42, 1, 1, "", "Joinable"], [41, 0, 0, "-", "ddp_comm_hooks"], [41, 0, 0, "-", "model_averaging"]], "torch.distributed.algorithms.Join": [[42, 3, 1, "", "notify_join_context"]], "torch.distributed.algorithms.JoinHook": [[42, 3, 1, "", "main_hook"], [42, 3, 1, "", "post_hook"]], "torch.distributed.algorithms.Joinable": [[42, 4, 1, "", "join_device"], [42, 3, 1, "", "join_hook"], [42, 4, 1, "", "join_process_group"]], "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks": [[39, 5, 1, "", "noop_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.default_hooks": [[39, 5, 1, "", "allreduce_hook"], [39, 5, 1, "", "bf16_compress_hook"], [39, 5, 1, "", "bf16_compress_wrapper"], [39, 5, 1, "", "fp16_compress_hook"], [39, 5, 1, "", "fp16_compress_wrapper"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook": [[39, 1, 1, "", "PowerSGDState"], [39, 5, 1, "", "batched_powerSGD_hook"], [39, 5, 1, "", "powerSGD_hook"]], "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState": [[39, 3, 1, "", "__getstate__"], [39, 3, 1, "", "__setstate__"]], "torch.distributed.autograd": [[1913, 5, 1, "", "backward"], [1913, 1, 1, "", "context"], [1913, 5, 1, "", "get_gradients"]], "torch.distributed.checkpoint": [[43, 1, 1, "", "DefaultLoadPlanner"], [43, 1, 1, "", "DefaultSavePlanner"], [43, 1, 1, "", "FileSystemReader"], [43, 1, 1, "", "FileSystemWriter"], [43, 1, 1, "", "LoadPlan"], [43, 1, 1, "", "LoadPlanner"], [43, 1, 1, "", "ReadItem"], [43, 1, 1, "", "SavePlan"], [43, 1, 1, "", "SavePlanner"], [43, 1, 1, "", "StorageReader"], [43, 1, 1, "", "StorageWriter"], [43, 1, 1, "", "WriteItem"], [43, 5, 1, "", "load_state_dict"], [43, 5, 1, "", "save_state_dict"]], "torch.distributed.checkpoint.DefaultLoadPlanner": [[43, 3, 1, "", "lookup_tensor"], [43, 3, 1, "", "transform_tensor"]], "torch.distributed.checkpoint.DefaultSavePlanner": [[43, 3, 1, "", "lookup_object"], [43, 3, 1, "", "transform_object"]], "torch.distributed.checkpoint.LoadPlanner": [[43, 3, 1, "", "commit_tensor"], [43, 3, 1, "", "create_global_plan"], [43, 3, 1, "", "create_local_plan"], [43, 3, 1, "", "finish_plan"], [43, 3, 1, "", "load_bytes"], [43, 3, 1, "", "resolve_tensor"], [43, 3, 1, "", "set_up_planner"]], "torch.distributed.checkpoint.SavePlanner": [[43, 3, 1, "", "create_global_plan"], [43, 3, 1, "", "create_local_plan"], [43, 3, 1, "", "finish_plan"], [43, 3, 1, "", "resolve_data"], [43, 3, 1, "", "set_up_planner"]], "torch.distributed.checkpoint.StorageReader": [[43, 3, 1, "", "prepare_global_plan"], [43, 3, 1, "", "prepare_local_plan"], [43, 3, 1, "", "read_data"], [43, 3, 1, "", "read_metadata"], [43, 3, 1, "", "set_up_storage_reader"]], "torch.distributed.checkpoint.StorageWriter": [[43, 3, 1, "", "finish"], [43, 3, 1, "", "prepare_global_plan"], [43, 3, 1, "", "prepare_local_plan"], [43, 3, 1, "", "set_up_storage_writer"], [43, 3, 1, "", "write_data"]], "torch.distributed.elastic": [[49, 0, 0, "-", "agent"], [52, 0, 0, "-", "events"], [55, 0, 0, "-", "metrics"], [56, 0, 0, "-", "multiprocessing"], [58, 0, 0, "-", "rendezvous"], [60, 0, 0, "-", "timer"], [41, 0, 0, "-", "utils"]], "torch.distributed.elastic.agent": [[49, 0, 0, "-", "server"]], "torch.distributed.elastic.agent.server": [[49, 1, 1, "", "ElasticAgent"], [49, 1, 1, "", "SimpleElasticAgent"], [49, 1, 1, "", "Worker"], [49, 1, 1, "", "WorkerGroup"], [49, 1, 1, "", "WorkerSpec"], [49, 1, 1, "", "WorkerState"]], "torch.distributed.elastic.agent.server.ElasticAgent": [[49, 3, 1, "", "get_worker_group"], [49, 3, 1, "", "run"]], "torch.distributed.elastic.agent.server.SimpleElasticAgent": [[49, 3, 1, "", "_assign_worker_ranks"], [49, 3, 1, "", "_exit_barrier"], [49, 3, 1, "", "_initialize_workers"], [49, 3, 1, "", "_monitor_workers"], [49, 3, 1, "", "_rendezvous"], [49, 3, 1, "", "_restart_workers"], [49, 3, 1, "", "_shutdown"], [49, 3, 1, "", "_start_workers"], [49, 3, 1, "", "_stop_workers"]], "torch.distributed.elastic.agent.server.WorkerSpec": [[49, 3, 1, "", "get_entrypoint_name"]], "torch.distributed.elastic.agent.server.WorkerState": [[49, 3, 1, "", "is_running"]], "torch.distributed.elastic.agent.server.api": [[49, 1, 1, "", "RunResult"]], "torch.distributed.elastic.agent.server.local_elastic_agent": [[49, 1, 1, "", "LocalElasticAgent"]], "torch.distributed.elastic.events.api": [[52, 1, 1, "", "Event"], [52, 2, 1, "", "EventMetadataValue"], [52, 1, 1, "", "EventSource"]], "torch.distributed.elastic.events": [[52, 5, 1, "", "get_logging_handler"], [52, 5, 1, "", "record"]], "torch.distributed.elastic.metrics.api": [[55, 1, 1, "", "ConsoleMetricHandler"], [55, 1, 1, "", "MetricHandler"], [55, 1, 1, "", "NullMetricHandler"]], "torch.distributed.elastic.metrics": [[55, 5, 1, "", "configure"], [55, 5, 1, "", "prof"], [55, 5, 1, "", "put_metric"]], "torch.distributed.elastic.multiprocessing.api": [[56, 1, 1, "", "MultiprocessContext"], [56, 1, 1, "", "PContext"], [56, 1, 1, "", "RunProcsResult"], [56, 1, 1, "", "SubprocessContext"]], "torch.distributed.elastic.multiprocessing": [[51, 0, 0, "-", "errors"], [56, 5, 1, "", "start_processes"]], "torch.distributed.elastic.multiprocessing.errors": [[51, 1, 1, "", "ChildFailedError"], [51, 1, 1, "", "ErrorHandler"], [51, 1, 1, "", "ProcessFailure"], [51, 5, 1, "", "record"]], "torch.distributed.elastic.rendezvous": [[58, 1, 1, "", "RendezvousClosedError"], [58, 1, 1, "", "RendezvousConnectionError"], [58, 1, 1, "", "RendezvousError"], [58, 1, 1, "", "RendezvousHandler"], [58, 1, 1, "", "RendezvousHandlerRegistry"], [58, 1, 1, "", "RendezvousParameters"], [58, 1, 1, "", "RendezvousStateError"], [58, 1, 1, "", "RendezvousTimeoutError"], [58, 0, 0, "-", "registry"]], "torch.distributed.elastic.rendezvous.RendezvousHandler": [[58, 3, 1, "", "get_backend"], [58, 3, 1, "", "get_run_id"], [58, 3, 1, "", "is_closed"], [58, 3, 1, "", "next_rendezvous"], [58, 3, 1, "", "num_nodes_waiting"], [58, 3, 1, "", "set_closed"], [58, 3, 1, "", "shutdown"]], "torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry": [[58, 3, 1, "", "create_handler"], [58, 3, 1, "", "register"]], "torch.distributed.elastic.rendezvous.RendezvousParameters": [[58, 3, 1, "", "get"], [58, 3, 1, "", "get_as_bool"], [58, 3, 1, "", "get_as_int"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend": [[58, 1, 1, "", "C10dRendezvousBackend"], [58, 5, 1, "", "create_backend"]], "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend": [[58, 3, 1, "", "get_state"], [58, 4, 1, "", "name"], [58, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous": [[58, 1, 1, "", "DynamicRendezvousHandler"], [58, 1, 1, "", "RendezvousBackend"], [58, 1, 1, "", "RendezvousTimeout"], [58, 5, 1, "", "create_handler"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler": [[58, 3, 1, "", "from_backend"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend": [[58, 3, 1, "", "get_state"], [58, 4, 1, "", "name"], [58, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout": [[58, 4, 1, "", "close"], [58, 4, 1, "", "heartbeat"], [58, 4, 1, "", "join"], [58, 4, 1, "", "last_call"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous": [[58, 1, 1, "", "EtcdRendezvousHandler"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend": [[58, 1, 1, "", "EtcdRendezvousBackend"], [58, 5, 1, "", "create_backend"]], "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend": [[58, 3, 1, "", "get_state"], [58, 4, 1, "", "name"], [58, 3, 1, "", "set_state"]], "torch.distributed.elastic.rendezvous.etcd_server": [[58, 1, 1, "", "EtcdServer"]], "torch.distributed.elastic.rendezvous.etcd_store": [[58, 1, 1, "", "EtcdStore"]], "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore": [[58, 3, 1, "", "add"], [58, 3, 1, "", "check"], [58, 3, 1, "", "get"], [58, 3, 1, "", "set"], [58, 3, 1, "", "wait"]], "torch.distributed.elastic.timer": [[60, 1, 1, "", "FileTimerClient"], [60, 1, 1, "", "FileTimerServer"], [60, 1, 1, "", "LocalTimerClient"], [60, 1, 1, "", "LocalTimerServer"], [60, 1, 1, "", "TimerClient"], [60, 1, 1, "", "TimerRequest"], [60, 1, 1, "", "TimerServer"], [60, 5, 1, "", "configure"], [60, 5, 1, "", "expires"]], "torch.distributed.elastic.timer.TimerClient": [[60, 3, 1, "", "acquire"], [60, 3, 1, "", "release"]], "torch.distributed.elastic.timer.TimerServer": [[60, 3, 1, "", "clear_timers"], [60, 3, 1, "", "get_expired_timers"], [60, 3, 1, "", "register_timers"]], "torch.distributed.elastic.utils": [[41, 0, 0, "-", "data"]], "torch.distributed.fsdp": [[63, 1, 1, "", "BackwardPrefetch"], [63, 1, 1, "", "CPUOffload"], [63, 1, 1, "", "FullyShardedDataParallel"], [63, 1, 1, "", "MixedPrecision"], [63, 1, 1, "", "ShardingStrategy"]], "torch.distributed.fsdp.FullyShardedDataParallel": [[63, 3, 1, "", "apply"], [63, 3, 1, "", "clip_grad_norm_"], [63, 3, 1, "", "flatten_sharded_optim_state_dict"], [63, 3, 1, "", "forward"], [63, 3, 1, "", "fsdp_modules"], [63, 3, 1, "", "full_optim_state_dict"], [63, 3, 1, "", "load_optim_state_dict_pre_hook"], [63, 4, 1, "", "module"], [63, 3, 1, "", "named_buffers"], [63, 3, 1, "", "named_parameters"], [63, 3, 1, "", "no_sync"], [63, 3, 1, "", "optim_state_dict"], [63, 3, 1, "", "optim_state_dict_post_hook"], [63, 3, 1, "", "optim_state_dict_to_load"], [63, 3, 1, "", "register_comm_hook"], [63, 3, 1, "", "rekey_optim_state_dict"], [63, 3, 1, "", "scatter_full_optim_state_dict"], [63, 3, 1, "", "set_state_dict_type"], [63, 3, 1, "", "shard_full_optim_state_dict"], [63, 3, 1, "", "sharded_optim_state_dict"], [63, 3, 1, "", "state_dict_type"], [63, 3, 1, "", "summon_full_params"]], "torch.distributed.nn": [[41, 0, 0, "-", "api"], [41, 0, 0, "-", "jit"]], "torch.distributed.nn.api.remote_module": [[1913, 1, 1, "", "RemoteModule"]], "torch.distributed.nn.api.remote_module.RemoteModule": [[1913, 3, 1, "", "get_module_rref"], [1913, 3, 1, "", "remote_parameters"]], "torch.distributed.nn.jit": [[41, 0, 0, "-", "templates"]], "torch.distributed.optim": [[45, 1, 1, "", "DistributedOptimizer"], [45, 1, 1, "", "PostLocalSGDOptimizer"], [45, 1, 1, "", "ZeroRedundancyOptimizer"]], "torch.distributed.optim.DistributedOptimizer": [[45, 3, 1, "", "step"]], "torch.distributed.optim.PostLocalSGDOptimizer": [[45, 3, 1, "", "load_state_dict"], [45, 3, 1, "", "state_dict"], [45, 3, 1, "", "step"]], "torch.distributed.optim.ZeroRedundancyOptimizer": [[45, 3, 1, "", "add_param_group"], [45, 3, 1, "", "consolidate_state_dict"], [45, 3, 1, "", "join_hook"], [45, 3, 1, "", "load_state_dict"], [45, 3, 1, "", "state_dict"], [45, 3, 1, "", "step"]], "torch.distributed.pipeline": [[41, 0, 0, "-", "sync"]], "torch.distributed.pipeline.sync": [[1906, 1, 1, "", "Pipe"], [41, 0, 0, "-", "skip"]], "torch.distributed.pipeline.sync.Pipe": [[1906, 3, 1, "", "forward"]], "torch.distributed.pipeline.sync.skip.skippable": [[1906, 1, 1, "", "pop"], [1906, 5, 1, "", "skippable"], [1906, 1, 1, "", "stash"], [1906, 5, 1, "", "verify_skippables"]], "torch.distributed.rpc": [[1913, 1, 1, "", "BackendType"], [1913, 1, 1, "", "RRef"], [1913, 1, 1, "", "RpcBackendOptions"], [1913, 1, 1, "", "TensorPipeRpcBackendOptions"], [1913, 1, 1, "", "WorkerInfo"], [1913, 5, 1, "", "get_worker_info"], [1913, 5, 1, "", "init_rpc"], [1913, 5, 1, "", "remote"], [1913, 5, 1, "", "rpc_async"], [1913, 5, 1, "", "rpc_sync"], [1913, 5, 1, "", "shutdown"]], "torch.distributed.rpc.RpcBackendOptions": [[1913, 4, 1, "", "init_method"], [1913, 4, 1, "", "rpc_timeout"]], "torch.distributed.rpc.TensorPipeRpcBackendOptions": [[1913, 4, 1, "", "device_maps"], [1913, 4, 1, "", "devices"], [1913, 4, 1, "", "init_method"], [1913, 4, 1, "", "num_worker_threads"], [1913, 4, 1, "", "rpc_timeout"], [1913, 3, 1, "", "set_device_map"], [1913, 3, 1, "", "set_devices"]], "torch.distributed.rpc.WorkerInfo": [[1913, 4, 1, "", "id"], [1913, 4, 1, "", "name"]], "torch.distributed.rpc.functions": [[1913, 5, 1, "", "async_execution"]], "torch.distributed.tensor": [[46, 0, 0, "-", "parallel"]], "torch.distributed.tensor.parallel.fsdp": [[46, 5, 1, "", "enable_2d_with_fsdp"]], "torch.distributed.tensor.parallel.multihead_attention_tp": [[46, 1, 1, "", "TensorParallelMultiheadAttention"]], "torch.distributed.tensor.parallel": [[46, 5, 1, "", "parallelize_module"]], "torch.distributed.tensor.parallel.style": [[46, 1, 1, "", "ColwiseParallel"], [46, 1, 1, "", "PairwiseParallel"], [46, 1, 1, "", "RowwiseParallel"], [46, 1, 1, "", "SequenceParallel"], [46, 5, 1, "", "make_input_replicate_1d"], [46, 5, 1, "", "make_input_reshard_replicate"], [46, 5, 1, "", "make_input_shard_1d"], [46, 5, 1, "", "make_input_shard_1d_last_dim"], [46, 5, 1, "", "make_output_replicate_1d"], [46, 5, 1, "", "make_output_reshard_tensor"], [46, 5, 1, "", "make_output_shard_1d"], [46, 5, 1, "", "make_output_tensor"]], "torch.distributions.bernoulli": [[47, 1, 1, "", "Bernoulli"]], "torch.distributions.bernoulli.Bernoulli": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "enumerate_support"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_enumerate_support"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "sample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.beta": [[47, 1, 1, "", "Beta"]], "torch.distributions.beta.Beta": [[47, 2, 1, "", "arg_constraints"], [47, 4, 1, "", "concentration0"], [47, 4, 1, "", "concentration1"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.binomial": [[47, 1, 1, "", "Binomial"]], "torch.distributions.binomial.Binomial": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "enumerate_support"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_enumerate_support"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.categorical": [[47, 1, 1, "", "Categorical"]], "torch.distributions.categorical.Categorical": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "enumerate_support"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_enumerate_support"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.cauchy": [[47, 1, 1, "", "Cauchy"]], "torch.distributions.cauchy.Cauchy": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.chi2": [[47, 1, 1, "", "Chi2"]], "torch.distributions.chi2.Chi2": [[47, 2, 1, "", "arg_constraints"], [47, 4, 1, "", "df"], [47, 3, 1, "", "expand"]], "torch.distributions": [[47, 0, 0, "-", "constraint_registry"], [47, 0, 0, "-", "constraints"], [47, 0, 0, "-", "kl"], [47, 0, 0, "-", "transforms"]], "torch.distributions.constraint_registry": [[47, 1, 1, "", "ConstraintRegistry"]], "torch.distributions.constraint_registry.ConstraintRegistry": [[47, 3, 1, "", "register"]], "torch.distributions.constraints": [[47, 1, 1, "", "Constraint"], [47, 2, 1, "", "cat"], [47, 2, 1, "", "dependent_property"], [47, 2, 1, "", "greater_than"], [47, 2, 1, "", "greater_than_eq"], [47, 2, 1, "", "half_open_interval"], [47, 2, 1, "", "independent"], [47, 2, 1, "", "integer_interval"], [47, 2, 1, "", "interval"], [47, 2, 1, "", "less_than"], [47, 2, 1, "", "multinomial"], [47, 2, 1, "", "stack"]], "torch.distributions.constraints.Constraint": [[47, 3, 1, "", "check"]], "torch.distributions.continuous_bernoulli": [[47, 1, 1, "", "ContinuousBernoulli"]], "torch.distributions.continuous_bernoulli.ContinuousBernoulli": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "rsample"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "stddev"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.dirichlet": [[47, 1, 1, "", "Dirichlet"]], "torch.distributions.dirichlet.Dirichlet": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.distribution": [[47, 1, 1, "", "Distribution"]], "torch.distributions.distribution.Distribution": [[47, 4, 1, "", "arg_constraints"], [47, 4, 1, "", "batch_shape"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "enumerate_support"], [47, 4, 1, "", "event_shape"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "perplexity"], [47, 3, 1, "", "rsample"], [47, 3, 1, "", "sample"], [47, 3, 1, "", "sample_n"], [47, 3, 1, "", "set_default_validate_args"], [47, 4, 1, "", "stddev"], [47, 4, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.exp_family": [[47, 1, 1, "", "ExponentialFamily"]], "torch.distributions.exp_family.ExponentialFamily": [[47, 3, 1, "", "entropy"]], "torch.distributions.exponential": [[47, 1, 1, "", "Exponential"]], "torch.distributions.exponential.Exponential": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 4, 1, "", "stddev"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.fishersnedecor": [[47, 1, 1, "", "FisherSnedecor"]], "torch.distributions.fishersnedecor.FisherSnedecor": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.gamma": [[47, 1, 1, "", "Gamma"]], "torch.distributions.gamma.Gamma": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.geometric": [[47, 1, 1, "", "Geometric"]], "torch.distributions.geometric.Geometric": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "sample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.gumbel": [[47, 1, 1, "", "Gumbel"]], "torch.distributions.gumbel.Gumbel": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "stddev"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.half_cauchy": [[47, 1, 1, "", "HalfCauchy"]], "torch.distributions.half_cauchy.HalfCauchy": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "scale"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.half_normal": [[47, 1, 1, "", "HalfNormal"]], "torch.distributions.half_normal.HalfNormal": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "scale"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.independent": [[47, 1, 1, "", "Independent"]], "torch.distributions.independent.Independent": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "enumerate_support"], [47, 3, 1, "", "expand"], [47, 4, 1, "", "has_enumerate_support"], [47, 4, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.kl": [[47, 5, 1, "", "kl_divergence"], [47, 5, 1, "", "register_kl"]], "torch.distributions.kumaraswamy": [[47, 1, 1, "", "Kumaraswamy"]], "torch.distributions.kumaraswamy.Kumaraswamy": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.laplace": [[47, 1, 1, "", "Laplace"]], "torch.distributions.laplace.Laplace": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 4, 1, "", "stddev"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.lkj_cholesky": [[47, 1, 1, "", "LKJCholesky"]], "torch.distributions.lkj_cholesky.LKJCholesky": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "log_prob"], [47, 3, 1, "", "sample"], [47, 2, 1, "", "support"]], "torch.distributions.log_normal": [[47, 1, 1, "", "LogNormal"]], "torch.distributions.log_normal.LogNormal": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 4, 1, "", "loc"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "scale"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.lowrank_multivariate_normal": [[47, 1, 1, "", "LowRankMultivariateNormal"]], "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal": [[47, 2, 1, "", "arg_constraints"], [47, 4, 1, "", "covariance_matrix"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "precision_matrix"], [47, 3, 1, "", "rsample"], [47, 4, 1, "", "scale_tril"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.mixture_same_family": [[47, 1, 1, "", "MixtureSameFamily"]], "torch.distributions.mixture_same_family.MixtureSameFamily": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 4, 1, "", "component_distribution"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mixture_distribution"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.multinomial": [[47, 1, 1, "", "Multinomial"]], "torch.distributions.multinomial.Multinomial": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "support"], [47, 2, 1, "", "total_count"], [47, 4, 1, "", "variance"]], "torch.distributions.multivariate_normal": [[47, 1, 1, "", "MultivariateNormal"]], "torch.distributions.multivariate_normal.MultivariateNormal": [[47, 2, 1, "", "arg_constraints"], [47, 4, 1, "", "covariance_matrix"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "precision_matrix"], [47, 3, 1, "", "rsample"], [47, 4, 1, "", "scale_tril"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.negative_binomial": [[47, 1, 1, "", "NegativeBinomial"]], "torch.distributions.negative_binomial.NegativeBinomial": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "sample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.normal": [[47, 1, 1, "", "Normal"]], "torch.distributions.normal.Normal": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "stddev"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.one_hot_categorical": [[47, 1, 1, "", "OneHotCategorical"]], "torch.distributions.one_hot_categorical.OneHotCategorical": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "enumerate_support"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_enumerate_support"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "sample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.pareto": [[47, 1, 1, "", "Pareto"]], "torch.distributions.pareto.Pareto": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.poisson": [[47, 1, 1, "", "Poisson"]], "torch.distributions.poisson.Poisson": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "sample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.relaxed_bernoulli": [[47, 1, 1, "", "LogitRelaxedBernoulli"], [47, 1, 1, "", "RelaxedBernoulli"]], "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "param_shape"], [47, 4, 1, "", "probs"], [47, 3, 1, "", "rsample"], [47, 2, 1, "", "support"]], "torch.distributions.relaxed_bernoulli.RelaxedBernoulli": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "probs"], [47, 2, 1, "", "support"], [47, 4, 1, "", "temperature"]], "torch.distributions.relaxed_categorical": [[47, 1, 1, "", "RelaxedOneHotCategorical"]], "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 4, 1, "", "logits"], [47, 4, 1, "", "probs"], [47, 2, 1, "", "support"], [47, 4, 1, "", "temperature"]], "torch.distributions.studentT": [[47, 1, 1, "", "StudentT"]], "torch.distributions.studentT.StudentT": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.transformed_distribution": [[47, 1, 1, "", "TransformedDistribution"]], "torch.distributions.transformed_distribution.TransformedDistribution": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "expand"], [47, 4, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 3, 1, "", "rsample"], [47, 3, 1, "", "sample"], [47, 4, 1, "", "support"]], "torch.distributions.transforms": [[47, 1, 1, "", "AbsTransform"], [47, 1, 1, "", "AffineTransform"], [47, 1, 1, "", "CatTransform"], [47, 1, 1, "", "ComposeTransform"], [47, 1, 1, "", "CorrCholeskyTransform"], [47, 1, 1, "", "CumulativeDistributionTransform"], [47, 1, 1, "", "ExpTransform"], [47, 1, 1, "", "IndependentTransform"], [47, 1, 1, "", "LowerCholeskyTransform"], [47, 1, 1, "", "PositiveDefiniteTransform"], [47, 1, 1, "", "PowerTransform"], [47, 1, 1, "", "ReshapeTransform"], [47, 1, 1, "", "SigmoidTransform"], [47, 1, 1, "", "SoftmaxTransform"], [47, 1, 1, "", "SoftplusTransform"], [47, 1, 1, "", "StackTransform"], [47, 1, 1, "", "StickBreakingTransform"], [47, 1, 1, "", "TanhTransform"], [47, 1, 1, "", "Transform"]], "torch.distributions.transforms.Transform": [[47, 3, 1, "", "forward_shape"], [47, 4, 1, "", "inv"], [47, 3, 1, "", "inverse_shape"], [47, 3, 1, "", "log_abs_det_jacobian"], [47, 4, 1, "", "sign"]], "torch.distributions.uniform": [[47, 1, 1, "", "Uniform"]], "torch.distributions.uniform.Uniform": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "cdf"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "icdf"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "rsample"], [47, 4, 1, "", "stddev"], [47, 4, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.von_mises": [[47, 1, 1, "", "VonMises"]], "torch.distributions.von_mises.VonMises": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 3, 1, "", "sample"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.weibull": [[47, 1, 1, "", "Weibull"]], "torch.distributions.weibull.Weibull": [[47, 2, 1, "", "arg_constraints"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.distributions.wishart": [[47, 1, 1, "", "Wishart"]], "torch.distributions.wishart.Wishart": [[47, 2, 1, "", "arg_constraints"], [47, 4, 1, "", "covariance_matrix"], [47, 3, 1, "", "entropy"], [47, 3, 1, "", "expand"], [47, 2, 1, "", "has_rsample"], [47, 3, 1, "", "log_prob"], [47, 4, 1, "", "mean"], [47, 4, 1, "", "mode"], [47, 4, 1, "", "precision_matrix"], [47, 3, 1, "", "rsample"], [47, 4, 1, "", "scale_tril"], [47, 2, 1, "", "support"], [47, 4, 1, "", "variance"]], "torch.fft": [[1079, 5, 1, "", "fft"], [1080, 5, 1, "", "fft2"], [1081, 5, 1, "", "fftfreq"], [1082, 5, 1, "", "fftn"], [1083, 5, 1, "", "fftshift"], [1084, 5, 1, "", "hfft"], [1085, 5, 1, "", "hfft2"], [1086, 5, 1, "", "hfftn"], [1087, 5, 1, "", "ifft"], [1088, 5, 1, "", "ifft2"], [1089, 5, 1, "", "ifftn"], [1090, 5, 1, "", "ifftshift"], [1091, 5, 1, "", "ihfft"], [1092, 5, 1, "", "ihfft2"], [1093, 5, 1, "", "ihfftn"], [1094, 5, 1, "", "irfft"], [1095, 5, 1, "", "irfft2"], [1096, 5, 1, "", "irfftn"], [1097, 5, 1, "", "rfft"], [1098, 5, 1, "", "rfft2"], [1099, 5, 1, "", "rfftfreq"], [1100, 5, 1, "", "rfftn"]], "torch.func": [[1119, 5, 1, "", "functional_call"], [1120, 5, 1, "", "functionalize"], [1121, 5, 1, "", "grad"], [1122, 5, 1, "", "grad_and_value"], [1123, 5, 1, "", "hessian"], [1124, 5, 1, "", "jacfwd"], [1125, 5, 1, "", "jacrev"], [1126, 5, 1, "", "jvp"], [1127, 5, 1, "", "linearize"], [1128, 5, 1, "", "replace_all_batch_norm_modules_"], [1129, 5, 1, "", "stack_module_state"], [1130, 5, 1, "", "vjp"], [1131, 5, 1, "", "vmap"]], "torch.futures": [[70, 1, 1, "", "Future"], [70, 5, 1, "", "collect_all"], [70, 5, 1, "", "wait_all"]], "torch.futures.Future": [[70, 3, 1, "", "add_done_callback"], [70, 3, 1, "", "done"], [70, 3, 1, "", "set_exception"], [70, 3, 1, "", "set_result"], [70, 3, 1, "", "then"], [70, 3, 1, "", "value"], [70, 3, 1, "", "wait"]], "torch.fx": [[71, 1, 1, "", "Graph"], [71, 1, 1, "", "GraphModule"], [71, 1, 1, "", "Interpreter"], [71, 1, 1, "", "Node"], [71, 1, 1, "", "Proxy"], [71, 1, 1, "", "Tracer"], [71, 1, 1, "", "Transformer"], [71, 0, 0, "-", "experimental"], [71, 0, 0, "-", "passes"], [71, 5, 1, "", "replace_pattern"], [71, 5, 1, "", "symbolic_trace"], [71, 5, 1, "", "wrap"]], "torch.fx.Graph": [[71, 3, 1, "", "__init__"], [71, 3, 1, "", "call_function"], [71, 3, 1, "", "call_method"], [71, 3, 1, "", "call_module"], [71, 3, 1, "", "create_node"], [71, 3, 1, "", "eliminate_dead_code"], [71, 3, 1, "", "erase_node"], [71, 3, 1, "", "get_attr"], [71, 3, 1, "", "graph_copy"], [71, 3, 1, "", "inserting_after"], [71, 3, 1, "", "inserting_before"], [71, 3, 1, "", "lint"], [71, 3, 1, "", "node_copy"], [71, 4, 1, "", "nodes"], [71, 3, 1, "", "on_generate_code"], [71, 3, 1, "", "output"], [71, 3, 1, "", "placeholder"], [71, 3, 1, "", "print_tabular"], [71, 3, 1, "", "process_inputs"], [71, 3, 1, "", "process_outputs"], [71, 3, 1, "", "python_code"], [71, 3, 1, "", "set_codegen"]], "torch.fx.GraphModule": [[71, 3, 1, "", "__init__"], [71, 3, 1, "", "add_submodule"], [71, 4, 1, "", "code"], [71, 3, 1, "", "delete_all_unused_submodules"], [71, 3, 1, "", "delete_submodule"], [71, 4, 1, "", "graph"], [71, 3, 1, "", "print_readable"], [71, 3, 1, "", "recompile"], [71, 3, 1, "", "to_folder"]], "torch.fx.Interpreter": [[71, 3, 1, "", "boxed_run"], [71, 3, 1, "", "call_function"], [71, 3, 1, "", "call_method"], [71, 3, 1, "", "call_module"], [71, 3, 1, "", "fetch_args_kwargs_from_env"], [71, 3, 1, "", "fetch_attr"], [71, 3, 1, "", "get_attr"], [71, 3, 1, "", "map_nodes_to_values"], [71, 3, 1, "", "output"], [71, 3, 1, "", "placeholder"], [71, 3, 1, "", "run"], [71, 3, 1, "", "run_node"]], "torch.fx.Node": [[71, 4, 1, "", "all_input_nodes"], [71, 3, 1, "", "append"], [71, 4, 1, "", "args"], [71, 3, 1, "", "format_node"], [71, 3, 1, "", "is_impure"], [71, 4, 1, "", "kwargs"], [71, 4, 1, "", "next"], [71, 3, 1, "", "normalized_arguments"], [71, 3, 1, "", "prepend"], [71, 4, 1, "", "prev"], [71, 3, 1, "", "replace_all_uses_with"], [71, 3, 1, "", "replace_input_with"], [71, 4, 1, "", "stack_trace"], [71, 3, 1, "", "update_arg"], [71, 3, 1, "", "update_kwarg"]], "torch.fx.Tracer": [[71, 3, 1, "", "call_module"], [71, 3, 1, "", "create_arg"], [71, 3, 1, "", "create_args_for_root"], [71, 3, 1, "", "create_node"], [71, 3, 1, "", "create_proxy"], [71, 3, 1, "", "getattr"], [71, 3, 1, "", "is_leaf_module"], [71, 3, 1, "", "iter"], [71, 3, 1, "", "keys"], [71, 3, 1, "", "path_of_module"], [71, 3, 1, "", "proxy"], [71, 3, 1, "", "to_bool"], [71, 3, 1, "", "trace"]], "torch.fx.Transformer": [[71, 3, 1, "", "call_function"], [71, 3, 1, "", "call_module"], [71, 3, 1, "", "get_attr"], [71, 3, 1, "", "placeholder"], [71, 3, 1, "", "transform"]], "torch.fx.experimental": [[71, 0, 0, "-", "migrate_gradual_types"], [71, 0, 0, "-", "unification"]], "torch.fx.experimental.unification": [[71, 0, 0, "-", "multipledispatch"]], "torch.fx.passes": [[71, 0, 0, "-", "backends"], [71, 0, 0, "-", "dialect"], [71, 0, 0, "-", "infra"], [71, 0, 0, "-", "tests"], [71, 0, 0, "-", "utils"]], "torch.fx.passes.dialect": [[71, 0, 0, "-", "common"]], "torch.hub": [[1857, 5, 1, "", "download_url_to_file"], [1857, 5, 1, "", "get_dir"], [1857, 5, 1, "", "help"], [1857, 5, 1, "", "list"], [1857, 5, 1, "", "load"], [1857, 5, 1, "", "load_state_dict_from_url"], [1857, 5, 1, "", "set_dir"]], "torch.jit": [[1188, 1, 1, "", "Attribute"], [1189, 1, 1, "", "ScriptFunction"], [1190, 1, 1, "", "ScriptModule"], [1191, 5, 1, "", "annotate"], [1192, 5, 1, "", "enable_onednn_fusion"], [1860, 5, 1, "", "export"], [1193, 5, 1, "", "fork"], [1194, 5, 1, "", "freeze"], [1195, 5, 1, "", "ignore"], [1862, 5, 1, "", "is_scripting"], [1862, 5, 1, "", "is_tracing"], [1196, 5, 1, "", "isinstance"], [1197, 5, 1, "", "load"], [1860, 0, 0, "-", "mobile"], [1198, 5, 1, "", "onednn_fusion_enabled"], [1199, 5, 1, "", "optimize_for_inference"], [1200, 5, 1, "", "save"], [1201, 5, 1, "", "script"], [1202, 5, 1, "", "script_if_tracing"], [1203, 5, 1, "", "set_fusion_strategy"], [1204, 1, 1, "", "strict_fusion"], [1861, 0, 0, "-", "supported_ops"], [1205, 5, 1, "", "trace"], [1206, 5, 1, "", "trace_module"], [1865, 0, 0, "-", "unsupported_tensor_ops"], [1207, 5, 1, "", "unused"], [1208, 5, 1, "", "wait"]], "torch.jit.Attribute": [[1188, 3, 1, "", "count"], [1188, 3, 1, "", "index"], [1188, 2, 1, "", "type"], [1188, 2, 1, "", "value"]], "torch.jit.ScriptFunction": [[1189, 3, 1, "", "get_debug_state"], [1189, 3, 1, "", "save"], [1189, 3, 1, "", "save_to_buffer"]], "torch.jit.ScriptModule": [[1190, 3, 1, "", "add_module"], [1190, 3, 1, "", "apply"], [1190, 3, 1, "", "bfloat16"], [1190, 3, 1, "", "buffers"], [1190, 3, 1, "", "children"], [1190, 4, 1, "", "code"], [1190, 4, 1, "", "code_with_constants"], [1190, 3, 1, "", "compile"], [1190, 3, 1, "", "cpu"], [1190, 3, 1, "", "cuda"], [1190, 3, 1, "", "double"], [1190, 3, 1, "", "eval"], [1190, 3, 1, "", "extra_repr"], [1190, 3, 1, "", "float"], [1190, 3, 1, "", "get_buffer"], [1190, 3, 1, "", "get_extra_state"], [1190, 3, 1, "", "get_parameter"], [1190, 3, 1, "", "get_submodule"], [1190, 4, 1, "", "graph"], [1190, 3, 1, "", "half"], [1190, 4, 1, "", "inlined_graph"], [1190, 3, 1, "", "ipu"], [1190, 3, 1, "", "load_state_dict"], [1190, 3, 1, "", "modules"], [1190, 3, 1, "", "named_buffers"], [1190, 3, 1, "", "named_children"], [1190, 3, 1, "", "named_modules"], [1190, 3, 1, "", "named_parameters"], [1190, 3, 1, "", "parameters"], [1190, 3, 1, "", "register_backward_hook"], [1190, 3, 1, "", "register_buffer"], [1190, 3, 1, "", "register_forward_hook"], [1190, 3, 1, "", "register_forward_pre_hook"], [1190, 3, 1, "", "register_full_backward_hook"], [1190, 3, 1, "", "register_full_backward_pre_hook"], [1190, 3, 1, "", "register_load_state_dict_post_hook"], [1190, 3, 1, "", "register_module"], [1190, 3, 1, "", "register_parameter"], [1190, 3, 1, "", "register_state_dict_pre_hook"], [1190, 3, 1, "", "requires_grad_"], [1190, 3, 1, "", "save"], [1190, 3, 1, "", "set_extra_state"], [1190, 3, 1, "", "share_memory"], [1190, 3, 1, "", "state_dict"], [1190, 3, 1, "", "to"], [1190, 3, 1, "", "to_empty"], [1190, 3, 1, "", "train"], [1190, 3, 1, "", "type"], [1190, 3, 1, "", "xpu"], [1190, 3, 1, "", "zero_grad"]], "torch.library": [[1867, 1, 1, "", "Library"]], "torch.library.Library": [[1867, 3, 1, "", "define"], [1867, 3, 1, "", "impl"]], "torch.linalg": [[1219, 5, 1, "", "cholesky"], [1220, 5, 1, "", "cholesky_ex"], [1221, 5, 1, "", "cond"], [1222, 5, 1, "", "cross"], [1223, 5, 1, "", "det"], [1224, 5, 1, "", "diagonal"], [1225, 5, 1, "", "eig"], [1226, 5, 1, "", "eigh"], [1227, 5, 1, "", "eigvals"], [1228, 5, 1, "", "eigvalsh"], [1229, 5, 1, "", "householder_product"], [1230, 5, 1, "", "inv"], [1231, 5, 1, "", "inv_ex"], [1232, 5, 1, "", "ldl_factor"], [1233, 5, 1, "", "ldl_factor_ex"], [1234, 5, 1, "", "ldl_solve"], [1235, 5, 1, "", "lstsq"], [1236, 5, 1, "", "lu"], [1237, 5, 1, "", "lu_factor"], [1238, 5, 1, "", "lu_factor_ex"], [1239, 5, 1, "", "lu_solve"], [1240, 5, 1, "", "matmul"], [1241, 5, 1, "", "matrix_exp"], [1242, 5, 1, "", "matrix_norm"], [1243, 5, 1, "", "matrix_power"], [1244, 5, 1, "", "matrix_rank"], [1245, 5, 1, "", "multi_dot"], [1246, 5, 1, "", "norm"], [1247, 5, 1, "", "pinv"], [1248, 5, 1, "", "qr"], [1249, 5, 1, "", "slogdet"], [1250, 5, 1, "", "solve"], [1251, 5, 1, "", "solve_ex"], [1252, 5, 1, "", "solve_triangular"], [1253, 5, 1, "", "svd"], [1254, 5, 1, "", "svdvals"], [1255, 5, 1, "", "tensorinv"], [1256, 5, 1, "", "tensorsolve"], [1257, 5, 1, "", "vander"], [1258, 5, 1, "", "vecdot"], [1259, 5, 1, "", "vector_norm"]], "torch.masked": [[1870, 0, 0, "-", "maskedtensor"]], "torch.monitor": [[1873, 1, 1, "", "Aggregation"], [1873, 1, 1, "", "Event"], [1873, 1, 1, "", "EventHandlerHandle"], [1873, 1, 1, "", "Stat"], [1873, 1, 1, "", "TensorboardEventHandler"], [1873, 1, 1, "", "data_value_t"], [1873, 5, 1, "", "log_event"], [1873, 5, 1, "", "register_event_handler"], [1873, 5, 1, "", "unregister_event_handler"]], "torch.monitor.Aggregation": [[1873, 4, 1, "", "name"]], "torch.monitor.Event": [[1873, 3, 1, "", "__init__"], [1873, 4, 1, "", "data"], [1873, 4, 1, "", "name"], [1873, 4, 1, "", "timestamp"]], "torch.monitor.Stat": [[1873, 3, 1, "", "__init__"], [1873, 3, 1, "", "add"], [1873, 4, 1, "", "count"], [1873, 3, 1, "", "get"], [1873, 4, 1, "", "name"]], "torch.monitor.TensorboardEventHandler": [[1873, 3, 1, "", "__init__"]], "torch.mps": [[1298, 5, 1, "", "current_allocated_memory"], [1299, 5, 1, "", "driver_allocated_memory"], [1300, 5, 1, "", "empty_cache"], [1301, 5, 1, "", "get_rng_state"], [1302, 5, 1, "", "manual_seed"], [1306, 5, 1, "", "seed"], [1307, 5, 1, "", "set_per_process_memory_fraction"], [1308, 5, 1, "", "set_rng_state"], [1309, 5, 1, "", "synchronize"]], "torch.mps.profiler": [[1303, 5, 1, "", "profile"], [1304, 5, 1, "", "start"], [1305, 5, 1, "", "stop"]], "torch.multiprocessing": [[1875, 1, 1, "", "SpawnContext"], [1875, 5, 1, "", "get_all_sharing_strategies"], [1875, 5, 1, "", "get_sharing_strategy"], [1875, 5, 1, "", "set_sharing_strategy"], [1875, 5, 1, "", "spawn"]], "torch.multiprocessing.SpawnContext": [[1875, 3, 1, "", "join"]], "torch.nested": [[1878, 5, 1, "", "as_nested_tensor"], [1878, 5, 1, "", "nested_tensor"], [1878, 5, 1, "", "to_padded_tensor"]], "torch.nn": [[1327, 1, 1, "", "AdaptiveAvgPool1d"], [1328, 1, 1, "", "AdaptiveAvgPool2d"], [1329, 1, 1, "", "AdaptiveAvgPool3d"], [1330, 1, 1, "", "AdaptiveLogSoftmaxWithLoss"], [1331, 1, 1, "", "AdaptiveMaxPool1d"], [1332, 1, 1, "", "AdaptiveMaxPool2d"], [1333, 1, 1, "", "AdaptiveMaxPool3d"], [1334, 1, 1, "", "AlphaDropout"], [1335, 1, 1, "", "AvgPool1d"], [1336, 1, 1, "", "AvgPool2d"], [1337, 1, 1, "", "AvgPool3d"], [1338, 1, 1, "", "BCELoss"], [1339, 1, 1, "", "BCEWithLogitsLoss"], [1340, 1, 1, "", "BatchNorm1d"], [1341, 1, 1, "", "BatchNorm2d"], [1342, 1, 1, "", "BatchNorm3d"], [1343, 1, 1, "", "Bilinear"], [1344, 1, 1, "", "CELU"], [1345, 1, 1, "", "CTCLoss"], [1346, 1, 1, "", "ChannelShuffle"], [1347, 1, 1, "", "ConstantPad1d"], [1348, 1, 1, "", "ConstantPad2d"], [1349, 1, 1, "", "ConstantPad3d"], [1350, 1, 1, "", "Conv1d"], [1351, 1, 1, "", "Conv2d"], [1352, 1, 1, "", "Conv3d"], [1353, 1, 1, "", "ConvTranspose1d"], [1354, 1, 1, "", "ConvTranspose2d"], [1355, 1, 1, "", "ConvTranspose3d"], [1356, 1, 1, "", "CosineEmbeddingLoss"], [1357, 1, 1, "", "CosineSimilarity"], [1358, 1, 1, "", "CrossEntropyLoss"], [1359, 1, 1, "", "DataParallel"], [1360, 1, 1, "", "Dropout"], [1361, 1, 1, "", "Dropout1d"], [1362, 1, 1, "", "Dropout2d"], [1363, 1, 1, "", "Dropout3d"], [1364, 1, 1, "", "ELU"], [1365, 1, 1, "", "Embedding"], [1366, 1, 1, "", "EmbeddingBag"], [1367, 1, 1, "", "FeatureAlphaDropout"], [1368, 1, 1, "", "Flatten"], [1369, 1, 1, "", "Fold"], [1370, 1, 1, "", "FractionalMaxPool2d"], [1371, 1, 1, "", "FractionalMaxPool3d"], [1372, 1, 1, "", "GELU"], [1373, 1, 1, "", "GLU"], [1374, 1, 1, "", "GRU"], [1375, 1, 1, "", "GRUCell"], [1376, 1, 1, "", "GaussianNLLLoss"], [1377, 1, 1, "", "GroupNorm"], [1378, 1, 1, "", "Hardshrink"], [1379, 1, 1, "", "Hardsigmoid"], [1380, 1, 1, "", "Hardswish"], [1381, 1, 1, "", "Hardtanh"], [1382, 1, 1, "", "HingeEmbeddingLoss"], [1383, 1, 1, "", "HuberLoss"], [1384, 1, 1, "", "Identity"], [1385, 1, 1, "", "InstanceNorm1d"], [1386, 1, 1, "", "InstanceNorm2d"], [1387, 1, 1, "", "InstanceNorm3d"], [1388, 1, 1, "", "KLDivLoss"], [1389, 1, 1, "", "L1Loss"], [1390, 1, 1, "", "LPPool1d"], [1391, 1, 1, "", "LPPool2d"], [1392, 1, 1, "", "LSTM"], [1393, 1, 1, "", "LSTMCell"], [1394, 1, 1, "", "LayerNorm"], [1395, 1, 1, "", "LazyBatchNorm1d"], [1396, 1, 1, "", "LazyBatchNorm2d"], [1397, 1, 1, "", "LazyBatchNorm3d"], [1398, 1, 1, "", "LazyConv1d"], [1399, 1, 1, "", "LazyConv2d"], [1400, 1, 1, "", "LazyConv3d"], [1401, 1, 1, "", "LazyConvTranspose1d"], [1402, 1, 1, "", "LazyConvTranspose2d"], [1403, 1, 1, "", "LazyConvTranspose3d"], [1404, 1, 1, "", "LazyInstanceNorm1d"], [1405, 1, 1, "", "LazyInstanceNorm2d"], [1406, 1, 1, "", "LazyInstanceNorm3d"], [1407, 1, 1, "", "LazyLinear"], [1408, 1, 1, "", "LeakyReLU"], [1409, 1, 1, "", "Linear"], [1410, 1, 1, "", "LocalResponseNorm"], [1411, 1, 1, "", "LogSigmoid"], [1412, 1, 1, "", "LogSoftmax"], [1413, 1, 1, "", "MSELoss"], [1414, 1, 1, "", "MarginRankingLoss"], [1415, 1, 1, "", "MaxPool1d"], [1416, 1, 1, "", "MaxPool2d"], [1417, 1, 1, "", "MaxPool3d"], [1418, 1, 1, "", "MaxUnpool1d"], [1419, 1, 1, "", "MaxUnpool2d"], [1420, 1, 1, "", "MaxUnpool3d"], [1421, 1, 1, "", "Mish"], [1422, 1, 1, "", "Module"], [1423, 1, 1, "", "ModuleDict"], [1424, 1, 1, "", "ModuleList"], [1425, 1, 1, "", "MultiLabelMarginLoss"], [1426, 1, 1, "", "MultiLabelSoftMarginLoss"], [1427, 1, 1, "", "MultiMarginLoss"], [1428, 1, 1, "", "MultiheadAttention"], [1429, 1, 1, "", "NLLLoss"], [1430, 1, 1, "", "PReLU"], [1431, 1, 1, "", "PairwiseDistance"], [1432, 1, 1, "", "ParameterDict"], [1433, 1, 1, "", "ParameterList"], [1434, 1, 1, "", "PixelShuffle"], [1435, 1, 1, "", "PixelUnshuffle"], [1436, 1, 1, "", "PoissonNLLLoss"], [1437, 1, 1, "", "RNN"], [1438, 1, 1, "", "RNNBase"], [1439, 1, 1, "", "RNNCell"], [1440, 1, 1, "", "RReLU"], [1441, 1, 1, "", "ReLU"], [1442, 1, 1, "", "ReLU6"], [1443, 1, 1, "", "ReflectionPad1d"], [1444, 1, 1, "", "ReflectionPad2d"], [1445, 1, 1, "", "ReflectionPad3d"], [1446, 1, 1, "", "ReplicationPad1d"], [1447, 1, 1, "", "ReplicationPad2d"], [1448, 1, 1, "", "ReplicationPad3d"], [1449, 1, 1, "", "SELU"], [1450, 1, 1, "", "Sequential"], [1451, 1, 1, "", "SiLU"], [1452, 1, 1, "", "Sigmoid"], [1453, 1, 1, "", "SmoothL1Loss"], [1454, 1, 1, "", "SoftMarginLoss"], [1455, 1, 1, "", "Softmax"], [1456, 1, 1, "", "Softmax2d"], [1457, 1, 1, "", "Softmin"], [1458, 1, 1, "", "Softplus"], [1459, 1, 1, "", "Softshrink"], [1460, 1, 1, "", "Softsign"], [1461, 1, 1, "", "SyncBatchNorm"], [1462, 1, 1, "", "Tanh"], [1463, 1, 1, "", "Tanhshrink"], [1464, 1, 1, "", "Threshold"], [1465, 1, 1, "", "Transformer"], [1466, 1, 1, "", "TransformerDecoder"], [1467, 1, 1, "", "TransformerDecoderLayer"], [1468, 1, 1, "", "TransformerEncoder"], [1469, 1, 1, "", "TransformerEncoderLayer"], [1470, 1, 1, "", "TripletMarginLoss"], [1471, 1, 1, "", "TripletMarginWithDistanceLoss"], [1472, 1, 1, "", "Unflatten"], [1473, 1, 1, "", "Unfold"], [1474, 1, 1, "", "Upsample"], [1475, 1, 1, "", "UpsamplingBilinear2d"], [1476, 1, 1, "", "UpsamplingNearest2d"], [1477, 1, 1, "", "ZeroPad1d"], [1478, 1, 1, "", "ZeroPad2d"], [1479, 1, 1, "", "ZeroPad3d"], [1879, 0, 0, "-", "backends"], [1911, 0, 0, "-", "intrinsic"], [1879, 0, 0, "-", "modules"], [1879, 0, 0, "-", "parallel"], [1911, 0, 0, "-", "qat"], [1911, 0, 0, "-", "quantizable"], [1911, 0, 0, "-", "quantized"], [1879, 0, 0, "-", "utils"]], "torch.nn.AdaptiveLogSoftmaxWithLoss": [[1330, 3, 1, "", "log_prob"], [1330, 3, 1, "", "predict"]], "torch.nn.Embedding": [[1365, 3, 1, "", "from_pretrained"]], "torch.nn.EmbeddingBag": [[1366, 3, 1, "", "forward"], [1366, 3, 1, "", "from_pretrained"]], "torch.nn.LazyBatchNorm1d": [[1395, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm2d": [[1396, 2, 1, "", "cls_to_become"]], "torch.nn.LazyBatchNorm3d": [[1397, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv1d": [[1398, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv2d": [[1399, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConv3d": [[1400, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose1d": [[1401, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose2d": [[1402, 2, 1, "", "cls_to_become"]], "torch.nn.LazyConvTranspose3d": [[1403, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm1d": [[1404, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm2d": [[1405, 2, 1, "", "cls_to_become"]], "torch.nn.LazyInstanceNorm3d": [[1406, 2, 1, "", "cls_to_become"]], "torch.nn.LazyLinear": [[1407, 2, 1, "", "cls_to_become"]], "torch.nn.Module": [[1422, 3, 1, "", "add_module"], [1422, 3, 1, "", "apply"], [1422, 3, 1, "", "bfloat16"], [1422, 3, 1, "", "buffers"], [1422, 3, 1, "", "children"], [1422, 3, 1, "", "compile"], [1422, 3, 1, "", "cpu"], [1422, 3, 1, "", "cuda"], [1422, 3, 1, "", "double"], [1422, 3, 1, "", "eval"], [1422, 3, 1, "", "extra_repr"], [1422, 3, 1, "", "float"], [1422, 3, 1, "", "forward"], [1422, 3, 1, "", "get_buffer"], [1422, 3, 1, "", "get_extra_state"], [1422, 3, 1, "", "get_parameter"], [1422, 3, 1, "", "get_submodule"], [1422, 3, 1, "", "half"], [1422, 3, 1, "", "ipu"], [1422, 3, 1, "", "load_state_dict"], [1422, 3, 1, "", "modules"], [1422, 3, 1, "", "named_buffers"], [1422, 3, 1, "", "named_children"], [1422, 3, 1, "", "named_modules"], [1422, 3, 1, "", "named_parameters"], [1422, 3, 1, "", "parameters"], [1422, 3, 1, "", "register_backward_hook"], [1422, 3, 1, "", "register_buffer"], [1422, 3, 1, "", "register_forward_hook"], [1422, 3, 1, "", "register_forward_pre_hook"], [1422, 3, 1, "", "register_full_backward_hook"], [1422, 3, 1, "", "register_full_backward_pre_hook"], [1422, 3, 1, "", "register_load_state_dict_post_hook"], [1422, 3, 1, "", "register_module"], [1422, 3, 1, "", "register_parameter"], [1422, 3, 1, "", "register_state_dict_pre_hook"], [1422, 3, 1, "", "requires_grad_"], [1422, 3, 1, "", "set_extra_state"], [1422, 3, 1, "", "share_memory"], [1422, 3, 1, "", "state_dict"], [1422, 3, 1, "", "to"], [1422, 3, 1, "", "to_empty"], [1422, 3, 1, "", "train"], [1422, 3, 1, "", "type"], [1422, 3, 1, "", "xpu"], [1422, 3, 1, "", "zero_grad"]], "torch.nn.ModuleDict": [[1423, 3, 1, "", "clear"], [1423, 3, 1, "", "items"], [1423, 3, 1, "", "keys"], [1423, 3, 1, "", "pop"], [1423, 3, 1, "", "update"], [1423, 3, 1, "", "values"]], "torch.nn.ModuleList": [[1424, 3, 1, "", "append"], [1424, 3, 1, "", "extend"], [1424, 3, 1, "", "insert"]], "torch.nn.MultiheadAttention": [[1428, 3, 1, "", "forward"], [1428, 3, 1, "", "merge_masks"]], "torch.nn.ParameterDict": [[1432, 3, 1, "", "clear"], [1432, 3, 1, "", "copy"], [1432, 3, 1, "", "fromkeys"], [1432, 3, 1, "", "get"], [1432, 3, 1, "", "items"], [1432, 3, 1, "", "keys"], [1432, 3, 1, "", "pop"], [1432, 3, 1, "", "popitem"], [1432, 3, 1, "", "setdefault"], [1432, 3, 1, "", "update"], [1432, 3, 1, "", "values"]], "torch.nn.ParameterList": [[1433, 3, 1, "", "append"], [1433, 3, 1, "", "extend"]], "torch.nn.RNNBase": [[1438, 3, 1, "", "flatten_parameters"]], "torch.nn.Sequential": [[1450, 3, 1, "", "append"]], "torch.nn.SyncBatchNorm": [[1461, 3, 1, "", "convert_sync_batchnorm"]], "torch.nn.Transformer": [[1465, 3, 1, "", "forward"], [1465, 3, 1, "", "generate_square_subsequent_mask"]], "torch.nn.TransformerDecoder": [[1466, 3, 1, "", "forward"]], "torch.nn.TransformerDecoderLayer": [[1467, 3, 1, "", "forward"]], "torch.nn.TransformerEncoder": [[1468, 3, 1, "", "forward"]], "torch.nn.TransformerEncoderLayer": [[1469, 3, 1, "", "forward"]], "torch.nn.functional": [[1480, 5, 1, "", "adaptive_avg_pool1d"], [1481, 5, 1, "", "adaptive_avg_pool2d"], [1482, 5, 1, "", "adaptive_avg_pool3d"], [1483, 5, 1, "", "adaptive_max_pool1d"], [1484, 5, 1, "", "adaptive_max_pool2d"], [1485, 5, 1, "", "adaptive_max_pool3d"], [1486, 5, 1, "", "affine_grid"], [1487, 5, 1, "", "alpha_dropout"], [1488, 5, 1, "", "avg_pool1d"], [1489, 5, 1, "", "avg_pool2d"], [1490, 5, 1, "", "avg_pool3d"], [1491, 5, 1, "", "batch_norm"], [1492, 5, 1, "", "bilinear"], [1493, 5, 1, "", "binary_cross_entropy"], [1494, 5, 1, "", "binary_cross_entropy_with_logits"], [1495, 5, 1, "", "celu"], [1496, 5, 1, "", "conv1d"], [1497, 5, 1, "", "conv2d"], [1498, 5, 1, "", "conv3d"], [1499, 5, 1, "", "conv_transpose1d"], [1500, 5, 1, "", "conv_transpose2d"], [1501, 5, 1, "", "conv_transpose3d"], [1502, 5, 1, "", "cosine_embedding_loss"], [1503, 5, 1, "", "cosine_similarity"], [1504, 5, 1, "", "cross_entropy"], [1505, 5, 1, "", "ctc_loss"], [1506, 5, 1, "", "dropout"], [1507, 5, 1, "", "dropout1d"], [1508, 5, 1, "", "dropout2d"], [1509, 5, 1, "", "dropout3d"], [1510, 5, 1, "", "elu"], [1511, 5, 1, "", "elu_"], [1512, 5, 1, "", "embedding"], [1513, 5, 1, "", "embedding_bag"], [1514, 5, 1, "", "feature_alpha_dropout"], [1515, 5, 1, "", "fold"], [1516, 5, 1, "", "fractional_max_pool2d"], [1517, 5, 1, "", "fractional_max_pool3d"], [1518, 5, 1, "", "gaussian_nll_loss"], [1519, 5, 1, "", "gelu"], [1520, 5, 1, "", "glu"], [1521, 5, 1, "", "grid_sample"], [1522, 5, 1, "", "group_norm"], [1523, 5, 1, "", "gumbel_softmax"], [1524, 5, 1, "", "hardshrink"], [1525, 5, 1, "", "hardsigmoid"], [1526, 5, 1, "", "hardswish"], [1527, 5, 1, "", "hardtanh"], [1528, 5, 1, "", "hardtanh_"], [1529, 5, 1, "", "hinge_embedding_loss"], [1530, 5, 1, "", "huber_loss"], [1531, 5, 1, "", "instance_norm"], [1532, 5, 1, "", "interpolate"], [1533, 5, 1, "", "kl_div"], [1534, 5, 1, "", "l1_loss"], [1535, 5, 1, "", "layer_norm"], [1536, 5, 1, "", "leaky_relu"], [1537, 5, 1, "", "leaky_relu_"], [1538, 5, 1, "", "linear"], [1539, 5, 1, "", "local_response_norm"], [1540, 5, 1, "", "log_softmax"], [1541, 5, 1, "", "logsigmoid"], [1542, 5, 1, "", "lp_pool1d"], [1543, 5, 1, "", "lp_pool2d"], [1544, 5, 1, "", "margin_ranking_loss"], [1545, 5, 1, "", "max_pool1d"], [1546, 5, 1, "", "max_pool2d"], [1547, 5, 1, "", "max_pool3d"], [1548, 5, 1, "", "max_unpool1d"], [1549, 5, 1, "", "max_unpool2d"], [1550, 5, 1, "", "max_unpool3d"], [1551, 5, 1, "", "mish"], [1552, 5, 1, "", "mse_loss"], [1553, 5, 1, "", "multi_margin_loss"], [1554, 5, 1, "", "multilabel_margin_loss"], [1555, 5, 1, "", "multilabel_soft_margin_loss"], [1556, 5, 1, "", "nll_loss"], [1557, 5, 1, "", "normalize"], [1558, 5, 1, "", "one_hot"], [1559, 5, 1, "", "pad"], [1560, 5, 1, "", "pairwise_distance"], [1561, 5, 1, "", "pdist"], [1562, 5, 1, "", "pixel_shuffle"], [1563, 5, 1, "", "pixel_unshuffle"], [1564, 5, 1, "", "poisson_nll_loss"], [1565, 5, 1, "", "prelu"], [1566, 5, 1, "", "relu"], [1567, 5, 1, "", "relu6"], [1568, 5, 1, "", "relu_"], [1569, 5, 1, "", "rrelu"], [1570, 5, 1, "", "rrelu_"], [1571, 5, 1, "", "scaled_dot_product_attention"], [1572, 5, 1, "", "selu"], [1573, 5, 1, "", "sigmoid"], [1574, 5, 1, "", "silu"], [1575, 5, 1, "", "smooth_l1_loss"], [1576, 5, 1, "", "soft_margin_loss"], [1577, 5, 1, "", "softmax"], [1578, 5, 1, "", "softmin"], [1579, 5, 1, "", "softplus"], [1580, 5, 1, "", "softshrink"], [1581, 5, 1, "", "softsign"], [1582, 5, 1, "", "tanh"], [1583, 5, 1, "", "tanhshrink"], [1584, 5, 1, "", "threshold"], [1585, 5, 1, "", "threshold_"], [1587, 5, 1, "", "triplet_margin_loss"], [1588, 5, 1, "", "triplet_margin_with_distance_loss"], [1589, 5, 1, "", "unfold"], [1590, 5, 1, "", "upsample"], [1591, 5, 1, "", "upsample_bilinear"], [1592, 5, 1, "", "upsample_nearest"]], "torch.nn.init": [[1881, 5, 1, "", "calculate_gain"], [1881, 5, 1, "", "constant_"], [1881, 5, 1, "", "dirac_"], [1881, 5, 1, "", "eye_"], [1881, 5, 1, "", "kaiming_normal_"], [1881, 5, 1, "", "kaiming_uniform_"], [1881, 5, 1, "", "normal_"], [1881, 5, 1, "", "ones_"], [1881, 5, 1, "", "orthogonal_"], [1881, 5, 1, "", "sparse_"], [1881, 5, 1, "", "trunc_normal_"], [1881, 5, 1, "", "uniform_"], [1881, 5, 1, "", "xavier_normal_"], [1881, 5, 1, "", "xavier_uniform_"], [1881, 5, 1, "", "zeros_"]], "torch.nn.intrinsic": [[1911, 0, 0, "-", "modules"], [1911, 0, 0, "-", "qat"], [1911, 0, 0, "-", "quantized"]], "torch.nn.intrinsic.qat": [[1911, 0, 0, "-", "modules"]], "torch.nn.intrinsic.quantized": [[1911, 0, 0, "-", "dynamic"], [1911, 0, 0, "-", "modules"]], "torch.nn.intrinsic.quantized.dynamic": [[1911, 0, 0, "-", "modules"]], "torch.nn.modules.lazy": [[1593, 1, 1, "", "LazyModuleMixin"]], "torch.nn.modules.lazy.LazyModuleMixin": [[1593, 3, 1, "", "has_uninitialized_params"], [1593, 3, 1, "", "initialize_parameters"]], "torch.nn.modules.module": [[1594, 5, 1, "", "register_module_backward_hook"], [1595, 5, 1, "", "register_module_buffer_registration_hook"], [1596, 5, 1, "", "register_module_forward_hook"], [1597, 5, 1, "", "register_module_forward_pre_hook"], [1598, 5, 1, "", "register_module_full_backward_hook"], [1599, 5, 1, "", "register_module_full_backward_pre_hook"], [1600, 5, 1, "", "register_module_module_registration_hook"], [1601, 5, 1, "", "register_module_parameter_registration_hook"]], "torch.nn.parallel": [[1602, 1, 1, "", "DistributedDataParallel"], [1586, 5, 1, "", "data_parallel"]], "torch.nn.parallel.DistributedDataParallel": [[1602, 3, 1, "", "join"], [1602, 3, 1, "", "join_hook"], [1602, 3, 1, "", "no_sync"], [1602, 3, 1, "", "register_comm_hook"]], "torch.nn.parameter": [[1603, 1, 1, "", "Parameter"], [1604, 1, 1, "", "UninitializedBuffer"], [1605, 1, 1, "", "UninitializedParameter"]], "torch.nn.parameter.UninitializedParameter": [[1605, 2, 1, "", "cls_to_become"]], "torch.nn.qat": [[1911, 0, 0, "-", "dynamic"], [1911, 0, 0, "-", "modules"]], "torch.nn.qat.dynamic": [[1911, 0, 0, "-", "modules"]], "torch.nn.quantizable": [[1911, 0, 0, "-", "modules"]], "torch.nn.quantized": [[1911, 0, 0, "-", "dynamic"], [1911, 0, 0, "-", "modules"]], "torch.nn.quantized.dynamic": [[1911, 0, 0, "-", "modules"]], "torch.nn.utils": [[1606, 5, 1, "", "clip_grad_norm_"], [1607, 5, 1, "", "clip_grad_value_"], [1608, 5, 1, "", "parameters_to_vector"], [1633, 5, 1, "", "remove_spectral_norm"], [1634, 5, 1, "", "remove_weight_norm"], [1642, 5, 1, "", "skip_init"], [1643, 5, 1, "", "spectral_norm"], [1879, 0, 0, "-", "stateless"], [1645, 5, 1, "", "vector_to_parameters"], [1646, 5, 1, "", "weight_norm"]], "torch.nn.utils.parametrizations": [[1609, 5, 1, "", "orthogonal"], [1610, 5, 1, "", "spectral_norm"]], "torch.nn.utils.parametrize": [[1611, 1, 1, "", "ParametrizationList"], [1612, 5, 1, "", "cached"], [1613, 5, 1, "", "is_parametrized"], [1614, 5, 1, "", "register_parametrization"], [1615, 5, 1, "", "remove_parametrizations"]], "torch.nn.utils.parametrize.ParametrizationList": [[1611, 3, 1, "", "right_inverse"]], "torch.nn.utils.prune": [[1616, 1, 1, "", "BasePruningMethod"], [1617, 1, 1, "", "CustomFromMask"], [1618, 1, 1, "", "Identity"], [1619, 1, 1, "", "L1Unstructured"], [1620, 1, 1, "", "LnStructured"], [1621, 1, 1, "", "PruningContainer"], [1622, 1, 1, "", "RandomStructured"], [1623, 1, 1, "", "RandomUnstructured"], [1624, 5, 1, "", "custom_from_mask"], [1625, 5, 1, "", "global_unstructured"], [1626, 5, 1, "", "identity"], [1627, 5, 1, "", "is_pruned"], [1628, 5, 1, "", "l1_unstructured"], [1629, 5, 1, "", "ln_structured"], [1630, 5, 1, "", "random_structured"], [1631, 5, 1, "", "random_unstructured"], [1632, 5, 1, "", "remove"]], "torch.nn.utils.prune.BasePruningMethod": [[1616, 3, 1, "", "apply"], [1616, 3, 1, "", "apply_mask"], [1616, 3, 1, "", "compute_mask"], [1616, 3, 1, "", "prune"], [1616, 3, 1, "", "remove"]], "torch.nn.utils.prune.CustomFromMask": [[1617, 3, 1, "", "apply"], [1617, 3, 1, "", "apply_mask"], [1617, 3, 1, "", "prune"], [1617, 3, 1, "", "remove"]], "torch.nn.utils.prune.Identity": [[1618, 3, 1, "", "apply"], [1618, 3, 1, "", "apply_mask"], [1618, 3, 1, "", "prune"], [1618, 3, 1, "", "remove"]], "torch.nn.utils.prune.L1Unstructured": [[1619, 3, 1, "", "apply"], [1619, 3, 1, "", "apply_mask"], [1619, 3, 1, "", "prune"], [1619, 3, 1, "", "remove"]], "torch.nn.utils.prune.LnStructured": [[1620, 3, 1, "", "apply"], [1620, 3, 1, "", "apply_mask"], [1620, 3, 1, "", "compute_mask"], [1620, 3, 1, "", "prune"], [1620, 3, 1, "", "remove"]], "torch.nn.utils.prune.PruningContainer": [[1621, 3, 1, "", "add_pruning_method"], [1621, 3, 1, "", "apply"], [1621, 3, 1, "", "apply_mask"], [1621, 3, 1, "", "compute_mask"], [1621, 3, 1, "", "prune"], [1621, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomStructured": [[1622, 3, 1, "", "apply"], [1622, 3, 1, "", "apply_mask"], [1622, 3, 1, "", "compute_mask"], [1622, 3, 1, "", "prune"], [1622, 3, 1, "", "remove"]], "torch.nn.utils.prune.RandomUnstructured": [[1623, 3, 1, "", "apply"], [1623, 3, 1, "", "apply_mask"], [1623, 3, 1, "", "prune"], [1623, 3, 1, "", "remove"]], "torch.nn.utils.rnn": [[1635, 1, 1, "", "PackedSequence"], [1636, 5, 1, "", "pack_padded_sequence"], [1637, 5, 1, "", "pack_sequence"], [1638, 5, 1, "", "pad_packed_sequence"], [1639, 5, 1, "", "pad_sequence"], [1640, 5, 1, "", "unpack_sequence"], [1641, 5, 1, "", "unpad_sequence"]], "torch.nn.utils.rnn.PackedSequence": [[1635, 2, 1, "", "batch_sizes"], [1635, 3, 1, "", "count"], [1635, 2, 1, "", "data"], [1635, 3, 1, "", "index"], [1635, 4, 1, "", "is_cuda"], [1635, 3, 1, "", "is_pinned"], [1635, 2, 1, "", "sorted_indices"], [1635, 3, 1, "", "to"], [1635, 2, 1, "", "unsorted_indices"]], "torch.nn.utils.stateless": [[1644, 5, 1, "", "functional_call"]], "torch.onnx": [[1655, 1, 1, "", "ExportOptions"], [1656, 1, 1, "", "ExportOutput"], [1657, 1, 1, "", "ExportOutputSerializer"], [1658, 1, 1, "", "JitScalarType"], [1901, 5, 1, "", "disable_log"], [1901, 5, 1, "", "dynamo_export"], [1901, 5, 1, "", "enable_log"], [1901, 5, 1, "", "export"], [1901, 5, 1, "", "export_to_pretty_string"], [1901, 5, 1, "", "is_in_onnx_export"], [1901, 5, 1, "", "register_custom_op_symbolic"], [1901, 5, 1, "", "select_model_mode_for_export"], [1901, 5, 1, "", "unregister_custom_op_symbolic"]], "torch.onnx.ExportOutput": [[1656, 3, 1, "", "adapt_torch_inputs_to_onnx"], [1656, 3, 1, "", "adapt_torch_outputs_to_onnx"], [1656, 4, 1, "", "diagnostic_context"], [1656, 4, 1, "", "model_proto"], [1656, 3, 1, "", "save"]], "torch.onnx.ExportOutputSerializer": [[1657, 3, 1, "", "serialize"]], "torch.onnx.JitScalarType": [[1658, 3, 1, "", "dtype"], [1658, 3, 1, "", "from_dtype"], [1658, 3, 1, "", "from_value"], [1658, 3, 1, "", "onnx_compatible"], [1658, 3, 1, "", "onnx_type"], [1658, 3, 1, "", "scalar_name"], [1658, 3, 1, "", "torch_name"]], "torch.onnx._internal": [[1902, 0, 0, "-", "diagnostics"]], "torch.onnx._internal.diagnostics": [[1902, 1, 1, "", "ExportDiagnostic"]], "torch.onnx._internal.diagnostics.ExportDiagnostic": [[1902, 3, 1, "", "record_cpp_call_stack"]], "torch.onnx.verification": [[1659, 1, 1, "", "GraphInfo"], [1660, 1, 1, "", "VerificationOptions"], [1901, 5, 1, "", "find_mismatch"]], "torch.onnx.verification.GraphInfo": [[1659, 3, 1, "", "all_mismatch_leaf_graph_info"], [1659, 3, 1, "", "clear"], [1659, 3, 1, "", "essential_node_count"], [1659, 3, 1, "", "essential_node_kinds"], [1659, 3, 1, "", "export_repro"], [1659, 3, 1, "", "find_mismatch"], [1659, 3, 1, "", "find_partition"], [1659, 3, 1, "", "has_mismatch"], [1659, 3, 1, "", "pretty_print_mismatch"], [1659, 3, 1, "", "pretty_print_tree"], [1659, 3, 1, "", "verify_export"]], "torch.optim": [[1661, 1, 1, "", "ASGD"], [1662, 1, 1, "", "Adadelta"], [1663, 1, 1, "", "Adagrad"], [1664, 1, 1, "", "Adam"], [1665, 1, 1, "", "AdamW"], [1666, 1, 1, "", "Adamax"], [1667, 1, 1, "", "LBFGS"], [1668, 1, 1, "", "NAdam"], [1904, 1, 1, "", "Optimizer"], [1674, 1, 1, "", "RAdam"], [1675, 1, 1, "", "RMSprop"], [1676, 1, 1, "", "Rprop"], [1677, 1, 1, "", "SGD"], [1678, 1, 1, "", "SparseAdam"]], "torch.optim.ASGD": [[1661, 3, 1, "", "add_param_group"], [1661, 3, 1, "", "load_state_dict"], [1661, 3, 1, "", "register_step_post_hook"], [1661, 3, 1, "", "register_step_pre_hook"], [1661, 3, 1, "", "state_dict"], [1661, 3, 1, "", "zero_grad"]], "torch.optim.Adadelta": [[1662, 3, 1, "", "add_param_group"], [1662, 3, 1, "", "load_state_dict"], [1662, 3, 1, "", "register_step_post_hook"], [1662, 3, 1, "", "register_step_pre_hook"], [1662, 3, 1, "", "state_dict"], [1662, 3, 1, "", "zero_grad"]], "torch.optim.Adagrad": [[1663, 3, 1, "", "add_param_group"], [1663, 3, 1, "", "load_state_dict"], [1663, 3, 1, "", "register_step_post_hook"], [1663, 3, 1, "", "register_step_pre_hook"], [1663, 3, 1, "", "state_dict"], [1663, 3, 1, "", "zero_grad"]], "torch.optim.Adam": [[1664, 3, 1, "", "add_param_group"], [1664, 3, 1, "", "load_state_dict"], [1664, 3, 1, "", "register_step_post_hook"], [1664, 3, 1, "", "register_step_pre_hook"], [1664, 3, 1, "", "state_dict"], [1664, 3, 1, "", "zero_grad"]], "torch.optim.AdamW": [[1665, 3, 1, "", "add_param_group"], [1665, 3, 1, "", "load_state_dict"], [1665, 3, 1, "", "register_step_post_hook"], [1665, 3, 1, "", "register_step_pre_hook"], [1665, 3, 1, "", "state_dict"], [1665, 3, 1, "", "zero_grad"]], "torch.optim.Adamax": [[1666, 3, 1, "", "add_param_group"], [1666, 3, 1, "", "load_state_dict"], [1666, 3, 1, "", "register_step_post_hook"], [1666, 3, 1, "", "register_step_pre_hook"], [1666, 3, 1, "", "state_dict"], [1666, 3, 1, "", "zero_grad"]], "torch.optim.LBFGS": [[1667, 3, 1, "", "add_param_group"], [1667, 3, 1, "", "load_state_dict"], [1667, 3, 1, "", "register_step_post_hook"], [1667, 3, 1, "", "register_step_pre_hook"], [1667, 3, 1, "", "state_dict"], [1667, 3, 1, "", "step"], [1667, 3, 1, "", "zero_grad"]], "torch.optim.NAdam": [[1668, 3, 1, "", "add_param_group"], [1668, 3, 1, "", "load_state_dict"], [1668, 3, 1, "", "register_step_post_hook"], [1668, 3, 1, "", "register_step_pre_hook"], [1668, 3, 1, "", "state_dict"], [1668, 3, 1, "", "zero_grad"]], "torch.optim.Optimizer": [[1669, 3, 1, "", "add_param_group"], [1670, 3, 1, "", "load_state_dict"], [1671, 3, 1, "", "state_dict"], [1672, 3, 1, "", "step"], [1673, 3, 1, "", "zero_grad"]], "torch.optim.RAdam": [[1674, 3, 1, "", "add_param_group"], [1674, 3, 1, "", "load_state_dict"], [1674, 3, 1, "", "register_step_post_hook"], [1674, 3, 1, "", "register_step_pre_hook"], [1674, 3, 1, "", "state_dict"], [1674, 3, 1, "", "zero_grad"]], "torch.optim.RMSprop": [[1675, 3, 1, "", "add_param_group"], [1675, 3, 1, "", "load_state_dict"], [1675, 3, 1, "", "register_step_post_hook"], [1675, 3, 1, "", "register_step_pre_hook"], [1675, 3, 1, "", "state_dict"], [1675, 3, 1, "", "zero_grad"]], "torch.optim.Rprop": [[1676, 3, 1, "", "add_param_group"], [1676, 3, 1, "", "load_state_dict"], [1676, 3, 1, "", "register_step_post_hook"], [1676, 3, 1, "", "register_step_pre_hook"], [1676, 3, 1, "", "state_dict"], [1676, 3, 1, "", "zero_grad"]], "torch.optim.SGD": [[1677, 3, 1, "", "add_param_group"], [1677, 3, 1, "", "load_state_dict"], [1677, 3, 1, "", "register_step_post_hook"], [1677, 3, 1, "", "register_step_pre_hook"], [1677, 3, 1, "", "state_dict"], [1677, 3, 1, "", "zero_grad"]], "torch.optim.SparseAdam": [[1678, 3, 1, "", "add_param_group"], [1678, 3, 1, "", "load_state_dict"], [1678, 3, 1, "", "register_step_post_hook"], [1678, 3, 1, "", "register_step_pre_hook"], [1678, 3, 1, "", "state_dict"], [1678, 3, 1, "", "step"], [1678, 3, 1, "", "zero_grad"]], "torch.optim.lr_scheduler": [[1679, 1, 1, "", "ChainedScheduler"], [1680, 1, 1, "", "ConstantLR"], [1681, 1, 1, "", "CosineAnnealingLR"], [1682, 1, 1, "", "CosineAnnealingWarmRestarts"], [1683, 1, 1, "", "CyclicLR"], [1684, 1, 1, "", "ExponentialLR"], [1685, 1, 1, "", "LambdaLR"], [1686, 1, 1, "", "LinearLR"], [1687, 1, 1, "", "MultiStepLR"], [1688, 1, 1, "", "MultiplicativeLR"], [1689, 1, 1, "", "OneCycleLR"], [1690, 1, 1, "", "PolynomialLR"], [1691, 1, 1, "", "ReduceLROnPlateau"], [1692, 1, 1, "", "SequentialLR"], [1693, 1, 1, "", "StepLR"]], "torch.optim.lr_scheduler.ChainedScheduler": [[1679, 3, 1, "", "get_last_lr"], [1679, 3, 1, "", "load_state_dict"], [1679, 3, 1, "", "print_lr"], [1679, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.ConstantLR": [[1680, 3, 1, "", "get_last_lr"], [1680, 3, 1, "", "load_state_dict"], [1680, 3, 1, "", "print_lr"], [1680, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.CosineAnnealingLR": [[1681, 3, 1, "", "get_last_lr"], [1681, 3, 1, "", "load_state_dict"], [1681, 3, 1, "", "print_lr"], [1681, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts": [[1682, 3, 1, "", "get_last_lr"], [1682, 3, 1, "", "load_state_dict"], [1682, 3, 1, "", "print_lr"], [1682, 3, 1, "", "state_dict"], [1682, 3, 1, "", "step"]], "torch.optim.lr_scheduler.CyclicLR": [[1683, 3, 1, "", "get_last_lr"], [1683, 3, 1, "", "get_lr"], [1683, 3, 1, "", "print_lr"]], "torch.optim.lr_scheduler.ExponentialLR": [[1684, 3, 1, "", "get_last_lr"], [1684, 3, 1, "", "load_state_dict"], [1684, 3, 1, "", "print_lr"], [1684, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.LambdaLR": [[1685, 3, 1, "", "get_last_lr"], [1685, 3, 1, "", "load_state_dict"], [1685, 3, 1, "", "print_lr"], [1685, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.LinearLR": [[1686, 3, 1, "", "get_last_lr"], [1686, 3, 1, "", "load_state_dict"], [1686, 3, 1, "", "print_lr"], [1686, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.MultiStepLR": [[1687, 3, 1, "", "get_last_lr"], [1687, 3, 1, "", "load_state_dict"], [1687, 3, 1, "", "print_lr"], [1687, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.MultiplicativeLR": [[1688, 3, 1, "", "get_last_lr"], [1688, 3, 1, "", "load_state_dict"], [1688, 3, 1, "", "print_lr"], [1688, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.OneCycleLR": [[1689, 3, 1, "", "get_last_lr"], [1689, 3, 1, "", "load_state_dict"], [1689, 3, 1, "", "print_lr"], [1689, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.PolynomialLR": [[1690, 3, 1, "", "get_last_lr"], [1690, 3, 1, "", "load_state_dict"], [1690, 3, 1, "", "print_lr"], [1690, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.SequentialLR": [[1692, 3, 1, "", "get_last_lr"], [1692, 3, 1, "", "load_state_dict"], [1692, 3, 1, "", "print_lr"], [1692, 3, 1, "", "state_dict"]], "torch.optim.lr_scheduler.StepLR": [[1693, 3, 1, "", "get_last_lr"], [1693, 3, 1, "", "load_state_dict"], [1693, 3, 1, "", "print_lr"], [1693, 3, 1, "", "state_dict"]], "torch.overrides": [[1928, 5, 1, "", "get_ignored_functions"], [1928, 5, 1, "", "get_overridable_functions"], [1928, 5, 1, "", "get_testing_overrides"], [1928, 5, 1, "", "handle_torch_function"], [1928, 5, 1, "", "has_torch_function"], [1928, 5, 1, "", "is_tensor_like"], [1928, 5, 1, "", "is_tensor_method_or_property"], [1928, 5, 1, "", "resolve_name"], [1928, 5, 1, "", "wrap_torch_function"]], "torch.package": [[1905, 1, 1, "", "Directory"], [1905, 1, 1, "", "EmptyMatchError"], [1905, 1, 1, "", "PackageExporter"], [1905, 1, 1, "", "PackageImporter"], [1905, 1, 1, "", "PackagingError"], [1905, 0, 0, "-", "analyze"]], "torch.package.Directory": [[1905, 3, 1, "", "has_file"]], "torch.package.PackageExporter": [[1905, 3, 1, "", "__init__"], [1905, 3, 1, "", "add_dependency"], [1905, 3, 1, "", "all_paths"], [1905, 3, 1, "", "close"], [1905, 3, 1, "", "denied_modules"], [1905, 3, 1, "", "deny"], [1905, 3, 1, "", "dependency_graph_string"], [1905, 3, 1, "", "extern"], [1905, 3, 1, "", "externed_modules"], [1905, 3, 1, "", "get_rdeps"], [1905, 3, 1, "", "get_unique_id"], [1905, 3, 1, "", "intern"], [1905, 3, 1, "", "interned_modules"], [1905, 3, 1, "", "mock"], [1905, 3, 1, "", "mocked_modules"], [1905, 3, 1, "", "register_extern_hook"], [1905, 3, 1, "", "register_intern_hook"], [1905, 3, 1, "", "register_mock_hook"], [1905, 3, 1, "", "save_binary"], [1905, 3, 1, "", "save_module"], [1905, 3, 1, "", "save_pickle"], [1905, 3, 1, "", "save_source_file"], [1905, 3, 1, "", "save_source_string"], [1905, 3, 1, "", "save_text"]], "torch.package.PackageImporter": [[1905, 3, 1, "", "__init__"], [1905, 3, 1, "", "file_structure"], [1905, 3, 1, "", "id"], [1905, 3, 1, "", "import_module"], [1905, 3, 1, "", "load_binary"], [1905, 3, 1, "", "load_pickle"], [1905, 3, 1, "", "load_text"], [1905, 3, 1, "", "python_version"]], "torch.profiler": [[1907, 1, 1, "", "ProfilerAction"], [1907, 1, 1, "", "ProfilerActivity"], [1907, 1, 1, "", "_KinetoProfile"], [1907, 1, 1, "", "profile"], [1907, 5, 1, "", "schedule"], [1907, 5, 1, "", "tensorboard_trace_handler"]], "torch.profiler.ProfilerActivity": [[1907, 4, 1, "", "name"]], "torch.profiler._KinetoProfile": [[1907, 3, 1, "", "add_metadata"], [1907, 3, 1, "", "add_metadata_json"], [1907, 3, 1, "", "events"], [1907, 3, 1, "", "export_chrome_trace"], [1907, 3, 1, "", "export_memory_timeline"], [1907, 3, 1, "", "export_stacks"], [1907, 3, 1, "", "key_averages"]], "torch.profiler.itt": [[1907, 5, 1, "", "is_available"], [1907, 5, 1, "", "mark"], [1907, 5, 1, "", "range_pop"], [1907, 5, 1, "", "range_push"]], "torch.profiler.profile": [[1907, 3, 1, "", "step"]], "torch.quantization": [[1911, 0, 0, "-", "fx"]], "torch.quasirandom": [[1714, 1, 1, "", "SobolEngine"]], "torch.quasirandom.SobolEngine": [[1714, 3, 1, "", "draw"], [1714, 3, 1, "", "draw_base2"], [1714, 3, 1, "", "fast_forward"], [1714, 3, 1, "", "reset"]], "torch.random": [[1912, 5, 1, "", "fork_rng"], [1912, 5, 1, "", "get_rng_state"], [1912, 5, 1, "", "initial_seed"], [1912, 5, 1, "", "manual_seed"], [1912, 5, 1, "", "seed"], [1912, 5, 1, "", "set_rng_state"]], "torch.signal": [[1916, 0, 0, "-", "windows"]], "torch.signal.windows": [[1762, 5, 1, "", "bartlett"], [1763, 5, 1, "", "blackman"], [1764, 5, 1, "", "cosine"], [1765, 5, 1, "", "exponential"], [1766, 5, 1, "", "gaussian"], [1767, 5, 1, "", "general_cosine"], [1768, 5, 1, "", "general_hamming"], [1769, 5, 1, "", "hamming"], [1770, 5, 1, "", "hann"], [1771, 5, 1, "", "kaiser"], [1772, 5, 1, "", "nuttall"]], "torch.sparse": [[1782, 5, 1, "", "addmm"], [1783, 1, 1, "", "check_sparse_tensor_invariants"], [1784, 5, 1, "", "log_softmax"], [1785, 5, 1, "", "mm"], [1786, 5, 1, "", "sampled_addmm"], [1787, 5, 1, "", "softmax"], [1788, 5, 1, "", "spdiags"], [1789, 5, 1, "", "sum"]], "torch.sparse.check_sparse_tensor_invariants": [[1783, 3, 1, "", "disable"], [1783, 3, 1, "", "enable"], [1783, 3, 1, "", "is_enabled"]], "torch.special": [[1918, 5, 1, "", "airy_ai"], [1918, 5, 1, "", "bessel_j0"], [1918, 5, 1, "", "bessel_j1"], [1918, 5, 1, "", "digamma"], [1918, 5, 1, "", "entr"], [1918, 5, 1, "", "erf"], [1918, 5, 1, "", "erfc"], [1918, 5, 1, "", "erfcx"], [1918, 5, 1, "", "erfinv"], [1918, 5, 1, "", "exp2"], [1918, 5, 1, "", "expit"], [1918, 5, 1, "", "expm1"], [1918, 5, 1, "", "gammainc"], [1918, 5, 1, "", "gammaincc"], [1918, 5, 1, "", "gammaln"], [1918, 5, 1, "", "i0"], [1918, 5, 1, "", "i0e"], [1918, 5, 1, "", "i1"], [1918, 5, 1, "", "i1e"], [1918, 5, 1, "", "log1p"], [1918, 5, 1, "", "log_ndtr"], [1918, 5, 1, "", "log_softmax"], [1918, 5, 1, "", "logit"], [1918, 5, 1, "", "logsumexp"], [1918, 5, 1, "", "multigammaln"], [1918, 5, 1, "", "ndtr"], [1918, 5, 1, "", "ndtri"], [1918, 5, 1, "", "polygamma"], [1918, 5, 1, "", "psi"], [1918, 5, 1, "", "round"], [1918, 5, 1, "", "scaled_modified_bessel_k0"], [1918, 5, 1, "", "scaled_modified_bessel_k1"], [1918, 5, 1, "", "sinc"], [1918, 5, 1, "", "softmax"], [1918, 5, 1, "", "spherical_bessel_j0"], [1918, 5, 1, "", "xlog1py"], [1918, 5, 1, "", "xlogy"], [1918, 5, 1, "", "zeta"]], "torch.testing": [[1924, 5, 1, "", "assert_allclose"], [1924, 5, 1, "", "assert_close"], [1924, 5, 1, "", "make_tensor"]], "torch.torch": [[1925, 2, 1, "", "default_generator"], [1929, 1, 1, "", "finfo"], [1929, 1, 1, "", "iinfo"]], "torch.utils": [[1925, 0, 0, "-", "backcompat"], [4, 0, 0, "-", "benchmark"], [5, 0, 0, "-", "bottleneck"], [38, 0, 0, "-", "data"], [1925, 0, 0, "-", "hipify"], [1866, 0, 0, "-", "jit"], [1925, 0, 0, "-", "model_dump"], [1872, 0, 0, "-", "model_zoo"], [1922, 0, 0, "-", "tensorboard"]], "torch.utils.benchmark": [[4, 1, 1, "", "CallgrindStats"], [4, 1, 1, "", "FunctionCounts"], [4, 1, 1, "", "Measurement"], [4, 1, 1, "", "Timer"], [4, 0, 0, "-", "examples"], [4, 0, 0, "-", "op_fuzzers"], [4, 0, 0, "-", "utils"]], "torch.utils.benchmark.CallgrindStats": [[4, 3, 1, "", "as_standardized"], [4, 3, 1, "", "counts"], [4, 3, 1, "", "delta"], [4, 3, 1, "", "stats"]], "torch.utils.benchmark.FunctionCounts": [[4, 3, 1, "", "denoise"], [4, 3, 1, "", "filter"], [4, 3, 1, "", "transform"]], "torch.utils.benchmark.Measurement": [[4, 3, 1, "", "merge"], [4, 4, 1, "", "significant_figures"]], "torch.utils.benchmark.Timer": [[4, 3, 1, "", "blocked_autorange"], [4, 3, 1, "", "collect_callgrind"], [4, 3, 1, "", "timeit"]], "torch.utils.benchmark.utils": [[4, 0, 0, "-", "valgrind_wrapper"]], "torch.utils.checkpoint": [[6, 5, 1, "", "checkpoint"], [6, 5, 1, "", "checkpoint_sequential"]], "torch.utils.cpp_extension": [[32, 5, 1, "", "BuildExtension"], [32, 5, 1, "", "CUDAExtension"], [32, 5, 1, "", "CppExtension"], [32, 5, 1, "", "get_compiler_abi_compatibility_and_version"], [32, 5, 1, "", "include_paths"], [32, 5, 1, "", "is_ninja_available"], [32, 5, 1, "", "load"], [32, 5, 1, "", "load_inline"], [32, 5, 1, "", "verify_ninja_availability"]], "torch.utils.data": [[38, 1, 1, "", "BatchSampler"], [38, 1, 1, "", "ChainDataset"], [38, 1, 1, "", "ConcatDataset"], [38, 1, 1, "", "DataLoader"], [38, 1, 1, "", "Dataset"], [38, 1, 1, "", "IterableDataset"], [38, 1, 1, "", "RandomSampler"], [38, 1, 1, "", "Sampler"], [38, 1, 1, "", "SequentialSampler"], [38, 1, 1, "", "StackDataset"], [38, 1, 1, "", "Subset"], [38, 1, 1, "", "SubsetRandomSampler"], [38, 1, 1, "", "TensorDataset"], [38, 1, 1, "", "WeightedRandomSampler"], [38, 0, 0, "-", "datapipes"], [38, 5, 1, "", "default_collate"], [38, 5, 1, "", "default_convert"], [38, 5, 1, "", "get_worker_info"], [38, 5, 1, "", "random_split"]], "torch.utils.data._utils.collate": [[38, 5, 1, "", "collate"]], "torch.utils.data.datapipes": [[38, 0, 0, "-", "dataframe"], [38, 0, 0, "-", "iter"], [38, 0, 0, "-", "map"], [38, 0, 0, "-", "utils"]], "torch.utils.data.distributed": [[38, 1, 1, "", "DistributedSampler"]], "torch.utils.dlpack": [[48, 5, 1, "", "from_dlpack"], [48, 5, 1, "", "to_dlpack"]], "torch.utils.mobile_optimizer": [[1871, 5, 1, "", "optimize_for_mobile"]], "torch.utils.model_zoo": [[1872, 5, 1, "", "load_url"]], "torch.utils.tensorboard.writer": [[1922, 1, 1, "", "SummaryWriter"]], "torch.utils.tensorboard.writer.SummaryWriter": [[1922, 3, 1, "", "__init__"], [1922, 3, 1, "", "add_audio"], [1922, 3, 1, "", "add_custom_scalars"], [1922, 3, 1, "", "add_embedding"], [1922, 3, 1, "", "add_figure"], [1922, 3, 1, "", "add_graph"], [1922, 3, 1, "", "add_histogram"], [1922, 3, 1, "", "add_hparams"], [1922, 3, 1, "", "add_image"], [1922, 3, 1, "", "add_images"], [1922, 3, 1, "", "add_mesh"], [1922, 3, 1, "", "add_pr_curve"], [1922, 3, 1, "", "add_scalar"], [1922, 3, 1, "", "add_scalars"], [1922, 3, 1, "", "add_text"], [1922, 3, 1, "", "add_video"], [1922, 3, 1, "", "close"], [1922, 3, 1, "", "flush"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:attribute", "3": "py:method", "4": "py:property", "5": "py:function", "6": "py:exception", "7": "std:envvar"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python class"], "2": ["py", "attribute", "Python attribute"], "3": ["py", "method", "Python method"], "4": ["py", "property", "Python property"], "5": ["py", "function", "Python function"], "6": ["py", "exception", "Python exception"], "7": ["std", "envvar", "environment variable"]}, "titleterms": {"torch": [0, 1, 2, 3, 4, 5, 6, 11, 18, 19, 22, 27, 31, 32, 34, 38, 40, 41, 43, 44, 46, 47, 48, 59, 62, 64, 65, 67, 68, 69, 70, 71, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 621, 622, 623, 624, 625, 626, 627, 628, 629, 630, 631, 632, 633, 634, 635, 636, 637, 638, 639, 640, 641, 642, 643, 644, 645, 646, 647, 648, 649, 650, 651, 652, 653, 654, 655, 656, 657, 658, 659, 660, 661, 662, 663, 664, 665, 666, 667, 668, 669, 670, 671, 672, 673, 674, 675, 676, 677, 678, 679, 680, 681, 682, 683, 684, 685, 686, 687, 688, 689, 690, 691, 692, 693, 694, 695, 696, 862, 863, 864, 865, 866, 867, 868, 869, 870, 871, 872, 873, 874, 875, 876, 877, 878, 879, 880, 881, 882, 883, 884, 885, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 918, 919, 920, 921, 922, 923, 924, 925, 926, 927, 928, 929, 930, 931, 932, 933, 934, 935, 936, 937, 938, 939, 940, 941, 942, 943, 944, 945, 946, 947, 948, 949, 950, 951, 952, 953, 954, 955, 956, 957, 958, 959, 960, 961, 962, 963, 968, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1042, 1043, 1044, 1045, 1046, 1047, 1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1056, 1057, 1058, 1059, 1060, 1061, 1062, 1063, 1064, 1065, 1066, 1068, 1069, 1070, 1071, 1072, 1073, 1074, 1075, 1076, 1077, 1078, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100, 1101, 1102, 1103, 1104, 1105, 1106, 1107, 1108, 1109, 1110, 1111, 1112, 1113, 1114, 1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1132, 1133, 1134, 1135, 1136, 1137, 1138, 1139, 1140, 1141, 1142, 1143, 1144, 1145, 1146, 1147, 1148, 1149, 1150, 1151, 1152, 1153, 1154, 1155, 1156, 1157, 1158, 1159, 1160, 1161, 1162, 1163, 1164, 1166, 1167, 1168, 1169, 1170, 1171, 1172, 1173, 1174, 1175, 1176, 1177, 1178, 1179, 1180, 1181, 1182, 1183, 1184, 1185, 1186, 1187, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1209, 1210, 1211, 1212, 1213, 1214, 1215, 1216, 1217, 1218, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1260, 1261, 1262, 1263, 1264, 1265, 1266, 1267, 1268, 1269, 1270, 1271, 1272, 1273, 1274, 1275, 1276, 1277, 1278, 1279, 1280, 1281, 1282, 1283, 1284, 1285, 1286, 1287, 1288, 1289, 1290, 1291, 1292, 1293, 1294, 1295, 1296, 1297, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1310, 1311, 1312, 1313, 1314, 1315, 1316, 1317, 1318, 1319, 1320, 1321, 1322, 1323, 1324, 1325, 1326, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1606, 1607, 1608, 1609, 1610, 1612, 1613, 1614, 1615, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1648, 1649, 1650, 1651, 1652, 1653, 1654, 1669, 1670, 1671, 1672, 1673, 1694, 1695, 1696, 1697, 1698, 1699, 1700, 1701, 1702, 1703, 1704, 1705, 1706, 1707, 1708, 1709, 1710, 1711, 1712, 1713, 1715, 1716, 1717, 1718, 1719, 1720, 1721, 1722, 1723, 1724, 1725, 1726, 1727, 1728, 1729, 1730, 1731, 1732, 1733, 1734, 1735, 1736, 1737, 1738, 1739, 1740, 1741, 1742, 1743, 1744, 1745, 1746, 1747, 1748, 1749, 1750, 1751, 1752, 1754, 1755, 1756, 1757, 1758, 1759, 1760, 1761, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1773, 1774, 1775, 1776, 1777, 1778, 1779, 1780, 1781, 1782, 1784, 1785, 1786, 1787, 1788, 1789, 1790, 1791, 1792, 1793, 1794, 1795, 1796, 1797, 1798, 1799, 1800, 1801, 1802, 1803, 1804, 1805, 1806, 1807, 1808, 1809, 1810, 1811, 1812, 1813, 1814, 1815, 1816, 1817, 1818, 1819, 1820, 1821, 1822, 1823, 1824, 1825, 1826, 1827, 1828, 1829, 1830, 1831, 1832, 1833, 1834, 1835, 1836, 1837, 1838, 1839, 1840, 1841, 1842, 1843, 1844, 1845, 1846, 1847, 1848, 1849, 1850, 1851, 1852, 1853, 1854, 1855, 1856, 1857, 1858, 1863, 1865, 1866, 1867, 1868, 1869, 1870, 1871, 1872, 1873, 1874, 1875, 1878, 1879, 1880, 1881, 1886, 1888, 1889, 1892, 1897, 1899, 1901, 1902, 1904, 1905, 1907, 1911, 1912, 1916, 1917, 1918, 1919, 1920, 1922, 1923, 1924, 1925, 1926, 1927, 1928, 1929], "_dynamo": [0, 18, 27], "automat": [1, 2, 38, 1860, 1882, 1889], "mix": [1, 1860, 1882], "precis": [1, 1882, 1886, 1897], "packag": [1, 2, 33, 41, 1875, 1900, 1905], "amp": [1, 1886], "autocast": [1, 1882], "gradient": [1, 2, 69, 1143, 1882, 1883, 1889, 1925], "scale": [1, 1882, 1893], "op": [1, 1865, 1882, 1901, 1925], "refer": [1, 35, 65, 71, 1860, 1862, 1863, 1864, 1873, 1877, 1892, 1902, 1905, 1907, 1908, 1911, 1915, 1923], "elig": 1, "cuda": [1, 3, 11, 12, 34, 35, 210, 968, 971, 972, 973, 974, 975, 976, 977, 978, 979, 980, 981, 982, 983, 984, 986, 988, 989, 990, 991, 992, 993, 994, 995, 996, 997, 999, 1000, 1001, 1002, 1003, 1004, 1005, 1006, 1007, 1008, 1009, 1010, 1011, 1012, 1013, 1014, 1015, 1016, 1017, 1018, 1019, 1020, 1021, 1022, 1023, 1024, 1025, 1026, 1027, 1028, 1029, 1030, 1031, 1032, 1033, 1034, 1035, 1036, 1037, 1038, 1039, 1040, 1041, 1875, 1882, 1886, 1890, 1892, 1896, 1898, 1900], "specif": [1, 38, 1917], "behavior": [1, 38, 1883, 1891], "can": [1, 25, 1883, 1890], "float16": 1, "float32": 1, "promot": [1, 8], "widest": 1, "input": [1, 1876, 1882, 1891], "type": [1, 38, 600, 1862, 1863, 1888, 1901, 1905, 1923, 1929], "prefer": 1, "binary_cross_entropy_with_logit": [1, 1494], "over": [1, 9, 1862], "binary_cross_entropi": [1, 1493], "cpu": [1, 3, 11, 207, 1883, 1885, 1908], "bfloat16": [1, 156], "differenti": [2, 1883], "autograd": [2, 11, 30, 33, 68, 886, 887, 888, 889, 890, 892, 893, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 904, 905, 906, 907, 908, 909, 910, 911, 912, 913, 914, 915, 916, 1877, 1882, 1883, 1888, 1889, 1901, 1913, 1914], "forward": [2, 887, 1888, 1914], "mode": [2, 59, 66, 414, 1295, 1883, 1888, 1891, 1901, 1908, 1914], "function": [2, 27, 41, 47, 62, 64, 65, 67, 69, 71, 78, 83, 86, 87, 886, 887, 888, 889, 894, 895, 896, 897, 898, 899, 900, 901, 902, 903, 1120, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1860, 1861, 1862, 1863, 1865, 1868, 1870, 1876, 1878, 1879, 1880, 1882, 1883, 1889, 1891, 1901, 1911, 1917, 1918, 1928], "higher": 2, "level": [2, 11, 1911], "api": [2, 11, 15, 16, 18, 33, 35, 44, 52, 65, 68, 71, 1858, 1860, 1863, 1873, 1877, 1885, 1886, 1888, 1892, 1893, 1902, 1905, 1906, 1907, 1908, 1911], "local": [2, 25, 28, 1863, 1883, 1925], "disabl": [2, 18, 38, 1860, 1883, 1925], "comput": [2, 69, 1883, 1897, 1914, 1925], "default": [2, 38, 39, 1862, 1883, 1886, 1891, 1910], "layout": [2, 1920], "manual": 2, "In": [2, 9, 1883, 1884, 1925], "place": [2, 68, 1876, 1883, 1884, 1901, 1925], "oper": [2, 11, 16, 39, 41, 68, 88, 1862, 1863, 1868, 1870, 1876, 1877, 1878, 1883, 1888, 1893, 1900, 1901, 1903, 1908, 1917, 1923, 1925], "tensor": [2, 16, 30, 33, 46, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489, 490, 491, 492, 493, 494, 495, 496, 497, 498, 499, 500, 501, 502, 503, 504, 505, 506, 507, 508, 509, 510, 511, 512, 513, 514, 515, 516, 517, 518, 519, 520, 521, 522, 523, 524, 525, 526, 527, 528, 529, 530, 531, 532, 533, 534, 535, 536, 537, 538, 539, 540, 541, 542, 543, 544, 545, 546, 547, 548, 549, 550, 551, 552, 553, 554, 555, 556, 557, 558, 559, 560, 561, 562, 563, 564, 565, 566, 567, 568, 569, 570, 571, 572, 573, 574, 575, 576, 577, 578, 579, 580, 581, 582, 583, 584, 585, 586, 587, 588, 589, 590, 591, 592, 593, 594, 595, 596, 597, 598, 599, 600, 601, 602, 603, 604, 605, 606, 607, 608, 609, 610, 611, 612, 613, 614, 615, 616, 617, 618, 619, 620, 1822, 1861, 1865, 1868, 1875, 1876, 1877, 1878, 1883, 1888, 1899, 1901, 1908, 1911, 1917, 1920, 1921, 1923, 1925], "correct": [2, 71, 1883], "check": [2, 25, 71, 1860, 1883, 1892], "variabl": [2, 21, 23, 41, 59, 1860, 1862, 1863, 1886], "deprec": 2, "context": [2, 42, 56, 1914], "method": [2, 51, 52, 55, 60, 1861, 1862, 1865, 1901, 1911, 1917], "mixin": 2, "numer": [2, 1891, 1897, 1909], "profil": [2, 23, 29, 41, 912, 913, 914, 915, 916, 1303, 1304, 1305, 1874, 1893, 1894, 1907], "anomali": 2, "detect": 2, "graph": [2, 12, 17, 28, 29, 34, 71, 907, 908, 909, 910, 911, 998, 1860, 1883, 1886, 1908], "backend": [3, 13, 20, 29, 41, 58, 59, 1860, 1892, 1895, 1908, 1910, 1913], "cudnn": 3, "mp": [3, 11, 1298, 1299, 1300, 1301, 1302, 1303, 1304, 1305, 1306, 1307, 1308, 1309, 1874, 1895], "mkl": 3, "mkldnn": [3, 11], "openmp": 3, "opt_einsum": 3, "xeon": 3, "benchmark": [4, 23, 1898], "util": [4, 5, 6, 11, 28, 32, 38, 41, 48, 65, 67, 1041, 1606, 1607, 1608, 1609, 1610, 1612, 1613, 1614, 1615, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1866, 1871, 1872, 1879, 1911, 1922, 1925, 1927], "bottleneck": 5, "checkpoint": [6, 39, 43], "pytorch": [7, 8, 9, 10, 11, 12, 20, 24, 25, 29, 33, 40, 41, 68, 1858, 1860, 1861, 1865, 1883, 1886, 1888, 1898, 1899, 1901, 1906], "govern": [7, 10, 11], "build": [7, 8, 11, 1885, 1893, 1894, 1900], "ci": [7, 11], "how": [7, 16, 17, 25, 39, 66, 1857, 1883, 1888, 1904, 1905], "add": [7, 10, 77, 98, 682], "new": [7, 8, 10], "maintain": [7, 10, 11], "contribut": [8, 1901], "guid": 8, "process": [8, 10, 38, 56, 1882], "get": [8, 17, 20, 44, 1901], "start": [8, 20, 44, 56, 1304], "propos": 8, "featur": [8, 1893, 1894], "report": [8, 1890], "issu": [8, 29, 1860], "implement": [8, 16, 49, 58, 60, 1857, 1887, 1891, 1901, 1909, 1915], "fix": [8, 59, 66, 261, 1101], "bug": 8, "ad": [8, 1888, 1901], "tutori": [8, 11, 1905, 1906, 1913], "improv": [8, 1894], "document": [8, 44, 1858], "particip": 8, "onlin": 8, "discuss": 8, "submit": 8, "pull": 8, "request": 8, "open": 8, "review": 8, "code": [8, 17, 20, 71, 1860, 1886, 1905], "readabl": 8, "test": [8, 25, 1863, 1888, 1905, 1924], "case": [8, 1860], "make": [8, 10, 12, 21, 81], "codebas": 8, "more": [8, 22, 64, 1913], "robust": 8, "triag": 8, "about": [8, 16, 1883, 1913], "sourc": [8, 1898, 1900, 1905], "develop": [8, 1858, 1901], "common": [8, 41, 71, 1893, 1908], "mistak": 8, "To": 8, "avoid": [8, 1896, 1898, 1901, 1905], "frequent": [8, 17, 1860, 1890, 1901, 1908], "ask": [8, 17, 1860, 1890, 1901, 1908], "question": [8, 17, 1860, 1890, 1901, 1908], "On": [8, 39, 1862], "python": [8, 9, 21, 68, 1858, 1860, 1861, 1862, 1863, 1864, 1865, 1898, 1901], "doc": [8, 11, 1892], "c": [8, 11, 33, 1883, 1888, 1892, 1899, 1901], "overview": [8, 13, 21, 26, 35, 71, 1902, 1905, 1907, 1917], "design": [9, 1863, 1887, 1913, 1914, 1915], "philosophi": 9, "principl": [9, 10], "1": [9, 18, 59, 66, 1860, 1889], "usabl": 9, "perform": [9, 11, 16, 25, 29, 1894, 1899], "2": [9, 18, 24, 25, 27, 29, 66, 1860, 1886, 1889, 1890], "simpl": [9, 1862, 1863, 1894, 1914], "easi": 9, "3": [9, 18, 59, 66], "first": [9, 1905], "best": [9, 1886, 1896, 1908], "class": [9, 51, 71, 1860, 1862, 1863, 1865, 1901, 1904, 1905, 1923], "languag": [9, 1858, 1860, 1862, 1863, 1864], "interoper": 9, "mechan": [10, 1880, 1883, 1891], "summari": [10, 18, 21, 1908], "modul": [10, 11, 24, 65, 67, 71, 1422, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1860, 1861, 1862, 1863, 1865, 1879, 1883, 1888, 1894, 1899, 1905, 1908], "core": [10, 11, 1859], "lead": [10, 11], "bdfl": [10, 11], "nomin": [10, 1863], "confirm": 10, "remov": [10, 1632, 1876], "The": [10, 15, 71, 1863, 1883], "re": [10, 1905], "scope": 10, "project": 10, "decis": 10, "uncontroversi": 10, "chang": [10, 17, 59, 66], "controversi": 10, "gener": [10, 34, 42, 68, 71, 89, 1884, 1889, 1898, 1908, 1909, 1925], "polici": [10, 15], "faq": [10, 18, 1900], "respons": 11, "nn": [11, 24, 65, 67, 1480, 1481, 1482, 1483, 1484, 1485, 1486, 1487, 1488, 1489, 1490, 1491, 1492, 1493, 1494, 1495, 1496, 1497, 1498, 1499, 1500, 1501, 1502, 1503, 1504, 1505, 1506, 1507, 1508, 1509, 1510, 1511, 1512, 1513, 1514, 1515, 1516, 1517, 1518, 1519, 1520, 1521, 1522, 1523, 1524, 1525, 1526, 1527, 1528, 1529, 1530, 1531, 1532, 1533, 1534, 1535, 1536, 1537, 1538, 1539, 1540, 1541, 1542, 1543, 1544, 1545, 1546, 1547, 1548, 1549, 1550, 1551, 1552, 1553, 1554, 1555, 1556, 1557, 1558, 1559, 1560, 1561, 1562, 1563, 1564, 1565, 1566, 1567, 1568, 1569, 1570, 1571, 1572, 1573, 1574, 1575, 1576, 1577, 1578, 1579, 1580, 1581, 1582, 1583, 1584, 1585, 1586, 1587, 1588, 1589, 1590, 1591, 1592, 1594, 1595, 1596, 1597, 1598, 1599, 1600, 1601, 1606, 1607, 1608, 1609, 1610, 1612, 1613, 1614, 1615, 1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1633, 1634, 1636, 1637, 1638, 1639, 1640, 1641, 1642, 1643, 1644, 1645, 1646, 1862, 1863, 1879, 1880, 1881, 1883, 1886, 1888, 1899, 1911], "optim": [11, 20, 22, 45, 1669, 1670, 1671, 1672, 1673, 1882, 1883, 1904, 1913, 1914, 1925], "compil": [11, 17, 19, 22, 27, 29, 67, 950, 1858, 1886], "jit": [11, 1191, 1192, 1193, 1194, 1195, 1196, 1197, 1198, 1199, 1200, 1201, 1202, 1203, 1205, 1206, 1207, 1208, 1860, 1863, 1866], "torchscript": [11, 33, 1860, 1861, 1862, 1863, 1865, 1885, 1893, 1903, 1905], "fx": [11, 71, 73, 74, 75, 76, 77, 79, 80, 81, 82, 84, 1894, 1908, 1911, 1927], "torchdynamo": [11, 12, 14, 17, 18, 29, 1887, 1901], "distribut": [11, 17, 41, 43, 44, 45, 46, 47, 59, 1879, 1880, 1887, 1892, 1894, 1913, 1914], "rng": 11, "multiprocess": [11, 56, 1875, 1886, 1896, 1900], "dataload": [11, 1898], "linear": [11, 30, 729, 730, 753, 761, 778, 1127, 1409, 1538, 1879, 1880, 1897, 1917], "algebra": [11, 30, 1897, 1917], "linalg": [11, 1219, 1220, 1221, 1222, 1223, 1224, 1225, 1226, 1227, 1228, 1229, 1230, 1231, 1232, 1233, 1234, 1235, 1236, 1237, 1238, 1239, 1240, 1241, 1242, 1243, 1244, 1245, 1246, 1247, 1248, 1249, 1250, 1251, 1252, 1253, 1254, 1255, 1256, 1257, 1258, 1259, 1868, 1897], "spars": [11, 1782, 1784, 1785, 1786, 1787, 1788, 1789, 1879, 1880, 1917], "nestedtensor": 11, "nest": [11, 1878], "maskedtensor": [11, 1870], "mask": [11, 1870], "fast": [11, 62, 1891, 1914], "fourier": [11, 62], "transform": [11, 27, 28, 47, 62, 64, 65, 67, 69, 71, 1465, 1879, 1888, 1894], "fft": [11, 62, 1079, 1080, 1081, 1082, 1083, 1084, 1085, 1086, 1087, 1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098, 1099, 1100], "inductor": [11, 17], "gpu": [11, 23, 41, 1879, 1880, 1882, 1890, 1906], "triton": [11, 23], "nvfuser": 11, "amd": [11, 1897], "rocm": [11, 1892], "hip": [11, 1892], "tool": [11, 34, 1909, 1917], "c10": 11, "dispatch": 11, "onnx": [11, 79, 80, 85, 1901, 1902, 1903], "export": [11, 17, 1901, 1905], "mobil": 11, "edg": [11, 1860, 1905], "model": [11, 15, 23, 33, 1857, 1882, 1890, 1893, 1904, 1905, 1906, 1908, 1911], "compress": [11, 1917], "window": [11, 1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1900, 1916], "appl": 11, "m1": 11, "powerpc": 11, "librari": [11, 1858, 1867, 1898], "xla": 11, "torchserv": 11, "torchvis": [11, 66], "torchtext": 11, "torchaudio": 11, "torchrec": 11, "torchx": 11, "torchdata": 11, "torcharrow": 11, "cudagraph": [12, 964], "tree": 12, "background": [12, 1891, 1914, 1915], "integr": 12, "callabl": 12, "previou": 12, "limit": [12, 18, 24, 68, 71, 1857, 1889, 1901], "comparison": [12, 1860, 1862, 1863, 1925], "custom": [13, 50, 60, 71, 86, 1863, 1882, 1886, 1888, 1889, 1894, 1901, 1904, 1905, 1908], "regist": [13, 1883], "after": 13, "aotautograd": [13, 75], "exampl": [13, 53, 71, 1882, 1887, 1888, 1889, 1901, 1914], "debug": [13, 29, 39, 41, 71, 1860, 1908, 1909], "speedi": 13, "compos": [13, 64, 69], "deeper": 14, "dive": 14, "what": [14, 25, 39, 64, 66, 69, 1870, 1883, 1905], "i": [14, 16, 17, 25, 69, 1870, 1883, 1905], "guard": [14, 15, 21], "dynamo": [14, 17, 81], "do": [14, 17, 20, 1905], "dynam": [15, 16, 58, 68, 71, 1908, 1911], "shape": [15, 16, 68, 85, 1901], "motiv": [15, 16, 1870], "abridg": 15, "public": 15, "overal": [15, 16], "architectur": [15, 16], "intern": [15, 1887, 1901, 1905], "dimdynam": 15, "unback": 15, "symint": 15, "fake": 16, "relat": [16, 1911], "work": [16, 27, 38, 65, 1882, 1890, 1917], "import": [16, 59, 1857, 1900, 1905], "bit": 16, "detail": 16, "subclass": [16, 1888], "each": [16, 1905], "individu": [16, 23], "doe": [16, 39, 1883], "convert": [16, 76, 794], "characterist": 16, "interact": [16, 27], "other": [16, 41, 1879, 1898, 1905, 1917, 1925], "resourc": [16, 1905], "you": [17, 20], "support": [17, 24, 88, 1861, 1863, 1870, 1876, 1877, 1878, 1889, 1901, 1903, 1908, 1917], "still": 17, "need": [17, 20, 1882], "whole": [17, 1886], "why": [17, 20, 64, 69, 1886, 1891, 1905, 1917], "my": [17, 25, 1857, 1883, 1890, 1905], "crash": 17, "error": [17, 29, 51, 1890, 1900, 1908, 1909], "torchinductor": [17, 23, 25, 29], "slow": 17, "excess": [17, 29], "recompil": [17, 29], "ar": [17, 64, 69, 1857, 1883, 1905], "product": [17, 69, 1868], "speed": [17, 1900], "up": [17, 59], "am": 17, "see": [17, 1905], "speedup": 17, "break": [17, 29, 1862, 1863], "identifi": [17, 29, 1863], "caus": [17, 29], "didn": 17, "t": [17, 27, 567, 1817, 1863, 1890], "when": [17, 1863, 1883, 1888, 1901, 1908, 1917], "incorrect": 17, "result": 17, "oom": 17, "control": [18, 68, 71, 1898], "fine": 18, "grain": 18, "trace": [18, 71, 588, 1205, 1827, 1860, 1901, 1907, 1908], "section": 18, "tabl": [18, 1858, 1899], "disallow_in_graph": 18, "4": [18, 59, 66], "5": 18, "6": [18, 1886], "exist": 20, "anoth": [20, 1889], "wai": 20, "cach": [21, 1612, 1857, 1886, 1892], "frame": 21, "evalu": [21, 1883, 1891], "pep": 21, "523": 21, "instructiontransl": 21, "troubleshoot": [22, 29], "gotcha": [22, 1889], "learn": [22, 1904], "relev": 23, "environ": [23, 41, 59, 1886, 1893, 1905], "breakdown": 23, "time": [23, 1886], "kernel": [23, 1892, 1908], "0": [24, 25, 27, 29], "nnmodul": 24, "hook": [24, 39, 1883, 1894], "__call__": 24, "usag": [24, 35, 44, 59, 1886, 1889, 1893, 1894, 1900], "state_dict": [24, 1671], "dashboard": 25, "read": [25, 64, 1901], "measur": 25, "pr": 25, "affect": 25, "": [25, 66, 1905], "befor": 25, "merg": 25, "run": [25, 1857], "ani": [25, 119, 696, 1863], "technic": 26, "func": [27, 64, 65, 67, 69, 1119, 1120, 1121, 1122, 1123, 1124, 1125, 1126, 1127, 1128, 1129, 1130, 1131, 1888, 1889], "appli": 27, "d": 27, "doesn": [27, 1890], "pt": 27, "call": [27, 83, 1862, 1863, 1889], "insid": [27, 1905], "ed": 27, "workaround": 27, "us": [27, 29, 39, 41, 71, 1862, 1883, 1886, 1888, 1891, 1901, 1904, 1905, 1906, 1908, 1917], "allow_in_graph": 27, "write": [28, 60, 71, 1883, 1888, 1901], "aten": [28, 1859, 1901], "ir": [28, 77, 1859], "pass": [28, 76, 82, 1863, 1886, 1896, 1908, 1914], "One": [28, 1900], "x": 28, "none": 28, "inform": [28, 1891, 1913], "subgraph": [28, 71], "rewrit": [28, 71], "manag": [28, 34, 42, 1875, 1886, 1892, 1905], "partition": 28, "matcher": 28, "capabl": 28, "base": [28, 1904], "titl": 29, "diagnos": 29, "runtim": [29, 1885, 1890], "minifi": 29, "access": [29, 30, 1862, 1905], "torch_compile_debug": 29, "accuraci": [29, 1897, 1908, 1909], "file": [29, 41, 1875, 1905], "an": [29, 1857, 1901, 1904, 1905], "complex": [30, 952, 1883, 1891], "number": [30, 34, 59, 1883, 1885, 1890, 1898, 1925], "creat": [30, 1860, 1877], "transit": [30, 59], "from": [30, 59, 67, 71, 1857, 1876, 1900, 1901, 1905], "old": 30, "represent": 30, "real": [30, 482, 1725, 1891], "imag": [30, 311, 1160], "angl": [30, 118, 695], "ab": [30, 90, 678], "serial": [30, 1899, 1925], "__config__": 31, "cpp_extens": 32, "extend": [33, 49, 1888, 1889], "extens": [33, 34, 1888, 1893, 1900], "author": [33, 71], "random": [34, 38, 68, 1890, 1898, 1912, 1925], "commun": [34, 39, 41, 1858], "collect": [34, 41], "stream": [34, 35, 969, 1038, 1886], "event": [34, 50, 52, 966], "beta": [34, 47], "memori": [34, 38, 1886, 1890, 1892, 1894], "nvidia": [34, 1897], "nvtx": [34, 1023, 1024, 1025], "jiter": [34, 1006, 1007], "sanit": [34, 35], "prototyp": [34, 1908, 1909], "data": [38, 68, 1863, 1887, 1890, 1901, 1909, 1923], "dataset": 38, "map": [38, 1892], "style": 38, "iter": [38, 1862], "load": [38, 1197, 1261, 1857, 1899, 1905, 1908], "order": [38, 1883], "sampler": 38, "batch": [38, 66, 1897, 1904], "non": [38, 71, 1879, 1880, 1883, 1886, 1897, 1905, 1908], "collate_fn": 38, "singl": [38, 59, 1882], "multi": [38, 41, 59, 1879, 1880], "platform": 38, "pin": [38, 1886], "ddp": 39, "powersgd": 39, "state": [39, 1894, 1905], "acknowledg": [39, 1906], "deploi": 40, "ha": 40, "been": 40, "move": 40, "multipi": 40, "come": [41, 1883], "which": [41, 1883], "choos": 41, "network": [41, 1886, 1890, 1894], "interfac": [41, 1892], "nccl": [41, 1886], "basic": [41, 1863, 1877, 1889, 1913, 1923], "initi": [41, 1879, 1894, 1923], "tcp": 41, "share": [41, 1875, 1886, 1905, 1915], "system": [41, 1863, 1875, 1889], "post": [41, 1908], "kei": [41, 1900], "valu": [41, 611, 1862, 1863, 1897, 1910, 1915], "store": [41, 58], "group": 41, "point": [41, 1893], "synchron": [41, 1039, 1309], "asynchron": [41, 1863, 1886, 1896], "third": 41, "parti": 41, "launch": [41, 59], "spawn": [41, 1875], "applic": 41, "monitor": [41, 1873], "barrier": 41, "torch_distributed_debug": 41, "log": [41, 369, 1263, 1893], "join": [42, 1925], "elast": [44, 49, 59], "advanc": [44, 1894], "plugin": 44, "parallel": [46, 1586, 1886, 1887, 1890, 1906, 1925], "probabl": 47, "score": 47, "pathwis": 47, "deriv": [47, 1883], "exponentialfamili": 47, "bernoulli": [47, 154, 920], "binomi": 47, "categor": 47, "cauchi": 47, "chi2": 47, "continuousbernoulli": 47, "dirichlet": 47, "exponenti": [47, 1765], "fishersnedecor": 47, "gamma": 47, "geometr": 47, "gumbel": 47, "halfcauchi": 47, "halfnorm": 47, "independ": 47, "kumaraswami": 47, "lkjcholeski": 47, "laplac": 47, "lognorm": 47, "lowrankmultivariatenorm": 47, "mixturesamefamili": 47, "multinomi": [47, 420, 1312], "multivariatenorm": 47, "negativebinomi": 47, "normal": [47, 1557, 1650, 1879, 1904], "onehotcategor": 47, "pareto": 47, "poisson": [47, 1700], "relaxedbernoulli": 47, "logitrelaxedbernoulli": 47, "relaxedonehotcategor": 47, "studentt": 47, "transformeddistribut": 47, "uniform": 47, "vonmis": 47, "weibul": 47, "wishart": 47, "kl": 47, "diverg": [47, 1865], "constraint": [47, 1886], "registri": [47, 58], "dlpack": 48, "agent": 49, "server": [49, 58, 60], "concept": 49, "watchdog": 49, "launcher": 50, "rendezv": [50, 58, 59], "handler": [50, 55, 58, 1890], "metric": [50, 55], "propag": [51, 1877], "object": [52, 1905], "torchelast": 54, "kubernet": 54, "multipl": [56, 1882, 1886, 1888, 1906], "worker": [56, 59, 1890], "quickstart": 57, "except": [58, 1890], "c10d": 58, "etcd": 58, "legaci": 58, "torchrun": 59, "node": [59, 77, 80, 84, 85, 907, 908, 909, 910, 911, 1883], "stack": [59, 1801, 1908], "fault": 59, "toler": 59, "size": [59, 534, 1878], "failur": [59, 74], "min": [59, 411, 1292], "max": [59, 407, 1287], "membership": [59, 1863], "note": [59, 1858, 1863, 1886, 1908, 1913], "definit": [59, 1863], "deploy": [59, 1893], "notic": [59, 1857], "expir": 60, "timer": 60, "client": 60, "train": [61, 1882, 1894, 1896, 1908], "script": [61, 1201, 1860, 1900, 1901], "helper": 62, "fullyshardeddataparallel": 63, "patch": [66, 1905], "norm": [66, 452, 1246, 1649], "happen": 66, "option": [66, 1862, 1885, 1900, 1904], "batchnorm": 66, "paramet": [66, 1603, 1862, 1904], "functorch": [66, 67], "eval": [66, 1883], "migrat": [67, 1860], "make_funct": 67, "combine_state_for_ensembl": 67, "ux": 68, "vmap": [68, 69, 889, 1131, 1850, 1888, 1889], "mutat": [68, 1925], "arbitrari": [68, 1905], "structur": [68, 1863], "out": [68, 1876, 1890], "depend": [68, 1905, 1914], "flow": [68, 71, 1908], "item": [68, 352], "nonzero": [68, 451, 1648], "friend": 68, "whirlwind": 69, "tour": 69, "grad": [69, 290, 904, 1121, 1883, 1886], "auto": 69, "vector": 69, "vjp": [69, 903, 1130], "jacobian": [69, 900], "jvp": [69, 888, 901, 1126, 1889], "jacrev": [69, 1125], "jacfwd": [69, 1124], "hessian": [69, 898, 1123], "futur": 70, "A": [71, 1894], "quick": 71, "primer": 71, "manipul": [71, 1877], "direct": 71, "With": [71, 1865], "replace_pattern": 71, "proxi": 71, "retrac": 71, "interpret": [71, 1860], "pattern": [71, 1862, 1901, 1905], "introduct": [71, 1870, 1878, 1908], "pitfal": [71, 1901], "pdb": 71, "print": [71, 1862, 1863], "to_fold": 71, "graphmodul": 71, "avail": 71, "debugg": 71, "symbol": [71, 78, 83, 86, 87, 1901, 1908, 1925], "static": [71, 1901, 1908], "tracer": [71, 73, 74, 1860], "leaf": 71, "miscellanea": 71, "diagsys0001": 72, "arg": 72, "format": [72, 1905], "too": 72, "verbos": 72, "fxe0001": 73, "success": 73, "fxe0002": 74, "fxe0003": 75, "frontend": [75, 81], "fxe0004": 76, "neg": [76, 439, 441, 1324, 1325], "sigmoid": [76, 523, 756, 1452, 1573, 1760], "fxe0005": 77, "fxe0006": 78, "atenlib": [78, 79], "fxe0007": 79, "fxe0008": 80, "fxe0009": 81, "fxe0010": 82, "fxe0011": 83, "fxe0012": 84, "unsupport": [84, 1862, 1863, 1865, 1901, 1903], "analysi": 84, "poe0001": 85, "miss": [85, 86, 87], "infer": [85, 1877, 1883, 1885, 1899], "poe0002": 86, "poe0003": 87, "standard": 87, "poe0004": 88, "newer": 88, "opset": 88, "version": [88, 1899], "abs_": 91, "absolut": [92, 679], "absolute_": 93, "aco": [94, 680], "acos_": 95, "acosh": [96, 681], "acosh_": 97, "add_": 99, "addbmm": [100, 683], "addbmm_": 101, "addcdiv": [102, 684], "addcdiv_": 103, "addcmul": [104, 685], "addcmul_": 105, "addmm": [106, 686, 1782], "addmm_": 107, "addmv": [108, 687], "addmv_": 109, "addr": [110, 688], "addr_": 111, "adjoint": [112, 689], "all": [113, 690, 1901, 1904], "allclos": [114, 691], "amax": [115, 692], "amin": [116, 693], "aminmax": [117, 694], "apply_": 120, "arcco": [121, 863], "arccos_": 122, "arccosh": [123, 864], "arccosh_": 124, "arcsin": [125, 865], "arcsin_": 126, "arcsinh": [127, 866], "arcsinh_": 128, "arctan": [129, 867], "arctan2": [130, 868], "arctan2_": 131, "arctan_": 132, "arctanh": [133, 869], "arctanh_": 134, "argmax": [135, 871], "argmin": [136, 872], "argsort": [137, 873], "argwher": [138, 874], "as_strid": [139, 875], "as_subclass": 140, "asin": [141, 878], "asin_": 142, "asinh": [143, 879], "asinh_": 144, "atan": [145, 880], "atan2": [146, 881], "atan2_": 147, "atan_": 148, "atanh": [149, 882], "atanh_": 150, "backward": [151, 886, 890, 1883, 1884, 1886, 1891, 1914], "baddbmm": [152, 918], "baddbmm_": 153, "bernoulli_": 155, "bincount": [157, 921], "bitwise_and": [158, 922], "bitwise_and_": 159, "bitwise_left_shift": [160, 923], "bitwise_left_shift_": 161, "bitwise_not": [162, 924], "bitwise_not_": 163, "bitwise_or": [164, 925], "bitwise_or_": 165, "bitwise_right_shift": [166, 926], "bitwise_right_shift_": 167, "bitwise_xor": [168, 927], "bitwise_xor_": 169, "bmm": [170, 930], "bool": 171, "broadcast_to": [172, 933], "byte": 173, "cauchy_": 174, "ccol_indic": 175, "cdoubl": 176, "ceil": [177, 939], "ceil_": 178, "cfloat": 179, "chalf": 180, "char": 181, "choleski": [182, 941, 1219], "cholesky_invers": [183, 942], "cholesky_solv": [184, 943], "chunk": [185, 944], "clamp": [186, 768, 945], "clamp_": 187, "clip": [188, 946, 1882], "clip_": 189, "clone": [190, 947], "coalesc": 191, "col_indic": 192, "conj": [193, 955], "conj_phys": [194, 956], "conj_physical_": 195, "contigu": 196, "copy_": 197, "copysign": [198, 957], "copysign_": 199, "corrcoef": [200, 958], "co": [201, 959], "cos_": 202, "cosh": [203, 960], "cosh_": 204, "count_nonzero": [205, 961], "cov": [206, 962], "cross": [208, 963, 1222, 1883], "crow_indic": 209, "cummax": [211, 1042], "cummin": [212, 1043], "cumprod": [213, 1044], "cumprod_": 214, "cumsum": [215, 1045], "cumsum_": 216, "data_ptr": 217, "deg2rad": [218, 1047], "dense_dim": 219, "dequant": [220, 1048, 1908], "det": [221, 1049, 1223], "detach": 222, "detach_": 223, "devic": [224, 985, 1886, 1897, 1920], "diag": [225, 1050], "diag_emb": [226, 1051], "diagflat": [227, 1052], "diagon": [228, 1053, 1224], "diagonal_scatt": [229, 1054], "diff": [230, 1055], "digamma": [231, 1056], "digamma_": 232, "dim": [233, 1876], "dist": [234, 1057], "div": [235, 1058, 1899], "div_": 236, "divid": [237, 1059], "divide_": 238, "dot": [239, 1060], "doubl": 240, "dsplit": [241, 1061], "element_s": 242, "eq": [243, 1068], "eq_": 244, "equal": [245, 1069], "erf": [246, 1070], "erf_": 247, "erfc": [248, 1071], "erfc_": 249, "erfinv": [250, 1072], "erfinv_": 251, "exp": [252, 1073], "exp_": 253, "expand": 254, "expand_a": 255, "expm1": [256, 1075], "expm1_": 257, "exponential_": 258, "fill_": 259, "fill_diagonal_": 260, "fix_": 262, "flatten": [263, 1102, 1368], "flip": [264, 1103], "fliplr": [265, 1104], "flipud": [266, 1105], "float": [267, 1899], "float_pow": [268, 1106], "float_power_": 269, "floor": [270, 1107], "floor_": 271, "floor_divid": [272, 1108], "floor_divide_": 273, "fmax": [274, 1109], "fmin": [275, 1110], "fmod": [276, 1111], "fmod_": 277, "frac": [278, 1112], "frac_": 279, "frexp": [280, 1113], "gather": [281, 978, 1132], "gcd": [282, 1133], "gcd_": 283, "ge": [284, 1134], "ge_": 285, "geometric_": 286, "geqrf": [287, 1135], "ger": [288, 1136], "get_devic": 289, "greater": [291, 1144], "greater_": 292, "greater_equ": [293, 1145], "greater_equal_": 294, "gt": [295, 1146], "gt_": 296, "half": 297, "hardshrink": [298, 1378, 1524], "heavisid": [299, 1149], "histc": [300, 1150], "histogram": [301, 1151], "hsplit": [302, 1153], "hypot": [303, 1156], "hypot_": 304, "i0": [305, 1157], "i0_": 306, "igamma": [307, 1158], "igamma_": 308, "igammac": [309, 1159], "igammac_": 310, "index_add": [312, 1161], "index_add_": 313, "index_copi": [314, 1162], "index_copy_": 315, "index_fil": 316, "index_fill_": 317, "index_put": 318, "index_put_": 319, "index_reduc": [320, 1163], "index_reduce_": 321, "index_select": [322, 1164], "indic": [323, 1858], "inner": [324, 1167], "int": 325, "int_repr": 326, "invers": [327, 1168, 1868], "is_coalesc": 328, "is_complex": [329, 1169], "is_conj": [330, 1170], "is_contigu": 331, "is_cuda": 332, "is_floating_point": [333, 1172], "is_infer": 334, "is_leaf": 335, "is_meta": 336, "is_pin": 337, "is_quant": 338, "is_set_to": 339, "is_shar": 340, "is_sign": 341, "is_spars": 342, "is_sparse_csr": 343, "isclos": [344, 1179], "isfinit": [345, 1180], "isinf": [346, 1182], "isnan": [347, 1183], "isneginf": [348, 1184], "isposinf": [349, 1185], "isreal": [350, 1186], "istft": [351, 1187], "items": 353, "kthvalu": [354, 1211], "lcm": [355, 1212], "lcm_": 356, "ldexp": [357, 1213], "ldexp_": 358, "le": [359, 1214], "le_": 360, "lerp": [361, 1215], "lerp_": 362, "less": [363, 1216], "less_": 364, "less_equ": [365, 1217], "less_equal_": 366, "lgamma": [367, 1218], "lgamma_": 368, "log10": [370, 1264], "log10_": 371, "log1p": [372, 1265], "log1p_": 373, "log2": [374, 1266], "log2_": 375, "log_": 376, "log_normal_": 377, "logaddexp": [378, 1267], "logaddexp2": [379, 1268], "logcumsumexp": [380, 1269], "logdet": [381, 1270], "logical_and": [382, 1271], "logical_and_": 383, "logical_not": [384, 1272], "logical_not_": 385, "logical_or": [386, 1273], "logical_or_": 387, "logical_xor": [388, 1274], "logical_xor_": 389, "logit": [390, 1275], "logit_": 391, "logsumexp": [392, 1277], "long": 393, "lt": [394, 1278], "lt_": 395, "lu": [396, 1236, 1279], "lu_solv": [397, 1239, 1280], "map_": 398, "masked_fil": 399, "masked_fill_": 400, "masked_scatt": 401, "masked_scatter_": 402, "masked_select": [403, 1283], "matmul": [404, 1240, 1284], "matrix_exp": [405, 1241, 1285], "matrix_pow": [406, 1243, 1286], "maximum": [408, 1288], "mean": [409, 1289], "median": [410, 1290], "minimum": [412, 1293], "mm": [413, 1294, 1785], "moveaxi": [415, 1296], "movedim": [416, 1297], "msort": [417, 1310], "mul": [418, 1311], "mul_": 419, "multipli": [421, 1313], "multiply_": 422, "mv": [423, 1314], "mvlgamma": [424, 1315], "mvlgamma_": 425, "nan_to_num": [426, 1316], "nan_to_num_": 427, "nanmean": [428, 1317], "nanmedian": [429, 1318], "nanquantil": [430, 1319], "nansum": [431, 1320], "narrow": [432, 1321], "narrow_copi": [433, 1322], "nbyte": 434, "ndim": 435, "ndimens": 436, "ne": [437, 1323], "ne_": 438, "neg_": 440, "negative_": 442, "nelement": 443, "new_empti": 444, "new_ful": 445, "new_on": 446, "new_tensor": 447, "new_zero": 448, "nextaft": [449, 1326], "nextafter_": 450, "normal_": 453, "not_equ": [454, 1651], "not_equal_": 455, "numel": [456, 1652], "numpi": [457, 1901], "orgqr": [458, 1694], "ormqr": [459, 1695], "outer": [460, 1696], "permut": [461, 1698, 1876], "pin_memori": 462, "pinvers": [463, 1699], "polygamma": [464, 1702], "polygamma_": 465, "posit": [466, 1703], "pow": [467, 1704], "pow_": 468, "prod": [469, 1705], "put_": 470, "q_per_channel_axi": 471, "q_per_channel_scal": 472, "q_per_channel_zero_point": 473, "q_scale": 474, "q_zero_point": 475, "qr": [476, 1248, 1707], "qscheme": 477, "quantil": [478, 1708], "rad2deg": [479, 1715], "random_": 480, "ravel": [481, 1724], "reciproc": [483, 1726], "reciprocal_": 484, "record_stream": 485, "register_hook": [486, 910], "remaind": [487, 1727], "remainder_": 488, "renorm": [489, 1728], "renorm_": 490, "repeat": 491, "repeat_interleav": [492, 1729], "requires_grad": [493, 1883], "requires_grad_": 494, "reshap": [495, 1730], "reshape_a": 496, "resize_": 497, "resize_as_": 498, "resolve_conj": [499, 1731], "resolve_neg": [500, 1732], "retain_grad": 501, "retains_grad": 502, "roll": [503, 1734], "rot90": [504, 1735], "round": [505, 1736], "round_": 506, "row_indic": 507, "rsqrt": [508, 1738], "rsqrt_": 509, "scatter": [510, 980, 1740], "scatter_": 511, "scatter_add": [512, 1741], "scatter_add_": 513, "scatter_reduc": [514, 1742], "scatter_reduce_": 515, "select": [516, 1745, 1870], "select_scatt": [517, 1746], "set_": 518, "sgn": [519, 1759], "sgn_": 520, "share_memory_": 521, "short": 522, "sigmoid_": 524, "sign": [525, 1761], "sign_": 526, "signbit": [527, 1773], "sin": [528, 1774], "sin_": 529, "sinc": [530, 1775], "sinc_": 531, "sinh": [532, 1776], "sinh_": 533, "slice_scatt": [535, 1777], "slogdet": [536, 1249, 1778], "smm": [537, 1779], "softmax": [538, 1455, 1577, 1780, 1787], "sort": [539, 1781], "sparse_dim": 540, "sparse_mask": 541, "sparse_resize_": 542, "sparse_resize_and_clear_": 543, "split": [544, 1796], "sqrt": [545, 1797], "sqrt_": 546, "squar": [547, 1798], "square_": 548, "squeez": [549, 1799], "squeeze_": 550, "sspaddmm": [551, 1800], "std": [552, 1802], "stft": [553, 1804], "storag": [554, 1919], "storage_offset": 555, "storage_typ": 556, "stride": 557, "sub": [558, 1805], "sub_": 559, "subtract": [560, 1806], "subtract_": 561, "sum": [562, 1789, 1807, 1879], "sum_to_s": 563, "svd": [564, 1253, 1808], "swapax": [565, 1810], "swapdim": [566, 1811], "t_": 568, "take": [569, 1818, 1904], "take_along_dim": [570, 1819], "tan": [571, 1820], "tan_": 572, "tanh": [573, 1462, 1582, 1821], "tanh_": 574, "tensor_split": [575, 1823], "tile": [576, 1825], "to_dens": 578, "to_mkldnn": 579, "to_spars": 580, "to_sparse_bsc": 581, "to_sparse_bsr": 582, "to_sparse_coo": 583, "to_sparse_csc": 584, "to_sparse_csr": 585, "tolist": 586, "topk": [587, 1826], "transpos": [589, 1828], "transpose_": 590, "triangular_solv": [591, 1831], "tril": [592, 1832], "tril_": 593, "triu": [594, 1834], "triu_": 595, "true_divid": [596, 1836], "true_divide_": 597, "trunc": [598, 1837], "trunc_": 599, "type_a": 601, "unbind": [602, 1838, 1878], "unflatten": [603, 1472, 1839], "unfold": [604, 1473, 1589], "uniform_": 605, "uniqu": [606, 1840], "unique_consecut": [607, 1841], "unsqueez": [608, 1842], "unsqueeze_": 609, "untyped_storag": 610, "var": [612, 1845], "vdot": [613, 1847], "view": [614, 1870, 1899, 1921], "view_a": 615, "vsplit": [616, 1851], "where": [617, 1853, 1857], "xlogi": [618, 1854], "xlogy_": 619, "zero_": 620, "_assert": 621, "_foreach_ab": 622, "_foreach_abs_": 623, "_foreach_aco": 624, "_foreach_acos_": 625, "_foreach_asin": 626, "_foreach_asin_": 627, "_foreach_atan": 628, "_foreach_atan_": 629, "_foreach_ceil": 630, "_foreach_ceil_": 631, "_foreach_co": 632, "_foreach_cos_": 633, "_foreach_cosh": 634, "_foreach_cosh_": 635, "_foreach_erf": 636, "_foreach_erf_": 637, "_foreach_erfc": 638, "_foreach_erfc_": 639, "_foreach_exp": 640, "_foreach_exp_": 641, "_foreach_expm1": 642, "_foreach_expm1_": 643, "_foreach_floor": 644, "_foreach_floor_": 645, "_foreach_frac": 646, "_foreach_frac_": 647, "_foreach_lgamma": 648, "_foreach_lgamma_": 649, "_foreach_log": 650, "_foreach_log10": 651, "_foreach_log10_": 652, "_foreach_log1p": 653, "_foreach_log1p_": 654, "_foreach_log2": 655, "_foreach_log2_": 656, "_foreach_log_": 657, "_foreach_neg": 658, "_foreach_neg_": 659, "_foreach_reciproc": 660, "_foreach_reciprocal_": 661, "_foreach_round": 662, "_foreach_round_": 663, "_foreach_sigmoid": 664, "_foreach_sigmoid_": 665, "_foreach_sin": 666, "_foreach_sin_": 667, "_foreach_sinh": 668, "_foreach_sinh_": 669, "_foreach_sqrt": 670, "_foreach_sqrt_": 671, "_foreach_tan": 672, "_foreach_tan_": 673, "_foreach_trunc": 674, "_foreach_trunc_": 675, "_foreach_zero_": 676, "_log": [677, 1869], "set_log": 677, "bnrelu2d": [697, 720], "bnrelu3d": [698, 721], "convbn1d": [699, 709], "convbn2d": [700, 710], "convbn3d": [701, 711], "convbnrelu1d": [702, 712], "convbnrelu2d": [703, 713], "convbnrelu3d": [704, 714], "convrelu1d": [705, 722], "convrelu2d": [706, 715, 723], "convrelu3d": [707, 716, 724], "linearrelu": [708, 717, 725, 726], "freeze_bn_stat": 718, "update_bn_stat": 719, "conv2d": [727, 736, 770, 1351, 1497], "conv3d": [728, 737, 771, 1352, 1498], "lstm": [731, 759, 1392, 1898], "multiheadattent": [732, 1428], "batchnorm2d": [733, 1341], "batchnorm3d": [734, 1342], "conv1d": [735, 769, 1350, 1496], "convtranspose1d": [738, 1353], "convtranspose2d": [739, 1354], "convtranspose3d": [740, 1355], "elu": [741, 772, 1364, 1510], "embed": [742, 1365, 1512], "embeddingbag": [743, 1366], "fxfloatfunct": 744, "floatfunct": 745, "groupnorm": [746, 1377], "hardswish": [747, 774, 1380, 1526], "instancenorm1d": [748, 1385], "instancenorm2d": [749, 1386], "instancenorm3d": [750, 1387], "layernorm": [751, 1394], "leakyrelu": [752, 1408], "qfunction": 754, "relu6": [755, 1442, 1567], "gru": [757, 1374], "grucel": [758, 1375], "lstmcell": [760, 1393], "rnncell": [762, 1439], "adaptive_avg_pool2d": [763, 1481], "adaptive_avg_pool3d": [764, 1482], "avg_pool2d": [765, 1489], "avg_pool3d": [766, 1490], "celu": [767, 1344, 1495], "hardsigmoid": [773, 1379, 1525], "hardtanh": [775, 1381, 1527], "interpol": [776, 1532], "leaky_relu": [777, 1536], "max_pool1d": [779, 1545], "max_pool2d": [780, 1546], "threshold": [781, 1464, 1584], "upsampl": [782, 1474, 1590], "upsample_bilinear": [783, 1591], "upsample_nearest": [784, 1592], "dequantstub": 785, "quantstub": 786, "quantwrapp": 787, "add_quant_dequ": 788, "backendconfig": 789, "backendpatternconfig": 790, "dtypeconfig": 791, "dtypewithconstraint": 792, "observationtyp": 793, "default_eval_fn": 795, "fakequant": [796, 1908], "fakequantizebas": 797, "fixedqparamsfakequant": 798, "fusedmovingavgobsfakequant": 799, "default_fake_qu": 800, "default_fused_act_fake_qu": 801, "default_fused_per_channel_wt_fake_qu": 802, "default_fused_wt_fake_qu": 803, "default_histogram_fake_qu": 804, "default_per_channel_weight_fake_qu": 805, "default_weight_fake_qu": 806, "disable_fake_qu": 807, "disable_observ": 808, "enable_fake_qu": 809, "enable_observ": 810, "fuse_modul": 811, "convertcustomconfig": 812, "fusecustomconfig": 813, "preparecustomconfig": 814, "standalonemoduleconfigentri": 815, "histogramobserv": 816, "minmaxobserv": 817, "movingaverageminmaxobserv": 818, "movingaverageperchannelminmaxobserv": 819, "noopobserv": 820, "observerbas": 821, "perchannelminmaxobserv": 822, "placeholderobserv": 823, "recordingobserv": 824, "default_debug_observ": 825, "default_dynamic_quant_observ": 826, "default_float_qparams_observ": 827, "default_histogram_observ": 828, "default_observ": 829, "default_per_channel_weight_observ": 830, "default_placeholder_observ": 831, "default_weight_observ": 832, "get_observer_state_dict": 833, "load_observer_state_dict": 834, "prepar": [835, 1908, 1911], "prepare_qat": 836, "propagate_qconfig": 837, "qconfig": [838, 1908, 1911], "default_activation_only_qconfig": 839, "default_debug_qconfig": 840, "default_dynamic_qconfig": 841, "default_per_channel_qconfig": 842, "default_qat_qconfig": 843, "default_qat_qconfig_v2": 844, "default_qconfig": 845, "default_weight_only_qconfig": 846, "float16_dynamic_qconfig": 847, "float16_static_qconfig": 848, "float_qparams_weight_only_qconfig": 849, "per_channel_dynamic_qconfig": 850, "qconfigmap": 851, "get_default_qat_qconfig_map": 852, "get_default_qconfig_map": 853, "quantiz": [854, 1879, 1894, 1901, 1908, 1909, 1910, 1911], "quantize_dynam": 855, "convert_fx": 856, "fuse_fx": 857, "prepare_fx": 858, "prepare_qat_fx": 859, "quantize_qat": 860, "swap_modul": 861, "arang": 862, "are_deterministic_algorithms_en": 870, "as_tensor": 876, "asarrai": 877, "atleast_1d": 883, "atleast_2d": 884, "atleast_3d": 885, "dual_level": 891, "forward_ad": [892, 893], "make_du": 892, "unpack_du": 893, "functionctx": [894, 895, 896, 897], "mark_dirti": 894, "mark_non_differenti": 895, "save_for_backward": 896, "set_materialize_grad": 897, "hvp": 899, "vhp": 902, "gradcheck": [905, 1891], "gradgradcheck": [906, 1891], "metadata": [907, 1893], "name": [908, 1862, 1876, 1877], "next_funct": 909, "register_prehook": 911, "load_nvprof": 912, "export_chrome_trac": 913, "key_averag": 914, "self_cpu_time_tot": 915, "total_averag": 916, "set_multithreading_en": 917, "bartlett_window": 919, "blackman_window": 928, "block_diag": 929, "broadcast_shap": 931, "broadcast_tensor": 932, "bucket": 934, "can_cast": 935, "cartesian_prod": 936, "cat": 937, "cdist": 938, "chain_matmul": 940, "column_stack": 948, "combin": [949, 1888], "compiled_with_cxx11_abi": 951, "concat": 953, "concaten": 954, "cudapluggablealloc": 965, "externalstream": 967, "outofmemoryerror": 968, "streamcontext": 970, "caching_allocator_alloc": 971, "caching_allocator_delet": 972, "can_device_access_p": 973, "change_current_alloc": 974, "clock_rat": 975, "comm": [976, 977, 978, 979, 980], "broadcast": [976, 1884], "broadcast_coalesc": 977, "reduce_add": 979, "current_blas_handl": 981, "current_devic": 982, "current_stream": 983, "default_stream": 984, "device_count": 986, "device_of": 987, "empty_cach": [988, 1300], "get_allocator_backend": 989, "get_arch_list": 990, "get_device_cap": 991, "get_device_nam": 992, "get_device_properti": 993, "get_gencode_flag": 994, "get_rng_stat": [995, 1142, 1301], "get_rng_state_al": 996, "get_sync_debug_mod": 997, "graph_pool_handl": 999, "init": [1000, 1881], "initial_se": [1001, 1166], "ipc_collect": 1002, "is_avail": 1003, "is_current_stream_captur": 1004, "is_initi": 1005, "_create_jit_fn": 1006, "_create_multi_output_jit_fn": 1007, "list_gpu_process": 1008, "make_graphed_cal": 1009, "manual_se": [1010, 1282, 1302], "manual_seed_al": 1011, "max_memory_alloc": 1012, "max_memory_cach": 1013, "max_memory_reserv": 1014, "mem_get_info": 1015, "memory_alloc": 1016, "memory_cach": 1017, "memory_reserv": 1018, "memory_snapshot": 1019, "memory_stat": 1020, "memory_summari": 1021, "memory_usag": 1022, "mark": 1023, "range_pop": 1024, "range_push": 1025, "power_draw": 1026, "reset_max_memory_alloc": 1027, "reset_max_memory_cach": 1028, "reset_peak_memory_stat": 1029, "seed": [1030, 1306, 1744], "seed_al": 1031, "set_devic": 1032, "set_per_process_memory_fract": [1033, 1307], "set_rng_stat": [1034, 1308, 1757], "set_rng_state_al": 1035, "set_stream": 1036, "set_sync_debug_mod": 1037, "temperatur": 1040, "cumulative_trapezoid": 1046, "dstack": 1062, "einsum": 1063, "empti": 1064, "empty_lik": 1065, "empty_strid": 1066, "enable_grad": 1067, "exp2": 1074, "ey": 1076, "fake_quantize_per_channel_affin": 1077, "fake_quantize_per_tensor_affin": 1078, "fft2": 1080, "fftfreq": 1081, "fftn": 1082, "fftshift": 1083, "hfft": 1084, "hfft2": 1085, "hfftn": 1086, "ifft": 1087, "ifft2": 1088, "ifftn": 1089, "ifftshift": 1090, "ihfft": 1091, "ihfft2": 1092, "ihfftn": 1093, "irfft": 1094, "irfft2": 1095, "irfftn": 1096, "rfft": 1097, "rfft2": 1098, "rfftfreq": 1099, "rfftn": 1100, "from_dlpack": 1114, "from_numpi": 1115, "frombuff": 1116, "full": [1117, 1899], "full_lik": 1118, "functional_cal": [1119, 1644], "grad_and_valu": 1122, "replace_all_batch_norm_modules_": 1128, "stack_module_st": 1129, "get_default_dtyp": 1137, "get_deterministic_debug_mod": 1138, "get_float32_matmul_precis": 1139, "get_num_interop_thread": 1140, "get_num_thread": 1141, "hamming_window": 1147, "hann_window": 1148, "histogramdd": 1152, "hspmm": 1154, "hstack": 1155, "inference_mod": 1165, "is_deterministic_algorithms_warn_only_en": 1171, "is_grad_en": 1173, "is_inference_mode_en": 1174, "is_nonzero": 1175, "is_storag": 1176, "is_tensor": 1177, "is_warn_always_en": 1178, "isin": 1181, "attribut": [1188, 1860, 1862, 1863, 1865, 1920], "scriptfunct": 1189, "scriptmodul": [1190, 1899], "annot": [1191, 1863], "enable_onednn_fus": 1192, "fork": 1193, "freez": 1194, "ignor": 1195, "isinst": 1196, "onednn_fusion_en": 1198, "optimize_for_infer": 1199, "save": [1200, 1739, 1857, 1883, 1893, 1899, 1908], "script_if_trac": 1202, "set_fusion_strategi": 1203, "strict_fus": 1204, "trace_modul": 1206, "unus": 1207, "wait": 1208, "kaiser_window": 1209, "kron": 1210, "cholesky_ex": 1220, "cond": 1221, "eig": 1225, "eigh": 1226, "eigval": 1227, "eigvalsh": 1228, "householder_product": 1229, "inv": 1230, "inv_ex": 1231, "ldl_factor": 1232, "ldl_factor_ex": 1233, "ldl_solv": 1234, "lstsq": 1235, "lu_factor": 1237, "lu_factor_ex": 1238, "matrix_norm": 1242, "matrix_rank": 1244, "multi_dot": 1245, "pinv": 1247, "solv": 1250, "solve_ex": 1251, "solve_triangular": 1252, "svdval": 1254, "tensorinv": 1255, "tensorsolv": 1256, "vander": [1257, 1844], "vecdot": 1258, "vector_norm": 1259, "linspac": 1260, "lobpcg": 1262, "logspac": 1276, "lu_unpack": 1281, "meshgrid": 1291, "current_allocated_memori": 1298, "driver_allocated_memori": 1299, "stop": 1305, "adaptiveavgpool1d": 1327, "adaptiveavgpool2d": 1328, "adaptiveavgpool3d": 1329, "adaptivelogsoftmaxwithloss": 1330, "adaptivemaxpool1d": 1331, "adaptivemaxpool2d": 1332, "adaptivemaxpool3d": 1333, "alphadropout": 1334, "avgpool1d": 1335, "avgpool2d": 1336, "avgpool3d": 1337, "bceloss": 1338, "bcewithlogitsloss": 1339, "batchnorm1d": 1340, "bilinear": [1343, 1492], "ctcloss": 1345, "channelshuffl": 1346, "constantpad1d": 1347, "constantpad2d": 1348, "constantpad3d": 1349, "cosineembeddingloss": 1356, "cosinesimilar": 1357, "crossentropyloss": 1358, "dataparallel": [1359, 1879, 1880, 1882, 1886], "dropout": [1360, 1506, 1879, 1880], "dropout1d": [1361, 1507], "dropout2d": [1362, 1508], "dropout3d": [1363, 1509], "featurealphadropout": 1367, "fold": [1369, 1515], "fractionalmaxpool2d": 1370, "fractionalmaxpool3d": 1371, "gelu": [1372, 1519], "glu": [1373, 1520], "gaussiannllloss": 1376, "hingeembeddingloss": 1382, "huberloss": 1383, "ident": [1384, 1618, 1626, 1863, 1890], "kldivloss": 1388, "l1loss": 1389, "lppool1d": 1390, "lppool2d": 1391, "lazybatchnorm1d": 1395, "lazybatchnorm2d": 1396, "lazybatchnorm3d": 1397, "lazyconv1d": 1398, "lazyconv2d": 1399, "lazyconv3d": 1400, "lazyconvtranspose1d": 1401, "lazyconvtranspose2d": 1402, "lazyconvtranspose3d": 1403, "lazyinstancenorm1d": 1404, "lazyinstancenorm2d": 1405, "lazyinstancenorm3d": 1406, "lazylinear": 1407, "localresponsenorm": 1410, "logsigmoid": [1411, 1541], "logsoftmax": 1412, "mseloss": 1413, "marginrankingloss": 1414, "maxpool1d": 1415, "maxpool2d": 1416, "maxpool3d": 1417, "maxunpool1d": 1418, "maxunpool2d": 1419, "maxunpool3d": 1420, "mish": [1421, 1551], "moduledict": [1423, 1863], "modulelist": [1424, 1862, 1863], "multilabelmarginloss": 1425, "multilabelsoftmarginloss": 1426, "multimarginloss": 1427, "nllloss": 1429, "prelu": [1430, 1565], "pairwisedist": 1431, "parameterdict": 1432, "parameterlist": 1433, "pixelshuffl": 1434, "pixelunshuffl": 1435, "poissonnllloss": 1436, "rnn": [1437, 1636, 1637, 1638, 1639, 1640, 1641, 1898], "rnnbase": 1438, "rrelu": [1440, 1569], "relu": [1441, 1566], "reflectionpad1d": 1443, "reflectionpad2d": 1444, "reflectionpad3d": 1445, "replicationpad1d": 1446, "replicationpad2d": 1447, "replicationpad3d": 1448, "selu": [1449, 1572], "sequenti": 1450, "silu": [1451, 1574], "smoothl1loss": 1453, "softmarginloss": 1454, "softmax2d": 1456, "softmin": [1457, 1578], "softplu": [1458, 1579], "softshrink": [1459, 1580], "softsign": [1460, 1581], "syncbatchnorm": 1461, "tanhshrink": [1463, 1583], "transformerdecod": 1466, "transformerdecoderlay": 1467, "transformerencod": 1468, "transformerencoderlay": 1469, "tripletmarginloss": 1470, "tripletmarginwithdistanceloss": 1471, "upsamplingbilinear2d": 1475, "upsamplingnearest2d": 1476, "zeropad1d": 1477, "zeropad2d": 1478, "zeropad3d": 1479, "adaptive_avg_pool1d": 1480, "adaptive_max_pool1d": 1483, "adaptive_max_pool2d": 1484, "adaptive_max_pool3d": 1485, "affine_grid": 1486, "alpha_dropout": 1487, "avg_pool1d": 1488, "batch_norm": 1491, "conv_transpose1d": 1499, "conv_transpose2d": 1500, "conv_transpose3d": 1501, "cosine_embedding_loss": 1502, "cosine_similar": 1503, "cross_entropi": 1504, "ctc_loss": 1505, "elu_": 1511, "embedding_bag": 1513, "feature_alpha_dropout": 1514, "fractional_max_pool2d": 1516, "fractional_max_pool3d": 1517, "gaussian_nll_loss": 1518, "grid_sampl": 1521, "group_norm": 1522, "gumbel_softmax": 1523, "hardtanh_": 1528, "hinge_embedding_loss": 1529, "huber_loss": 1530, "instance_norm": 1531, "kl_div": 1533, "l1_loss": 1534, "layer_norm": 1535, "leaky_relu_": 1537, "local_response_norm": 1539, "log_softmax": [1540, 1784], "lp_pool1d": 1542, "lp_pool2d": 1543, "margin_ranking_loss": 1544, "max_pool3d": 1547, "max_unpool1d": 1548, "max_unpool2d": 1549, "max_unpool3d": 1550, "mse_loss": 1552, "multi_margin_loss": 1553, "multilabel_margin_loss": 1554, "multilabel_soft_margin_loss": 1555, "nll_loss": 1556, "one_hot": 1558, "pad": [1559, 1879], "pairwise_dist": 1560, "pdist": 1561, "pixel_shuffl": 1562, "pixel_unshuffl": 1563, "poisson_nll_loss": 1564, "relu_": 1568, "rrelu_": 1570, "scaled_dot_product_attent": 1571, "smooth_l1_loss": 1575, "soft_margin_loss": 1576, "threshold_": 1585, "data_parallel": [1586, 1880], "triplet_margin_loss": 1587, "triplet_margin_with_distance_loss": 1588, "lazymodulemixin": 1593, "register_module_backward_hook": 1594, "register_module_buffer_registration_hook": 1595, "register_module_forward_hook": 1596, "register_module_forward_pre_hook": 1597, "register_module_full_backward_hook": 1598, "register_module_full_backward_pre_hook": 1599, "register_module_module_registration_hook": 1600, "register_module_parameter_registration_hook": 1601, "distributeddataparallel": [1602, 1882, 1886, 1887], "uninitializedbuff": 1604, "uninitializedparamet": 1605, "clip_grad_norm_": 1606, "clip_grad_value_": 1607, "parameters_to_vector": 1608, "parametr": [1609, 1610, 1612, 1613, 1614, 1615, 1894], "orthogon": 1609, "spectral_norm": [1610, 1643], "parametrizationlist": 1611, "is_parametr": 1613, "register_parametr": 1614, "remove_parametr": 1615, "basepruningmethod": 1616, "customfrommask": 1617, "l1unstructur": 1619, "lnstructur": 1620, "pruningcontain": 1621, "randomstructur": 1622, "randomunstructur": 1623, "prune": [1624, 1625, 1626, 1627, 1628, 1629, 1630, 1631, 1632, 1894], "custom_from_mask": 1624, "global_unstructur": 1625, "is_prun": 1627, "l1_unstructur": 1628, "ln_structur": 1629, "random_structur": 1630, "random_unstructur": 1631, "remove_spectral_norm": 1633, "remove_weight_norm": 1634, "packedsequ": 1635, "pack_padded_sequ": 1636, "pack_sequ": 1637, "pad_packed_sequ": 1638, "pad_sequ": 1639, "unpack_sequ": 1640, "unpad_sequ": 1641, "skip_init": 1642, "stateless": 1644, "vector_to_paramet": 1645, "weight_norm": 1646, "no_grad": 1647, "ones": 1653, "ones_lik": 1654, "exportopt": 1655, "exportoutput": 1656, "exportoutputseri": 1657, "jitscalartyp": 1658, "graphinfo": 1659, "verificationopt": 1660, "asgd": 1661, "adadelta": 1662, "adagrad": 1663, "adam": 1664, "adamw": 1665, "adamax": 1666, "lbfg": 1667, "nadam": 1668, "add_param_group": 1669, "load_state_dict": 1670, "step": [1672, 1904], "zero_grad": 1673, "radam": 1674, "rmsprop": 1675, "rprop": 1676, "sgd": 1677, "sparseadam": 1678, "chainedschedul": 1679, "constantlr": 1680, "cosineannealinglr": 1681, "cosineannealingwarmrestart": 1682, "cycliclr": 1683, "exponentiallr": 1684, "lambdalr": 1685, "linearlr": 1686, "multisteplr": 1687, "multiplicativelr": 1688, "onecyclelr": 1689, "polynomiallr": 1690, "reducelronplateau": 1691, "sequentiallr": 1692, "steplr": 1693, "pca_lowrank": 1697, "polar": 1701, "promote_typ": 1706, "quantize_per_channel": 1709, "quantize_per_tensor": 1710, "quantized_batch_norm": 1711, "quantized_max_pool1d": 1712, "quantized_max_pool2d": 1713, "sobolengin": 1714, "rand": 1716, "rand_lik": 1717, "randint": 1718, "randint_lik": 1719, "randn": 1720, "randn_lik": 1721, "randperm": 1722, "rang": [1723, 1862], "result_typ": 1733, "row_stack": 1737, "searchsort": 1743, "set_default_devic": 1747, "set_default_dtyp": 1748, "set_default_tensor_typ": 1749, "set_deterministic_debug_mod": 1750, "set_float32_matmul_precis": 1751, "set_flush_denorm": 1752, "set_grad_en": 1753, "set_num_interop_thread": 1754, "set_num_thread": 1755, "set_printopt": 1756, "set_warn_alwai": 1758, "signal": [1762, 1763, 1764, 1765, 1766, 1767, 1768, 1769, 1770, 1771, 1772, 1916], "bartlett": 1762, "blackman": 1763, "cosin": 1764, "gaussian": 1766, "general_cosin": 1767, "general_ham": 1768, "ham": 1769, "hann": 1770, "kaiser": 1771, "nuttal": 1772, "check_sparse_tensor_invari": 1783, "sampled_addmm": 1786, "spdiag": 1788, "sparse_bsc_tensor": 1790, "sparse_bsr_tensor": 1791, "sparse_compressed_tensor": 1792, "sparse_coo_tensor": 1793, "sparse_csc_tensor": 1794, "sparse_csr_tensor": 1795, "std_mean": 1803, "svd_lowrank": 1809, "sym_float": 1812, "sym_int": 1813, "sym_max": 1814, "sym_min": 1815, "sym_not": 1816, "tensordot": 1824, "trapezoid": 1829, "trapz": 1830, "tril_indic": 1833, "triu_indic": 1835, "use_deterministic_algorithm": 1843, "var_mean": 1846, "view_as_complex": 1848, "view_as_r": 1849, "vstack": 1852, "zero": 1855, "zeros_lik": 1856, "hub": 1857, "publish": 1857, "entrypoint": 1857, "download": 1857, "logic": [1857, 1862], "known": [1857, 1860], "bind": 1858, "prim": 1859, "built": [1860, 1861, 1863, 1901], "inspect": 1860, "warn": 1860, "appendix": [1860, 1863], "recurs": 1860, "constant": [1860, 1862], "fusion": 1860, "builtin": 1861, "math": [1861, 1925], "construct": [1862, 1863, 1865, 1878, 1904, 1917], "refin": [1862, 1863], "enum": [1862, 1863], "tupl": [1862, 1863], "express": [1862, 1863], "liter": [1862, 1863], "list": [1862, 1863, 1901], "dict": 1862, "arithmet": [1862, 1863], "subscript": [1862, 1863], "slice": [1862, 1863, 1897, 1925], "ternari": [1862, 1863], "cast": 1862, "statement": [1862, 1863], "assign": [1862, 1863], "match": [1862, 1877], "If": 1862, "while": [1862, 1863], "loop": 1862, "For": 1862, "continu": [1862, 1863], "return": [1862, 1863, 1890, 1915], "resolut": [1862, 1863], "lookup": 1862, "defin": [1862, 1888, 1889], "terminologi": 1863, "meta": 1863, "primit": 1863, "special": [1863, 1883, 1918], "instanc": 1863, "signatur": 1863, "expr": 1863, "convers": [1863, 1878], "atom": 1863, "parenthes": 1863, "form": 1863, "dictionari": 1863, "displai": 1863, "primari": 1863, "power": 1863, "unari": [1863, 1870, 1917], "bitwis": 1863, "binari": [1863, 1870], "shift": 1863, "boolean": 1863, "condit": 1863, "augment": 1863, "rais": 1863, "assert": [1863, 1892], "del": 1863, "compound": 1863, "els": 1863, "getattr": 1863, "hasattr": 1863, "zip": [1863, 1905], "enumer": 1863, "rule": [1863, 1877, 1889, 1902], "remot": [1863, 1915], "procedur": 1863, "execut": [1863, 1883, 1886, 1905, 1906], "program": 1863, "coverag": [1864, 1876, 1888], "properti": [1865, 1868], "Not": 1865, "correctli": 1865, "bound": 1865, "schema": 1865, "between": [1865, 1905], "matrix": [1868, 1908], "decomposit": 1868, "solver": 1868, "misc": 1868, "experiment": 1868, "reduct": [1870, 1886, 1897, 1925], "mobile_optim": 1871, "model_zoo": 1872, "strategi": [1875, 1904], "descriptor": 1875, "file_descriptor": 1875, "file_system": 1875, "subprocess": 1875, "keep": [1876, 1905], "dimens": [1876, 1877], "unifi": 1876, "contract": 1876, "awai": 1876, "factori": 1876, "variant": 1876, "semant": [1877, 1884, 1886, 1892, 1899], "explicit": 1877, "align": 1877, "current": 1877, "subsystem": 1877, "constructor": 1878, "contain": 1879, "convolut": [1879, 1880, 1897, 1898], "layer": 1879, "pool": [1879, 1880], "activ": [1879, 1880], "weight": [1879, 1904], "nonlinear": 1879, "recurr": [1879, 1890], "distanc": [1879, 1880], "loss": [1879, 1880, 1882], "vision": [1879, 1880], "shuffl": 1879, "lazi": 1879, "attent": 1880, "typic": 1882, "unscal": 1882, "accumul": 1882, "penalti": 1882, "one": 1882, "per": [1882, 1904], "particular": [1882, 1883], "dtype": [1882, 1899, 1911, 1920], "encod": 1883, "histori": 1883, "set": [1883, 1901], "No": 1883, "multithread": 1883, "concurr": 1883, "determin": [1883, 1898], "retain": 1883, "thread": [1883, 1885], "safeti": 1883, "wirting": 1883, "calculu": 1883, "pictur": 1883, "conjug": 1883, "own": 1883, "formula": 1883, "domain": 1883, "whether": [1883, 1905], "fire": 1883, "differ": [1883, 1901], "modifi": 1883, "compat": 1884, "tune": 1885, "tensorfloat": [1886, 1892, 1897], "32": [1886, 1892, 1897, 1900], "tf32": [1886, 1892, 1897], "amper": [1886, 1897], "reduc": [1886, 1897], "fp16": [1886, 1897], "gemm": [1886, 1897], "bf16": [1886, 1897], "bc": 1886, "alloc": [1886, 1890], "cubla": 1886, "workspac": 1886, "cufft": 1886, "plan": [1886, 1892], "just": 1886, "practic": [1886, 1896, 1908], "agnost": 1886, "buffer": [1886, 1896], "instead": 1886, "captur": 1886, "partial": 1886, "9": 1886, "across": [1886, 1899], "processgroup": 1887, "ddpoptim": 1887, "separ": 1888, "setup_context": 1888, "like": [1888, 1905], "wrapper": 1888, "__torch_function__": 1888, "overrid": [1888, 1928], "specifi": 1889, "staticmethod": 1889, "isn": 1890, "freed": 1890, "properli": 1890, "loader": 1890, "notat": 1891, "analyt": 1891, "output": 1891, "u": 1891, "reus": [1892, 1896], "hipfft": 1892, "rocfft": 1892, "enabl": 1892, "larg": 1893, "fleet": 1893, "wide": 1893, "attach": 1893, "consider": 1893, "block": 1894, "neural": 1894, "tip": [1896, 1909], "fight": 1896, "deadlock": 1896, "through": 1896, "queue": 1896, "e": 1896, "g": 1896, "hogwild": 1896, "extrem": 1897, "finit": 1897, "instinct": 1897, "mi200": 1897, "reproduc": 1898, "nondeterminist": 1898, "algorithm": [1898, 1904, 1914], "content": [1899, 1905], "preserv": 1899, "them": [1899, 1905], "integ": 1899, "divis": 1899, "alwai": 1899, "includ": [1900, 1905], "compon": 1900, "instal": 1900, "cffi": 1900, "cpp": 1900, "found": 1900, "win": 1900, "channel": 1900, "without": 1900, "claus": 1900, "protect": 1900, "broken": 1900, "pipe": [1900, 1906], "driver": 1900, "shut": 1900, "down": 1900, "ipc": 1900, "alexnet": 1901, "v": 1901, "index": [1901, 1925], "inlin": 1901, "discov": 1901, "unconvert": 1901, "onc": 1901, "preview": 1901, "diagnost": 1902, "closur": 1904, "adjust": 1904, "rate": 1904, "averag": 1904, "swa": 1904, "ema": 1904, "schedul": 1904, "care": 1904, "put": 1904, "togeth": 1904, "your": 1905, "treat": 1905, "archiv": 1905, "file_structur": 1905, "given": 1905, "wa": 1905, "later": 1905, "distinguish": 1905, "explan": 1905, "framework": [1905, 1913], "user": [1905, 1915], "find": 1905, "analyz": 1905, "extern": 1905, "mock": 1905, "refactor": 1905, "sharp": 1905, "global": 1905, "isol": 1905, "mangl": 1905, "pipelin": 1906, "skip": 1906, "connect": 1906, "intel": 1907, "instrument": 1907, "technologi": 1907, "eager": 1908, "awar": 1908, "engin": [1908, 1925], "observ": [1908, 1911], "hardwar": 1908, "nativ": [1908, 1910], "configur": [1908, 1910, 1925], "insensit": 1909, "int8": 1909, "sensit": 1909, "ao": [1911, 1926, 1927], "top": 1911, "quantize_fx": 1911, "qconfig_map": 1911, "backend_config": 1911, "custom_config": 1911, "fake_quant": 1911, "intrins": 1911, "qat": 1911, "scheme": 1911, "rpc": 1913, "tensorpip": 1913, "rref": [1913, 1915], "remotemodul": 1913, "record": 1914, "dure": 1914, "smart": 1914, "end": 1914, "protocol": 1915, "assumpt": 1915, "lifetim": 1915, "reason": 1915, "scenario": 1915, "owner": 1915, "argument": 1915, "sparsiti": 1917, "coo": 1917, "hybrid": 1917, "uncoalesc": 1917, "csr": 1917, "csc": 1917, "bsr": 1917, "bsc": 1917, "memory_format": 1920, "tensorboard": 1922, "creation": 1925, "sampl": 1925, "quasi": 1925, "pointwis": 1925, "spectral": 1925, "bla": 1925, "lapack": 1925, "foreach": 1925, "tag": 1925, "n": [1926, 1927], "_numeric_suit": 1926, "_numeric_suite_fx": 1927, "info": 1929, "finfo": 1929, "iinfo": 1929}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"torch.Tensor.aminmax": [[117, "torch-tensor-aminmax"]], "torch.Tensor.argsort": [[137, "torch-tensor-argsort"]], "torch.Tensor.arctan2": [[130, "torch-tensor-arctan2"]], "torch.Tensor.addbmm_": [[101, "torch-tensor-addbmm"]], "torch.Tensor.arccosh_": [[124, "torch-tensor-arccosh"]], "torch.Tensor.asinh": [[143, "torch-tensor-asinh"]], "torch.Tensor.atan": [[145, "torch-tensor-atan"]], "torch.Tensor.adjoint": [[112, "torch-tensor-adjoint"]], "torch.Tensor.arcsin": [[125, "torch-tensor-arcsin"]], "torch.Tensor.addmv": [[108, "torch-tensor-addmv"]], "torch.Tensor.addmv_": [[109, "torch-tensor-addmv"]], "torch.Tensor.asin_": [[142, "torch-tensor-asin"]], "torch.Tensor.any": [[119, "torch-tensor-any"]], "torch.Tensor.addmm": [[106, "torch-tensor-addmm"]], "torch.Tensor.arctanh_": [[134, "torch-tensor-arctanh"]], "torch.Tensor.arcsinh": [[127, "torch-tensor-arcsinh"]], "torch.Tensor.angle": [[118, "torch-tensor-angle"]], "torch.Tensor.addmm_": [[107, "torch-tensor-addmm"]], "torch.Tensor.arccos_": [[122, "torch-tensor-arccos"]], "torch.Tensor.argmax": [[135, "torch-tensor-argmax"]], "torch.Tensor.arcsinh_": [[128, "torch-tensor-arcsinh"]], "torch.Tensor.addcmul": [[104, "torch-tensor-addcmul"]], "torch.Tensor.arccosh": [[123, "torch-tensor-arccosh"]], "torch.Tensor.as_strided": [[139, "torch-tensor-as-strided"]], "torch.Tensor.all": [[113, "torch-tensor-all"]], "torch.Tensor.asin": [[141, "torch-tensor-asin"]], "torch.Tensor.addcdiv": [[102, "torch-tensor-addcdiv"]], "torch.Tensor.amin": [[116, "torch-tensor-amin"]], "torch.Tensor.addcmul_": [[105, "torch-tensor-addcmul"]], "torch.Tensor.add_": [[99, "torch-tensor-add"]], "torch.Tensor.addbmm": [[100, "torch-tensor-addbmm"]], "torch.Tensor.argmin": [[136, "torch-tensor-argmin"]], "torch.Tensor.argwhere": [[138, "torch-tensor-argwhere"]], "torch.Tensor.arctan_": [[132, "torch-tensor-arctan"]], "torch.Tensor.as_subclass": [[140, "torch-tensor-as-subclass"]], "torch.Tensor.arctanh": [[133, "torch-tensor-arctanh"]], "torch.Tensor.arctan": [[129, "torch-tensor-arctan"]], "torch.Tensor.arccos": [[121, "torch-tensor-arccos"]], "torch.Tensor.arcsin_": [[126, "torch-tensor-arcsin"]], "torch.Tensor.addr_": [[111, "torch-tensor-addr"]], "torch.Tensor.arctan2_": [[131, "torch-tensor-arctan2"]], "torch.Tensor.addr": [[110, "torch-tensor-addr"]], "torch.Tensor.addcdiv_": [[103, "torch-tensor-addcdiv"]], "torch.Tensor.atan2": [[146, "torch-tensor-atan2"]], "torch.Tensor.amax": [[115, "torch-tensor-amax"]], "torch.Tensor.apply_": [[120, "torch-tensor-apply"]], "torch.Tensor.asinh_": [[144, "torch-tensor-asinh"]], "torch.Tensor.add": [[98, "torch-tensor-add"]], "torch.Tensor.allclose": [[114, "torch-tensor-allclose"]], "torch.Tensor.deg2rad": [[218, "torch-tensor-deg2rad"]], "torch.Tensor.cross": [[208, "torch-tensor-cross"]], "torch.Tensor.digamma_": [[232, "torch-tensor-digamma"]], "torch.Tensor.detach": [[222, "torch-tensor-detach"]], "torch.Tensor.cov": [[206, "torch-tensor-cov"]], "torch.Tensor.dsplit": [[241, "torch-tensor-dsplit"]], "torch.Tensor.diagonal_scatter": [[229, "torch-tensor-diagonal-scatter"]], "torch.Tensor.divide": [[237, "torch-tensor-divide"]], "torch.Tensor.detach_": [[223, "torch-tensor-detach"]], "torch.Tensor.cosh_": [[204, "torch-tensor-cosh"]], "torch.Tensor.cpu": [[207, "torch-tensor-cpu"]], "torch.Tensor.dist": [[234, "torch-tensor-dist"]], "torch.Tensor.eq": [[243, "torch-tensor-eq"]], "torch.Tensor.count_nonzero": [[205, "torch-tensor-count-nonzero"]], "torch.Tensor.copysign": [[198, "torch-tensor-copysign"]], "torch.Tensor.divide_": [[238, "torch-tensor-divide"]], "torch.Tensor.cumsum_": [[216, "torch-tensor-cumsum"]], "torch.Tensor.eq_": [[244, "torch-tensor-eq"]], "torch.Tensor.cuda": [[210, "torch-tensor-cuda"]], "torch.Tensor.device": [[224, "torch-tensor-device"]], "torch.Tensor.cumsum": [[215, "torch-tensor-cumsum"]], "torch.Tensor.diag_embed": [[226, "torch-tensor-diag-embed"]], "torch.Tensor.cosh": [[203, "torch-tensor-cosh"]], "torch.Tensor.div": [[235, "torch-tensor-div"]], "torch.Tensor.cummax": [[211, "torch-tensor-cummax"]], "torch.Tensor.data_ptr": [[217, "torch-tensor-data-ptr"]], "torch.Tensor.crow_indices": [[209, "torch-tensor-crow-indices"]], "torch.Tensor.double": [[240, "torch-tensor-double"]], "torch.Tensor.digamma": [[231, "torch-tensor-digamma"]], "torch.Tensor.copysign_": [[199, "torch-tensor-copysign"]], "torch.Tensor.diagonal": [[228, "torch-tensor-diagonal"]], "torch.Tensor.corrcoef": [[200, "torch-tensor-corrcoef"]], "torch.Tensor.diagflat": [[227, "torch-tensor-diagflat"]], "torch.Tensor.contiguous": [[196, "torch-tensor-contiguous"]], "torch.Tensor.dim": [[233, "torch-tensor-dim"]], "torch.Tensor.div_": [[236, "torch-tensor-div"]], "torch.Tensor.copy_": [[197, "torch-tensor-copy"]], "torch.Tensor.cos": [[201, "torch-tensor-cos"]], "torch.Tensor.cumprod_": [[214, "torch-tensor-cumprod"]], "torch.Tensor.dot": [[239, "torch-tensor-dot"]], "torch.Tensor.element_size": [[242, "torch-tensor-element-size"]], "torch.Tensor.cos_": [[202, "torch-tensor-cos"]], "torch.Tensor.diff": [[230, "torch-tensor-diff"]], "torch.Tensor.cummin": [[212, "torch-tensor-cummin"]], "torch.Tensor.dequantize": [[220, "torch-tensor-dequantize"]], "torch.Tensor.diag": [[225, "torch-tensor-diag"]], "torch.Tensor.det": [[221, "torch-tensor-det"]], "torch.Tensor.dense_dim": [[219, "torch-tensor-dense-dim"]], "torch.Tensor.cumprod": [[213, "torch-tensor-cumprod"]], "torch.Tensor.floor": [[270, "torch-tensor-floor"]], "torch.Tensor.equal": [[245, "torch-tensor-equal"]], "torch.Tensor.fill_diagonal_": [[260, "torch-tensor-fill-diagonal"]], "torch.Tensor.frac_": [[279, "torch-tensor-frac"]], "torch.Tensor.float_power": [[268, "torch-tensor-float-power"]], "torch.Tensor.float_power_": [[269, "torch-tensor-float-power"]], "torch.Tensor.greater_equal": [[293, "torch-tensor-greater-equal"]], "torch.Tensor.expm1": [[256, "torch-tensor-expm1"]], "torch.Tensor.floor_": [[271, "torch-tensor-floor"]], "torch.Tensor.fill_": [[259, "torch-tensor-fill"]], "torch.Tensor.flip": [[264, "torch-tensor-flip"]], "torch.Tensor.exponential_": [[258, "torch-tensor-exponential"]], "torch.Tensor.float": [[267, "torch-tensor-float"]], "torch.Tensor.gather": [[281, "torch-tensor-gather"]], "torch.Tensor.geometric_": [[286, "torch-tensor-geometric"]], "torch.Tensor.greater": [[291, "torch-tensor-greater"]], "torch.Tensor.fmin": [[275, "torch-tensor-fmin"]], "torch.Tensor.fix_": [[262, "torch-tensor-fix"]], "torch.Tensor.flatten": [[263, "torch-tensor-flatten"]], "torch.Tensor.erfc_": [[249, "torch-tensor-erfc"]], "torch.Tensor.floor_divide_": [[273, "torch-tensor-floor-divide"]], "torch.Tensor.exp_": [[253, "torch-tensor-exp"]], "torch.Tensor.erf": [[246, "torch-tensor-erf"]], "torch.Tensor.fix": [[261, "torch-tensor-fix"]], "torch.Tensor.grad": [[290, "torch-tensor-grad"]], "torch.Tensor.flipud": [[266, "torch-tensor-flipud"]], "torch.Tensor.gcd": [[282, "torch-tensor-gcd"]], "torch.Tensor.frexp": [[280, "torch-tensor-frexp"]], "torch.Tensor.erf_": [[247, "torch-tensor-erf"]], "torch.Tensor.greater_": [[292, "torch-tensor-greater"]], "torch.Tensor.erfinv": [[250, "torch-tensor-erfinv"]], "torch.Tensor.expand_as": [[255, "torch-tensor-expand-as"]], "torch.Tensor.fmod": [[276, "torch-tensor-fmod"]], "torch.Tensor.get_device": [[289, "torch-tensor-get-device"]], "torch.Tensor.frac": [[278, "torch-tensor-frac"]], "torch.Tensor.expm1_": [[257, "torch-tensor-expm1"]], "torch.Tensor.erfinv_": [[251, "torch-tensor-erfinv"]], "torch.Tensor.fmax": [[274, "torch-tensor-fmax"]], "torch.Tensor.fmod_": [[277, "torch-tensor-fmod"]], "torch.Tensor.floor_divide": [[272, "torch-tensor-floor-divide"]], "torch.Tensor.gcd_": [[283, "torch-tensor-gcd"]], "torch.Tensor.ge": [[284, "torch-tensor-ge"]], "torch.Tensor.geqrf": [[287, "torch-tensor-geqrf"]], "torch.Tensor.ge_": [[285, "torch-tensor-ge"]], "torch.Tensor.erfc": [[248, "torch-tensor-erfc"]], "torch.Tensor.ger": [[288, "torch-tensor-ger"]], "torch.Tensor.exp": [[252, "torch-tensor-exp"]], "torch.Tensor.fliplr": [[265, "torch-tensor-fliplr"]], "torch.Tensor.expand": [[254, "torch-tensor-expand"]], "torch.Tensor.index_copy_": [[315, "torch-tensor-index-copy"]], "torch.Tensor.index_fill": [[316, "torch-tensor-index-fill"]], "torch.Tensor.is_meta": [[336, "torch-tensor-is-meta"]], "torch.Tensor.igammac_": [[310, "torch-tensor-igammac"]], "torch.Tensor.index_add_": [[313, "torch-tensor-index-add"]], "torch.Tensor.is_leaf": [[335, "torch-tensor-is-leaf"]], "torch.Tensor.index_copy": [[314, "torch-tensor-index-copy"]], "torch.Tensor.greater_equal_": [[294, "torch-tensor-greater-equal"]], "torch.Tensor.is_quantized": [[338, "torch-tensor-is-quantized"]], "torch.Tensor.is_contiguous": [[331, "torch-tensor-is-contiguous"]], "torch.Tensor.hypot_": [[304, "torch-tensor-hypot"]], "torch.Tensor.index_fill_": [[317, "torch-tensor-index-fill"]], "torch.Tensor.index_put_": [[319, "torch-tensor-index-put"]], "torch.Tensor.histogram": [[301, "torch-tensor-histogram"]], "torch.Tensor.igammac": [[309, "torch-tensor-igammac"]], "torch.Tensor.igamma": [[307, "torch-tensor-igamma"]], "torch.Tensor.gt_": [[296, "torch-tensor-gt"]], "torch.Tensor.half": [[297, "torch-tensor-half"]], "torch.Tensor.is_pinned": [[337, "torch-tensor-is-pinned"]], "torch.Tensor.inverse": [[327, "torch-tensor-inverse"]], "torch.Tensor.i0": [[305, "torch-tensor-i0"]], "torch.Tensor.is_conj": [[330, "torch-tensor-is-conj"]], "torch.Tensor.igamma_": [[308, "torch-tensor-igamma"]], "torch.Tensor.is_signed": [[341, "torch-tensor-is-signed"]], "torch.Tensor.hsplit": [[302, "torch-tensor-hsplit"]], "torch.Tensor.i0_": [[306, "torch-tensor-i0"]], "torch.Tensor.int_repr": [[326, "torch-tensor-int-repr"]], "torch.Tensor.index_add": [[312, "torch-tensor-index-add"]], "torch.Tensor.is_sparse": [[342, "torch-tensor-is-sparse"]], "torch.Tensor.hardshrink": [[298, "torch-tensor-hardshrink"]], "torch.Tensor.inner": [[324, "torch-tensor-inner"]], "torch.Tensor.is_floating_point": [[333, "torch-tensor-is-floating-point"]], "torch.Tensor.is_complex": [[329, "torch-tensor-is-complex"]], "torch.Tensor.indices": [[323, "torch-tensor-indices"]], "torch.Tensor.index_reduce": [[320, "torch-tensor-index-reduce"]], "torch.Tensor.index_reduce_": [[321, "torch-tensor-index-reduce"]], "torch.Tensor.is_set_to": [[339, "torch-tensor-is-set-to"]], "torch.Tensor.is_cuda": [[332, "torch-tensor-is-cuda"]], "torch.Tensor.int": [[325, "torch-tensor-int"]], "torch.Tensor.is_inference": [[334, "torch-tensor-is-inference"]], "torch.Tensor.index_put": [[318, "torch-tensor-index-put"]], "torch.Tensor.gt": [[295, "torch-tensor-gt"]], "torch.Tensor.is_coalesced": [[328, "torch-tensor-is-coalesced"]], "torch.Tensor.index_select": [[322, "torch-tensor-index-select"]], "torch.Tensor.heaviside": [[299, "torch-tensor-heaviside"]], "torch.Tensor.imag": [[311, "torch-tensor-imag"]], "torch.Tensor.is_shared": [[340, "torch-tensor-is-shared"]], "torch.Tensor.histc": [[300, "torch-tensor-histc"]], "torch.Tensor.hypot": [[303, "torch-tensor-hypot"]], "torch.Tensor.cholesky": [[182, "torch-tensor-cholesky"]], "torch.Tensor.cauchy_": [[174, "torch-tensor-cauchy"]], "torch.Tensor.cholesky_solve": [[184, "torch-tensor-cholesky-solve"]], "torch.Tensor.bitwise_or_": [[165, "torch-tensor-bitwise-or"]], "torch.Tensor.bfloat16": [[156, "torch-tensor-bfloat16"]], "torch.Tensor.bitwise_left_shift": [[160, "torch-tensor-bitwise-left-shift"]], "torch.Tensor.clip": [[188, "torch-tensor-clip"]], "torch.Tensor.bitwise_right_shift": [[166, "torch-tensor-bitwise-right-shift"]], "torch.Tensor.clamp_": [[187, "torch-tensor-clamp"]], "torch.Tensor.bitwise_not_": [[163, "torch-tensor-bitwise-not"]], "torch.Tensor.bitwise_not": [[162, "torch-tensor-bitwise-not"]], "torch.Tensor.bernoulli": [[154, "torch-tensor-bernoulli"]], "torch.Tensor.atanh": [[149, "torch-tensor-atanh"]], "torch.Tensor.byte": [[173, "torch-tensor-byte"]], "torch.Tensor.bitwise_and_": [[159, "torch-tensor-bitwise-and"]], "torch.Tensor.cholesky_inverse": [[183, "torch-tensor-cholesky-inverse"]], "torch.Tensor.bincount": [[157, "torch-tensor-bincount"]], "torch.Tensor.col_indices": [[192, "torch-tensor-col-indices"]], "torch.Tensor.bitwise_xor": [[168, "torch-tensor-bitwise-xor"]], "torch.Tensor.bmm": [[170, "torch-tensor-bmm"]], "torch.Tensor.broadcast_to": [[172, "torch-tensor-broadcast-to"]], "torch.Tensor.clamp": [[186, "torch-tensor-clamp"]], "torch.Tensor.atan_": [[148, "torch-tensor-atan"]], "torch.Tensor.ccol_indices": [[175, "torch-tensor-ccol-indices"]], "torch.Tensor.bitwise_or": [[164, "torch-tensor-bitwise-or"]], "torch.Tensor.atanh_": [[150, "torch-tensor-atanh"]], "torch.Tensor.conj_physical": [[194, "torch-tensor-conj-physical"]], "torch.Tensor.bitwise_and": [[158, "torch-tensor-bitwise-and"]], "torch.Tensor.atan2_": [[147, "torch-tensor-atan2"]], "torch.Tensor.clip_": [[189, "torch-tensor-clip"]], "torch.Tensor.bitwise_left_shift_": [[161, "torch-tensor-bitwise-left-shift"]], "torch.Tensor.conj": [[193, "torch-tensor-conj"]], "torch.Tensor.clone": [[190, "torch-tensor-clone"]], "torch.Tensor.char": [[181, "torch-tensor-char"]], "torch.Tensor.bitwise_right_shift_": [[167, "torch-tensor-bitwise-right-shift"]], "torch.Tensor.cfloat": [[179, "torch-tensor-cfloat"]], "torch.Tensor.chalf": [[180, "torch-tensor-chalf"]], "torch.Tensor.bernoulli_": [[155, "torch-tensor-bernoulli"]], "torch.Tensor.ceil_": [[178, "torch-tensor-ceil"]], "torch.Tensor.chunk": [[185, "torch-tensor-chunk"]], "torch.Tensor.bool": [[171, "torch-tensor-bool"]], "torch.Tensor.cdouble": [[176, "torch-tensor-cdouble"]], "torch.Tensor.baddbmm": [[152, "torch-tensor-baddbmm"]], "torch.Tensor.ceil": [[177, "torch-tensor-ceil"]], "torch.Tensor.bitwise_xor_": [[169, "torch-tensor-bitwise-xor"]], "torch.Tensor.coalesce": [[191, "torch-tensor-coalesce"]], "torch.Tensor.backward": [[151, "torch-tensor-backward"]], "torch.Tensor.conj_physical_": [[195, "torch-tensor-conj-physical"]], "torch.Tensor.baddbmm_": [[153, "torch-tensor-baddbmm"]], "torch.Tensor.isinf": [[346, "torch-tensor-isinf"]], "torch.Tensor.logit_": [[391, "torch-tensor-logit"]], "torch.Tensor.isclose": [[344, "torch-tensor-isclose"]], "torch.Tensor.logaddexp2": [[379, "torch-tensor-logaddexp2"]], "torch.Tensor.le": [[359, "torch-tensor-le"]], "torch.Tensor.item": [[352, "torch-tensor-item"]], "torch.Tensor.log10_": [[371, "torch-tensor-log10"]], "torch.Tensor.isfinite": [[345, "torch-tensor-isfinite"]], "torch.Tensor.is_sparse_csr": [[343, "torch-tensor-is-sparse-csr"]], "torch.Tensor.logaddexp": [[378, "torch-tensor-logaddexp"]], "torch.Tensor.logical_or_": [[387, "torch-tensor-logical-or"]], "torch.Tensor.logdet": [[381, "torch-tensor-logdet"]], "torch.Tensor.kthvalue": [[354, "torch-tensor-kthvalue"]], "torch.Tensor.less": [[363, "torch-tensor-less"]], "torch.Tensor.logical_or": [[386, "torch-tensor-logical-or"]], "torch.Tensor.isposinf": [[349, "torch-tensor-isposinf"]], "torch.Tensor.lerp": [[361, "torch-tensor-lerp"]], "torch.Tensor.lgamma": [[367, "torch-tensor-lgamma"]], "torch.Tensor.logical_xor": [[388, "torch-tensor-logical-xor"]], "torch.Tensor.le_": [[360, "torch-tensor-le"]], "torch.Tensor.logical_not_": [[385, "torch-tensor-logical-not"]], "torch.Tensor.lcm": [[355, "torch-tensor-lcm"]], "torch.Tensor.isreal": [[350, "torch-tensor-isreal"]], "torch.Tensor.logit": [[390, "torch-tensor-logit"]], "torch.Tensor.lcm_": [[356, "torch-tensor-lcm"]], "torch.Tensor.less_": [[364, "torch-tensor-less"]], "torch.Tensor.logcumsumexp": [[380, "torch-tensor-logcumsumexp"]], "torch.Tensor.logical_not": [[384, "torch-tensor-logical-not"]], "torch.Tensor.lerp_": [[362, "torch-tensor-lerp"]], "torch.Tensor.log_normal_": [[377, "torch-tensor-log-normal"]], "torch.Tensor.logical_xor_": [[389, "torch-tensor-logical-xor"]], "torch.Tensor.istft": [[351, "torch-tensor-istft"]], "torch.Tensor.log1p": [[372, "torch-tensor-log1p"]], "torch.Tensor.log": [[369, "torch-tensor-log"]], "torch.Tensor.lgamma_": [[368, "torch-tensor-lgamma"]], "torch.Tensor.ldexp_": [[358, "torch-tensor-ldexp"]], "torch.Tensor.logical_and": [[382, "torch-tensor-logical-and"]], "torch.Tensor.logical_and_": [[383, "torch-tensor-logical-and"]], "torch.Tensor.itemsize": [[353, "torch-tensor-itemsize"]], "torch.Tensor.isneginf": [[348, "torch-tensor-isneginf"]], "torch.Tensor.ldexp": [[357, "torch-tensor-ldexp"]], "torch.Tensor.log2": [[374, "torch-tensor-log2"]], "torch.Tensor.log2_": [[375, "torch-tensor-log2"]], "torch.Tensor.log10": [[370, "torch-tensor-log10"]], "torch.Tensor.isnan": [[347, "torch-tensor-isnan"]], "torch.Tensor.less_equal": [[365, "torch-tensor-less-equal"]], "torch.Tensor.log1p_": [[373, "torch-tensor-log1p"]], "torch.Tensor.less_equal_": [[366, "torch-tensor-less-equal"]], "torch.Tensor.log_": [[376, "torch-tensor-log"]], "torch.resolve_neg": [[1732, "torch-resolve-neg"]], "torch.repeat_interleave": [[1729, "torch-repeat-interleave"]], "torch.scatter": [[1740, "torch-scatter"]], "torch.set_printoptions": [[1756, "torch-set-printoptions"]], "torch.remainder": [[1727, "torch-remainder"]], "torch.resolve_conj": [[1731, "torch-resolve-conj"]], "torch.row_stack": [[1737, "torch-row-stack"]], "torch.range": [[1723, "torch-range"]], "torch.set_num_interop_threads": [[1754, "torch-set-num-interop-threads"]], "torch.randn_like": [[1721, "torch-randn-like"]], "torch.seed": [[1744, "torch-seed"]], "torch.select": [[1745, "torch-select"]], "torch.round": [[1736, "torch-round"]], "torch.set_float32_matmul_precision": [[1751, "torch-set-float32-matmul-precision"]], "torch.save": [[1739, "torch-save"]], "torch.roll": [[1734, "torch-roll"]], "torch.rsqrt": [[1738, "torch-rsqrt"]], "torch.randn": [[1720, "torch-randn"]], "torch.randint": [[1718, "torch-randint"]], "torch.searchsorted": [[1743, "torch-searchsorted"]], "torch.sigmoid": [[1760, "torch-sigmoid"]], "torch.rot90": [[1735, "torch-rot90"]], "torch.set_default_device": [[1747, "torch-set-default-device"]], "torch.set_deterministic_debug_mode": [[1750, "torch-set-deterministic-debug-mode"]], "torch.set_rng_state": [[1757, "torch-set-rng-state"]], "torch.result_type": [[1733, "torch-result-type"]], "torch.scatter_add": [[1741, "torch-scatter-add"]], "torch.signal.windows.blackman": [[1763, "torch-signal-windows-blackman"]], "torch.renorm": [[1728, "torch-renorm"]], "torch.ravel": [[1724, "torch-ravel"]], "torch.scatter_reduce": [[1742, "torch-scatter-reduce"]], "set_grad_enabled": [[1753, "set-grad-enabled"]], "torch.rad2deg": [[1715, "torch-rad2deg"]], "torch.real": [[1725, "torch-real"]], "torch.select_scatter": [[1746, "torch-select-scatter"]], "torch.reshape": [[1730, "torch-reshape"]], "torch.set_warn_always": [[1758, "torch-set-warn-always"]], "torch.sgn": [[1759, "torch-sgn"]], "torch.randperm": [[1722, "torch-randperm"]], "torch.set_default_dtype": [[1748, "torch-set-default-dtype"]], "torch.signal.windows.bartlett": [[1762, "torch-signal-windows-bartlett"]], "torch.set_default_tensor_type": [[1749, "torch-set-default-tensor-type"]], "torch.rand_like": [[1717, "torch-rand-like"]], "torch.sign": [[1761, "torch-sign"]], "torch.set_flush_denormal": [[1752, "torch-set-flush-denormal"]], "torch.randint_like": [[1719, "torch-randint-like"]], "torch.set_num_threads": [[1755, "torch-set-num-threads"]], "torch.rand": [[1716, "torch-rand"]], "torch.reciprocal": [[1726, "torch-reciprocal"]], "torch.sparse_bsc_tensor": [[1790, "torch-sparse-bsc-tensor"]], "torch.signal.windows.kaiser": [[1771, "torch-signal-windows-kaiser"]], "torch.sparse.sum": [[1789, "torch-sparse-sum"]], "torch.sparse_csr_tensor": [[1795, "torch-sparse-csr-tensor"]], "torch.swapaxes": [[1810, "torch-swapaxes"]], "torch.sparse_bsr_tensor": [[1791, "torch-sparse-bsr-tensor"]], "torch.swapdims": [[1811, "torch-swapdims"]], "torch.slice_scatter": [[1777, "torch-slice-scatter"]], "torch.sparse.log_softmax": [[1784, "torch-sparse-log-softmax"]], "torch.sparse.addmm": [[1782, "torch-sparse-addmm"]], "torch.stack": [[1801, "torch-stack"]], "torch.sort": [[1781, "torch-sort"]], "check_sparse_tensor_invariants": [[1783, "check-sparse-tensor-invariants"]], "torch.signal.windows.general_hamming": [[1768, "torch-signal-windows-general-hamming"]], "torch.sparse.softmax": [[1787, "torch-sparse-softmax"]], "torch.svd_lowrank": [[1809, "torch-svd-lowrank"]], "torch.signal.windows.cosine": [[1764, "torch-signal-windows-cosine"]], "torch.signal.windows.exponential": [[1765, "torch-signal-windows-exponential"]], "torch.sparse_compressed_tensor": [[1792, "torch-sparse-compressed-tensor"]], "torch.split": [[1796, "torch-split"]], "torch.sparse.spdiags": [[1788, "torch-sparse-spdiags"]], "torch.std": [[1802, "torch-std"]], "torch.signal.windows.general_cosine": [[1767, "torch-signal-windows-general-cosine"]], "torch.std_mean": [[1803, "torch-std-mean"]], "torch.sqrt": [[1797, "torch-sqrt"]], "torch.subtract": [[1806, "torch-subtract"]], "torch.sym_float": [[1812, "torch-sym-float"]], "torch.signal.windows.gaussian": [[1766, "torch-signal-windows-gaussian"]], "torch.signal.windows.nuttall": [[1772, "torch-signal-windows-nuttall"]], "torch.sub": [[1805, "torch-sub"]], "torch.sinh": [[1776, "torch-sinh"]], "torch.softmax": [[1780, "torch-softmax"]], "torch.sum": [[1807, "torch-sum"]], "torch.stft": [[1804, "torch-stft"]], "torch.sspaddmm": [[1800, "torch-sspaddmm"]], "torch.signal.windows.hann": [[1770, "torch-signal-windows-hann"]], "torch.sinc": [[1775, "torch-sinc"]], "torch.smm": [[1779, "torch-smm"]], "torch.sparse_coo_tensor": [[1793, "torch-sparse-coo-tensor"]], "torch.sparse_csc_tensor": [[1794, "torch-sparse-csc-tensor"]], "torch.squeeze": [[1799, "torch-squeeze"]], "torch.signal.windows.hamming": [[1769, "torch-signal-windows-hamming"]], "torch.sparse.sampled_addmm": [[1786, "torch-sparse-sampled-addmm"]], "torch.sparse.mm": [[1785, "torch-sparse-mm"]], "torch.svd": [[1808, "torch-svd"]], "torch.signbit": [[1773, "torch-signbit"]], "torch.slogdet": [[1778, "torch-slogdet"]], "torch.square": [[1798, "torch-square"]], "torch.sin": [[1774, "torch-sin"]], "torch.zeros": [[1855, "torch-zeros"]], "torch.vstack": [[1852, "torch-vstack"]], "torch.topk": [[1826, "torch-topk"]], "torch.var": [[1845, "torch-var"]], "torch.unique": [[1840, "torch-unique"]], "torch.take": [[1818, "torch-take"]], "torch.triu": [[1834, "torch-triu"]], "torch.tan": [[1820, "torch-tan"]], "torch.tensordot": [[1824, "torch-tensordot"]], "torch.tensor_split": [[1823, "torch-tensor-split"]], "torch.view_as_complex": [[1848, "torch-view-as-complex"]], "torch.var_mean": [[1846, "torch-var-mean"]], "torch.vsplit": [[1851, "torch-vsplit"]], "torch.transpose": [[1828, "torch-transpose"]], "IRs": [[1859, "irs"]], "Core Aten IR": [[1859, "core-aten-ir"]], "Prims IR": [[1859, "prims-ir"]], "torch.view_as_real": [[1849, "torch-view-as-real"]], "torch.t": [[1817, "torch-t"]], "torch.unbind": [[1838, "torch-unbind"]], "TorchScript Builtins": [[1861, "torchscript-builtins"]], "Supported Tensor Methods": [[1861, "supported-tensor-methods"]], "Supported PyTorch Functions": [[1861, "supported-pytorch-functions"]], "TorchScript Builtin Functions": [[1861, "torchscript-builtin-functions"]], "Python Built-in Functions": [[1861, "python-built-in-functions"]], "math Module": [[1861, "math-module"]], "torch.trapezoid": [[1829, "torch-trapezoid"]], "torch.triu_indices": [[1835, "torch-triu-indices"]], "torch.take_along_dim": [[1819, "torch-take-along-dim"]], "torch.trunc": [[1837, "torch-trunc"]], "torch.where": [[1853, "torch-where"]], "TorchScript": [[1860, "torchscript"]], "Creating TorchScript Code": [[1860, "creating-torchscript-code"]], "Mixing Tracing and Scripting": [[1860, "mixing-tracing-and-scripting"]], "TorchScript Language": [[1860, "torchscript-language"]], "Built-in Functions and Modules": [[1860, "built-in-functions-and-modules"]], "PyTorch Functions and Modules": [[1860, "pytorch-functions-and-modules"]], "Python Functions and Modules": [[1860, "python-functions-and-modules"]], "Python Language Reference Comparison": [[1860, "python-language-reference-comparison"]], "Debugging": [[1860, "debugging"], [71, "debugging"]], "Disable JIT for Debugging": [[1860, "disable-jit-for-debugging"]], "Inspecting Code": [[1860, "inspecting-code"]], "Interpreting Graphs": [[1860, "interpreting-graphs"]], "Tracer": [[1860, "tracer"]], "Tracing Edge Cases": [[1860, "tracing-edge-cases"]], "Automatic Trace Checking": [[1860, "automatic-trace-checking"]], "Tracer Warnings": [[1860, "tracer-warnings"]], "Frequently Asked Questions": [[1860, "frequently-asked-questions"], [8, "frequently-asked-questions"], [17, "frequently-asked-questions"], [1890, "frequently-asked-questions"], [1908, "frequently-asked-questions"], [1901, "frequently-asked-questions"]], "Known Issues": [[1860, "known-issues"]], "Appendix": [[1860, "appendix"]], "Migrating to PyTorch 1.2 Recursive Scripting API": [[1860, "migrating-to-pytorch-1-2-recursive-scripting-api"]], "Modules": [[1860, "modules"], [1894, "modules"]], "Functions": [[1860, "functions"], [1901, "functions"], [1862, "functions"], [1928, "functions"], [1918, "functions"]], "TorchScript Classes": [[1860, "torchscript-classes"], [1862, "id2"]], "Attributes": [[1860, "attributes"]], "Constants": [[1860, "constants"]], "Variables": [[1860, "variables"], [21, "variables"], [1862, "variables"]], "Fusion Backends": [[1860, "fusion-backends"]], "References": [[1860, "references"]], "torch.sym_max": [[1814, "torch-sym-max"]], "torch.sym_int": [[1813, "torch-sym-int"]], "torch.sym_not": [[1816, "torch-sym-not"]], "torch.sym_min": [[1815, "torch-sym-min"]], "torch.triangular_solve": [[1831, "torch-triangular-solve"]], "torch.xlogy": [[1854, "torch-xlogy"]], "torch.unsqueeze": [[1842, "torch-unsqueeze"]], "PyTorch documentation": [[1858, "pytorch-documentation"]], "Community": [[1858, null]], "Developer Notes": [[1858, null]], "torch.compile": [[1858, null], [19, "torch-compile"], [22, "torch-compile"], [950, "torch-compile"]], "Language Bindings": [[1858, null]], "Python API": [[1858, null]], "Libraries": [[1858, null]], "Indices and tables": [[1858, "indices-and-tables"]], "torch.tensor": [[1822, "torch-tensor"]], "torch.unique_consecutive": [[1841, "torch-unique-consecutive"]], "torch.vander": [[1844, "torch-vander"]], "torch.zeros_like": [[1856, "torch-zeros-like"]], "torch.hub": [[1857, "torch-hub"]], "Publishing models": [[1857, "publishing-models"]], "How to implement an entrypoint?": [[1857, "how-to-implement-an-entrypoint"]], "Important Notice": [[1857, "important-notice"]], "Loading models from Hub": [[1857, "loading-models-from-hub"]], "Running a loaded model:": [[1857, "running-a-loaded-model"]], "Where are my downloaded models saved?": [[1857, "where-are-my-downloaded-models-saved"]], "Caching logic": [[1857, "caching-logic"]], "Known limitations:": [[1857, "known-limitations"]], "torch.tile": [[1825, "torch-tile"]], "torch.use_deterministic_algorithms": [[1843, "torch-use-deterministic-algorithms"]], "torch.tril_indices": [[1833, "torch-tril-indices"]], "torch.true_divide": [[1836, "torch-true-divide"]], "torch.vmap": [[1850, "torch-vmap"]], "torch.trapz": [[1830, "torch-trapz"]], "torch.tanh": [[1821, "torch-tanh"]], "torch.vdot": [[1847, "torch-vdot"]], "torch.trace": [[1827, "torch-trace"]], "torch.unflatten": [[1839, "torch-unflatten"]], "torch.tril": [[1832, "torch-tril"]], "torch.orgqr": [[1694, "torch-orgqr"]], "torch.outer": [[1696, "torch-outer"]], "torch.optim.Optimizer.step": [[1672, "torch-optim-optimizer-step"]], "RAdam": [[1674, "radam"]], "SparseAdam": [[1678, "sparseadam"]], "LinearLR": [[1686, "linearlr"]], "torch.prod": [[1705, "torch-prod"]], "SobolEngine": [[1714, "sobolengine"]], "OneCycleLR": [[1689, "onecyclelr"]], "CyclicLR": [[1683, "cycliclr"]], "SequentialLR": [[1692, "sequentiallr"]], "ReduceLROnPlateau": [[1691, "reducelronplateau"]], "SGD": [[1677, "sgd"]], "torch.poisson": [[1700, "torch-poisson"]], "torch.promote_types": [[1706, "torch-promote-types"]], "torch.quantized_max_pool1d": [[1712, "torch-quantized-max-pool1d"]], "ConstantLR": [[1680, "constantlr"]], "torch.optim.Optimizer.zero_grad": [[1673, "torch-optim-optimizer-zero-grad"]], "LambdaLR": [[1685, "lambdalr"]], "torch.optim.Optimizer.add_param_group": [[1669, "torch-optim-optimizer-add-param-group"]], "ChainedScheduler": [[1679, "chainedscheduler"]], "CosineAnnealingWarmRestarts": [[1682, "cosineannealingwarmrestarts"]], "torch.polygamma": [[1702, "torch-polygamma"]], "RMSprop": [[1675, "rmsprop"]], "torch.quantile": [[1708, "torch-quantile"]], "torch.quantize_per_tensor": [[1710, "torch-quantize-per-tensor"]], "PolynomialLR": [[1690, "polynomiallr"]], "NAdam": [[1668, "nadam"]], "StepLR": [[1693, "steplr"]], "ExponentialLR": [[1684, "exponentiallr"]], "torch.quantize_per_channel": [[1709, "torch-quantize-per-channel"]], "Adamax": [[1666, "adamax"]], "torch.optim.Optimizer.state_dict": [[1671, "torch-optim-optimizer-state-dict"]], "torch.quantized_max_pool2d": [[1713, "torch-quantized-max-pool2d"]], "torch.quantized_batch_norm": [[1711, "torch-quantized-batch-norm"]], "torch.qr": [[1707, "torch-qr"]], "torch.polar": [[1701, "torch-polar"]], "MultiplicativeLR": [[1688, "multiplicativelr"]], "torch.ormqr": [[1695, "torch-ormqr"]], "MultiStepLR": [[1687, "multisteplr"]], "torch.pinverse": [[1699, "torch-pinverse"]], "torch.permute": [[1698, "torch-permute"]], "torch.positive": [[1703, "torch-positive"]], "torch.pow": [[1704, "torch-pow"]], "torch.optim.Optimizer.load_state_dict": [[1670, "torch-optim-optimizer-load-state-dict"]], "torch.pca_lowrank": [[1697, "torch-pca-lowrank"]], "Rprop": [[1676, "rprop"]], "LBFGS": [[1667, "lbfgs"]], "CosineAnnealingLR": [[1681, "cosineannealinglr"]], "torch.nn.functional.silu": [[1574, "torch-nn-functional-silu"]], "torch.nn.functional.torch.nn.parallel.data_parallel": [[1586, "torch-nn-functional-torch-nn-parallel-data-parallel"]], "torch.nn.functional.relu_": [[1568, "torch-nn-functional-relu"]], "ParametrizationList": [[1611, "parametrizationlist"]], "torch.nn.modules.module.register_module_full_backward_pre_hook": [[1599, "torch-nn-modules-module-register-module-full-backward-pre-hook"]], "torch.nn.modules.module.register_module_parameter_registration_hook": [[1601, "torch-nn-modules-module-register-module-parameter-registration-hook"]], "torch.nn.utils.parametrize.register_parametrization": [[1614, "torch-nn-utils-parametrize-register-parametrization"]], "torch.nn.modules.module.register_module_buffer_registration_hook": [[1595, "torch-nn-modules-module-register-module-buffer-registration-hook"]], "torch.nn.modules.module.register_module_forward_hook": [[1596, "torch-nn-modules-module-register-module-forward-hook"]], "torch.nn.functional.selu": [[1572, "torch-nn-functional-selu"]], "torch.nn.functional.threshold_": [[1585, "torch-nn-functional-threshold"]], "torch.nn.functional.threshold": [[1584, "torch-nn-functional-threshold"]], "torch.nn.utils.clip_grad_norm_": [[1606, "torch-nn-utils-clip-grad-norm"]], "torch.nn.utils.parametrize.is_parametrized": [[1613, "torch-nn-utils-parametrize-is-parametrized"]], "torch.nn.functional.soft_margin_loss": [[1576, "torch-nn-functional-soft-margin-loss"]], "torch.nn.functional.smooth_l1_loss": [[1575, "torch-nn-functional-smooth-l1-loss"]], "torch.nn.modules.module.register_module_full_backward_hook": [[1598, "torch-nn-modules-module-register-module-full-backward-hook"]], "torch.nn.utils.parametrizations.spectral_norm": [[1610, "torch-nn-utils-parametrizations-spectral-norm"]], "torch.nn.modules.module.register_module_forward_pre_hook": [[1597, "torch-nn-modules-module-register-module-forward-pre-hook"]], "BasePruningMethod": [[1616, "basepruningmethod"]], "torch.nn.functional.sigmoid": [[1573, "torch-nn-functional-sigmoid"]], "torch.nn.functional.scaled_dot_product_attention": [[1571, "torch-nn-functional-scaled-dot-product-attention"]], "torch.nn.functional.rrelu_": [[1570, "torch-nn-functional-rrelu"]], "torch.nn.utils.parameters_to_vector": [[1608, "torch-nn-utils-parameters-to-vector"]], "torch.nn.utils.parametrize.cached": [[1612, "torch-nn-utils-parametrize-cached"]], "torch.nn.functional.softmax": [[1577, "torch-nn-functional-softmax"]], "torch.nn.modules.module.register_module_module_registration_hook": [[1600, "torch-nn-modules-module-register-module-module-registration-hook"]], "torch.nn.utils.parametrizations.orthogonal": [[1609, "torch-nn-utils-parametrizations-orthogonal"]], "torch.nn.functional.triplet_margin_with_distance_loss": [[1588, "torch-nn-functional-triplet-margin-with-distance-loss"]], "torch.nn.functional.tanh": [[1582, "torch-nn-functional-tanh"]], "UninitializedParameter": [[1605, "uninitializedparameter"]], "torch.nn.functional.softplus": [[1579, "torch-nn-functional-softplus"]], "Parameter": [[1603, "parameter"]], "LazyModuleMixin": [[1593, "lazymodulemixin"]], "torch.nn.functional.tanhshrink": [[1583, "torch-nn-functional-tanhshrink"]], "torch.nn.modules.module.register_module_backward_hook": [[1594, "torch-nn-modules-module-register-module-backward-hook"]], "DistributedDataParallel": [[1602, "distributeddataparallel"], [1887, "distributeddataparallel"]], "torch.nn.utils.clip_grad_value_": [[1607, "torch-nn-utils-clip-grad-value"]], "torch.nn.functional.softmin": [[1578, "torch-nn-functional-softmin"]], "torch.nn.functional.softshrink": [[1580, "torch-nn-functional-softshrink"]], "torch.nn.functional.upsample_bilinear": [[1591, "torch-nn-functional-upsample-bilinear"]], "torch.nn.functional.upsample": [[1590, "torch-nn-functional-upsample"]], "torch.nn.functional.upsample_nearest": [[1592, "torch-nn-functional-upsample-nearest"]], "torch.nn.functional.rrelu": [[1569, "torch-nn-functional-rrelu"]], "torch.nn.functional.softsign": [[1581, "torch-nn-functional-softsign"]], "torch.nn.functional.triplet_margin_loss": [[1587, "torch-nn-functional-triplet-margin-loss"]], "torch.nn.functional.unfold": [[1589, "torch-nn-functional-unfold"]], "torch.nn.utils.parametrize.remove_parametrizations": [[1615, "torch-nn-utils-parametrize-remove-parametrizations"]], "UninitializedBuffer": [[1604, "uninitializedbuffer"]], "Adam": [[1664, "adam"]], "PruningContainer": [[1621, "pruningcontainer"]], "ExportOptions": [[1655, "exportoptions"]], "torch.nn.utils.skip_init": [[1642, "torch-nn-utils-skip-init"]], "torch.nn.utils.prune.remove": [[1632, "torch-nn-utils-prune-remove"]], "VerificationOptions": [[1660, "verificationoptions"]], "torch.nn.utils.prune.random_structured": [[1630, "torch-nn-utils-prune-random-structured"]], "torch.nn.utils.rnn.pack_sequence": [[1637, "torch-nn-utils-rnn-pack-sequence"]], "PackedSequence": [[1635, "packedsequence"]], "Adagrad": [[1663, "adagrad"]], "torch.nn.utils.prune.random_unstructured": [[1631, "torch-nn-utils-prune-random-unstructured"]], "torch.nn.utils.spectral_norm": [[1643, "torch-nn-utils-spectral-norm"]], "torch.nn.utils.prune.ln_structured": [[1629, "torch-nn-utils-prune-ln-structured"]], "RandomStructured": [[1622, "randomstructured"]], "torch.ones": [[1653, "torch-ones"]], "torch.nn.utils.rnn.unpack_sequence": [[1640, "torch-nn-utils-rnn-unpack-sequence"]], "GraphInfo": [[1659, "graphinfo"]], "torch.nn.utils.remove_spectral_norm": [[1633, "torch-nn-utils-remove-spectral-norm"]], "LnStructured": [[1620, "lnstructured"]], "torch.nn.utils.prune.custom_from_mask": [[1624, "torch-nn-utils-prune-custom-from-mask"]], "JitScalarType": [[1658, "jitscalartype"]], "torch.numel": [[1652, "torch-numel"]], "CustomFromMask": [[1617, "customfrommask"]], "torch.nn.utils.weight_norm": [[1646, "torch-nn-utils-weight-norm"]], "torch.nn.utils.rnn.unpad_sequence": [[1641, "torch-nn-utils-rnn-unpad-sequence"]], "torch.nn.utils.remove_weight_norm": [[1634, "torch-nn-utils-remove-weight-norm"]], "no_grad": [[1647, "no-grad"]], "torch.nn.utils.prune.global_unstructured": [[1625, "torch-nn-utils-prune-global-unstructured"]], "ExportOutputSerializer": [[1657, "exportoutputserializer"]], "AdamW": [[1665, "adamw"]], "torch.norm": [[1649, "torch-norm"]], "RandomUnstructured": [[1623, "randomunstructured"]], "Identity": [[1618, "identity"], [1384, "identity"]], "torch.nn.utils.rnn.pad_packed_sequence": [[1638, "torch-nn-utils-rnn-pad-packed-sequence"]], "torch.normal": [[1650, "torch-normal"]], "torch.nn.utils.prune.is_pruned": [[1627, "torch-nn-utils-prune-is-pruned"]], "torch.nn.utils.rnn.pad_sequence": [[1639, "torch-nn-utils-rnn-pad-sequence"]], "torch.nn.utils.prune.l1_unstructured": [[1628, "torch-nn-utils-prune-l1-unstructured"]], "torch.nonzero": [[1648, "torch-nonzero"]], "ASGD": [[1661, "asgd"]], "torch.nn.utils.stateless.functional_call": [[1644, "torch-nn-utils-stateless-functional-call"]], "L1Unstructured": [[1619, "l1unstructured"]], "torch.nn.utils.prune.identity": [[1626, "torch-nn-utils-prune-identity"]], "torch.ones_like": [[1654, "torch-ones-like"]], "ExportOutput": [[1656, "exportoutput"]], "Adadelta": [[1662, "adadelta"]], "torch.nn.utils.vector_to_parameters": [[1645, "torch-nn-utils-vector-to-parameters"]], "torch.not_equal": [[1651, "torch-not-equal"]], "torch.nn.utils.rnn.pack_padded_sequence": [[1636, "torch-nn-utils-rnn-pack-padded-sequence"]], "torch.nn.functional.interpolate": [[1532, "torch-nn-functional-interpolate"]], "torch.nn.functional.lp_pool2d": [[1543, "torch-nn-functional-lp-pool2d"]], "torch.nn.functional.normalize": [[1557, "torch-nn-functional-normalize"]], "torch.nn.functional.glu": [[1520, "torch-nn-functional-glu"]], "torch.nn.functional.l1_loss": [[1534, "torch-nn-functional-l1-loss"]], "torch.nn.functional.log_softmax": [[1540, "torch-nn-functional-log-softmax"]], "torch.nn.functional.pixel_shuffle": [[1562, "torch-nn-functional-pixel-shuffle"]], "torch.nn.functional.max_unpool1d": [[1548, "torch-nn-functional-max-unpool1d"]], "torch.nn.functional.relu": [[1566, "torch-nn-functional-relu"]], "torch.nn.functional.grid_sample": [[1521, "torch-nn-functional-grid-sample"]], "torch.nn.functional.hardsigmoid": [[1525, "torch-nn-functional-hardsigmoid"]], "torch.nn.functional.one_hot": [[1558, "torch-nn-functional-one-hot"]], "torch.nn.functional.gelu": [[1519, "torch-nn-functional-gelu"]], "torch.nn.functional.margin_ranking_loss": [[1544, "torch-nn-functional-margin-ranking-loss"]], "torch.nn.functional.hinge_embedding_loss": [[1529, "torch-nn-functional-hinge-embedding-loss"]], "torch.nn.functional.group_norm": [[1522, "torch-nn-functional-group-norm"]], "torch.nn.functional.multi_margin_loss": [[1553, "torch-nn-functional-multi-margin-loss"]], "torch.nn.functional.pixel_unshuffle": [[1563, "torch-nn-functional-pixel-unshuffle"]], "torch.nn.functional.prelu": [[1565, "torch-nn-functional-prelu"]], "torch.nn.functional.max_pool1d": [[1545, "torch-nn-functional-max-pool1d"]], "torch.nn.functional.relu6": [[1567, "torch-nn-functional-relu6"]], "torch.nn.functional.layer_norm": [[1535, "torch-nn-functional-layer-norm"]], "torch.nn.functional.linear": [[1538, "torch-nn-functional-linear"]], "torch.nn.functional.hardshrink": [[1524, "torch-nn-functional-hardshrink"]], "torch.nn.functional.leaky_relu_": [[1537, "torch-nn-functional-leaky-relu"]], "torch.nn.functional.max_unpool2d": [[1549, "torch-nn-functional-max-unpool2d"]], "torch.nn.functional.nll_loss": [[1556, "torch-nn-functional-nll-loss"]], "torch.nn.functional.hardtanh_": [[1528, "torch-nn-functional-hardtanh"]], "torch.nn.functional.leaky_relu": [[1536, "torch-nn-functional-leaky-relu"]], "torch.nn.functional.max_pool2d": [[1546, "torch-nn-functional-max-pool2d"]], "torch.nn.functional.local_response_norm": [[1539, "torch-nn-functional-local-response-norm"]], "torch.nn.functional.kl_div": [[1533, "torch-nn-functional-kl-div"]], "torch.nn.functional.huber_loss": [[1530, "torch-nn-functional-huber-loss"]], "torch.nn.functional.lp_pool1d": [[1542, "torch-nn-functional-lp-pool1d"]], "torch.nn.functional.pairwise_distance": [[1560, "torch-nn-functional-pairwise-distance"]], "torch.nn.functional.max_unpool3d": [[1550, "torch-nn-functional-max-unpool3d"]], "torch.nn.functional.instance_norm": [[1531, "torch-nn-functional-instance-norm"]], "torch.nn.functional.gumbel_softmax": [[1523, "torch-nn-functional-gumbel-softmax"]], "torch.nn.functional.logsigmoid": [[1541, "torch-nn-functional-logsigmoid"]], "torch.nn.functional.hardswish": [[1526, "torch-nn-functional-hardswish"]], "torch.nn.functional.multilabel_soft_margin_loss": [[1555, "torch-nn-functional-multilabel-soft-margin-loss"]], "torch.nn.functional.poisson_nll_loss": [[1564, "torch-nn-functional-poisson-nll-loss"]], "torch.nn.functional.max_pool3d": [[1547, "torch-nn-functional-max-pool3d"]], "torch.nn.functional.multilabel_margin_loss": [[1554, "torch-nn-functional-multilabel-margin-loss"]], "torch.nn.functional.mish": [[1551, "torch-nn-functional-mish"]], "torch.nn.functional.pad": [[1559, "torch-nn-functional-pad"]], "torch.nn.functional.hardtanh": [[1527, "torch-nn-functional-hardtanh"]], "torch.nn.functional.mse_loss": [[1552, "torch-nn-functional-mse-loss"]], "torch.nn.functional.pdist": [[1561, "torch-nn-functional-pdist"]], "FullyShardedDataParallel": [[63, "module-torch.distributed.fsdp"]], "torch.Tensor.acosh": [[96, "torch-tensor-acosh"]], "TorchElastic Kubernetes": [[54, "torchelastic-kubernetes"]], "FXE0002:fx-tracer-failure": [[74, "fxe0002-fx-tracer-failure"]], "POE0004:operator-supported-in-newer-opset-version": [[88, "poe0004-operator-supported-in-newer-opset-version"]], "Migrating from functorch to torch.func": [[67, "migrating-from-functorch-to-torch-func"]], "function transforms": [[67, "function-transforms"]], "NN module utilities": [[67, "nn-module-utilities"]], "functorch.make_functional": [[67, "functorch-make-functional"]], "functorch.combine_state_for_ensemble": [[67, "functorch-combine-state-for-ensemble"]], "functorch.compile": [[67, "functorch-compile"]], "FXE0004:fx-pass-convert-neg-to-sigmoid": [[76, "fxe0004-fx-pass-convert-neg-to-sigmoid"]], "FXE0010:fx-pass": [[82, "fxe0010-fx-pass"]], "POE0003:missing-standard-symbolic-function": [[87, "poe0003-missing-standard-symbolic-function"]], "POE0002:missing-custom-symbolic-function": [[86, "poe0002-missing-custom-symbolic-function"]], "torch.fft": [[62, "torch-fft"]], "Fast Fourier Transforms": [[62, "fast-fourier-transforms"]], "Helper Functions": [[62, "helper-functions"]], "Train script": [[61, "train-script"]], "torch.Tensor.abs": [[90, "torch-tensor-abs"]], "FXE0011:no-symbolic-function-for-call-function": [[83, "fxe0011-no-symbolic-function-for-call-function"]], "Expiration Timers": [[60, "module-torch.distributed.elastic.timer"]], "Client Methods": [[60, "client-methods"]], "Server/Client Implementations": [[60, "server-client-implementations"]], "Writing a custom timer server/client": [[60, "writing-a-custom-timer-server-client"]], "Quickstart": [[57, "quickstart"]], "Examples": [[53, "examples"], [13, "examples"]], "torch.Tensor.acos": [[94, "torch-tensor-acos"]], "torch.Tensor.abs_": [[91, "torch-tensor-abs"]], "torch.fx": [[71, "torch-fx"]], "Overview": [[71, "module-torch.fx"], [13, "overview"], [35, "module-torch.cuda._sanitizer"], [1907, "module-torch.profiler"], [1902, "overview"]], "Writing Transformations": [[71, "writing-transformations"]], "A Quick Primer on Graphs": [[71, "a-quick-primer-on-graphs"]], "Graph Manipulation": [[71, "graph-manipulation"]], "Direct Graph Manipulation": [[71, "direct-graph-manipulation"]], "Subgraph Rewriting With replace_pattern()": [[71, "subgraph-rewriting-with-replace-pattern"]], "Graph Manipulation Examples": [[71, "graph-manipulation-examples"]], "Proxy/Retracing": [[71, "proxy-retracing"]], "The Interpreter Pattern": [[71, "the-interpreter-pattern"]], "Examples of the Interpreter Pattern": [[71, "examples-of-the-interpreter-pattern"]], "Introduction": [[71, "introduction"], [1870, "introduction"], [1878, "introduction"]], "Common Pitfalls in Transform Authoring": [[71, "common-pitfalls-in-transform-authoring"]], "Checking Correctness of Modules": [[71, "checking-correctness-of-modules"]], "Debugging the Generated Code": [[71, "debugging-the-generated-code"]], "Use pdb": [[71, "use-pdb"]], "Print the Generated Code": [[71, "print-the-generated-code"]], "Use the to_folder Function From GraphModule": [[71, "use-the-to-folder-function-from-graphmodule"]], "Debugging the Transformation": [[71, "debugging-the-transformation"]], "Available Debuggers": [[71, "available-debuggers"]], "Limitations of Symbolic Tracing": [[71, "limitations-of-symbolic-tracing"]], "Dynamic Control Flow": [[71, "dynamic-control-flow"]], "Static Control Flow": [[71, "static-control-flow"]], "Non-torch Functions": [[71, "non-torch-functions"]], "Customizing Tracing with the Tracer class": [[71, "customizing-tracing-with-the-tracer-class"]], "Leaf Modules": [[71, "leaf-modules"]], "Miscellanea": [[71, "miscellanea"]], "API Reference": [[71, "api-reference"], [35, "api-reference"], [1905, "api-reference"], [1873, "module-torch.monitor"], [1907, "api-reference"], [1902, "api-reference"]], "Patching Batch Norm": [[66, "patching-batch-norm"]], "What\u2019s happening?": [[66, "what-s-happening"]], "How to fix": [[66, "how-to-fix"]], "Option 1: Change the BatchNorm": [[66, "option-1-change-the-batchnorm"]], "Option 2: torchvision parameter": [[66, "option-2-torchvision-parameter"]], "Option 3: functorch\u2019s patching": [[66, "option-3-functorch-s-patching"]], "Option 4: eval mode": [[66, "option-4-eval-mode"]], "torch.func Whirlwind Tour": [[69, "torch-func-whirlwind-tour"]], "What is torch.func?": [[69, "what-is-torch-func"]], "Why composable function transforms?": [[69, "why-composable-function-transforms"], [64, "why-composable-function-transforms"]], "What are the transforms?": [[69, "what-are-the-transforms"]], "grad() (gradient computation)": [[69, "grad-gradient-computation"]], "vmap() (auto-vectorization)": [[69, "vmap-auto-vectorization"]], "vjp() (vector-Jacobian product)": [[69, "vjp-vector-jacobian-product"]], "jvp() (Jacobian-vector product)": [[69, "jvp-jacobian-vector-product"]], "jacrev(), jacfwd(), and hessian()": [[69, "jacrev-jacfwd-and-hessian"]], "torch.Tensor.acos_": [[95, "torch-tensor-acos"]], "FXE0009:fx-frontend-dynamo-make-fx": [[81, "fxe0009-fx-frontend-dynamo-make-fx"]], "UX Limitations": [[68, "ux-limitations"]], "General limitations": [[68, "general-limitations"]], "torch.autograd APIs": [[68, "torch-autograd-apis"]], "vmap limitations": [[68, "vmap-limitations"]], "Mutation: Arbitrary mutation of Python data structures": [[68, "mutation-arbitrary-mutation-of-python-data-structures"]], "Mutation: in-place PyTorch Operations": [[68, "mutation-in-place-pytorch-operations"]], "Mutation: out= PyTorch Operations": [[68, "mutation-out-pytorch-operations"]], "Data-dependent Python control flow": [[68, "data-dependent-python-control-flow"]], "Data-dependent operations (.item())": [[68, "data-dependent-operations-item"]], "Dynamic shape operations (nonzero and friends)": [[68, "dynamic-shape-operations-nonzero-and-friends"]], "Randomness": [[68, "randomness"]], "FXE0008:fx-node-to-onnx": [[80, "fxe0008-fx-node-to-onnx"]], "FXE0007:atenlib-fx-to-onnx": [[79, "fxe0007-atenlib-fx-to-onnx"]], "POE0001:node-missing-onnx-shape-inference": [[85, "poe0001-node-missing-onnx-shape-inference"]], "FXE0005:fx-ir-add-node": [[77, "fxe0005-fx-ir-add-node"]], "Rendezvous": [[58, "module-torch.distributed.elastic.rendezvous"]], "Registry": [[58, "registry"]], "Handler": [[58, "handler"]], "Exceptions": [[58, "exceptions"]], "Implementations": [[58, "implementations"], [49, "implementations"]], "Dynamic Rendezvous": [[58, "dynamic-rendezvous"]], "C10d Backend": [[58, "c10d-backend"]], "Etcd Backend": [[58, "etcd-backend"]], "Etcd Rendezvous (Legacy)": [[58, "etcd-rendezvous-legacy"]], "Etcd Store": [[58, "etcd-store"]], "Etcd Server": [[58, "etcd-server"]], "FXE0001:fx-tracer-success": [[73, "fxe0001-fx-tracer-success"]], "FXE0003:fx-frontend-aotautograd": [[75, "fxe0003-fx-frontend-aotautograd"]], "FXE0012:unsupported-fx-node-analysis": [[84, "fxe0012-unsupported-fx-node-analysis"]], "Multiprocessing": [[56, "module-torch.distributed.elastic.multiprocessing"]], "Starting Multiple Workers": [[56, "starting-multiple-workers"]], "Process Context": [[56, "process-context"]], "torchrun (Elastic Launch)": [[59, "module-torch.distributed.run"]], "Transitioning from torch.distributed.launch to torchrun": [[59, "transitioning-from-torch-distributed-launch-to-torchrun"]], "Usage": [[59, "usage"], [44, null], [35, "usage"]], "Single-node multi-worker": [[59, "single-node-multi-worker"]], "Stacked single-node multi-worker": [[59, "stacked-single-node-multi-worker"]], "Fault tolerant (fixed sized number of workers, no elasticity, tolerates 3 failures)": [[59, "fault-tolerant-fixed-sized-number-of-workers-no-elasticity-tolerates-3-failures"]], "Elastic (min=1, max=4, tolerates up to 3 membership changes or failures)": [[59, "elastic-min-1-max-4-tolerates-up-to-3-membership-changes-or-failures"]], "Note on rendezvous backend": [[59, "note-on-rendezvous-backend"]], "Definitions": [[59, "definitions"]], "Environment Variables": [[59, "environment-variables"]], "Deployment": [[59, "deployment"]], "Failure Modes": [[59, "failure-modes"]], "Membership Changes": [[59, "membership-changes"]], "Important Notices": [[59, "important-notices"]], "Error Propagation": [[51, "module-torch.distributed.elastic.multiprocessing.errors"]], "Methods and Classes": [[51, "methods-and-classes"]], "FXE0006:atenlib-symbolic-function": [[78, "fxe0006-atenlib-symbolic-function"]], "torch.Tensor.absolute": [[92, "torch-tensor-absolute"]], "torch.Tensor.acosh_": [[97, "torch-tensor-acosh"]], "torch.func API Reference": [[65, "module-torch.func"]], "Function Transforms": [[65, "function-transforms"]], "Utilities for working with torch.nn.Modules": [[65, "utilities-for-working-with-torch-nn-modules"]], "torch.futures": [[70, "torch-futures"]], "Events": [[52, "module-torch.distributed.elastic.events"]], "API Methods": [[52, "api-methods"]], "Event Objects": [[52, "event-objects"]], "torch.func": [[64, "torch-func"]], "What are composable function transforms?": [[64, "what-are-composable-function-transforms"]], "Read More": [[64, "read-more"]], "Elastic Agent": [[49, "module-torch.distributed.elastic.agent"]], "Server": [[49, "module-torch.distributed.elastic.agent.server"]], "Concepts": [[49, "concepts"]], "Extending the Agent": [[49, "extending-the-agent"]], "Watchdog in the Agent": [[49, "watchdog-in-the-agent"]], "Generator": [[89, "generator"]], "DIAGSYS0001:arg-format-too-verbose": [[72, "diagsys0001-arg-format-too-verbose"]], "torch.Tensor.absolute_": [[93, "torch-tensor-absolute"]], "Customization": [[50, "customization"]], "Launcher": [[50, "launcher"]], "Rendezvous Handler": [[50, "rendezvous-handler"]], "Metric Handler": [[50, "metric-handler"]], "Events Handler": [[50, "events-handler"]], "Metrics": [[55, "module-torch.distributed.elastic.metrics"]], "Metric Handlers": [[55, "metric-handlers"]], "Methods": [[55, "methods"]], "torch.nn.functional.conv1d": [[1496, "torch-nn-functional-conv1d"]], "torch.nn.functional.adaptive_avg_pool1d": [[1480, "torch-nn-functional-adaptive-avg-pool1d"]], "torch.nn.functional.adaptive_max_pool2d": [[1484, "torch-nn-functional-adaptive-max-pool2d"]], "ZeroPad1d": [[1477, "zeropad1d"]], "torch.nn.functional.dropout2d": [[1508, "torch-nn-functional-dropout2d"]], "Unfold": [[1473, "unfold"]], "Upsample": [[1474, "upsample"]], "torch.nn.functional.binary_cross_entropy": [[1493, "torch-nn-functional-binary-cross-entropy"]], "torch.nn.functional.ctc_loss": [[1505, "torch-nn-functional-ctc-loss"]], "torch.nn.functional.alpha_dropout": [[1487, "torch-nn-functional-alpha-dropout"]], "torch.nn.functional.cross_entropy": [[1504, "torch-nn-functional-cross-entropy"]], "torch.nn.functional.dropout": [[1506, "torch-nn-functional-dropout"]], "torch.nn.functional.adaptive_avg_pool3d": [[1482, "torch-nn-functional-adaptive-avg-pool3d"]], "torch.nn.functional.adaptive_avg_pool2d": [[1481, "torch-nn-functional-adaptive-avg-pool2d"]], "ZeroPad3d": [[1479, "zeropad3d"]], "torch.nn.functional.batch_norm": [[1491, "torch-nn-functional-batch-norm"]], "torch.nn.functional.conv3d": [[1498, "torch-nn-functional-conv3d"]], "torch.nn.functional.conv_transpose3d": [[1501, "torch-nn-functional-conv-transpose3d"]], "torch.nn.functional.cosine_similarity": [[1503, "torch-nn-functional-cosine-similarity"]], "torch.nn.functional.dropout3d": [[1509, "torch-nn-functional-dropout3d"]], "torch.nn.functional.fold": [[1515, "torch-nn-functional-fold"]], "torch.nn.functional.avg_pool3d": [[1490, "torch-nn-functional-avg-pool3d"]], "UpsamplingBilinear2d": [[1475, "upsamplingbilinear2d"]], "torch.nn.functional.elu_": [[1511, "torch-nn-functional-elu"]], "TripletMarginLoss": [[1470, "tripletmarginloss"]], "torch.nn.functional.embedding": [[1512, "torch-nn-functional-embedding"]], "torch.nn.functional.bilinear": [[1492, "torch-nn-functional-bilinear"]], "torch.nn.functional.conv_transpose2d": [[1500, "torch-nn-functional-conv-transpose2d"]], "torch.nn.functional.fractional_max_pool2d": [[1516, "torch-nn-functional-fractional-max-pool2d"]], "torch.nn.functional.celu": [[1495, "torch-nn-functional-celu"]], "torch.nn.functional.adaptive_max_pool1d": [[1483, "torch-nn-functional-adaptive-max-pool1d"]], "torch.nn.functional.cosine_embedding_loss": [[1502, "torch-nn-functional-cosine-embedding-loss"]], "torch.nn.functional.fractional_max_pool3d": [[1517, "torch-nn-functional-fractional-max-pool3d"]], "torch.nn.functional.elu": [[1510, "torch-nn-functional-elu"]], "torch.nn.functional.gaussian_nll_loss": [[1518, "torch-nn-functional-gaussian-nll-loss"]], "torch.nn.functional.dropout1d": [[1507, "torch-nn-functional-dropout1d"]], "Unflatten": [[1472, "unflatten"]], "torch.nn.functional.feature_alpha_dropout": [[1514, "torch-nn-functional-feature-alpha-dropout"]], "torch.nn.functional.conv2d": [[1497, "torch-nn-functional-conv2d"]], "ZeroPad2d": [[1478, "zeropad2d"]], "UpsamplingNearest2d": [[1476, "upsamplingnearest2d"]], "torch.nn.functional.conv_transpose1d": [[1499, "torch-nn-functional-conv-transpose1d"]], "torch.nn.functional.adaptive_max_pool3d": [[1485, "torch-nn-functional-adaptive-max-pool3d"]], "torch.nn.functional.embedding_bag": [[1513, "torch-nn-functional-embedding-bag"]], "torch.nn.functional.affine_grid": [[1486, "torch-nn-functional-affine-grid"]], "torch.nn.functional.binary_cross_entropy_with_logits": [[1494, "torch-nn-functional-binary-cross-entropy-with-logits"]], "torch.nn.functional.avg_pool2d": [[1489, "torch-nn-functional-avg-pool2d"]], "torch.nn.functional.avg_pool1d": [[1488, "torch-nn-functional-avg-pool1d"]], "TripletMarginWithDistanceLoss": [[1471, "tripletmarginwithdistanceloss"]], "Linear": [[1409, "linear"], [761, "linear"], [753, "linear"], [730, "linear"], [729, "linear"]], "LazyConvTranspose1d": [[1401, "lazyconvtranspose1d"]], "MaxPool3d": [[1417, "maxpool3d"]], "LazyConv2d": [[1399, "lazyconv2d"]], "HingeEmbeddingLoss": [[1382, "hingeembeddingloss"]], "LazyConv1d": [[1398, "lazyconv1d"]], "LocalResponseNorm": [[1410, "localresponsenorm"]], "LPPool2d": [[1391, "lppool2d"]], "LazyConvTranspose2d": [[1402, "lazyconvtranspose2d"]], "KLDivLoss": [[1388, "kldivloss"]], "LPPool1d": [[1390, "lppool1d"]], "GaussianNLLLoss": [[1376, "gaussiannllloss"]], "InstanceNorm2d": [[1386, "instancenorm2d"], [749, "instancenorm2d"]], "LeakyReLU": [[1408, "leakyrelu"], [752, "leakyrelu"]], "MaxUnpool3d": [[1420, "maxunpool3d"]], "MaxPool1d": [[1415, "maxpool1d"]], "LazyConv3d": [[1400, "lazyconv3d"]], "MarginRankingLoss": [[1414, "marginrankingloss"]], "LazyBatchNorm1d": [[1395, "lazybatchnorm1d"]], "GELU": [[1372, "gelu"]], "LogSigmoid": [[1411, "logsigmoid"]], "GroupNorm": [[1377, "groupnorm"], [746, "groupnorm"]], "MaxUnpool1d": [[1418, "maxunpool1d"]], "Hardswish": [[1380, "hardswish"], [747, "hardswish"]], "LazyInstanceNorm2d": [[1405, "lazyinstancenorm2d"]], "LazyInstanceNorm3d": [[1406, "lazyinstancenorm3d"]], "Hardshrink": [[1378, "hardshrink"]], "HuberLoss": [[1383, "huberloss"]], "L1Loss": [[1389, "l1loss"]], "GLU": [[1373, "glu"]], "LazyBatchNorm3d": [[1397, "lazybatchnorm3d"]], "GRUCell": [[1375, "grucell"], [758, "grucell"]], "LogSoftmax": [[1412, "logsoftmax"]], "GRU": [[1374, "gru"], [757, "gru"]], "LazyInstanceNorm1d": [[1404, "lazyinstancenorm1d"]], "LayerNorm": [[1394, "layernorm"], [751, "layernorm"]], "Hardsigmoid": [[1379, "hardsigmoid"]], "MSELoss": [[1413, "mseloss"]], "MaxPool2d": [[1416, "maxpool2d"]], "InstanceNorm3d": [[1387, "instancenorm3d"], [750, "instancenorm3d"]], "LazyBatchNorm2d": [[1396, "lazybatchnorm2d"]], "Hardtanh": [[1381, "hardtanh"]], "LSTMCell": [[1393, "lstmcell"], [760, "lstmcell"]], "LazyConvTranspose3d": [[1403, "lazyconvtranspose3d"]], "LazyLinear": [[1407, "lazylinear"]], "InstanceNorm1d": [[1385, "instancenorm1d"], [748, "instancenorm1d"]], "MaxUnpool2d": [[1419, "maxunpool2d"]], "LSTM": [[1392, "lstm"], [759, "lstm"], [731, "lstm"]], "ReplicationPad2d": [[1447, "replicationpad2d"]], "Tanhshrink": [[1463, "tanhshrink"]], "Softmax2d": [[1456, "softmax2d"]], "PReLU": [[1430, "prelu"]], "Softmax": [[1455, "softmax"]], "PairwiseDistance": [[1431, "pairwisedistance"]], "ReflectionPad2d": [[1444, "reflectionpad2d"]], "PoissonNLLLoss": [[1436, "poissonnllloss"]], "Threshold": [[1464, "threshold"]], "MultiLabelMarginLoss": [[1425, "multilabelmarginloss"]], "Module": [[1422, "module"]], "ParameterDict": [[1432, "parameterdict"]], "MultiLabelSoftMarginLoss": [[1426, "multilabelsoftmarginloss"]], "NLLLoss": [[1429, "nllloss"]], "TransformerDecoderLayer": [[1467, "transformerdecoderlayer"]], "Mish": [[1421, "mish"]], "SiLU": [[1451, "silu"]], "ModuleList": [[1424, "modulelist"]], "Sigmoid": [[1452, "sigmoid"], [756, "sigmoid"]], "Tanh": [[1462, "tanh"]], "PixelUnshuffle": [[1435, "pixelunshuffle"]], "ReLU": [[1441, "relu"]], "ReplicationPad1d": [[1446, "replicationpad1d"]], "ReLU6": [[1442, "relu6"], [755, "relu6"]], "Softmin": [[1457, "softmin"]], "RNNCell": [[1439, "rnncell"], [762, "rnncell"]], "RNNBase": [[1438, "rnnbase"]], "RReLU": [[1440, "rrelu"]], "ModuleDict": [[1423, "moduledict"]], "SELU": [[1449, "selu"]], "ReflectionPad1d": [[1443, "reflectionpad1d"]], "ReplicationPad3d": [[1448, "replicationpad3d"]], "MultiheadAttention": [[1428, "multiheadattention"], [732, "multiheadattention"]], "SoftMarginLoss": [[1454, "softmarginloss"]], "RNN": [[1437, "rnn"]], "MultiMarginLoss": [[1427, "multimarginloss"]], "SyncBatchNorm": [[1461, "syncbatchnorm"]], "TransformerDecoder": [[1466, "transformerdecoder"]], "Transformer": [[1465, "transformer"], [28, "transformer"]], "Softshrink": [[1459, "softshrink"]], "ReflectionPad3d": [[1445, "reflectionpad3d"]], "Softplus": [[1458, "softplus"]], "TransformerEncoderLayer": [[1469, "transformerencoderlayer"]], "Softsign": [[1460, "softsign"]], "Sequential": [[1450, "sequential"]], "ParameterList": [[1433, "parameterlist"]], "SmoothL1Loss": [[1453, "smoothl1loss"]], "PixelShuffle": [[1434, "pixelshuffle"]], "TransformerEncoder": [[1468, "transformerencoder"]], "FeatureAlphaDropout": [[1367, "featurealphadropout"]], "ConvTranspose3d": [[1355, "convtranspose3d"], [740, "convtranspose3d"]], "ChannelShuffle": [[1346, "channelshuffle"]], "BatchNorm1d": [[1340, "batchnorm1d"]], "ConstantPad1d": [[1347, "constantpad1d"]], "DataParallel": [[1359, "dataparallel"]], "Conv1d": [[1350, "conv1d"], [735, "conv1d"]], "CosineSimilarity": [[1357, "cosinesimilarity"]], "Dropout2d": [[1362, "dropout2d"]], "AdaptiveAvgPool3d": [[1329, "adaptiveavgpool3d"]], "BCELoss": [[1338, "bceloss"]], "ConvTranspose1d": [[1353, "convtranspose1d"], [738, "convtranspose1d"]], "AvgPool1d": [[1335, "avgpool1d"]], "Conv2d": [[1351, "conv2d"], [736, "conv2d"], [727, "conv2d"]], "ELU": [[1364, "elu"], [741, "elu"]], "AdaptiveMaxPool1d": [[1331, "adaptivemaxpool1d"]], "torch.ne": [[1323, "torch-ne"]], "torch.negative": [[1325, "torch-negative"]], "BatchNorm2d": [[1341, "batchnorm2d"], [733, "batchnorm2d"]], "CosineEmbeddingLoss": [[1356, "cosineembeddingloss"]], "Dropout1d": [[1361, "dropout1d"]], "FractionalMaxPool2d": [[1370, "fractionalmaxpool2d"]], "CTCLoss": [[1345, "ctcloss"]], "AdaptiveAvgPool1d": [[1327, "adaptiveavgpool1d"]], "AdaptiveAvgPool2d": [[1328, "adaptiveavgpool2d"]], "BCEWithLogitsLoss": [[1339, "bcewithlogitsloss"]], "AdaptiveMaxPool3d": [[1333, "adaptivemaxpool3d"]], "EmbeddingBag": [[1366, "embeddingbag"], [743, "embeddingbag"]], "Flatten": [[1368, "flatten"]], "AvgPool3d": [[1337, "avgpool3d"]], "Fold": [[1369, "fold"]], "Dropout": [[1360, "dropout"]], "AdaptiveLogSoftmaxWithLoss": [[1330, "adaptivelogsoftmaxwithloss"]], "CrossEntropyLoss": [[1358, "crossentropyloss"]], "AvgPool2d": [[1336, "avgpool2d"]], "torch.neg": [[1324, "torch-neg"]], "Dropout3d": [[1363, "dropout3d"]], "Conv3d": [[1352, "conv3d"], [737, "conv3d"], [728, "conv3d"]], "ConvTranspose2d": [[1354, "convtranspose2d"], [739, "convtranspose2d"]], "FractionalMaxPool3d": [[1371, "fractionalmaxpool3d"]], "AlphaDropout": [[1334, "alphadropout"]], "BatchNorm3d": [[1342, "batchnorm3d"], [734, "batchnorm3d"]], "CELU": [[1344, "celu"]], "Embedding": [[1365, "embedding"], [742, "embedding"]], "ConstantPad2d": [[1348, "constantpad2d"]], "Bilinear": [[1343, "bilinear"]], "AdaptiveMaxPool2d": [[1332, "adaptivemaxpool2d"]], "ConstantPad3d": [[1349, "constantpad3d"]], "torch.nextafter": [[1326, "torch-nextafter"]], "torch.logit": [[1275, "torch-logit"]], "torch.nansum": [[1320, "torch-nansum"]], "torch.manual_seed": [[1282, "torch-manual-seed"]], "torch.mps.set_rng_state": [[1308, "torch-mps-set-rng-state"]], "torch.nanquantile": [[1319, "torch-nanquantile"]], "torch.maximum": [[1288, "torch-maximum"]], "torch.meshgrid": [[1291, "torch-meshgrid"]], "torch.mul": [[1311, "torch-mul"]], "torch.masked_select": [[1283, "torch-masked-select"]], "torch.matmul": [[1284, "torch-matmul"]], "torch.mps.set_per_process_memory_fraction": [[1307, "torch-mps-set-per-process-memory-fraction"]], "torch.mps.manual_seed": [[1302, "torch-mps-manual-seed"]], "torch.mvlgamma": [[1315, "torch-mvlgamma"]], "torch.logical_xor": [[1274, "torch-logical-xor"]], "torch.min": [[1292, "torch-min"]], "torch.median": [[1290, "torch-median"]], "torch.lt": [[1278, "torch-lt"]], "torch.mps.seed": [[1306, "torch-mps-seed"]], "torch.mode": [[1295, "torch-mode"]], "torch.nanmean": [[1317, "torch-nanmean"]], "torch.logspace": [[1276, "torch-logspace"]], "torch.mm": [[1294, "torch-mm"]], "torch.logsumexp": [[1277, "torch-logsumexp"]], "torch.multiply": [[1313, "torch-multiply"]], "torch.msort": [[1310, "torch-msort"]], "torch.mean": [[1289, "torch-mean"]], "torch.nan_to_num": [[1316, "torch-nan-to-num"]], "torch.mps.driver_allocated_memory": [[1299, "torch-mps-driver-allocated-memory"]], "torch.mps.profiler.profile": [[1303, "torch-mps-profiler-profile"]], "torch.mps.profiler.stop": [[1305, "torch-mps-profiler-stop"]], "torch.nanmedian": [[1318, "torch-nanmedian"]], "torch.mps.profiler.start": [[1304, "torch-mps-profiler-start"]], "torch.max": [[1287, "torch-max"]], "torch.narrow": [[1321, "torch-narrow"]], "torch.matrix_power": [[1286, "torch-matrix-power"]], "torch.multinomial": [[1312, "torch-multinomial"]], "torch.movedim": [[1297, "torch-movedim"]], "torch.mps.synchronize": [[1309, "torch-mps-synchronize"]], "torch.lu_solve": [[1280, "torch-lu-solve"]], "torch.matrix_exp": [[1285, "torch-matrix-exp"]], "torch.mps.current_allocated_memory": [[1298, "torch-mps-current-allocated-memory"]], "torch.mv": [[1314, "torch-mv"]], "torch.narrow_copy": [[1322, "torch-narrow-copy"]], "torch.minimum": [[1293, "torch-minimum"]], "torch.lu_unpack": [[1281, "torch-lu-unpack"]], "torch.lu": [[1279, "torch-lu"]], "torch.mps.get_rng_state": [[1301, "torch-mps-get-rng-state"]], "torch.mps.empty_cache": [[1300, "torch-mps-empty-cache"]], "torch.moveaxis": [[1296, "torch-moveaxis"]], "torch.linalg.qr": [[1248, "torch-linalg-qr"]], "torch.log10": [[1264, "torch-log10"]], "torch.linalg.matrix_rank": [[1244, "torch-linalg-matrix-rank"]], "torch.linalg.tensorinv": [[1255, "torch-linalg-tensorinv"]], "torch.linalg.matmul": [[1240, "torch-linalg-matmul"]], "torch.linalg.slogdet": [[1249, "torch-linalg-slogdet"]], "torch.linalg.inv_ex": [[1231, "torch-linalg-inv-ex"]], "torch.lobpcg": [[1262, "torch-lobpcg"]], "torch.linalg.vector_norm": [[1259, "torch-linalg-vector-norm"]], "torch.linalg.matrix_norm": [[1242, "torch-linalg-matrix-norm"]], "torch.linalg.eigh": [[1226, "torch-linalg-eigh"]], "torch.linalg.multi_dot": [[1245, "torch-linalg-multi-dot"]], "torch.logical_and": [[1271, "torch-logical-and"]], "torch.linalg.solve": [[1250, "torch-linalg-solve"]], "torch.linalg.lu_factor_ex": [[1238, "torch-linalg-lu-factor-ex"]], "torch.linalg.eig": [[1225, "torch-linalg-eig"]], "torch.logcumsumexp": [[1269, "torch-logcumsumexp"]], "torch.logical_not": [[1272, "torch-logical-not"]], "torch.linalg.householder_product": [[1229, "torch-linalg-householder-product"]], "torch.load": [[1261, "torch-load"]], "torch.logaddexp": [[1267, "torch-logaddexp"]], "torch.linalg.norm": [[1246, "torch-linalg-norm"]], "torch.linalg.ldl_factor": [[1232, "torch-linalg-ldl-factor"]], "torch.log2": [[1266, "torch-log2"]], "torch.linalg.ldl_factor_ex": [[1233, "torch-linalg-ldl-factor-ex"]], "torch.linalg.solve_triangular": [[1252, "torch-linalg-solve-triangular"]], "torch.linalg.inv": [[1230, "torch-linalg-inv"]], "torch.logaddexp2": [[1268, "torch-logaddexp2"]], "torch.linalg.lu": [[1236, "torch-linalg-lu"]], "torch.linalg.lstsq": [[1235, "torch-linalg-lstsq"]], "torch.linalg.lu_factor": [[1237, "torch-linalg-lu-factor"]], "torch.linalg.vander": [[1257, "torch-linalg-vander"]], "torch.linspace": [[1260, "torch-linspace"]], "torch.linalg.svd": [[1253, "torch-linalg-svd"]], "torch.logdet": [[1270, "torch-logdet"]], "torch.log1p": [[1265, "torch-log1p"]], "torch.linalg.tensorsolve": [[1256, "torch-linalg-tensorsolve"]], "torch.linalg.eigvalsh": [[1228, "torch-linalg-eigvalsh"]], "torch.linalg.vecdot": [[1258, "torch-linalg-vecdot"]], "torch.log": [[1263, "torch-log"]], "torch.linalg.ldl_solve": [[1234, "torch-linalg-ldl-solve"]], "torch.logical_or": [[1273, "torch-logical-or"]], "torch.linalg.solve_ex": [[1251, "torch-linalg-solve-ex"]], "torch.linalg.lu_solve": [[1239, "torch-linalg-lu-solve"]], "torch.linalg.matrix_power": [[1243, "torch-linalg-matrix-power"]], "torch.linalg.svdvals": [[1254, "torch-linalg-svdvals"]], "torch.linalg.matrix_exp": [[1241, "torch-linalg-matrix-exp"]], "torch.linalg.eigvals": [[1227, "torch-linalg-eigvals"]], "torch.linalg.pinv": [[1247, "torch-linalg-pinv"]], "torch.gather": [[1132, "torch-gather"]], "torch.heaviside": [[1149, "torch-heaviside"]], "torch.inner": [[1167, "torch-inner"]], "torch.get_default_dtype": [[1137, "torch-get-default-dtype"]], "torch.hamming_window": [[1147, "torch-hamming-window"]], "torch.func.vmap": [[1131, "torch-func-vmap"]], "torch.get_num_threads": [[1141, "torch-get-num-threads"]], "torch.histc": [[1150, "torch-histc"]], "torch.func.stack_module_state": [[1129, "torch-func-stack-module-state"]], "torch.greater": [[1144, "torch-greater"]], "torch.ge": [[1134, "torch-ge"]], "torch.histogramdd": [[1152, "torch-histogramdd"]], "inference_mode": [[1165, "inference-mode"]], "torch.is_inference_mode_enabled": [[1174, "torch-is-inference-mode-enabled"]], "torch.greater_equal": [[1145, "torch-greater-equal"]], "torch.gradient": [[1143, "torch-gradient"]], "torch.hstack": [[1155, "torch-hstack"]], "torch.get_num_interop_threads": [[1140, "torch-get-num-interop-threads"]], "torch.is_complex": [[1169, "torch-is-complex"]], "torch.ger": [[1136, "torch-ger"]], "torch.gt": [[1146, "torch-gt"]], "torch.imag": [[1160, "torch-imag"]], "torch.igamma": [[1158, "torch-igamma"]], "torch.is_grad_enabled": [[1173, "torch-is-grad-enabled"]], "torch.histogram": [[1151, "torch-histogram"]], "torch.hspmm": [[1154, "torch-hspmm"]], "torch.index_reduce": [[1163, "torch-index-reduce"]], "torch.is_nonzero": [[1175, "torch-is-nonzero"]], "torch.geqrf": [[1135, "torch-geqrf"]], "torch.i0": [[1157, "torch-i0"]], "torch.func.linearize": [[1127, "torch-func-linearize"]], "torch.is_conj": [[1170, "torch-is-conj"]], "torch.get_deterministic_debug_mode": [[1138, "torch-get-deterministic-debug-mode"]], "torch.igammac": [[1159, "torch-igammac"]], "torch.hsplit": [[1153, "torch-hsplit"]], "torch.func.replace_all_batch_norm_modules_": [[1128, "torch-func-replace-all-batch-norm-modules"]], "torch.hann_window": [[1148, "torch-hann-window"]], "torch.hypot": [[1156, "torch-hypot"]], "torch.index_select": [[1164, "torch-index-select"]], "torch.inverse": [[1168, "torch-inverse"]], "torch.is_floating_point": [[1172, "torch-is-floating-point"]], "torch.index_add": [[1161, "torch-index-add"]], "torch.get_rng_state": [[1142, "torch-get-rng-state"]], "torch.func.vjp": [[1130, "torch-func-vjp"]], "torch.initial_seed": [[1166, "torch-initial-seed"]], "torch.gcd": [[1133, "torch-gcd"]], "torch.index_copy": [[1162, "torch-index-copy"]], "torch.is_deterministic_algorithms_warn_only_enabled": [[1171, "torch-is-deterministic-algorithms-warn-only-enabled"]], "torch.get_float32_matmul_precision": [[1139, "torch-get-float32-matmul-precision"]], "torch.cuda.stream": [[1038, "torch-cuda-stream"]], "torch.cuda.set_device": [[1032, "torch-cuda-set-device"]], "torch.dequantize": [[1048, "torch-dequantize"]], "torch.empty_strided": [[1066, "torch-empty-strided"]], "torch.expm1": [[1075, "torch-expm1"]], "torch.cuda.seed_all": [[1031, "torch-cuda-seed-all"]], "torch.cuda.set_sync_debug_mode": [[1037, "torch-cuda-set-sync-debug-mode"]], "torch.erfinv": [[1072, "torch-erfinv"]], "torch.diff": [[1055, "torch-diff"]], "torch.diagflat": [[1052, "torch-diagflat"]], "torch.cuda.set_rng_state_all": [[1035, "torch-cuda-set-rng-state-all"]], "torch.dstack": [[1062, "torch-dstack"]], "torch.cumprod": [[1044, "torch-cumprod"]], "torch.cumulative_trapezoid": [[1046, "torch-cumulative-trapezoid"]], "torch.cuda.reset_peak_memory_stats": [[1029, "torch-cuda-reset-peak-memory-stats"]], "torch.cuda.synchronize": [[1039, "torch-cuda-synchronize"]], "torch.det": [[1049, "torch-det"]], "torch.cumsum": [[1045, "torch-cumsum"]], "torch.dot": [[1060, "torch-dot"]], "torch.erf": [[1070, "torch-erf"]], "torch.deg2rad": [[1047, "torch-deg2rad"]], "torch.exp": [[1073, "torch-exp"]], "torch.cummin": [[1043, "torch-cummin"]], "torch.div": [[1058, "torch-div"]], "torch.empty": [[1064, "torch-empty"]], "torch.cuda.seed": [[1030, "torch-cuda-seed"]], "torch.cummax": [[1042, "torch-cummax"]], "torch.diag": [[1050, "torch-diag"]], "torch.cuda.utilization": [[1041, "torch-cuda-utilization"]], "torch.diagonal_scatter": [[1054, "torch-diagonal-scatter"]], "torch.empty_like": [[1065, "torch-empty-like"]], "torch.equal": [[1069, "torch-equal"]], "torch.eq": [[1068, "torch-eq"]], "torch.digamma": [[1056, "torch-digamma"]], "torch.eye": [[1076, "torch-eye"]], "torch.cuda.temperature": [[1040, "torch-cuda-temperature"]], "torch.dsplit": [[1061, "torch-dsplit"]], "torch.cuda.set_stream": [[1036, "torch-cuda-set-stream"]], "enable_grad": [[1067, "enable-grad"]], "torch.exp2": [[1074, "torch-exp2"]], "torch.dist": [[1057, "torch-dist"]], "torch.fake_quantize_per_channel_affine": [[1077, "torch-fake-quantize-per-channel-affine"]], "torch.einsum": [[1063, "torch-einsum"]], "torch.diag_embed": [[1051, "torch-diag-embed"]], "torch.divide": [[1059, "torch-divide"]], "torch.erfc": [[1071, "torch-erfc"]], "torch.diagonal": [[1053, "torch-diagonal"]], "torch.cuda.set_rng_state": [[1034, "torch-cuda-set-rng-state"]], "torch.cuda.set_per_process_memory_fraction": [[1033, "torch-cuda-set-per-process-memory-fraction"]], "torch.isin": [[1181, "torch-isin"]], "torch.jit.ignore": [[1195, "torch-jit-ignore"]], "torch.is_storage": [[1176, "torch-is-storage"]], "torch.linalg.cholesky_ex": [[1220, "torch-linalg-cholesky-ex"]], "torch.isneginf": [[1184, "torch-isneginf"]], "torch.jit.freeze": [[1194, "torch-jit-freeze"]], "torch.isnan": [[1183, "torch-isnan"]], "torch.jit.isinstance": [[1196, "torch-jit-isinstance"]], "torch.jit.save": [[1200, "torch-jit-save"]], "torch.ldexp": [[1213, "torch-ldexp"]], "torch.isfinite": [[1180, "torch-isfinite"]], "torch.is_tensor": [[1177, "torch-is-tensor"]], "torch.lerp": [[1215, "torch-lerp"]], "ScriptModule": [[1190, "scriptmodule"]], "strict_fusion": [[1204, "strict-fusion"]], "torch.jit.script_if_tracing": [[1202, "torch-jit-script-if-tracing"]], "torch.jit.onednn_fusion_enabled": [[1198, "torch-jit-onednn-fusion-enabled"]], "torch.jit.trace": [[1205, "torch-jit-trace"]], "torch.jit.wait": [[1208, "torch-jit-wait"]], "torch.jit.unused": [[1207, "torch-jit-unused"]], "torch.lgamma": [[1218, "torch-lgamma"]], "torch.linalg.diagonal": [[1224, "torch-linalg-diagonal"]], "torch.le": [[1214, "torch-le"]], "torch.jit.enable_onednn_fusion": [[1192, "torch-jit-enable-onednn-fusion"]], "torch.jit.trace_module": [[1206, "torch-jit-trace-module"]], "torch.linalg.cond": [[1221, "torch-linalg-cond"]], "torch.linalg.cholesky": [[1219, "torch-linalg-cholesky"]], "torch.jit.script": [[1201, "torch-jit-script"]], "ScriptFunction": [[1189, "scriptfunction"]], "torch.jit.set_fusion_strategy": [[1203, "torch-jit-set-fusion-strategy"]], "torch.isposinf": [[1185, "torch-isposinf"]], "torch.jit.load": [[1197, "torch-jit-load"]], "torch.less": [[1216, "torch-less"]], "torch.jit.annotate": [[1191, "torch-jit-annotate"]], "torch.jit.fork": [[1193, "torch-jit-fork"]], "torch.is_warn_always_enabled": [[1178, "torch-is-warn-always-enabled"]], "torch.less_equal": [[1217, "torch-less-equal"]], "torch.isclose": [[1179, "torch-isclose"]], "torch.kthvalue": [[1211, "torch-kthvalue"]], "torch.linalg.det": [[1223, "torch-linalg-det"]], "torch.jit.optimize_for_inference": [[1199, "torch-jit-optimize-for-inference"]], "Attribute": [[1188, "attribute"]], "torch.kron": [[1210, "torch-kron"]], "torch.lcm": [[1212, "torch-lcm"]], "torch.linalg.cross": [[1222, "torch-linalg-cross"]], "torch.isreal": [[1186, "torch-isreal"]], "torch.isinf": [[1182, "torch-isinf"]], "torch.kaiser_window": [[1209, "torch-kaiser-window"]], "torch.istft": [[1187, "torch-istft"]], "torch.fft.ihfft": [[1091, "torch-fft-ihfft"]], "torch.frombuffer": [[1116, "torch-frombuffer"]], "torch.fft.irfft": [[1094, "torch-fft-irfft"]], "torch.from_dlpack": [[1114, "torch-from-dlpack"]], "torch.float_power": [[1106, "torch-float-power"]], "torch.func.jacfwd": [[1124, "torch-func-jacfwd"]], "torch.fft.rfftn": [[1100, "torch-fft-rfftn"]], "torch.fft.hfftn": [[1086, "torch-fft-hfftn"]], "torch.fft.fftn": [[1082, "torch-fft-fftn"]], "torch.fft.ifftn": [[1089, "torch-fft-ifftn"]], "torch.fft.ifft": [[1087, "torch-fft-ifft"]], "torch.func.functional_call": [[1119, "torch-func-functional-call"]], "torch.func.hessian": [[1123, "torch-func-hessian"]], "torch.flipud": [[1105, "torch-flipud"]], "torch.fft.rfftfreq": [[1099, "torch-fft-rfftfreq"]], "torch.fft.fftfreq": [[1081, "torch-fft-fftfreq"]], "torch.func.grad_and_value": [[1122, "torch-func-grad-and-value"]], "torch.fft.hfft2": [[1085, "torch-fft-hfft2"]], "torch.fft.fft": [[1079, "torch-fft-fft"]], "torch.fft.ifftshift": [[1090, "torch-fft-ifftshift"]], "torch.frac": [[1112, "torch-frac"]], "torch.from_numpy": [[1115, "torch-from-numpy"]], "torch.frexp": [[1113, "torch-frexp"]], "torch.floor": [[1107, "torch-floor"]], "torch.fmin": [[1110, "torch-fmin"]], "torch.func.functionalize": [[1120, "torch-func-functionalize"]], "torch.fmax": [[1109, "torch-fmax"]], "torch.fake_quantize_per_tensor_affine": [[1078, "torch-fake-quantize-per-tensor-affine"]], "torch.fft.fftshift": [[1083, "torch-fft-fftshift"]], "torch.fft.rfft": [[1097, "torch-fft-rfft"]], "torch.floor_divide": [[1108, "torch-floor-divide"]], "torch.fft.ifft2": [[1088, "torch-fft-ifft2"]], "torch.flatten": [[1102, "torch-flatten"]], "torch.full": [[1117, "torch-full"]], "torch.func.jacrev": [[1125, "torch-func-jacrev"]], "torch.fmod": [[1111, "torch-fmod"]], "torch.fft.irfft2": [[1095, "torch-fft-irfft2"]], "torch.full_like": [[1118, "torch-full-like"]], "torch.func.grad": [[1121, "torch-func-grad"]], "torch.fft.irfftn": [[1096, "torch-fft-irfftn"]], "torch.fliplr": [[1104, "torch-fliplr"]], "torch.flip": [[1103, "torch-flip"]], "torch.fix": [[1101, "torch-fix"]], "torch.fft.fft2": [[1080, "torch-fft-fft2"]], "torch.fft.hfft": [[1084, "torch-fft-hfft"]], "torch.fft.ihfft2": [[1092, "torch-fft-ihfft2"]], "torch.func.jvp": [[1126, "torch-func-jvp"]], "torch.fft.ihfftn": [[1093, "torch-fft-ihfftn"]], "torch.fft.rfft2": [[1098, "torch-fft-rfft2"]], "Fake tensor": [[16, "fake-tensor"]], "Motivation": [[16, "motivation"], [15, "motivation"], [1870, "motivation"]], "Related work": [[16, "related-work"]], "Overall architecture": [[16, "overall-architecture"], [15, "overall-architecture"]], "API: the important bits": [[16, "api-the-important-bits"]], "Details": [[16, "details"]], "About the tensor subclass": [[16, "about-the-tensor-subclass"]], "How is each individual operator implemented?": [[16, "how-is-each-individual-operator-implemented"]], "How does the converter work?": [[16, "how-does-the-converter-work"]], "Performance characteristics": [[16, "performance-characteristics"]], "Fake tensor of fake tensor?": [[16, "fake-tensor-of-fake-tensor"]], "Interaction with dynamic shapes": [[16, "interaction-with-dynamic-shapes"]], "Other resources": [[16, "other-resources"]], "Getting Started": [[20, "getting-started"], [8, "getting-started"]], "Existing Backends": [[20, "existing-backends"]], "Why do you need another way of optimizing PyTorch code?": [[20, "why-do-you-need-another-way-of-optimizing-pytorch-code"]], "DDP Communication Hooks": [[39, "ddp-communication-hooks"]], "How to Use a Communication Hook?": [[39, "how-to-use-a-communication-hook"]], "What Does a Communication Hook Operate On?": [[39, "what-does-a-communication-hook-operate-on"]], "Default Communication Hooks": [[39, "default-communication-hooks"]], "PowerSGD Communication Hook": [[39, "powersgd-communication-hook"]], "PowerSGD State": [[39, "powersgd-state"]], "PowerSGD Hooks": [[39, "powersgd-hooks"]], "Debugging Communication Hooks": [[39, "debugging-communication-hooks"]], "Checkpointing of Communication Hooks": [[39, "checkpointing-of-communication-hooks"]], "Acknowledgements": [[39, "acknowledgements"], [1906, "acknowledgements"]], "Distributed communication package - torch.distributed": [[41, "distributed-communication-package-torch-distributed"]], "Backends": [[41, "backends"], [1913, "backends"]], "Backends that come with PyTorch": [[41, "backends-that-come-with-pytorch"]], "Which backend to use?": [[41, "which-backend-to-use"]], "Common environment variables": [[41, "common-environment-variables"]], "Choosing the network interface to use": [[41, "choosing-the-network-interface-to-use"]], "Other NCCL environment variables": [[41, "other-nccl-environment-variables"]], "Basics": [[41, "basics"], [1913, "basics"]], "Initialization": [[41, "initialization"]], "TCP initialization": [[41, "tcp-initialization"]], "Shared file-system initialization": [[41, "shared-file-system-initialization"]], "Environment variable initialization": [[41, "environment-variable-initialization"]], "Post-Initialization": [[41, "post-initialization"]], "Distributed Key-Value Store": [[41, "distributed-key-value-store"]], "Groups": [[41, "groups"]], "Point-to-point communication": [[41, "point-to-point-communication"]], "Synchronous and asynchronous collective operations": [[41, "synchronous-and-asynchronous-collective-operations"]], "Collective functions": [[41, "collective-functions"]], "Profiling Collective Communication": [[41, "profiling-collective-communication"]], "Multi-GPU collective functions": [[41, "multi-gpu-collective-functions"]], "Third-party backends": [[41, "third-party-backends"]], "Launch utility": [[41, "launch-utility"]], "Spawn utility": [[41, "spawn-utility"]], "Debugging torch.distributed applications": [[41, "debugging-torch-distributed-applications"]], "Monitored Barrier": [[41, "monitored-barrier"]], "TORCH_DISTRIBUTED_DEBUG": [[41, "torch-distributed-debug"]], "Logging": [[41, "logging"]], "TorchDynamo APIs to control fine-grained tracing": [[18, "torchdynamo-apis-to-control-fine-grained-tracing"], [18, "id7"]], "Section 1 - Summary Table": [[18, "section-1-summary-table"]], "Section 2 - torch._dynamo.disable": [[18, "section-2-torch-dynamo-disable"]], "Section 3 - torch._dynamo.disallow_in_graph": [[18, "section-3-torch-dynamo-disallow-in-graph"]], "Section 4 - torch._dynamo.disallow_in_graph": [[18, "section-4-torch-dynamo-disallow-in-graph"]], "Section 5 - Limitations": [[18, "section-5-limitations"]], "Section 6 - FAQ": [[18, "section-6-faq"]], "Tensor Parallelism - torch.distributed.tensor.parallel": [[46, "tensor-parallelism-torch-distributed-tensor-parallel"]], "torch._dynamo": [[0, "torch-dynamo"]], "TorchInductor GPU Profiling": [[23, "torchinductor-gpu-profiling"]], "Relevant Environment Variables": [[23, "relevant-environment-variables"]], "Breakdown Model GPU Time": [[23, "breakdown-model-gpu-time"]], "Benchmark Individual Triton Kernel": [[23, "benchmark-individual-triton-kernel"]], "Torch Distributed Elastic": [[44, "torch-distributed-elastic"]], "Get Started": [[44, "get-started"]], "Documentation": [[44, "documentation"]], "API": [[44, null]], "Advanced": [[44, null]], "Plugins": [[44, null]], "PyTorch Governance | Build + CI": [[7, "pytorch-governance-build-ci"]], "How to Add a New Maintainer": [[7, "how-to-add-a-new-maintainer"]], "Distributed Checkpoint - torch.distributed.checkpoint": [[43, "distributed-checkpoint-torch-distributed-checkpoint"]], "Distributed Optimizers": [[45, "distributed-optimizers"]], "Custom Backends": [[13, "custom-backends"]], "Registering Custom Backends": [[13, "registering-custom-backends"]], "Custom Backends after AOTAutograd": [[13, "custom-backends-after-aotautograd"]], "Debugging Backend": [[13, "debugging-backend"]], "Speedy Backend": [[13, "speedy-backend"]], "Composable Backends": [[13, "composable-backends"]], "torch.utils.dlpack": [[48, "torch-utils-dlpack"]], "Optimizations": [[22, "optimizations"], [1925, "optimizations"]], "Troubleshooting and Gotchas": [[22, "troubleshooting-and-gotchas"]], "Learn more": [[22, "learn-more"]], "CUDA Stream Sanitizer": [[35, "cuda-stream-sanitizer"]], "PyTorch Contribution Guide": [[8, "pytorch-contribution-guide"]], "Contribution Process": [[8, "contribution-process"]], "Proposing New Features": [[8, "proposing-new-features"]], "Reporting Issues": [[8, "reporting-issues"]], "Implementing Features or Fixing Bugs": [[8, "implementing-features-or-fixing-bugs"]], "Adding Tutorials": [[8, "adding-tutorials"]], "Improving Documentation & Tutorials": [[8, "improving-documentation-tutorials"]], "Participating in Online Discussions": [[8, "participating-in-online-discussions"]], "Submitting Pull Requests to Fix Open Issues": [[8, "submitting-pull-requests-to-fix-open-issues"]], "Reviewing Open Pull Requests": [[8, "reviewing-open-pull-requests"]], "Improving Code Readability": [[8, "improving-code-readability"]], "Adding Test Cases to Make the Codebase More Robust": [[8, "adding-test-cases-to-make-the-codebase-more-robust"]], "Promoting PyTorch": [[8, "promoting-pytorch"]], "Triaging Issues": [[8, "triaging-issues"]], "About Open Source Development": [[8, "about-open-source-development"]], "Common Mistakes To Avoid": [[8, "common-mistakes-to-avoid"]], "On Documentation": [[8, "on-documentation"]], "Python Docs": [[8, "python-docs"]], "C++ Docs": [[8, "c-docs"]], "Tutorials": [[8, "tutorials"], [1905, "tutorials"], [1906, "tutorials"], [1913, "tutorials"]], "Tutorials Build Overview": [[8, "tutorials-build-overview"]], "Contributing a New Tutorial": [[8, "contributing-a-new-tutorial"]], "torch.utils.data": [[38, "module-torch.utils.data"]], "Dataset Types": [[38, "dataset-types"]], "Map-style datasets": [[38, "map-style-datasets"]], "Iterable-style datasets": [[38, "iterable-style-datasets"]], "Data Loading Order and Sampler": [[38, "data-loading-order-and-sampler"]], "Loading Batched and Non-Batched Data": [[38, "loading-batched-and-non-batched-data"]], "Automatic batching (default)": [[38, "automatic-batching-default"]], "Disable automatic batching": [[38, "disable-automatic-batching"]], "Working with collate_fn": [[38, "working-with-collate-fn"]], "Single- and Multi-process Data Loading": [[38, "single-and-multi-process-data-loading"]], "Single-process data loading (default)": [[38, "single-process-data-loading-default"]], "Multi-process data loading": [[38, "multi-process-data-loading"]], "Platform-specific behaviors": [[38, "platform-specific-behaviors"]], "Randomness in multi-process data loading": [[38, "randomness-in-multi-process-data-loading"]], "Memory Pinning": [[38, "memory-pinning"]], "torch.__config__": [[31, "module-torch.__config__"]], "TorchDynamo Deeper Dive": [[14, "torchdynamo-deeper-dive"]], "What is a guard?": [[14, "what-is-a-guard"]], "What is Dynamo doing?": [[14, "what-is-dynamo-doing"]], "Probability distributions - torch.distributions": [[47, "module-torch.distributions"]], "Score function": [[47, "score-function"]], "Pathwise derivative": [[47, "pathwise-derivative"]], "Distribution": [[47, "distribution"]], "ExponentialFamily": [[47, "exponentialfamily"]], "Bernoulli": [[47, "bernoulli"]], "Beta": [[47, "beta"]], "Binomial": [[47, "binomial"]], "Categorical": [[47, "categorical"]], "Cauchy": [[47, "cauchy"]], "Chi2": [[47, "chi2"]], "ContinuousBernoulli": [[47, "continuousbernoulli"]], "Dirichlet": [[47, "dirichlet"]], "Exponential": [[47, "exponential"]], "FisherSnedecor": [[47, "fishersnedecor"]], "Gamma": [[47, "gamma"]], "Geometric": [[47, "geometric"]], "Gumbel": [[47, "gumbel"]], "HalfCauchy": [[47, "halfcauchy"]], "HalfNormal": [[47, "halfnormal"]], "Independent": [[47, "independent"]], "Kumaraswamy": [[47, "kumaraswamy"]], "LKJCholesky": [[47, "lkjcholesky"]], "Laplace": [[47, "laplace"]], "LogNormal": [[47, "lognormal"]], "LowRankMultivariateNormal": [[47, "lowrankmultivariatenormal"]], "MixtureSameFamily": [[47, "mixturesamefamily"]], "Multinomial": [[47, "multinomial"]], "MultivariateNormal": [[47, "multivariatenormal"]], "NegativeBinomial": [[47, "negativebinomial"]], "Normal": [[47, "normal"]], "OneHotCategorical": [[47, "onehotcategorical"]], "Pareto": [[47, "pareto"]], "Poisson": [[47, "poisson"]], "RelaxedBernoulli": [[47, "relaxedbernoulli"]], "LogitRelaxedBernoulli": [[47, "logitrelaxedbernoulli"]], "RelaxedOneHotCategorical": [[47, "relaxedonehotcategorical"]], "StudentT": [[47, "studentt"]], "TransformedDistribution": [[47, "transformeddistribution"]], "Uniform": [[47, "uniform"]], "VonMises": [[47, "vonmises"]], "Weibull": [[47, "weibull"]], "Wishart": [[47, "wishart"]], "KL Divergence": [[47, "module-torch.distributions.kl"]], "Transforms": [[47, "module-torch.distributions.transforms"]], "Constraints": [[47, "module-torch.distributions.constraints"], [1886, "constraints"]], "Constraint Registry": [[47, "module-torch.distributions.constraint_registry"]], "torch.backends": [[3, "module-torch.backends"]], "torch.backends.cpu": [[3, "module-torch.backends.cpu"]], "torch.backends.cuda": [[3, "module-torch.backends.cuda"]], "torch.backends.cudnn": [[3, "module-torch.backends.cudnn"]], "torch.backends.mps": [[3, "module-torch.backends.mps"]], "torch.backends.mkl": [[3, "module-torch.backends.mkl"]], "torch.backends.mkldnn": [[3, "module-torch.backends.mkldnn"]], "torch.backends.openmp": [[3, "module-torch.backends.openmp"]], "torch.backends.opt_einsum": [[3, "module-torch.backends.opt_einsum"]], "torch.backends.xeon": [[3, "module-torch.backends.xeon"]], "torch::deploy has been moved to pytorch/multipy": [[40, "torch-deploy-has-been-moved-to-pytorch-multipy"]], "PyTorch Governance | Maintainers": [[11, "pytorch-governance-maintainers"]], "Responsibilities": [[11, "responsibilities"]], "Lead Core Maintainer (BDFL)": [[11, "lead-core-maintainer-bdfl"], [10, "lead-core-maintainer-bdfl"]], "Core Maintainers": [[11, "core-maintainers"], [10, "core-maintainers"]], "Module-level maintainers": [[11, "module-level-maintainers"]], "NN APIs (torch.nn)": [[11, "nn-apis-torch-nn"]], "Optimizers (torch.optim)": [[11, "optimizers-torch-optim"]], "Autograd (torch.autograd)": [[11, "autograd-torch-autograd"]], "Compilers (JIT / TorchScript / FX / TorchDynamo)": [[11, "compilers-jit-torchscript-fx-torchdynamo"]], "Distributions & RNG": [[11, "distributions-rng"]], "Distributed": [[11, "distributed"]], "Multiprocessing and DataLoaders": [[11, "multiprocessing-and-dataloaders"]], "Linear Algebra (torch.linalg)": [[11, "linear-algebra-torch-linalg"]], "Sparse (torch.sparse)": [[11, "sparse-torch-sparse"]], "NestedTensor (torch.nested)": [[11, "nestedtensor-torch-nested"]], "MaskedTensor (torch.masked)": [[11, "maskedtensor-torch-masked"]], "Fast Fourier Transform (torch.fft)": [[11, "fast-fourier-transform-torch-fft"]], "CPU Performance (Torch Inductor / MKLDNN)": [[11, "cpu-performance-torch-inductor-mkldnn"]], "GPU Performance (Torch Inductor / Triton / CUDA)": [[11, "gpu-performance-torch-inductor-triton-cuda"]], "NVFuser": [[11, "nvfuser"]], "AMD/ROCm/HIP": [[11, "amd-rocm-hip"]], "Build + CI": [[11, "build-ci"]], "Performance Tools": [[11, "performance-tools"]], "C++ API": [[11, "c-api"]], "C10 utils and operator dispatch": [[11, "c10-utils-and-operator-dispatch"]], "ONNX exporter": [[11, "onnx-exporter"]], "Mobile / Edge": [[11, "mobile-edge"]], "Model Compression & Optimization": [[11, "model-compression-optimization"]], "Windows": [[11, "windows"]], "Apple M1/MPS": [[11, "apple-m1-mps"]], "PowerPC": [[11, "powerpc"]], "Docs / Tutorials": [[11, "docs-tutorials"]], "Library-level maintainers": [[11, "library-level-maintainers"]], "XLA": [[11, "xla"]], "TorchServe": [[11, "torchserve"]], "TorchVision": [[11, "torchvision"]], "TorchText": [[11, "torchtext"]], "TorchAudio": [[11, "torchaudio"]], "TorchRec": [[11, "torchrec"]], "TorchX": [[11, "torchx"]], "TorchData / TorchArrow": [[11, "torchdata-torcharrow"]], "Guards Overview": [[21, "guards-overview"]], "Caching and Guards Overview": [[21, "caching-and-guards-overview"]], "Python Frame Evaluation and PEP 523": [[21, "python-frame-evaluation-and-pep-523"]], "InstructionTranslator": [[21, "instructiontranslator"]], "Making Guards": [[21, "making-guards"]], "Summary": [[21, "summary"], [10, "summary"]], "CUDAGraph Trees": [[12, "cudagraph-trees"]], "CUDAGraph Background": [[12, "cudagraph-background"]], "PyTorch CUDAGraph Integration": [[12, "pytorch-cudagraph-integration"]], "Make Graphed Callables": [[12, "make-graphed-callables"]], "TorchDynamo Previous CUDA Graphs Integration": [[12, "torchdynamo-previous-cuda-graphs-integration"]], "CUDAGraph Trees Integration": [[12, "cudagraph-trees-integration"]], "Limitations": [[12, "limitations"], [1901, "limitations"]], "Comparisons": [[12, "comparisons"], [1863, "comparisons"]], "Writing Graph Transformations on ATen IR": [[28, "writing-graph-transformations-on-aten-ir"]], "Passes": [[28, "passes"]], "One-to-One Pass": [[28, "one-to-one-pass"]], "One-to-X Pass": [[28, "one-to-x-pass"]], "One-to-None Pass": [[28, "one-to-none-pass"]], "Utilizing Local Information": [[28, "utilizing-local-information"]], "Subgraph Rewriter": [[28, "subgraph-rewriter"]], "Pass Manager": [[28, "pass-manager"]], "Partitioner": [[28, "partitioner"]], "Subgraph Matcher": [[28, "subgraph-matcher"]], "Capability Based Partitioner": [[28, "capability-based-partitioner"]], "Complex Numbers": [[30, "complex-numbers"]], "Creating Complex Tensors": [[30, "creating-complex-tensors"]], "Transition from the old representation": [[30, "transition-from-the-old-representation"]], "Accessing real and imag": [[30, "accessing-real-and-imag"]], "Angle and abs": [[30, "angle-and-abs"]], "Linear Algebra": [[30, "linear-algebra"]], "Serialization": [[30, "serialization"], [1925, "serialization"]], "Autograd": [[30, "autograd"]], "Generic Join Context Manager": [[42, "generic-join-context-manager"]], "torch.func interaction with torch.compile": [[27, "torch-func-interaction-with-torch-compile"]], "Applying a torch.func transform to a torch.compile\u2019d function": [[27, "applying-a-torch-func-transform-to-a-torch-compile-d-function"]], "Doesn\u2019t work (PT 2.0): calling a torch.func transform inside of a torch.compile\u2019ed function": [[27, "doesn-t-work-pt-2-0-calling-a-torch-func-transform-inside-of-a-torch-compile-ed-function"]], "Workaround: use torch._dynamo.allow_in_graph": [[27, "workaround-use-torch-dynamo-allow-in-graph"]], "Dynamic shapes": [[15, "dynamic-shapes"]], "Abridged public API": [[15, "abridged-public-api"]], "The Guard Model": [[15, "the-guard-model"]], "Abridged internal API": [[15, "abridged-internal-api"]], "DimDynamic policy": [[15, "dimdynamic-policy"]], "Unbacked SymInts": [[15, "unbacked-symints"]], "PyTorch 2.0 Troubleshooting": [[29, "pytorch-2-0-troubleshooting"]], "Title": [[29, "id1"]], "Diagnosing Runtime Errors": [[29, "diagnosing-runtime-errors"]], "Torchdynamo Errors": [[29, "torchdynamo-errors"]], "TorchInductor Errors": [[29, "torchinductor-errors"], [17, "torchinductor-errors"]], "Minifying TorchInductor Errors": [[29, "minifying-torchinductor-errors"]], "Minifying Backend Compiler Errors": [[29, "minifying-backend-compiler-errors"]], "Performance Profiling": [[29, "performance-profiling"]], "Accessing TorchDynamo Profiler": [[29, "accessing-torchdynamo-profiler"]], "TorchInductor Debugging using TORCH_COMPILE_DEBUG": [[29, "torchinductor-debugging-using-torch-compile-debug"]], "Graph Breaks": [[29, "graph-breaks"], [17, "graph-breaks"]], "Identifying the Cause of a Graph Break": [[29, "identifying-the-cause-of-a-graph-break"]], "Excessive Recompilation": [[29, "excessive-recompilation"], [17, "excessive-recompilation"]], "Accuracy Debugging": [[29, "accuracy-debugging"]], "File an Issue": [[29, "file-an-issue"]], "C++": [[33, "c"]], "TorchScript C++ API": [[33, "torchscript-c-api"]], "Extending PyTorch and TorchScript with C++ Extensions": [[33, "extending-pytorch-and-torchscript-with-c-extensions"]], "Tensor and Autograd in C++": [[33, "tensor-and-autograd-in-c"]], "Authoring Models in C++": [[33, "authoring-models-in-c"]], "Packaging for C++": [[33, "packaging-for-c"]], "Automatic Mixed Precision package - torch.amp": [[1, "automatic-mixed-precision-package-torch-amp"]], "Autocasting": [[1, "autocasting"]], "Gradient Scaling": [[1, "gradient-scaling"]], "Autocast Op Reference": [[1, "autocast-op-reference"]], "Op Eligibility": [[1, "op-eligibility"]], "CUDA Op-Specific Behavior": [[1, "cuda-op-specific-behavior"]], "CUDA Ops that can autocast to float16": [[1, "cuda-ops-that-can-autocast-to-float16"]], "CUDA Ops that can autocast to float32": [[1, "cuda-ops-that-can-autocast-to-float32"]], "CUDA Ops that promote to the widest input type": [[1, "cuda-ops-that-promote-to-the-widest-input-type"]], "Prefer binary_cross_entropy_with_logits over binary_cross_entropy": [[1, "prefer-binary-cross-entropy-with-logits-over-binary-cross-entropy"]], "CPU Op-Specific Behavior": [[1, "cpu-op-specific-behavior"]], "CPU Ops that can autocast to bfloat16": [[1, "cpu-ops-that-can-autocast-to-bfloat16"]], "CPU Ops that can autocast to float32": [[1, "cpu-ops-that-can-autocast-to-float32"]], "CPU Ops that promote to the widest input type": [[1, "cpu-ops-that-promote-to-the-widest-input-type"]], "Benchmark Utils - torch.utils.benchmark": [[4, "module-torch.utils.benchmark"]], "PyTorch Design Philosophy": [[9, "pytorch-design-philosophy"]], "Design Principles": [[9, "design-principles"]], "Principle 1: Usability over Performance": [[9, "principle-1-usability-over-performance"]], "Principle 2: Simple Over Easy": [[9, "principle-2-simple-over-easy"]], "Principle 3: Python First with Best In Class Language Interoperability": [[9, "principle-3-python-first-with-best-in-class-language-interoperability"]], "torch.cuda": [[34, "module-torch.cuda"]], "Random Number Generator": [[34, "random-number-generator"]], "Communication collectives": [[34, "communication-collectives"]], "Streams and events": [[34, "streams-and-events"]], "Graphs (beta)": [[34, "graphs-beta"]], "Memory management": [[34, "memory-management"], [1892, "memory-management"], [1886, "memory-management"]], "NVIDIA Tools Extension (NVTX)": [[34, "nvidia-tools-extension-nvtx"]], "Jiterator (beta)": [[34, "jiterator-beta"]], "Stream Sanitizer (prototype)": [[34, "stream-sanitizer-prototype"]], "torch.utils.bottleneck": [[5, "module-torch.utils.bottleneck"]], "torch.utils.cpp_extension": [[32, "torch-utils-cpp-extension"]], "torch.utils.checkpoint": [[6, "torch-utils-checkpoint"]], "PyTorch Governance | Mechanics": [[10, "pytorch-governance-mechanics"]], "Module Maintainers": [[10, "module-maintainers"]], "Nominating, Confirming and Removing Maintainers": [[10, "nominating-confirming-and-removing-maintainers"]], "The Principles": [[10, "the-principles"]], "The Process for Nomination": [[10, "the-process-for-nomination"]], "The Process for Removal": [[10, "the-process-for-removal"]], "Nominating Core Maintainers": [[10, "nominating-core-maintainers"]], "Removing the Lead Core Maintainer and Nominating a New Lead Core Maintainer": [[10, "removing-the-lead-core-maintainer-and-nominating-a-new-lead-core-maintainer"]], "Add, Remove, and Re-Scope Modules and Projects": [[10, "add-remove-and-re-scope-modules-and-projects"]], "Decision Making": [[10, "decision-making"]], "Uncontroversial Changes": [[10, "uncontroversial-changes"]], "Controversial Decision Process": [[10, "controversial-decision-process"]], "General Project Policies": [[10, "general-project-policies"]], "FAQ": [[10, "faq"]], "PyTorch 2.0 Performance Dashboard": [[25, "pytorch-2-0-performance-dashboard"]], "How to read the dashboard?": [[25, "how-to-read-the-dashboard"]], "What is measured on the dashboard?": [[25, "what-is-measured-on-the-dashboard"]], "Can I check if my PR affects TorchInductor\u2019s performance on the dashboard before merging?": [[25, "can-i-check-if-my-pr-affects-torchinductor-s-performance-on-the-dashboard-before-merging"]], "How can I run any performance test locally?": [[25, "how-can-i-run-any-performance-test-locally"]], "Automatic differentiation package - torch.autograd": [[2, "module-torch.autograd"]], "Forward-mode Automatic Differentiation": [[2, "forward-mode-automatic-differentiation"]], "Functional higher level API": [[2, "functional-higher-level-api"]], "Locally disabling gradient computation": [[2, "locally-disabling-gradient-computation"], [1883, "locally-disabling-gradient-computation"], [1925, "locally-disabling-gradient-computation"]], "Default gradient layouts": [[2, "default-gradient-layouts"]], "Manual gradient layouts": [[2, "manual-gradient-layouts"]], "In-place operations on Tensors": [[2, "in-place-operations-on-tensors"]], "In-place correctness checks": [[2, "in-place-correctness-checks"], [1883, "in-place-correctness-checks"]], "Variable (deprecated)": [[2, "variable-deprecated"]], "Tensor autograd functions": [[2, "tensor-autograd-functions"]], "Function": [[2, "function"]], "Context method mixins": [[2, "context-method-mixins"]], "Numerical gradient checking": [[2, "numerical-gradient-checking"]], "Profiler": [[2, "profiler"]], "Anomaly detection": [[2, "anomaly-detection"]], "Autograd graph": [[2, "autograd-graph"]], "Do you support Distributed code?": [[17, "do-you-support-distributed-code"]], "Do I still need to export whole graphs?": [[17, "do-i-still-need-to-export-whole-graphs"]], "Why is my code crashing?": [[17, "why-is-my-code-crashing"]], "TorchDynamo Errors": [[17, "torchdynamo-errors"]], "Why is compilation slow?": [[17, "why-is-compilation-slow"]], "Dynamo Compilation": [[17, "dynamo-compilation"]], "Inductor Compilation": [[17, "inductor-compilation"]], "Why are you recompiling in production?": [[17, "why-are-you-recompiling-in-production"]], "How are you speeding up my code?": [[17, "how-are-you-speeding-up-my-code"]], "Why am I not seeing speedups?": [[17, "why-am-i-not-seeing-speedups"]], "Identifying the cause of a graph break": [[17, "identifying-the-cause-of-a-graph-break"]], "Why didn\u2019t my code recompile when I changed it?": [[17, "why-didnt-my-code-recompile-when-i-changed-it"]], "Why am I getting incorrect results?": [[17, "why-am-i-getting-incorrect-results"]], "Why am I getting OOMs?": [[17, "why-am-i-getting-ooms"]], "PyTorch 2.0 NNModule Support": [[24, "pytorch-2-0-nnmodule-support"]], "NNModule Hooks Support": [[24, "nnmodule-hooks-support"]], "nn.Module.__call__ Hooks Usage and limitations": [[24, "nn-module-call-hooks-usage-and-limitations"]], "state_dict Hooks": [[24, "state-dict-hooks"]], "Technical Overview": [[26, "technical-overview"]], "My model reports \u201ccuda runtime error(2): out of memory\u201d": [[1890, "my-model-reports-cuda-runtime-error-2-out-of-memory"]], "My GPU memory isn\u2019t freed properly": [[1890, "my-gpu-memory-isn-t-freed-properly"]], "My out of memory exception handler can\u2019t allocate memory": [[1890, "my-out-of-memory-exception-handler-can-t-allocate-memory"]], "My data loader workers return identical random numbers": [[1890, "my-data-loader-workers-return-identical-random-numbers"]], "My recurrent network doesn\u2019t work with data parallelism": [[1890, "my-recurrent-network-doesn-t-work-with-data-parallelism"]], "torch.package": [[1905, "torch-package"]], "Packaging your first model": [[1905, "packaging-your-first-model"]], "How do I\u2026": [[1905, "how-do-i"]], "See what is inside a package?": [[1905, "see-what-is-inside-a-package"]], "Treat the package like a ZIP archive": [[1905, "treat-the-package-like-a-zip-archive"]], "Use the file_structure() API": [[1905, "use-the-file-structure-api"]], "See why a given module was included as a dependency?": [[1905, "see-why-a-given-module-was-included-as-a-dependency"]], "Include arbitrary resources with my package and access them later?": [[1905, "include-arbitrary-resources-with-my-package-and-access-them-later"]], "Customize how a class is packaged?": [[1905, "customize-how-a-class-is-packaged"]], "Test in my source code whether or not it is executing inside a package?": [[1905, "test-in-my-source-code-whether-or-not-it-is-executing-inside-a-package"]], "Patch code into a package?": [[1905, "patch-code-into-a-package"]], "Access package contents from packaged code?": [[1905, "access-package-contents-from-packaged-code"]], "Distinguish between packaged code and non-packaged code?": [[1905, "distinguish-between-packaged-code-and-non-packaged-code"]], "Re-export an imported object?": [[1905, "re-export-an-imported-object"]], "Package a TorchScript module?": [[1905, "package-a-torchscript-module"]], "Explanation": [[1905, "explanation"]], "torch.package Format Overview": [[1905, "torch-package-format-overview"]], "Framework files": [[1905, "framework-files"]], "User files": [[1905, "user-files"]], "How torch.package finds your code\u2019s dependencies": [[1905, "how-torch-package-finds-your-code-s-dependencies"]], "Analyzing an object\u2019s dependencies": [[1905, "analyzing-an-object-s-dependencies"]], "Analyzing a module\u2019s dependencies": [[1905, "analyzing-a-module-s-dependencies"]], "Dependency Management": [[1905, "dependency-management"]], "intern": [[1905, "intern"]], "extern": [[1905, "extern"]], "mock": [[1905, "mock"]], "Refactoring": [[1905, "refactoring"]], "Patterns": [[1905, "patterns"]], "torch.package sharp edges": [[1905, "torch-package-sharp-edges"]], "Avoid global state in your modules": [[1905, "avoid-global-state-in-your-modules"]], "Types are not shared between packages and the loading environment": [[1905, "types-are-not-shared-between-packages-and-the-loading-environment"]], "How torch.package keeps packages isolated from each other": [[1905, "how-torch-package-keeps-packages-isolated-from-each-other"]], "Mangling": [[1905, "mangling"]], "Named Tensors operator coverage": [[1876, "named-tensors-operator-coverage"]], "Supported Operations": [[1876, "id1"]], "Keeps input names": [[1876, "keeps-input-names"]], "Removes dimensions": [[1876, "removes-dimensions"]], "Unifies names from inputs": [[1876, "unifies-names-from-inputs"]], "Permutes dimensions": [[1876, "permutes-dimensions"]], "Contracts away dims": [[1876, "contracts-away-dims"]], "Factory functions": [[1876, "factory-functions"]], "out function and in-place variants": [[1876, "out-function-and-in-place-variants"]], "Extending torch.func with autograd.Function": [[1889, "extending-torch-func-with-autograd-function"]], "Basic Usage": [[1889, "basic-usage"]], "Example 1: autograd.Function calls into another system": [[1889, "example-1-autograd-function-calls-into-another-system"]], "Example 2: autograd.Function specifies custom gradient rules": [[1889, "example-2-autograd-function-specifies-custom-gradient-rules"]], "Limitations and gotchas": [[1889, "limitations-and-gotchas"]], "torch.vmap() Support": [[1889, "torch-vmap-support"]], "Automatically generate a vmap rule": [[1889, "automatically-generate-a-vmap-rule"]], "Defining the vmap staticmethod": [[1889, "defining-the-vmap-staticmethod"]], "torch.func.jvp() Support": [[1889, "torch-func-jvp-support"]], "Numerical accuracy": [[1897, "numerical-accuracy"]], "Batched computations or slice computations": [[1897, "batched-computations-or-slice-computations"]], "Extremal values": [[1897, "extremal-values"]], "Linear algebra (torch.linalg)": [[1897, "linear-algebra-torch-linalg"]], "Non-finite values": [[1897, "non-finite-values"]], "Extremal values in linalg": [[1897, "extremal-values-in-linalg"]], "TensorFloat-32(TF32) on Nvidia Ampere devices": [[1897, "tensorfloat-32-tf32-on-nvidia-ampere-devices"]], "Reduced Precision Reduction for FP16  and BF16 GEMMs": [[1897, "reduced-precision-reduction-for-fp16-and-bf16-gemms"]], "Reduced Precision FP16 and BF16 GEMMs and Convolutions on AMD Instinct MI200 devices": [[1897, "reduced-precision-fp16-and-bf16-gemms-and-convolutions-on-amd-instinct-mi200-devices"]], "Features for large-scale deployments": [[1893, "features-for-large-scale-deployments"]], "Fleet-wide operator profiling": [[1893, "fleet-wide-operator-profiling"]], "API usage logging": [[1893, "api-usage-logging"]], "Attaching metadata to saved TorchScript models": [[1893, "attaching-metadata-to-saved-torchscript-models"]], "Build environment considerations": [[1893, "build-environment-considerations"]], "Common extension points": [[1893, "common-extension-points"]], "ONNX supported TorchScript operators": [[1903, "onnx-supported-torchscript-operators"]], "Supported operators": [[1903, "supported-operators"]], "ONNX support for TorchScript operators": [[1903, "id1"]], "Unsupported operators": [[1903, "unsupported-operators"], [1903, "id2"]], "torch.library": [[1867, "torch-library"]], "Quantization": [[1908, "module-torch.ao.quantization"]], "Introduction to Quantization": [[1908, "introduction-to-quantization"]], "Quantization API Summary": [[1908, "quantization-api-summary"]], "Eager Mode Quantization": [[1908, "eager-mode-quantization"]], "Post Training Dynamic Quantization": [[1908, "post-training-dynamic-quantization"]], "Post Training Static Quantization": [[1908, "post-training-static-quantization"]], "Quantization Aware Training for Static Quantization": [[1908, "quantization-aware-training-for-static-quantization"]], "Model Preparation for Eager Mode Static Quantization": [[1908, "model-preparation-for-eager-mode-static-quantization"]], "(Prototype) FX Graph Mode Quantization": [[1908, "prototype-fx-graph-mode-quantization"]], "Quantization Stack": [[1908, "quantization-stack"]], "Quantized Model": [[1908, "quantized-model"]], "Quantized Tensor": [[1908, "quantized-tensor"]], "Quantize and Dequantize": [[1908, "quantize-and-dequantize"]], "Quantized Operators/Modules": [[1908, "quantized-operators-modules"]], "Quantized Engine": [[1908, "quantized-engine"]], "Quantization Flow": [[1908, "quantization-flow"]], "Observer and FakeQuantize": [[1908, "observer-and-fakequantize"]], "QConfig": [[1908, "qconfig"], [838, "qconfig"]], "General Quantization Flow": [[1908, "general-quantization-flow"]], "Quantization Support Matrix": [[1908, "quantization-support-matrix"]], "Quantization Mode Support": [[1908, "quantization-mode-support"]], "Quantization Flow Support": [[1908, "quantization-flow-support"]], "Backend/Hardware Support": [[1908, "backend-hardware-support"]], "Note for native CPU backends": [[1908, "note-for-native-cpu-backends"]], "Operator Support": [[1908, "operator-support"]], "Quantization API Reference": [[1908, "quantization-api-reference"], [1911, "quantization-api-reference"]], "Quantization Backend Configuration": [[1908, "quantization-backend-configuration"], [1910, "quantization-backend-configuration"]], "Quantization Accuracy Debugging": [[1908, "quantization-accuracy-debugging"], [1909, "quantization-accuracy-debugging"]], "Quantization Customizations": [[1908, "quantization-customizations"]], "Quantization Custom Module API": [[1908, "quantization-custom-module-api"]], "Best Practices": [[1908, "best-practices"]], "Common Errors": [[1908, "common-errors"]], "Passing a non-quantized Tensor into a quantized kernel": [[1908, "passing-a-non-quantized-tensor-into-a-quantized-kernel"]], "Passing a quantized Tensor into a non-quantized kernel": [[1908, "passing-a-quantized-tensor-into-a-non-quantized-kernel"]], "Saving and Loading Quantized models": [[1908, "saving-and-loading-quantized-models"]], "Symbolic Trace Error when using FX Graph Mode Quantization": [[1908, "symbolic-trace-error-when-using-fx-graph-mode-quantization"]], "Default values for native configurations": [[1910, "default-values-for-native-configurations"]], "Multiprocessing best practices": [[1896, "multiprocessing-best-practices"]], "CUDA in multiprocessing": [[1896, "cuda-in-multiprocessing"]], "Best practices and tips": [[1896, "best-practices-and-tips"]], "Avoiding and fighting deadlocks": [[1896, "avoiding-and-fighting-deadlocks"]], "Reuse buffers passed through a Queue": [[1896, "reuse-buffers-passed-through-a-queue"]], "Asynchronous multiprocess training (e.g. Hogwild)": [[1896, "asynchronous-multiprocess-training-e-g-hogwild"]], "Hogwild": [[1896, "hogwild"]], "torch.monitor": [[1873, "torch-monitor"]], "Data insensitive error": [[1909, "data-insensitive-error"]], "General tips": [[1909, "general-tips"]], "Int8 quantization tips": [[1909, "int8-quantization-tips"]], "Data sensitive error": [[1909, "data-sensitive-error"]], "Implementation error": [[1909, "implementation-error"]], "Numerical Debugging Tooling (prototype)": [[1909, "numerical-debugging-tooling-prototype"]], "CUDA Automatic Mixed Precision examples": [[1882, "cuda-automatic-mixed-precision-examples"]], "Typical Mixed Precision Training": [[1882, "typical-mixed-precision-training"]], "Working with Unscaled Gradients": [[1882, "working-with-unscaled-gradients"]], "Gradient clipping": [[1882, "gradient-clipping"]], "Working with Scaled Gradients": [[1882, "working-with-scaled-gradients"]], "Gradient accumulation": [[1882, "gradient-accumulation"]], "Gradient penalty": [[1882, "gradient-penalty"]], "Working with Multiple Models, Losses, and Optimizers": [[1882, "working-with-multiple-models-losses-and-optimizers"]], "Working with Multiple GPUs": [[1882, "working-with-multiple-gpus"]], "DataParallel in a single process": [[1882, "dataparallel-in-a-single-process"]], "DistributedDataParallel, one GPU per process": [[1882, "distributeddataparallel-one-gpu-per-process"]], "DistributedDataParallel, multiple GPUs per process": [[1882, "distributeddataparallel-multiple-gpus-per-process"]], "Autocast and Custom Autograd Functions": [[1882, "autocast-and-custom-autograd-functions"]], "Functions with multiple inputs or autocastable ops": [[1882, "functions-with-multiple-inputs-or-autocastable-ops"]], "Functions that need a particular dtype": [[1882, "functions-that-need-a-particular-dtype"]], "Serialization semantics": [[1899, "serialization-semantics"]], "Table of Contents": [[1899, "table-of-contents"]], "Saving and loading tensors": [[1899, "saving-and-loading-tensors"]], "Saving and loading tensors preserves views": [[1899, "saving-and-loading-tensors-preserves-views"]], "Saving and loading torch.nn.Modules": [[1899, "saving-and-loading-torch-nn-modules"]], "Serializing torch.nn.Modules and loading them in C++": [[1899, "serializing-torch-nn-modules-and-loading-them-in-c"]], "Saving and loading ScriptModules across PyTorch versions": [[1899, "saving-and-loading-scriptmodules-across-pytorch-versions"]], "torch.div performing integer division": [[1899, "torch-div-performing-integer-division"]], "torch.full always inferring a float dtype": [[1899, "torch-full-always-inferring-a-float-dtype"]], "torch.onnx": [[1901, "torch-onnx"]], "Example: AlexNet from PyTorch to ONNX": [[1901, "example-alexnet-from-pytorch-to-onnx"]], "Tracing vs Scripting": [[1901, "tracing-vs-scripting"]], "Avoiding Pitfalls": [[1901, "avoiding-pitfalls"]], "Avoid NumPy and built-in Python types": [[1901, "avoid-numpy-and-built-in-python-types"]], "Avoid Tensor.data": [[1901, "avoid-tensor-data"]], "Avoid in-place operations when using tensor.shape in tracing mode": [[1901, "avoid-in-place-operations-when-using-tensor-shape-in-tracing-mode"]], "Types": [[1901, "types"], [1862, "supported-type"]], "Differences in Operator Implementations": [[1901, "differences-in-operator-implementations"]], "Unsupported Tensor Indexing Patterns": [[1901, "unsupported-tensor-indexing-patterns"]], "Reads / Gets": [[1901, "reads-gets"]], "Writes / Sets": [[1901, "writes-sets"]], "Adding support for operators": [[1901, "adding-support-for-operators"]], "ONNX exporter internals": [[1901, "onnx-exporter-internals"]], "ATen operators": [[1901, "aten-operators"]], "List of supported operators": [[1901, "list-of-supported-operators"]], "Adding support for an aten or quantized operator": [[1901, "adding-support-for-an-aten-or-quantized-operator"]], "torch.autograd.Functions": [[1901, "torch-autograd-functions"]], "Static Symbolic Method": [[1901, "static-symbolic-method"]], "Inline Autograd Function": [[1901, "inline-autograd-function"]], "Custom operators": [[1901, "custom-operators"]], "ONNX-script functions": [[1901, "onnx-script-functions"]], "C++ Operators": [[1901, "c-operators"]], "Discovering all unconvertible ATen ops at once": [[1901, "discovering-all-unconvertible-aten-ops-at-once"]], "Contributing / developing": [[1901, "contributing-developing"]], "Classes": [[1901, "classes"]], "Preview: torch.onnx TorchDynamo Exporter": [[1901, "preview-torch-onnx-torchdynamo-exporter"]], "A Simple Custom Module": [[1894, "a-simple-custom-module"]], "Modules as Building Blocks": [[1894, "modules-as-building-blocks"]], "Neural Network Training with Modules": [[1894, "neural-network-training-with-modules"]], "Module State": [[1894, "module-state"]], "Module Initialization": [[1894, "module-initialization"]], "Module Hooks": [[1894, "module-hooks"]], "Advanced Features": [[1894, "advanced-features"]], "Distributed Training": [[1894, "distributed-training"]], "Profiling Performance": [[1894, "profiling-performance"]], "Improving Performance with Quantization": [[1894, "improving-performance-with-quantization"]], "Improving Memory Usage with Pruning": [[1894, "improving-memory-usage-with-pruning"]], "Parametrizations": [[1894, "parametrizations"]], "Transforming Modules with FX": [[1894, "transforming-modules-with-fx"]], "torch.utils.model_zoo": [[1872, "torch-utils-model-zoo"]], "Named Tensors": [[1877, "named-tensors"]], "Creating named tensors": [[1877, "creating-named-tensors"]], "Named dimensions": [[1877, "named-dimensions"]], "Name propagation semantics": [[1877, "name-propagation-semantics"]], "match semantics": [[1877, "match-semantics"]], "Basic name inference rules": [[1877, "basic-name-inference-rules"]], "Explicit alignment by names": [[1877, "explicit-alignment-by-names"]], "Manipulating dimensions": [[1877, "manipulating-dimensions"]], "Autograd support": [[1877, "autograd-support"]], "Currently supported operations and subsystems": [[1877, "currently-supported-operations-and-subsystems"]], "Operators": [[1877, "operators"]], "Subsystems": [[1877, "subsystems"]], "Named tensor API reference": [[1877, "named-tensor-api-reference"]], "Windows FAQ": [[1900, "windows-faq"]], "Building from source": [[1900, "building-from-source"]], "Include optional components": [[1900, "include-optional-components"]], "Speeding CUDA build for Windows": [[1900, "speeding-cuda-build-for-windows"]], "One key install script": [[1900, "one-key-install-script"]], "Extension": [[1900, "extension"]], "CFFI Extension": [[1900, "cffi-extension"]], "Cpp Extension": [[1900, "cpp-extension"]], "Installation": [[1900, "installation"]], "Package not found in win-32 channel.": [[1900, "package-not-found-in-win-32-channel"]], "Import error": [[1900, "import-error"]], "Usage (multiprocessing)": [[1900, "usage-multiprocessing"]], "Multiprocessing error without if-clause protection": [[1900, "multiprocessing-error-without-if-clause-protection"]], "Multiprocessing error \u201cBroken pipe\u201d": [[1900, "multiprocessing-error-broken-pipe"]], "Multiprocessing error \u201cdriver shut down\u201d": [[1900, "multiprocessing-error-driver-shut-down"]], "CUDA IPC operations": [[1900, "cuda-ipc-operations"]], "torch.optim": [[1904, "module-torch.optim"]], "How to use an optimizer": [[1904, "how-to-use-an-optimizer"]], "Constructing it": [[1904, "constructing-it"]], "Per-parameter options": [[1904, "per-parameter-options"]], "Taking an optimization step": [[1904, "taking-an-optimization-step"]], "optimizer.step()": [[1904, "optimizer-step"]], "optimizer.step(closure)": [[1904, "optimizer-step-closure"]], "Base class": [[1904, "base-class"]], "Algorithms": [[1904, "algorithms"]], "How to adjust learning rate": [[1904, "how-to-adjust-learning-rate"]], "Weight Averaging (SWA and EMA)": [[1904, "weight-averaging-swa-and-ema"]], "Constructing averaged models": [[1904, "constructing-averaged-models"]], "Custom averaging strategies": [[1904, "custom-averaging-strategies"]], "SWA learning rate schedules": [[1904, "swa-learning-rate-schedules"]], "Taking care of batch normalization": [[1904, "taking-care-of-batch-normalization"]], "Putting it all together: SWA": [[1904, "putting-it-all-together-swa"]], "Putting it all together: EMA": [[1904, "putting-it-all-together-ema"]], "torch.masked": [[1870, "torch-masked"]], "What is a MaskedTensor?": [[1870, "what-is-a-maskedtensor"]], "Supported Operators": [[1870, "supported-operators"]], "Unary Operators": [[1870, "unary-operators"]], "Binary Operators": [[1870, "binary-operators"]], "Reductions": [[1870, "reductions"]], "View and select functions": [[1870, "view-and-select-functions"]], "Autograd mechanics": [[1883, "autograd-mechanics"]], "How autograd encodes the history": [[1883, "how-autograd-encodes-the-history"]], "Saved tensors": [[1883, "saved-tensors"]], "Gradients for non-differentiable functions": [[1883, "gradients-for-non-differentiable-functions"]], "Setting requires_grad": [[1883, "setting-requires-grad"]], "Grad Modes": [[1883, "grad-modes"]], "Default Mode (Grad Mode)": [[1883, "default-mode-grad-mode"]], "No-grad Mode": [[1883, "no-grad-mode"]], "Inference Mode": [[1883, "inference-mode"]], "Evaluation Mode (nn.Module.eval())": [[1883, "evaluation-mode-nn-module-eval"]], "In-place operations with autograd": [[1883, "in-place-operations-with-autograd"]], "Multithreaded Autograd": [[1883, "multithreaded-autograd"]], "Concurrency on CPU": [[1883, "concurrency-on-cpu"]], "Non-determinism": [[1883, "non-determinism"]], "Graph retaining": [[1883, "graph-retaining"]], "Thread Safety on Autograd Node": [[1883, "thread-safety-on-autograd-node"]], "No thread safety on C++ hooks": [[1883, "no-thread-safety-on-c-hooks"]], "Autograd for Complex Numbers": [[1883, "autograd-for-complex-numbers"]], "What are complex derivatives?": [[1883, "what-are-complex-derivatives"]], "Wirtinger Calculus comes into the picture \u2026": [[1883, "wirtinger-calculus-comes-into-the-picture"]], "How is Wirtinger Calculus useful in optimization?": [[1883, "how-is-wirtinger-calculus-useful-in-optimization"]], "How does PyTorch compute the conjugate Wirtinger derivative?": [[1883, "how-does-pytorch-compute-the-conjugate-wirtinger-derivative"]], "How can I write my own derivative formula for a complex function?": [[1883, "how-can-i-write-my-own-derivative-formula-for-a-complex-function"]], "What about cross-domain functions?": [[1883, "what-about-cross-domain-functions"]], "Hooks for saved tensors": [[1883, "hooks-for-saved-tensors"]], "Registering hooks for a saved tensor": [[1883, "registering-hooks-for-a-saved-tensor"]], "Registering default hooks for saved tensors": [[1883, "registering-default-hooks-for-saved-tensors"]], "Backward Hooks execution": [[1883, "backward-hooks-execution"]], "Whether a particular hook will be fired": [[1883, "whether-a-particular-hook-will-be-fired"]], "The order in which the different hooks are fired": [[1883, "the-order-in-which-the-different-hooks-are-fired"]], "Special hooks": [[1883, "special-hooks"]], "Behavior of Tensor hooks when Tensor is modified in-place": [[1883, "behavior-of-tensor-hooks-when-tensor-is-modified-in-place"]], "Gradcheck mechanics": [[1891, "gradcheck-mechanics"]], "Notations and background information": [[1891, "notations-and-background-information"]], "Default backward mode gradcheck behavior": [[1891, "default-backward-mode-gradcheck-behavior"]], "Real-to-real functions": [[1891, "real-to-real-functions"]], "Default real input numerical evaluation": [[1891, "default-real-input-numerical-evaluation"]], "Default real input analytical evaluation": [[1891, "default-real-input-analytical-evaluation"]], "Complex-to-real functions": [[1891, "complex-to-real-functions"]], "Default complex input numerical evaluation": [[1891, "default-complex-input-numerical-evaluation"]], "Default complex input analytical evaluation": [[1891, "default-complex-input-analytical-evaluation"]], "Functions with complex outputs": [[1891, "functions-with-complex-outputs"]], "Fast backward mode gradcheck": [[1891, "fast-backward-mode-gradcheck"]], "Fast gradcheck for real-to-real functions": [[1891, "fast-gradcheck-for-real-to-real-functions"]], "Fast gradcheck for complex-to-real functions": [[1891, "fast-gradcheck-for-complex-to-real-functions"]], "Fast complex input numerical evaluation": [[1891, "fast-complex-input-numerical-evaluation"]], "Fast complex input analytical evaluation": [[1891, "fast-complex-input-analytical-evaluation"]], "Why not use a complex u": [[1891, "why-not-use-a-complex-u"]], "Fast gradcheck for functions with complex outputs": [[1891, "fast-gradcheck-for-functions-with-complex-outputs"]], "Gradgradcheck implementation": [[1891, "gradgradcheck-implementation"]], "HIP (ROCm) semantics": [[1892, "hip-rocm-semantics"]], "HIP Interfaces Reuse the CUDA Interfaces": [[1892, "hip-interfaces-reuse-the-cuda-interfaces"]], "Checking for HIP": [[1892, "checking-for-hip"]], "TensorFloat-32(TF32) on ROCm": [[1892, "tensorfloat-32-tf32-on-rocm"]], "hipFFT/rocFFT plan cache": [[1892, "hipfft-rocfft-plan-cache"]], "torch.distributed backends": [[1892, "torch-distributed-backends"]], "CUDA API to HIP API mappings in C++": [[1892, "cuda-api-to-hip-api-mappings-in-c"]], "Refer to CUDA Semantics doc": [[1892, "refer-to-cuda-semantics-doc"]], "Enabling kernel asserts": [[1892, "enabling-kernel-asserts"]], "torch.linalg": [[1868, "torch-linalg"]], "Matrix Properties": [[1868, "matrix-properties"]], "Decompositions": [[1868, "decompositions"]], "Solvers": [[1868, "solvers"]], "Inverses": [[1868, "inverses"]], "Matrix Functions": [[1868, "matrix-functions"]], "Matrix Products": [[1868, "matrix-products"]], "Tensor Operations": [[1868, "tensor-operations"]], "Misc": [[1868, "misc"]], "Experimental Functions": [[1868, "experimental-functions"]], "torch.profiler": [[1907, "torch-profiler"]], "Intel Instrumentation and Tracing Technology APIs": [[1907, "intel-instrumentation-and-tracing-technology-apis"]], "Distributed Data Parallel": [[1887, "distributed-data-parallel"]], "Example": [[1887, "example"], [1888, "example"]], "Internal Design": [[1887, "internal-design"]], "Implementation": [[1887, "implementation"], [1915, "implementation"]], "ProcessGroup": [[1887, "processgroup"]], "TorchDynamo DDPOptimizer": [[1887, "id1"]], "MPS backend": [[1895, "mps-backend"]], "torch._logging": [[1869, "torch-logging"]], "torch.mps": [[1874, "module-torch.mps"]], "MPS Profiler": [[1874, "mps-profiler"]], "Reproducibility": [[1898, "reproducibility"]], "Controlling sources of randomness": [[1898, "controlling-sources-of-randomness"]], "PyTorch random number generator": [[1898, "pytorch-random-number-generator"]], "Python": [[1898, "python"]], "Random number generators in other libraries": [[1898, "random-number-generators-in-other-libraries"]], "CUDA convolution benchmarking": [[1898, "cuda-convolution-benchmarking"]], "Avoiding nondeterministic algorithms": [[1898, "avoiding-nondeterministic-algorithms"]], "CUDA convolution determinism": [[1898, "cuda-convolution-determinism"]], "CUDA RNN and LSTM": [[1898, "cuda-rnn-and-lstm"]], "DataLoader": [[1898, "dataloader"]], "Python Language Reference Coverage": [[1864, "python-language-reference-coverage"]], "Multiprocessing package - torch.multiprocessing": [[1875, "module-torch.multiprocessing"]], "Strategy management": [[1875, "strategy-management"]], "Sharing CUDA tensors": [[1875, "sharing-cuda-tensors"]], "Sharing strategies": [[1875, "sharing-strategies"]], "File descriptor - file_descriptor": [[1875, "file-descriptor-file-descriptor"]], "File system - file_system": [[1875, "file-system-file-system"]], "Spawning subprocesses": [[1875, "spawning-subprocesses"]], "Extending PyTorch": [[1888, "extending-pytorch"]], "Extending torch.autograd": [[1888, "extending-torch-autograd"]], "When to use": [[1888, "when-to-use"]], "When not to use": [[1888, "when-not-to-use"]], "How to use": [[1888, "how-to-use"]], "Combined or separate forward() and setup_context()": [[1888, "combined-or-separate-forward-and-setup-context"]], "Forward mode AD": [[1888, "forward-mode-ad"]], "torch.func transforms and/or torch.vmap()": [[1888, "torch-func-transforms-and-or-torch-vmap"]], "Extending torch.nn": [[1888, "extending-torch-nn"]], "Adding a Module": [[1888, "adding-a-module"]], "Extending torch": [[1888, "extending-torch"]], "Extending torch with a Tensor-like type": [[1888, "extending-torch-with-a-tensor-like-type"]], "Subclassing torch.Tensor": [[1888, "subclassing-torch-tensor"]], "Extending torch with a Tensor wrapper type": [[1888, "extending-torch-with-a-tensor-wrapper-type"]], "Operations on multiple types that define __torch_function__": [[1888, "operations-on-multiple-types-that-define-torch-function"]], "Testing Coverage of Overrides for the PyTorch API": [[1888, "testing-coverage-of-overrides-for-the-pytorch-api"]], "Writing custom C++ extensions": [[1888, "writing-custom-c-extensions"]], "Writing custom C extensions": [[1888, "id2"]], "TorchScript Unsupported PyTorch Constructs": [[1865, "torchscript-unsupported-pytorch-constructs"]], "Torch and Tensor Unsupported Attributes": [[1865, "torch-and-tensor-unsupported-attributes"]], "Unsupported Tensor Methods": [[1865, "unsupported-tensor-methods"]], "Unsupported Tensor Properties": [[1865, "unsupported-tensor-properties"]], "Functions Not Correctly Bound on Torch": [[1865, "functions-not-correctly-bound-on-torch"]], "Ops With Divergent Schemas Between Torch & Python": [[1865, "ops-with-divergent-schemas-between-torch-python"]], "PyTorch Unsupported Modules and Classes": [[1865, "pytorch-unsupported-modules-and-classes"]], "Pipeline Parallelism": [[1906, "pipeline-parallelism"]], "Model Parallelism using multiple GPUs": [[1906, "model-parallelism-using-multiple-gpus"]], "Pipelined Execution": [[1906, "pipelined-execution"]], "Pipe APIs in PyTorch": [[1906, "pipe-apis-in-pytorch"]], "Skip connections": [[1906, "skip-connections"]], "torch.nested": [[1878, "module-torch.nested"]], "Construction": [[1878, "construction"], [1917, "construction"]], "size": [[1878, "size"]], "unbind": [[1878, "unbind"]], "Nested tensor constructor and conversion functions": [[1878, "nested-tensor-constructor-and-conversion-functions"]], "Supported operations": [[1878, "supported-operations"], [1917, "supported-operations"]], "CPU threading and TorchScript inference": [[1885, "cpu-threading-and-torchscript-inference"]], "Build options": [[1885, "build-options"]], "Runtime API": [[1885, "runtime-api"]], "Tuning the number of threads": [[1885, "tuning-the-number-of-threads"]], "torch.nn": [[1879, "module-torch.nn"], [1879, "id1"]], "Containers": [[1879, "containers"]], "Convolution Layers": [[1879, "convolution-layers"]], "Pooling layers": [[1879, "pooling-layers"]], "Padding Layers": [[1879, "padding-layers"]], "Non-linear Activations (weighted sum, nonlinearity)": [[1879, "non-linear-activations-weighted-sum-nonlinearity"]], "Non-linear Activations (other)": [[1879, "non-linear-activations-other"]], "Normalization Layers": [[1879, "normalization-layers"]], "Recurrent Layers": [[1879, "recurrent-layers"]], "Transformer Layers": [[1879, "transformer-layers"]], "Linear Layers": [[1879, "linear-layers"]], "Dropout Layers": [[1879, "dropout-layers"]], "Sparse Layers": [[1879, "sparse-layers"]], "Distance Functions": [[1879, "distance-functions"]], "Loss Functions": [[1879, "loss-functions"]], "Vision Layers": [[1879, "vision-layers"]], "Shuffle Layers": [[1879, "shuffle-layers"]], "DataParallel Layers (multi-GPU, distributed)": [[1879, "module-torch.nn.parallel"]], "Utilities": [[1879, "module-torch.nn.utils"], [1925, "utilities"]], "Quantized Functions": [[1879, "quantized-functions"]], "Lazy Modules Initialization": [[1879, "lazy-modules-initialization"]], "Broadcasting semantics": [[1884, "broadcasting-semantics"]], "General semantics": [[1884, "general-semantics"]], "In-place semantics": [[1884, "in-place-semantics"]], "Backwards compatibility": [[1884, "backwards-compatibility"]], "CUDA semantics": [[1886, "cuda-semantics"]], "TensorFloat-32(TF32) on Ampere devices": [[1886, "tensorfloat-32-tf32-on-ampere-devices"]], "Reduced Precision Reduction in FP16 GEMMs": [[1886, "reduced-precision-reduction-in-fp16-gemms"]], "Reduced Precision Reduction in BF16 GEMMs": [[1886, "reduced-precision-reduction-in-bf16-gemms"]], "Asynchronous execution": [[1886, "asynchronous-execution"]], "CUDA streams": [[1886, "cuda-streams"]], "Stream semantics of backward passes": [[1886, "stream-semantics-of-backward-passes"]], "BC note: Using grads on the default stream": [[1886, "bc-note-using-grads-on-the-default-stream"]], "Environment variables": [[1886, "environment-variables"]], "Using custom memory allocators for CUDA": [[1886, "using-custom-memory-allocators-for-cuda"]], "cuBLAS workspaces": [[1886, "cublas-workspaces"]], "cuFFT plan cache": [[1886, "cufft-plan-cache"]], "Just-in-Time Compilation": [[1886, "just-in-time-compilation"]], "Best practices": [[1886, "best-practices"]], "Device-agnostic code": [[1886, "device-agnostic-code"]], "Use pinned memory buffers": [[1886, "use-pinned-memory-buffers"]], "Use nn.parallel.DistributedDataParallel instead of multiprocessing or nn.DataParallel": [[1886, "use-nn-parallel-distributeddataparallel-instead-of-multiprocessing-or-nn-dataparallel"]], "CUDA Graphs": [[1886, "cuda-graphs"]], "Why CUDA Graphs?": [[1886, "why-cuda-graphs"]], "PyTorch API": [[1886, "pytorch-api"]], "Non-constraints": [[1886, "non-constraints"]], "Whole-network capture": [[1886, "whole-network-capture"]], "Partial-network capture": [[1886, "partial-network-capture"]], "Usage with torch.cuda.amp": [[1886, "usage-with-torch-cuda-amp"]], "Usage with multiple streams": [[1886, "usage-with-multiple-streams"]], "Usage with DistributedDataParallel": [[1886, "usage-with-distributeddataparallel"]], "NCCL < 2.9.6": [[1886, "nccl-2-9-6"]], "NCCL >= 2.9.6": [[1886, "id5"]], "Graph memory management": [[1886, "graph-memory-management"]], "Sharing memory across captures": [[1886, "sharing-memory-across-captures"]], "torch.onnx diagnostics": [[1902, "torch-onnx-diagnostics"]], "Diagnostic Rules": [[1902, "diagnostic-rules"]], "torch.nn.init": [[1881, "torch-nn-init"]], "TorchScript Language Reference": [[1862, "torchscript-language-reference"], [1863, "torchscript-language-reference"]], "Unsupported Typing Constructs": [[1862, "unsupported-typing-constructs"], [1863, "unsupported-typing-constructs"]], "Default Types": [[1862, "default-types"]], "Optional Type Refinement": [[1862, "optional-type-refinement"]], "TorchScript Enums": [[1862, "id4"]], "Named Tuples": [[1862, "named-tuples"]], "Iterables": [[1862, "iterables"]], "Expressions": [[1862, "expressions"], [1863, "expressions"]], "Literals": [[1862, "literals"], [1863, "literals"]], "List Construction": [[1862, "list-construction"]], "Tuple Construction": [[1862, "tuple-construction"]], "Dict Construction": [[1862, "dict-construction"]], "Arithmetic Operators": [[1862, "arithmetic-operators"]], "Comparison Operators": [[1862, "comparison-operators"]], "Logical Operators": [[1862, "logical-operators"]], "Subscripts and Slicing": [[1862, "subscripts-and-slicing"]], "Function Calls": [[1862, "function-calls"]], "Method Calls": [[1862, "method-calls"]], "Ternary Expressions": [[1862, "ternary-expressions"]], "Casts": [[1862, "casts"]], "Accessing Module Parameters": [[1862, "accessing-module-parameters"]], "Statements": [[1862, "statements"]], "Simple Assignments": [[1862, "simple-assignments"]], "Pattern Matching Assignments": [[1862, "pattern-matching-assignments"]], "Print Statements": [[1862, "print-statements"]], "If Statements": [[1862, "if-statements"]], "While Loops": [[1862, "while-loops"]], "For loops with range": [[1862, "for-loops-with-range"]], "For loops over tuples": [[1862, "for-loops-over-tuples"]], "For loops over constant nn.ModuleList": [[1862, "for-loops-over-constant-nn-modulelist"]], "Break and Continue": [[1862, "break-and-continue"]], "Return": [[1862, "return"]], "Variable Resolution": [[1862, "variable-resolution"]], "Use of Python Values": [[1862, "use-of-python-values"]], "Attribute Lookup On Python Modules": [[1862, "attribute-lookup-on-python-modules"]], "Python-defined Constants": [[1862, "python-defined-constants"]], "Module Attributes": [[1862, "module-attributes"]], "Terminology": [[1863, "terminology"]], "Type System": [[1863, "id1"]], "TorchScript Types": [[1863, "torchscript-types"]], "Meta Types": [[1863, "meta-types"]], "Any Type": [[1863, "any-type"]], "Operators Supported for Any Type": [[1863, "operators-supported-for-any-type"]], "Design Notes": [[1863, "design-notes"], [1913, "design-notes"]], "Primitive Types": [[1863, "primitive-types"]], "Structural Types": [[1863, "structural-types"]], "Nominal Types": [[1863, "nominal-types"]], "Built-in Class": [[1863, "built-in-class"]], "Special Note on torch.nn.ModuleList and torch.nn.ModuleDict": [[1863, "special-note-on-torch-nn-modulelist-and-torch-nn-moduledict"]], "Custom Class": [[1863, "custom-class"]], "Enum Type": [[1863, "enum-type"]], "TorchScript Module Class": [[1863, "torchscript-module-class"]], "Module Instance Class": [[1863, "module-instance-class"]], "Type Annotation": [[1863, "type-annotation"]], "When to Annotate Types": [[1863, "when-to-annotate-types"]], "Annotate Function Signature": [[1863, "annotate-function-signature"]], "Annotate Variables and Data Attributes": [[1863, "annotate-variables-and-data-attributes"]], "Local Variables": [[1863, "local-variables"]], "Instance Data Attributes": [[1863, "instance-data-attributes"]], "Type Annotation APIs": [[1863, "type-annotation-apis"]], "torch.jit.annotate(T, expr)": [[1863, "torch-jit-annotate-t-expr"]], "Type Annotation Appendix": [[1863, "type-annotation-appendix"]], "TorchScript Type System Definition": [[1863, "torchscript-type-system-definition"]], "Arithmetic Conversions": [[1863, "arithmetic-conversions"]], "Atoms": [[1863, "atoms"]], "Identifiers": [[1863, "identifiers"]], "Parenthesized Forms": [[1863, "parenthesized-forms"]], "List and Dictionary Displays": [[1863, "list-and-dictionary-displays"]], "Primaries": [[1863, "primaries"]], "Attribute References": [[1863, "attribute-references"]], "Subscriptions": [[1863, "subscriptions"]], "Slicings": [[1863, "slicings"]], "Calls": [[1863, "calls"]], "Power Operator": [[1863, "power-operator"]], "Unary and Arithmetic Bitwise Operations": [[1863, "unary-and-arithmetic-bitwise-operations"]], "Binary Arithmetic Operations": [[1863, "binary-arithmetic-operations"]], "Shifting Operations": [[1863, "shifting-operations"]], "Binary Bitwise Operations": [[1863, "binary-bitwise-operations"]], "Value Comparisons": [[1863, "value-comparisons"]], "Membership Test Operations": [[1863, "membership-test-operations"]], "Identity Comparisons": [[1863, "identity-comparisons"]], "Boolean Operations": [[1863, "boolean-operations"]], "Conditional Expressions": [[1863, "conditional-expressions"]], "Expression Lists": [[1863, "expression-lists"]], "Simple Statements": [[1863, "simple-statements"]], "Expression Statements": [[1863, "expression-statements"]], "Assignment Statements": [[1863, "assignment-statements"]], "Augmented Assignment Statements": [[1863, "augmented-assignment-statements"]], "Annotated Assignment Statements": [[1863, "annotated-assignment-statements"]], "The raise Statement": [[1863, "the-raise-statement"]], "The assert Statement": [[1863, "the-assert-statement"]], "The return Statement": [[1863, "the-return-statement"]], "The del Statement": [[1863, "the-del-statement"]], "The pass Statement": [[1863, "the-pass-statement"]], "The print Statement": [[1863, "the-print-statement"]], "The break Statement": [[1863, "the-break-statement"]], "The continue Statement:": [[1863, "the-continue-statement"]], "Compound Statements": [[1863, "compound-statements"]], "The if Statement": [[1863, "the-if-statement"]], "Basic if/else Statement": [[1863, "basic-if-else-statement"]], "Ternary if/else Statement": [[1863, "ternary-if-else-statement"]], "The while Statement": [[1863, "the-while-statement"]], "The for-in Statement": [[1863, "the-for-in-statement"]], "The with Statement": [[1863, "the-with-statement"]], "The tuple Statement": [[1863, "the-tuple-statement"]], "The getattr Statement": [[1863, "the-getattr-statement"]], "The hasattr Statement": [[1863, "the-hasattr-statement"]], "The zip Statement": [[1863, "the-zip-statement"]], "The enumerate Statement": [[1863, "the-enumerate-statement"]], "Python Values": [[1863, "python-values"]], "Resolution Rules": [[1863, "resolution-rules"]], "Python Built-in Functions Support": [[1863, "python-built-in-functions-support"]], "TorchScript Support for Python Built-in Functions": [[1863, "id5"]], "Python Built-in Values Support": [[1863, "python-built-in-values-support"]], "TorchScript Support for Python Built-in Values": [[1863, "id6"]], "torch.* APIs": [[1863, "torch-apis"]], "Remote Procedure Calls": [[1863, "remote-procedure-calls"]], "Asynchronous Execution": [[1863, "asynchronous-execution"]], "Type Annotations": [[1863, "type-annotations"]], "Meta Programming": [[1863, "meta-programming"]], "Type Refinement": [[1863, "type-refinement"]], "JIT Utils - torch.utils.jit": [[1866, "module-torch.utils.jit"]], "torch.nn.functional": [[1880, "torch-nn-functional"]], "Convolution functions": [[1880, "convolution-functions"]], "Pooling functions": [[1880, "pooling-functions"]], "Attention Mechanisms": [[1880, "attention-mechanisms"]], "Non-linear activation functions": [[1880, "non-linear-activation-functions"]], "Linear functions": [[1880, "linear-functions"]], "Dropout functions": [[1880, "dropout-functions"]], "Sparse functions": [[1880, "sparse-functions"]], "Distance functions": [[1880, "distance-functions"]], "Loss functions": [[1880, "loss-functions"]], "Vision functions": [[1880, "vision-functions"]], "DataParallel functions (multi-GPU, distributed)": [[1880, "dataparallel-functions-multi-gpu-distributed"]], "data_parallel": [[1880, "data-parallel"]], "torch.utils.mobile_optimizer": [[1871, "torch-utils-mobile-optimizer"]], "torch.cuda.jiterator._create_jit_fn": [[1006, "torch-cuda-jiterator-create-jit-fn"]], "torch.cuda.get_allocator_backend": [[989, "torch-cuda-get-allocator-backend"]], "torch.cuda.is_current_stream_capturing": [[1004, "torch-cuda-is-current-stream-capturing"]], "torch.cuda.get_sync_debug_mode": [[997, "torch-cuda-get-sync-debug-mode"]], "torch.cuda.nvtx.range_pop": [[1024, "torch-cuda-nvtx-range-pop"]], "torch.cuda.comm.scatter": [[980, "torch-cuda-comm-scatter"]], "torch.cuda.list_gpu_processes": [[1008, "torch-cuda-list-gpu-processes"]], "torch.cuda.device_count": [[986, "torch-cuda-device-count"]], "torch.cuda.get_arch_list": [[990, "torch-cuda-get-arch-list"]], "torch.cuda.power_draw": [[1026, "torch-cuda-power-draw"]], "torch.cuda.current_device": [[982, "torch-cuda-current-device"]], "torch.cuda.max_memory_reserved": [[1014, "torch-cuda-max-memory-reserved"]], "torch.cuda.ipc_collect": [[1002, "torch-cuda-ipc-collect"]], "torch.cuda.initial_seed": [[1001, "torch-cuda-initial-seed"]], "torch.cuda.get_device_properties": [[993, "torch-cuda-get-device-properties"]], "torch.cuda.manual_seed": [[1010, "torch-cuda-manual-seed"]], "torch.cuda.current_stream": [[983, "torch-cuda-current-stream"]], "torch.cuda.get_rng_state_all": [[996, "torch-cuda-get-rng-state-all"]], "torch.cuda.manual_seed_all": [[1011, "torch-cuda-manual-seed-all"]], "torch.cuda.max_memory_cached": [[1013, "torch-cuda-max-memory-cached"]], "torch.cuda.get_device_name": [[992, "torch-cuda-get-device-name"]], "torch.cuda.default_stream": [[984, "torch-cuda-default-stream"]], "torch.cuda.memory_summary": [[1021, "torch-cuda-memory-summary"]], "torch.cuda.memory_usage": [[1022, "torch-cuda-memory-usage"]], "graph": [[998, "graph"]], "torch.cuda.max_memory_allocated": [[1012, "torch-cuda-max-memory-allocated"]], "torch.cuda.get_device_capability": [[991, "torch-cuda-get-device-capability"]], "torch.cuda.mem_get_info": [[1015, "torch-cuda-mem-get-info"]], "torch.cuda.current_blas_handle": [[981, "torch-cuda-current-blas-handle"]], "torch.cuda.memory_cached": [[1017, "torch-cuda-memory-cached"]], "torch.cuda.reset_max_memory_cached": [[1028, "torch-cuda-reset-max-memory-cached"]], "device": [[985, "device"]], "device_of": [[987, "device-of"]], "torch.cuda.is_available": [[1003, "torch-cuda-is-available"]], "torch.cuda.memory_allocated": [[1016, "torch-cuda-memory-allocated"]], "torch.cuda.nvtx.mark": [[1023, "torch-cuda-nvtx-mark"]], "torch.cuda.reset_max_memory_allocated": [[1027, "torch-cuda-reset-max-memory-allocated"]], "torch.cuda.nvtx.range_push": [[1025, "torch-cuda-nvtx-range-push"]], "torch.cuda.empty_cache": [[988, "torch-cuda-empty-cache"]], "torch.cuda.graph_pool_handle": [[999, "torch-cuda-graph-pool-handle"]], "torch.cuda.init": [[1000, "torch-cuda-init"]], "torch.cuda.get_gencode_flags": [[994, "torch-cuda-get-gencode-flags"]], "torch.cuda.make_graphed_callables": [[1009, "torch-cuda-make-graphed-callables"]], "torch.cuda.get_rng_state": [[995, "torch-cuda-get-rng-state"]], "torch.cuda.jiterator._create_multi_output_jit_fn": [[1007, "torch-cuda-jiterator-create-multi-output-jit-fn"]], "torch.cuda.memory_stats": [[1020, "torch-cuda-memory-stats"]], "torch.cuda.is_initialized": [[1005, "torch-cuda-is-initialized"]], "torch.cuda.memory_snapshot": [[1019, "torch-cuda-memory-snapshot"]], "torch.cuda.memory_reserved": [[1018, "torch-cuda-memory-reserved"]], "torch.cdist": [[938, "torch-cdist"]], "torch.cuda.comm.gather": [[978, "torch-cuda-comm-gather"]], "torch.chunk": [[944, "torch-chunk"]], "torch.broadcast_shapes": [[931, "torch-broadcast-shapes"]], "torch.compiled_with_cxx11_abi": [[951, "torch-compiled-with-cxx11-abi"]], "torch.clip": [[946, "torch-clip"]], "torch.conj_physical": [[956, "torch-conj-physical"]], "CUDAGraph": [[964, "cudagraph"]], "ExternalStream": [[967, "externalstream"]], "StreamContext": [[970, "streamcontext"]], "torch.cartesian_prod": [[936, "torch-cartesian-prod"]], "torch.cuda.change_current_allocator": [[974, "torch-cuda-change-current-allocator"]], "torch.broadcast_tensors": [[932, "torch-broadcast-tensors"]], "torch.cosh": [[960, "torch-cosh"]], "torch.chain_matmul": [[940, "torch-chain-matmul"]], "torch.cuda.can_device_access_peer": [[973, "torch-cuda-can-device-access-peer"]], "torch.cholesky": [[941, "torch-cholesky"]], "torch.cholesky_solve": [[943, "torch-cholesky-solve"]], "torch.cuda.OutOfMemoryError": [[968, "torch-cuda-outofmemoryerror"]], "torch.cuda.comm.broadcast": [[976, "torch-cuda-comm-broadcast"]], "torch.can_cast": [[935, "torch-can-cast"]], "torch.cholesky_inverse": [[942, "torch-cholesky-inverse"]], "torch.cuda.caching_allocator_delete": [[972, "torch-cuda-caching-allocator-delete"]], "torch.complex": [[952, "torch-complex"]], "torch.cuda.caching_allocator_alloc": [[971, "torch-cuda-caching-allocator-alloc"]], "torch.cuda.clock_rate": [[975, "torch-cuda-clock-rate"]], "torch.ceil": [[939, "torch-ceil"]], "torch.concatenate": [[954, "torch-concatenate"]], "torch.cos": [[959, "torch-cos"]], "torch.column_stack": [[948, "torch-column-stack"]], "Stream": [[969, "stream"]], "torch.cuda.comm.reduce_add": [[979, "torch-cuda-comm-reduce-add"]], "torch.conj": [[955, "torch-conj"]], "torch.clone": [[947, "torch-clone"]], "torch.broadcast_to": [[933, "torch-broadcast-to"]], "torch.cat": [[937, "torch-cat"]], "torch.count_nonzero": [[961, "torch-count-nonzero"]], "Event": [[966, "event"]], "torch.cuda.comm.broadcast_coalesced": [[977, "torch-cuda-comm-broadcast-coalesced"]], "torch.bucketize": [[934, "torch-bucketize"]], "torch.copysign": [[957, "torch-copysign"]], "torch.combinations": [[949, "torch-combinations"]], "torch.cov": [[962, "torch-cov"]], "torch.cross": [[963, "torch-cross"]], "CUDAPluggableAllocator": [[965, "cudapluggableallocator"]], "torch.corrcoef": [[958, "torch-corrcoef"]], "torch.concat": [[953, "torch-concat"]], "torch.clamp": [[945, "torch-clamp"]], "torch.Storage": [[1919, "torch-storage"]], "Tensor Attributes": [[1920, "tensor-attributes"]], "torch.dtype": [[1920, "torch-dtype"]], "torch.device": [[1920, "torch-device"]], "torch.layout": [[1920, "torch-layout"]], "torch.memory_format": [[1920, "torch-memory-format"]], "Tensor Views": [[1921, "tensor-views"]], "torch.overrides": [[1928, "torch-overrides"]], "Remote Reference Protocol": [[1915, "remote-reference-protocol"]], "Background": [[1915, "background"], [1914, "background"]], "Assumptions": [[1915, "assumptions"]], "RRef Lifetime": [[1915, "rref-lifetime"]], "Design Reasoning": [[1915, "design-reasoning"]], "Protocol Scenarios": [[1915, "protocol-scenarios"]], "User Share RRef with Owner as Return Value": [[1915, "user-share-rref-with-owner-as-return-value"]], "User Share RRef with Owner as Argument": [[1915, "user-share-rref-with-owner-as-argument"]], "Owner Share RRef with User": [[1915, "owner-share-rref-with-user"]], "User Share RRef with User": [[1915, "user-share-rref-with-user"]], "torch.special": [[1918, "torch-special"]], "torch": [[1925, "module-torch"]], "Tensors": [[1925, "tensors"]], "Creation Ops": [[1925, "creation-ops"]], "Indexing, Slicing, Joining, Mutating Ops": [[1925, "indexing-slicing-joining-mutating-ops"]], "Generators": [[1925, "generators"]], "Random sampling": [[1925, "random-sampling"]], "In-place random sampling": [[1925, "in-place-random-sampling"]], "Quasi-random sampling": [[1925, "quasi-random-sampling"]], "Parallelism": [[1925, "parallelism"]], "Math operations": [[1925, "math-operations"]], "Pointwise Ops": [[1925, "pointwise-ops"]], "Reduction Ops": [[1925, "reduction-ops"]], "Comparison Ops": [[1925, "comparison-ops"]], "Spectral Ops": [[1925, "spectral-ops"]], "Other Operations": [[1925, "other-operations"]], "BLAS and LAPACK Operations": [[1925, "blas-and-lapack-operations"]], "Foreach Operations": [[1925, "foreach-operations"]], "Symbolic Numbers": [[1925, "symbolic-numbers"]], "Operator Tags": [[1925, "operator-tags"]], "Engine Configuration": [[1925, "engine-configuration"]], "Distributed Autograd Design": [[1914, "distributed-autograd-design"]], "Autograd recording during the forward pass": [[1914, "autograd-recording-during-the-forward-pass"]], "Distributed Autograd Context": [[1914, "distributed-autograd-context"]], "Distributed Backward Pass": [[1914, "distributed-backward-pass"]], "Computing dependencies": [[1914, "computing-dependencies"]], "FAST mode algorithm": [[1914, "fast-mode-algorithm"]], "SMART mode algorithm": [[1914, "smart-mode-algorithm"]], "Distributed Optimizer": [[1914, "distributed-optimizer"], [1913, "distributed-optimizer"]], "Simple end to end example": [[1914, "simple-end-to-end-example"]], "torch.signal": [[1916, "module-torch.signal"]], "torch.signal.windows": [[1916, "module-torch.signal.windows"]], "Type Info": [[1929, "type-info"]], "torch.finfo": [[1929, "torch-finfo"]], "torch.iinfo": [[1929, "torch-iinfo"]], "torch.utils.tensorboard": [[1922, "module-torch.utils.tensorboard"]], "torch.Tensor": [[1923, "torch-tensor"]], "Data types": [[1923, "data-types"]], "Initializing and basic operations": [[1923, "initializing-and-basic-operations"]], "Tensor class reference": [[1923, "tensor-class-reference"]], "torch.testing": [[1924, "module-torch.testing"]], "Distributed RPC Framework": [[1913, "distributed-rpc-framework"]], "RPC": [[1913, "rpc"]], "TensorPipe Backend": [[1913, "tensorpipe-backend"]], "RRef": [[1913, "rref"]], "More Information about RRef": [[1913, null]], "RemoteModule": [[1913, "remotemodule"]], "Distributed Autograd Framework": [[1913, "distributed-autograd-framework"]], "More Information about RPC Autograd": [[1913, null]], "torch.ao.ns._numeric_suite": [[1926, "torch-ao-ns-numeric-suite"]], "torch.ao.ns._numeric_suite_fx": [[1927, "torch-ao-ns-numeric-suite-fx"]], "torch.ao.ns.fx.utils": [[1927, "torch-ao-ns-fx-utils"]], "torch.ao.quantization": [[1911, "torch-ao-quantization"]], "Top level APIs": [[1911, "top-level-apis"]], "Preparing model for quantization": [[1911, "preparing-model-for-quantization"]], "Utility functions": [[1911, "utility-functions"]], "torch.ao.quantization.quantize_fx": [[1911, "torch-ao-quantization-quantize-fx"]], "torch.ao.quantization.qconfig_mapping": [[1911, "torch-ao-quantization-qconfig-mapping"]], "torch.ao.quantization.backend_config": [[1911, "torch-ao-quantization-backend-config"]], "torch.ao.quantization.fx.custom_config": [[1911, "torch-ao-quantization-fx-custom-config"]], "torch (quantization related functions)": [[1911, "torch-quantization-related-functions"]], "torch.Tensor (quantization related methods)": [[1911, "torch-tensor-quantization-related-methods"]], "torch.ao.quantization.observer": [[1911, "torch-ao-quantization-observer"]], "torch.ao.quantization.fake_quantize": [[1911, "torch-ao-quantization-fake-quantize"]], "torch.ao.quantization.qconfig": [[1911, "torch-ao-quantization-qconfig"]], "torch.ao.nn.intrinsic": [[1911, "module-torch.ao.nn.intrinsic"]], "torch.ao.nn.intrinsic.qat": [[1911, "module-torch.ao.nn.intrinsic.qat"]], "torch.ao.nn.intrinsic.quantized": [[1911, "module-torch.ao.nn.intrinsic.quantized"]], "torch.ao.nn.intrinsic.quantized.dynamic": [[1911, "module-torch.ao.nn.intrinsic.quantized.dynamic"]], "torch.ao.nn.qat": [[1911, "module-torch.ao.nn.qat"]], "torch.ao.nn.qat.dynamic": [[1911, "module-torch.ao.nn.qat.dynamic"]], "torch.ao.nn.quantized": [[1911, "module-torch.ao.nn.quantized.modules"]], "torch.ao.nn.quantized.functional": [[1911, "module-torch.ao.nn.quantized.functional"]], "torch.ao.nn.quantizable": [[1911, "torch-ao-nn-quantizable"]], "torch.ao.nn.quantized.dynamic": [[1911, "module-torch.ao.nn.quantized.dynamic"]], "Quantized dtypes and quantization schemes": [[1911, "quantized-dtypes-and-quantization-schemes"]], "torch.random": [[1912, "module-torch.random"]], "torch.sparse": [[1917, "torch-sparse"]], "Why and when to use sparsity": [[1917, "why-and-when-to-use-sparsity"]], "Functionality overview": [[1917, "functionality-overview"]], "Operator overview": [[1917, "operator-overview"]], "Sparse COO tensors": [[1917, "sparse-coo-tensors"]], "Sparse hybrid COO tensors": [[1917, "sparse-hybrid-coo-tensors"]], "Uncoalesced sparse COO tensors": [[1917, "uncoalesced-sparse-coo-tensors"]], "Working with sparse COO tensors": [[1917, "working-with-sparse-coo-tensors"]], "Sparse Compressed Tensors": [[1917, "sparse-compressed-tensors"]], "Sparse CSR Tensor": [[1917, "sparse-csr-tensor"]], "Construction of CSR tensors": [[1917, "construction-of-csr-tensors"]], "CSR Tensor Operations": [[1917, "csr-tensor-operations"]], "Sparse CSC Tensor": [[1917, "sparse-csc-tensor"]], "Construction of CSC tensors": [[1917, "construction-of-csc-tensors"]], "Sparse BSR Tensor": [[1917, "sparse-bsr-tensor"]], "Construction of BSR tensors": [[1917, "construction-of-bsr-tensors"]], "Sparse BSC Tensor": [[1917, "sparse-bsc-tensor"]], "Construction of BSC tensors": [[1917, "construction-of-bsc-tensors"]], "Tools for working with sparse compressed tensors": [[1917, "tools-for-working-with-sparse-compressed-tensors"]], "Construction of sparse compressed tensors": [[1917, "construction-of-sparse-compressed-tensors"]], "Linear Algebra operations": [[1917, "linear-algebra-operations"]], "Tensor methods and sparse": [[1917, "tensor-methods-and-sparse"]], "Torch functions specific to sparse Tensors": [[1917, "torch-functions-specific-to-sparse-tensors"]], "Other functions": [[1917, "other-functions"]], "Unary functions": [[1917, "unary-functions"]], "torch.atleast_2d": [[884, "torch-atleast-2d"]], "torch.autograd.Function.jvp": [[888, "torch-autograd-function-jvp"]], "dual_level": [[891, "dual-level"]], "torch.block_diag": [[929, "torch-block-diag"]], "torch.autograd.profiler.profile.total_average": [[916, "torch-autograd-profiler-profile-total-average"]], "torch.autograd.graph.Node.register_hook": [[910, "torch-autograd-graph-node-register-hook"]], "torch.blackman_window": [[928, "torch-blackman-window"]], "torch.autograd.function.FunctionCtx.mark_non_differentiable": [[895, "torch-autograd-function-functionctx-mark-non-differentiable"]], "torch.atanh": [[882, "torch-atanh"]], "torch.autograd.functional.vjp": [[903, "torch-autograd-functional-vjp"]], "torch.autograd.profiler.load_nvprof": [[912, "torch-autograd-profiler-load-nvprof"]], "torch.autograd.function.FunctionCtx.mark_dirty": [[894, "torch-autograd-function-functionctx-mark-dirty"]], "torch.autograd.gradgradcheck": [[906, "torch-autograd-gradgradcheck"]], "torch.autograd.profiler.profile.export_chrome_trace": [[913, "torch-autograd-profiler-profile-export-chrome-trace"]], "torch.autograd.graph.Node.metadata": [[907, "torch-autograd-graph-node-metadata"]], "torch.autograd.graph.Node.register_prehook": [[911, "torch-autograd-graph-node-register-prehook"]], "torch.autograd.functional.jvp": [[901, "torch-autograd-functional-jvp"]], "torch.autograd.graph.Node.next_functions": [[909, "torch-autograd-graph-node-next-functions"]], "torch.bitwise_left_shift": [[923, "torch-bitwise-left-shift"]], "torch.autograd.grad": [[904, "torch-autograd-grad"]], "torch.autograd.function.FunctionCtx.set_materialize_grads": [[897, "torch-autograd-function-functionctx-set-materialize-grads"]], "torch.bitwise_or": [[925, "torch-bitwise-or"]], "torch.autograd.forward_ad.unpack_dual": [[893, "torch-autograd-forward-ad-unpack-dual"]], "torch.autograd.Function.backward": [[886, "torch-autograd-function-backward"]], "torch.bitwise_right_shift": [[926, "torch-bitwise-right-shift"]], "torch.autograd.functional.jacobian": [[900, "torch-autograd-functional-jacobian"]], "torch.autograd.gradcheck": [[905, "torch-autograd-gradcheck"]], "torch.autograd.functional.hessian": [[898, "torch-autograd-functional-hessian"]], "torch.bitwise_and": [[922, "torch-bitwise-and"]], "torch.atleast_3d": [[885, "torch-atleast-3d"]], "torch.bernoulli": [[920, "torch-bernoulli"]], "torch.bitwise_not": [[924, "torch-bitwise-not"]], "torch.bincount": [[921, "torch-bincount"]], "torch.autograd.profiler.profile.self_cpu_time_total": [[915, "torch-autograd-profiler-profile-self-cpu-time-total"]], "torch.bmm": [[930, "torch-bmm"]], "torch.autograd.backward": [[890, "torch-autograd-backward"]], "torch.autograd.functional.hvp": [[899, "torch-autograd-functional-hvp"]], "torch.atleast_1d": [[883, "torch-atleast-1d"]], "torch.autograd.function.FunctionCtx.save_for_backward": [[896, "torch-autograd-function-functionctx-save-for-backward"]], "torch.autograd.functional.vhp": [[902, "torch-autograd-functional-vhp"]], "torch.bitwise_xor": [[927, "torch-bitwise-xor"]], "torch.autograd.graph.Node.name": [[908, "torch-autograd-graph-node-name"]], "torch.baddbmm": [[918, "torch-baddbmm"]], "torch.bartlett_window": [[919, "torch-bartlett-window"]], "torch.autograd.Function.forward": [[887, "torch-autograd-function-forward"]], "set_multithreading_enabled": [[917, "set-multithreading-enabled"]], "torch.autograd.Function.vmap": [[889, "torch-autograd-function-vmap"]], "torch.autograd.forward_ad.make_dual": [[892, "torch-autograd-forward-ad-make-dual"]], "torch.autograd.profiler.profile.key_averages": [[914, "torch-autograd-profiler-profile-key-averages"]], "convert_fx": [[856, "convert-fx"]], "get_default_qconfig_mapping": [[853, "get-default-qconfig-mapping"]], "default_per_channel_qconfig": [[842, "default-per-channel-qconfig"]], "quantize": [[854, "quantize"]], "swap_module": [[861, "swap-module"]], "torch.arccosh": [[864, "torch-arccosh"]], "prepare_qat": [[836, "prepare-qat"]], "float16_static_qconfig": [[848, "float16-static-qconfig"]], "torch.arctan2": [[868, "torch-arctan2"]], "torch.as_strided": [[875, "torch-as-strided"]], "propagate_qconfig": [[837, "propagate-qconfig"]], "prepare": [[835, "prepare"]], "torch.asarray": [[877, "torch-asarray"]], "float_qparams_weight_only_qconfig": [[849, "float-qparams-weight-only-qconfig"]], "torch.arcsin": [[865, "torch-arcsin"]], "torch.as_tensor": [[876, "torch-as-tensor"]], "QConfigMapping": [[851, "qconfigmapping"]], "torch.arccos": [[863, "torch-arccos"]], "get_default_qat_qconfig_mapping": [[852, "get-default-qat-qconfig-mapping"]], "torch.argmin": [[872, "torch-argmin"]], "torch.are_deterministic_algorithms_enabled": [[870, "torch-are-deterministic-algorithms-enabled"]], "torch.asin": [[878, "torch-asin"]], "torch.asinh": [[879, "torch-asinh"]], "default_activation_only_qconfig": [[839, "default-activation-only-qconfig"]], "torch.argmax": [[871, "torch-argmax"]], "default_dynamic_qconfig": [[841, "default-dynamic-qconfig"]], "prepare_qat_fx": [[859, "prepare-qat-fx"]], "default_debug_qconfig": [[840, "default-debug-qconfig"]], "load_observer_state_dict": [[834, "load-observer-state-dict"]], "torch.atan2": [[881, "torch-atan2"]], "default_qconfig": [[845, "default-qconfig"]], "default_weight_only_qconfig": [[846, "default-weight-only-qconfig"]], "float16_dynamic_qconfig": [[847, "float16-dynamic-qconfig"]], "quantize_dynamic": [[855, "quantize-dynamic"]], "prepare_fx": [[858, "prepare-fx"]], "torch.arange": [[862, "torch-arange"]], "torch.arctan": [[867, "torch-arctan"]], "default_qat_qconfig": [[843, "default-qat-qconfig"]], "quantize_qat": [[860, "quantize-qat"]], "torch.atan": [[880, "torch-atan"]], "torch.argsort": [[873, "torch-argsort"]], "fuse_fx": [[857, "fuse-fx"]], "torch.arcsinh": [[866, "torch-arcsinh"]], "get_observer_state_dict": [[833, "get-observer-state-dict"]], "default_qat_qconfig_v2": [[844, "default-qat-qconfig-v2"]], "torch.arctanh": [[869, "torch-arctanh"]], "torch.argwhere": [[874, "torch-argwhere"]], "per_channel_dynamic_qconfig": [[850, "per-channel-dynamic-qconfig"]], "MovingAverageMinMaxObserver": [[818, "movingaverageminmaxobserver"]], "default_placeholder_observer": [[831, "default-placeholder-observer"]], "ConvertCustomConfig": [[812, "convertcustomconfig"]], "DeQuantStub": [[785, "dequantstub"]], "default_fused_act_fake_quant": [[801, "default-fused-act-fake-quant"]], "PerChannelMinMaxObserver": [[822, "perchannelminmaxobserver"]], "disable_observer": [[808, "disable-observer"]], "DTypeWithConstraints": [[792, "dtypewithconstraints"]], "default_dynamic_quant_observer": [[826, "default-dynamic-quant-observer"]], "DTypeConfig": [[791, "dtypeconfig"]], "default_weight_observer": [[832, "default-weight-observer"]], "ObserverBase": [[821, "observerbase"]], "disable_fake_quant": [[807, "disable-fake-quant"]], "default_debug_observer": [[825, "default-debug-observer"]], "PlaceholderObserver": [[823, "placeholderobserver"]], "default_fake_quant": [[800, "default-fake-quant"]], "MinMaxObserver": [[817, "minmaxobserver"]], "FusedMovingAvgObsFakeQuantize": [[799, "fusedmovingavgobsfakequantize"]], "HistogramObserver": [[816, "histogramobserver"]], "upsample_nearest": [[784, "upsample-nearest"]], "enable_observer": [[810, "enable-observer"]], "default_eval_fn": [[795, "default-eval-fn"]], "PrepareCustomConfig": [[814, "preparecustomconfig"]], "default_fused_wt_fake_quant": [[803, "default-fused-wt-fake-quant"]], "fuse_modules": [[811, "fuse-modules"]], "add_quant_dequant": [[788, "add-quant-dequant"]], "default_float_qparams_observer": [[827, "default-float-qparams-observer"]], "StandaloneModuleConfigEntry": [[815, "standalonemoduleconfigentry"]], "NoopObserver": [[820, "noopobserver"]], "FakeQuantizeBase": [[797, "fakequantizebase"]], "QuantStub": [[786, "quantstub"]], "default_histogram_fake_quant": [[804, "default-histogram-fake-quant"]], "default_observer": [[829, "default-observer"]], "BackendPatternConfig": [[790, "backendpatternconfig"]], "convert": [[794, "convert"]], "default_weight_fake_quant": [[806, "default-weight-fake-quant"]], "MovingAveragePerChannelMinMaxObserver": [[819, "movingaverageperchannelminmaxobserver"]], "default_fused_per_channel_wt_fake_quant": [[802, "default-fused-per-channel-wt-fake-quant"]], "FakeQuantize": [[796, "fakequantize"]], "RecordingObserver": [[824, "recordingobserver"]], "FuseCustomConfig": [[813, "fusecustomconfig"]], "default_per_channel_weight_fake_quant": [[805, "default-per-channel-weight-fake-quant"]], "QuantWrapper": [[787, "quantwrapper"]], "ObservationType": [[793, "observationtype"]], "BackendConfig": [[789, "backendconfig"]], "enable_fake_quant": [[809, "enable-fake-quant"]], "FixedQParamsFakeQuantize": [[798, "fixedqparamsfakequantize"]], "default_histogram_observer": [[828, "default-histogram-observer"]], "default_per_channel_weight_observer": [[830, "default-per-channel-weight-observer"]], "QFunctional": [[754, "qfunctional"]], "max_pool2d": [[780, "max-pool2d"]], "hardtanh": [[775, "hardtanh"]], "hardswish": [[774, "hardswish"]], "max_pool1d": [[779, "max-pool1d"]], "conv3d": [[771, "conv3d"]], "hardsigmoid": [[773, "hardsigmoid"]], "threshold": [[781, "threshold"]], "FloatFunctional": [[745, "floatfunctional"]], "upsample": [[782, "upsample"]], "linear": [[778, "linear"]], "elu": [[772, "elu"]], "avg_pool3d": [[766, "avg-pool3d"]], "upsample_bilinear": [[783, "upsample-bilinear"]], "interpolate": [[776, "interpolate"]], "adaptive_avg_pool3d": [[764, "adaptive-avg-pool3d"]], "adaptive_avg_pool2d": [[763, "adaptive-avg-pool2d"]], "celu": [[767, "celu"]], "leaky_relu": [[777, "leaky-relu"]], "clamp": [[768, "clamp"]], "FXFloatFunctional": [[744, "fxfloatfunctional"]], "conv1d": [[769, "conv1d"]], "avg_pool2d": [[765, "avg-pool2d"]], "conv2d": [[770, "conv2d"]], "LinearReLU": [[726, "linearrelu"], [717, "linearrelu"], [708, "linearrelu"], [725, "linearrelu"]], "update_bn_stats": [[719, "update-bn-stats"]], "torch.addmm": [[686, "torch-addmm"]], "ConvReLU2d": [[715, "convrelu2d"], [723, "convrelu2d"], [706, "convrelu2d"]], "ConvReLU1d": [[705, "convrelu1d"], [722, "convrelu1d"]], "BNReLU3d": [[721, "bnrelu3d"], [698, "bnrelu3d"]], "ConvBn1d": [[699, "convbn1d"], [709, "convbn1d"]], "ConvBnReLU3d": [[714, "convbnrelu3d"], [704, "convbnrelu3d"]], "ConvReLU3d": [[724, "convrelu3d"], [716, "convrelu3d"], [707, "convrelu3d"]], "ConvBnReLU2d": [[713, "convbnrelu2d"], [703, "convbnrelu2d"]], "torch.adjoint": [[689, "torch-adjoint"]], "torch.addmv": [[687, "torch-addmv"]], "ConvBn3d": [[711, "convbn3d"], [701, "convbn3d"]], "torch.amax": [[692, "torch-amax"]], "torch.addr": [[688, "torch-addr"]], "freeze_bn_stats": [[718, "freeze-bn-stats"]], "torch.aminmax": [[694, "torch-aminmax"]], "ConvBn2d": [[710, "convbn2d"], [700, "convbn2d"]], "ConvBnReLU1d": [[712, "convbnrelu1d"], [702, "convbnrelu1d"]], "torch.any": [[696, "torch-any"]], "torch.all": [[690, "torch-all"]], "BNReLU2d": [[697, "bnrelu2d"], [720, "bnrelu2d"]], "torch.allclose": [[691, "torch-allclose"]], "torch.amin": [[693, "torch-amin"]], "torch.angle": [[695, "torch-angle"]], "torch._foreach_sin": [[666, "torch-foreach-sin"]], "torch._foreach_trunc_": [[675, "torch-foreach-trunc"]], "torch._foreach_log1p_": [[654, "torch-foreach-log1p"]], "torch._foreach_sigmoid_": [[665, "torch-foreach-sigmoid"]], "torch._foreach_lgamma_": [[649, "torch-foreach-lgamma"]], "torch._foreach_frac": [[646, "torch-foreach-frac"]], "torch._foreach_log10": [[651, "torch-foreach-log10"]], "torch._foreach_erfc_": [[639, "torch-foreach-erfc"]], "torch._foreach_reciprocal": [[660, "torch-foreach-reciprocal"]], "torch._foreach_log10_": [[652, "torch-foreach-log10"]], "torch._foreach_expm1": [[642, "torch-foreach-expm1"]], "torch._foreach_log_": [[657, "torch-foreach-log"]], "torch._foreach_floor_": [[645, "torch-foreach-floor"]], "torch.acosh": [[681, "torch-acosh"]], "torch.absolute": [[679, "torch-absolute"]], "torch._foreach_erfc": [[638, "torch-foreach-erfc"]], "torch._foreach_tan": [[672, "torch-foreach-tan"]], "torch._foreach_reciprocal_": [[661, "torch-foreach-reciprocal"]], "torch._foreach_log2_": [[656, "torch-foreach-log2"]], "torch._logging.set_logs": [[677, "torch-logging-set-logs"]], "torch._foreach_zero_": [[676, "torch-foreach-zero"]], "torch._foreach_sin_": [[667, "torch-foreach-sin"]], "torch.addcmul": [[685, "torch-addcmul"]], "torch.add": [[682, "torch-add"]], "torch._foreach_sinh": [[668, "torch-foreach-sinh"]], "torch._foreach_sqrt_": [[671, "torch-foreach-sqrt"]], "torch._foreach_log": [[650, "torch-foreach-log"]], "torch._foreach_sinh_": [[669, "torch-foreach-sinh"]], "torch._foreach_neg_": [[659, "torch-foreach-neg"]], "torch._foreach_sigmoid": [[664, "torch-foreach-sigmoid"]], "torch._foreach_expm1_": [[643, "torch-foreach-expm1"]], "torch._foreach_log2": [[655, "torch-foreach-log2"]], "torch._foreach_floor": [[644, "torch-foreach-floor"]], "torch._foreach_trunc": [[674, "torch-foreach-trunc"]], "torch.addbmm": [[683, "torch-addbmm"]], "torch._foreach_sqrt": [[670, "torch-foreach-sqrt"]], "torch._foreach_tan_": [[673, "torch-foreach-tan"]], "torch._foreach_exp": [[640, "torch-foreach-exp"]], "torch._foreach_round_": [[663, "torch-foreach-round"]], "torch.addcdiv": [[684, "torch-addcdiv"]], "torch._foreach_exp_": [[641, "torch-foreach-exp"]], "torch._foreach_round": [[662, "torch-foreach-round"]], "torch._foreach_log1p": [[653, "torch-foreach-log1p"]], "torch._foreach_lgamma": [[648, "torch-foreach-lgamma"]], "torch._foreach_neg": [[658, "torch-foreach-neg"]], "torch.acos": [[680, "torch-acos"]], "torch._foreach_frac_": [[647, "torch-foreach-frac"]], "torch.abs": [[678, "torch-abs"]], "torch._foreach_erf_": [[637, "torch-foreach-erf"]], "torch._foreach_atan": [[628, "torch-foreach-atan"]], "torch.Tensor.unsqueeze_": [[609, "torch-tensor-unsqueeze"]], "torch.Tensor.zero_": [[620, "torch-tensor-zero"]], "torch.Tensor.transpose_": [[590, "torch-tensor-transpose"]], "torch.Tensor.uniform_": [[605, "torch-tensor-uniform"]], "torch._foreach_cosh": [[634, "torch-foreach-cosh"]], "torch.Tensor.unbind": [[602, "torch-tensor-unbind"]], "torch._foreach_asin": [[626, "torch-foreach-asin"]], "torch.Tensor.xlogy_": [[619, "torch-tensor-xlogy"]], "torch.Tensor.transpose": [[589, "torch-tensor-transpose"]], "torch.Tensor.var": [[612, "torch-tensor-var"]], "torch._foreach_acos_": [[625, "torch-foreach-acos"]], "torch.Tensor.vsplit": [[616, "torch-tensor-vsplit"]], "torch.Tensor.trunc_": [[599, "torch-tensor-trunc"]], "torch.Tensor.triangular_solve": [[591, "torch-tensor-triangular-solve"]], "torch._assert": [[621, "torch-assert"]], "torch._foreach_acos": [[624, "torch-foreach-acos"]], "torch._foreach_abs_": [[623, "torch-foreach-abs"]], "torch._foreach_asin_": [[627, "torch-foreach-asin"]], "torch._foreach_erf": [[636, "torch-foreach-erf"]], "torch.Tensor.unique_consecutive": [[607, "torch-tensor-unique-consecutive"]], "torch.Tensor.unsqueeze": [[608, "torch-tensor-unsqueeze"]], "torch.Tensor.where": [[617, "torch-tensor-where"]], "torch.Tensor.values": [[611, "torch-tensor-values"]], "torch.Tensor.xlogy": [[618, "torch-tensor-xlogy"]], "torch.Tensor.type_as": [[601, "torch-tensor-type-as"]], "torch.Tensor.trunc": [[598, "torch-tensor-trunc"]], "torch.Tensor.untyped_storage": [[610, "torch-tensor-untyped-storage"]], "torch.Tensor.unfold": [[604, "torch-tensor-unfold"]], "torch.Tensor.unflatten": [[603, "torch-tensor-unflatten"]], "torch._foreach_abs": [[622, "torch-foreach-abs"]], "torch._foreach_ceil": [[630, "torch-foreach-ceil"]], "torch.Tensor.view": [[614, "torch-tensor-view"]], "torch.Tensor.tril": [[592, "torch-tensor-tril"]], "torch.Tensor.triu": [[594, "torch-tensor-triu"]], "torch.Tensor.trace": [[588, "torch-tensor-trace"]], "torch.Tensor.true_divide": [[596, "torch-tensor-true-divide"]], "torch._foreach_ceil_": [[631, "torch-foreach-ceil"]], "torch._foreach_cosh_": [[635, "torch-foreach-cosh"]], "torch._foreach_cos_": [[633, "torch-foreach-cos"]], "torch._foreach_cos": [[632, "torch-foreach-cos"]], "torch.Tensor.vdot": [[613, "torch-tensor-vdot"]], "torch.Tensor.unique": [[606, "torch-tensor-unique"]], "torch._foreach_atan_": [[629, "torch-foreach-atan"]], "torch.Tensor.type": [[600, "torch-tensor-type"]], "torch.Tensor.tril_": [[593, "torch-tensor-tril"]], "torch.Tensor.view_as": [[615, "torch-tensor-view-as"]], "torch.Tensor.triu_": [[595, "torch-tensor-triu"]], "torch.Tensor.true_divide_": [[597, "torch-tensor-true-divide"]], "torch.Tensor.t_": [[568, "torch-tensor-t"]], "torch.Tensor.to": [[577, "torch-tensor-to"]], "torch.Tensor.squeeze_": [[550, "torch-tensor-squeeze"]], "torch.Tensor.sspaddmm": [[551, "torch-tensor-sspaddmm"]], "torch.Tensor.storage": [[554, "torch-tensor-storage"]], "torch.Tensor.take_along_dim": [[570, "torch-tensor-take-along-dim"]], "torch.Tensor.square_": [[548, "torch-tensor-square"]], "torch.Tensor.sparse_resize_": [[542, "torch-tensor-sparse-resize"]], "torch.Tensor.squeeze": [[549, "torch-tensor-squeeze"]], "torch.Tensor.subtract_": [[561, "torch-tensor-subtract"]], "torch.Tensor.tensor_split": [[575, "torch-tensor-tensor-split"]], "torch.Tensor.t": [[567, "torch-tensor-t"]], "torch.Tensor.to_sparse_bsc": [[581, "torch-tensor-to-sparse-bsc"]], "torch.Tensor.to_sparse_csc": [[584, "torch-tensor-to-sparse-csc"]], "torch.Tensor.std": [[552, "torch-tensor-std"]], "torch.Tensor.sparse_resize_and_clear_": [[543, "torch-tensor-sparse-resize-and-clear"]], "torch.Tensor.sort": [[539, "torch-tensor-sort"]], "torch.Tensor.to_sparse": [[580, "torch-tensor-to-sparse"]], "torch.Tensor.tan_": [[572, "torch-tensor-tan"]], "torch.Tensor.topk": [[587, "torch-tensor-topk"]], "torch.Tensor.svd": [[564, "torch-tensor-svd"]], "torch.Tensor.to_sparse_coo": [[583, "torch-tensor-to-sparse-coo"]], "torch.Tensor.tolist": [[586, "torch-tensor-tolist"]], "torch.Tensor.sub": [[558, "torch-tensor-sub"]], "torch.Tensor.swapdims": [[566, "torch-tensor-swapdims"]], "torch.Tensor.subtract": [[560, "torch-tensor-subtract"]], "torch.Tensor.stft": [[553, "torch-tensor-stft"]], "torch.Tensor.sparse_dim": [[540, "torch-tensor-sparse-dim"]], "torch.Tensor.sum_to_size": [[563, "torch-tensor-sum-to-size"]], "torch.Tensor.take": [[569, "torch-tensor-take"]], "torch.Tensor.stride": [[557, "torch-tensor-stride"]], "torch.Tensor.split": [[544, "torch-tensor-split"]], "torch.Tensor.swapaxes": [[565, "torch-tensor-swapaxes"]], "torch.Tensor.sum": [[562, "torch-tensor-sum"]], "torch.Tensor.sqrt_": [[546, "torch-tensor-sqrt"]], "torch.Tensor.to_sparse_bsr": [[582, "torch-tensor-to-sparse-bsr"]], "torch.Tensor.sparse_mask": [[541, "torch-tensor-sparse-mask"]], "torch.Tensor.storage_type": [[556, "torch-tensor-storage-type"]], "torch.Tensor.tanh": [[573, "torch-tensor-tanh"]], "torch.Tensor.sqrt": [[545, "torch-tensor-sqrt"]], "torch.Tensor.to_mkldnn": [[579, "torch-tensor-to-mkldnn"]], "torch.Tensor.storage_offset": [[555, "torch-tensor-storage-offset"]], "torch.Tensor.tan": [[571, "torch-tensor-tan"]], "torch.Tensor.tanh_": [[574, "torch-tensor-tanh"]], "torch.Tensor.tile": [[576, "torch-tensor-tile"]], "torch.Tensor.square": [[547, "torch-tensor-square"]], "torch.Tensor.to_sparse_csr": [[585, "torch-tensor-to-sparse-csr"]], "torch.Tensor.to_dense": [[578, "torch-tensor-to-dense"]], "torch.Tensor.sub_": [[559, "torch-tensor-sub"]], "torch.Tensor.rot90": [[504, "torch-tensor-rot90"]], "torch.Tensor.roll": [[503, "torch-tensor-roll"]], "torch.Tensor.row_indices": [[507, "torch-tensor-row-indices"]], "torch.Tensor.retain_grad": [[501, "torch-tensor-retain-grad"]], "torch.Tensor.scatter_": [[511, "torch-tensor-scatter"]], "torch.Tensor.sigmoid": [[523, "torch-tensor-sigmoid"]], "torch.Tensor.repeat_interleave": [[492, "torch-tensor-repeat-interleave"]], "torch.Tensor.scatter_add_": [[513, "torch-tensor-scatter-add"]], "torch.Tensor.share_memory_": [[521, "torch-tensor-share-memory"]], "torch.Tensor.reshape_as": [[496, "torch-tensor-reshape-as"]], "torch.Tensor.sgn": [[519, "torch-tensor-sgn"]], "torch.Tensor.smm": [[537, "torch-tensor-smm"]], "torch.Tensor.renorm_": [[490, "torch-tensor-renorm"]], "torch.Tensor.signbit": [[527, "torch-tensor-signbit"]], "torch.Tensor.select_scatter": [[517, "torch-tensor-select-scatter"]], "torch.Tensor.resolve_conj": [[499, "torch-tensor-resolve-conj"]], "torch.Tensor.resolve_neg": [[500, "torch-tensor-resolve-neg"]], "torch.Tensor.resize_as_": [[498, "torch-tensor-resize-as"]], "torch.Tensor.short": [[522, "torch-tensor-short"]], "torch.Tensor.sgn_": [[520, "torch-tensor-sgn"]], "torch.Tensor.size": [[534, "torch-tensor-size"]], "torch.Tensor.sinh_": [[533, "torch-tensor-sinh"]], "torch.Tensor.sinh": [[532, "torch-tensor-sinh"]], "torch.Tensor.sin_": [[529, "torch-tensor-sin"]], "torch.Tensor.repeat": [[491, "torch-tensor-repeat"]], "torch.Tensor.requires_grad_": [[494, "torch-tensor-requires-grad"]], "torch.Tensor.round_": [[506, "torch-tensor-round"]], "torch.Tensor.sin": [[528, "torch-tensor-sin"]], "torch.Tensor.slogdet": [[536, "torch-tensor-slogdet"]], "torch.Tensor.scatter_reduce": [[514, "torch-tensor-scatter-reduce"]], "torch.Tensor.scatter_add": [[512, "torch-tensor-scatter-add"]], "torch.Tensor.select": [[516, "torch-tensor-select"]], "torch.Tensor.requires_grad": [[493, "torch-tensor-requires-grad"]], "torch.Tensor.scatter_reduce_": [[515, "torch-tensor-scatter-reduce"]], "torch.Tensor.resize_": [[497, "torch-tensor-resize"]], "torch.Tensor.sign_": [[526, "torch-tensor-sign"]], "torch.Tensor.reshape": [[495, "torch-tensor-reshape"]], "torch.Tensor.set_": [[518, "torch-tensor-set"]], "torch.Tensor.scatter": [[510, "torch-tensor-scatter"]], "torch.Tensor.sign": [[525, "torch-tensor-sign"]], "torch.Tensor.sigmoid_": [[524, "torch-tensor-sigmoid"]], "torch.Tensor.slice_scatter": [[535, "torch-tensor-slice-scatter"]], "torch.Tensor.sinc": [[530, "torch-tensor-sinc"]], "torch.Tensor.round": [[505, "torch-tensor-round"]], "torch.Tensor.rsqrt_": [[509, "torch-tensor-rsqrt"]], "torch.Tensor.rsqrt": [[508, "torch-tensor-rsqrt"]], "torch.Tensor.softmax": [[538, "torch-tensor-softmax"]], "torch.Tensor.retains_grad": [[502, "torch-tensor-retains-grad"]], "torch.Tensor.sinc_": [[531, "torch-tensor-sinc"]], "torch.Tensor.orgqr": [[458, "torch-tensor-orgqr"]], "torch.Tensor.ormqr": [[459, "torch-tensor-ormqr"]], "torch.Tensor.qr": [[476, "torch-tensor-qr"]], "torch.Tensor.ravel": [[481, "torch-tensor-ravel"]], "torch.Tensor.new_ones": [[446, "torch-tensor-new-ones"]], "torch.Tensor.remainder_": [[488, "torch-tensor-remainder"]], "torch.Tensor.reciprocal_": [[484, "torch-tensor-reciprocal"]], "torch.Tensor.new_zeros": [[448, "torch-tensor-new-zeros"]], "torch.Tensor.q_scale": [[474, "torch-tensor-q-scale"]], "torch.Tensor.renorm": [[489, "torch-tensor-renorm"]], "torch.Tensor.q_zero_point": [[475, "torch-tensor-q-zero-point"]], "torch.Tensor.norm": [[452, "torch-tensor-norm"]], "torch.Tensor.prod": [[469, "torch-tensor-prod"]], "torch.Tensor.record_stream": [[485, "torch-tensor-record-stream"]], "torch.Tensor.quantile": [[478, "torch-tensor-quantile"]], "torch.Tensor.register_hook": [[486, "torch-tensor-register-hook"]], "torch.Tensor.numel": [[456, "torch-tensor-numel"]], "torch.Tensor.nextafter_": [[450, "torch-tensor-nextafter"]], "torch.Tensor.negative": [[441, "torch-tensor-negative"]], "torch.Tensor.nonzero": [[451, "torch-tensor-nonzero"]], "torch.Tensor.rad2deg": [[479, "torch-tensor-rad2deg"]], "torch.Tensor.nelement": [[443, "torch-tensor-nelement"]], "torch.Tensor.new_tensor": [[447, "torch-tensor-new-tensor"]], "torch.Tensor.polygamma_": [[465, "torch-tensor-polygamma"]], "torch.Tensor.not_equal_": [[455, "torch-tensor-not-equal"]], "torch.Tensor.new_full": [[445, "torch-tensor-new-full"]], "torch.Tensor.normal_": [[453, "torch-tensor-normal"]], "torch.Tensor.pow": [[467, "torch-tensor-pow"]], "torch.Tensor.pow_": [[468, "torch-tensor-pow"]], "torch.Tensor.random_": [[480, "torch-tensor-random"]], "torch.Tensor.q_per_channel_axis": [[471, "torch-tensor-q-per-channel-axis"]], "torch.Tensor.remainder": [[487, "torch-tensor-remainder"]], "torch.Tensor.negative_": [[442, "torch-tensor-negative"]], "torch.Tensor.polygamma": [[464, "torch-tensor-polygamma"]], "torch.Tensor.numpy": [[457, "torch-tensor-numpy"]], "torch.Tensor.new_empty": [[444, "torch-tensor-new-empty"]], "torch.Tensor.nextafter": [[449, "torch-tensor-nextafter"]], "torch.Tensor.qscheme": [[477, "torch-tensor-qscheme"]], "torch.Tensor.q_per_channel_scales": [[472, "torch-tensor-q-per-channel-scales"]], "torch.Tensor.real": [[482, "torch-tensor-real"]], "torch.Tensor.put_": [[470, "torch-tensor-put"]], "torch.Tensor.outer": [[460, "torch-tensor-outer"]], "torch.Tensor.pin_memory": [[462, "torch-tensor-pin-memory"]], "torch.Tensor.pinverse": [[463, "torch-tensor-pinverse"]], "torch.Tensor.not_equal": [[454, "torch-tensor-not-equal"]], "torch.Tensor.positive": [[466, "torch-tensor-positive"]], "torch.Tensor.permute": [[461, "torch-tensor-permute"]], "torch.Tensor.q_per_channel_zero_points": [[473, "torch-tensor-q-per-channel-zero-points"]], "torch.Tensor.reciprocal": [[483, "torch-tensor-reciprocal"]], "torch.Tensor.movedim": [[416, "torch-tensor-movedim"]], "torch.Tensor.mm": [[413, "torch-tensor-mm"]], "torch.Tensor.map_": [[398, "torch-tensor-map"]], "torch.Tensor.mode": [[414, "torch-tensor-mode"]], "torch.Tensor.median": [[410, "torch-tensor-median"]], "torch.Tensor.mvlgamma": [[424, "torch-tensor-mvlgamma"]], "torch.Tensor.masked_fill_": [[400, "torch-tensor-masked-fill"]], "torch.Tensor.nan_to_num": [[426, "torch-tensor-nan-to-num"]], "torch.Tensor.logsumexp": [[392, "torch-tensor-logsumexp"]], "torch.Tensor.minimum": [[412, "torch-tensor-minimum"]], "torch.Tensor.max": [[407, "torch-tensor-max"]], "torch.Tensor.mv": [[423, "torch-tensor-mv"]], "torch.Tensor.matrix_power": [[406, "torch-tensor-matrix-power"]], "torch.Tensor.lt_": [[395, "torch-tensor-lt"]], "torch.Tensor.masked_select": [[403, "torch-tensor-masked-select"]], "torch.Tensor.masked_fill": [[399, "torch-tensor-masked-fill"]], "torch.Tensor.mvlgamma_": [[425, "torch-tensor-mvlgamma"]], "torch.Tensor.neg_": [[440, "torch-tensor-neg"]], "torch.Tensor.multinomial": [[420, "torch-tensor-multinomial"]], "torch.Tensor.nanmean": [[428, "torch-tensor-nanmean"]], "torch.Tensor.moveaxis": [[415, "torch-tensor-moveaxis"]], "torch.Tensor.ne_": [[438, "torch-tensor-ne"]], "torch.Tensor.ne": [[437, "torch-tensor-ne"]], "torch.Tensor.narrow_copy": [[433, "torch-tensor-narrow-copy"]], "torch.Tensor.masked_scatter": [[401, "torch-tensor-masked-scatter"]], "torch.Tensor.multiply": [[421, "torch-tensor-multiply"]], "torch.Tensor.nanmedian": [[429, "torch-tensor-nanmedian"]], "torch.Tensor.matmul": [[404, "torch-tensor-matmul"]], "torch.Tensor.matrix_exp": [[405, "torch-tensor-matrix-exp"]], "torch.Tensor.masked_scatter_": [[402, "torch-tensor-masked-scatter"]], "torch.Tensor.msort": [[417, "torch-tensor-msort"]], "torch.Tensor.nan_to_num_": [[427, "torch-tensor-nan-to-num"]], "torch.Tensor.nbytes": [[434, "torch-tensor-nbytes"]], "torch.Tensor.mean": [[409, "torch-tensor-mean"]], "torch.Tensor.maximum": [[408, "torch-tensor-maximum"]], "torch.Tensor.lu": [[396, "torch-tensor-lu"]], "torch.Tensor.long": [[393, "torch-tensor-long"]], "torch.Tensor.multiply_": [[422, "torch-tensor-multiply"]], "torch.Tensor.mul": [[418, "torch-tensor-mul"]], "torch.Tensor.mul_": [[419, "torch-tensor-mul"]], "torch.Tensor.lu_solve": [[397, "torch-tensor-lu-solve"]], "torch.Tensor.min": [[411, "torch-tensor-min"]], "torch.Tensor.ndim": [[435, "torch-tensor-ndim"]], "torch.Tensor.neg": [[439, "torch-tensor-neg"]], "torch.Tensor.nansum": [[431, "torch-tensor-nansum"]], "torch.Tensor.narrow": [[432, "torch-tensor-narrow"]], "torch.Tensor.ndimension": [[436, "torch-tensor-ndimension"]], "torch.Tensor.nanquantile": [[430, "torch-tensor-nanquantile"]], "torch.Tensor.lt": [[394, "torch-tensor-lt"]]}, "indexentries": {"optimizedmodule (class in torch._dynamo)": [[0, "torch._dynamo.OptimizedModule"]], "allow_in_graph() (in module torch._dynamo)": [[0, "torch._dynamo.allow_in_graph"]], "disable() (in module torch._dynamo)": [[0, "torch._dynamo.disable"]], "disallow_in_graph() (in module torch._dynamo)": [[0, "torch._dynamo.disallow_in_graph"]], "export() (in module torch._dynamo)": [[0, "torch._dynamo.export"]], "forbid_in_graph() (in module torch._dynamo)": [[0, "torch._dynamo.forbid_in_graph"]], "graph_break() (in module torch._dynamo)": [[0, "torch._dynamo.graph_break"]], "list_backends() (in module torch._dynamo)": [[0, "torch._dynamo.list_backends"]], "mark_dynamic() (in module torch._dynamo)": [[0, "torch._dynamo.mark_dynamic"]], "mark_static() (in module torch._dynamo)": [[0, "torch._dynamo.mark_static"]], "module": [[0, "module-torch._dynamo"], [1, "module-torch.amp"], [1, "module-torch.cpu"], [1, "module-torch.cpu.amp"], [1, "module-torch.cuda.amp"], [2, "module-torch.autograd"], [3, "module-torch.backends"], [3, "module-torch.backends.cpu"], [3, "module-torch.backends.cuda"], [3, "module-torch.backends.cudnn"], [3, "module-torch.backends.mkl"], [3, "module-torch.backends.mkldnn"], [3, "module-torch.backends.mps"], [3, "module-torch.backends.openmp"], [3, "module-torch.backends.opt_einsum"], [3, "module-torch.backends.quantized"], [3, "module-torch.backends.xeon"], [3, "module-torch.backends.xnnpack"], [4, "module-torch.utils.benchmark"], [4, "module-torch.utils.benchmark.examples"], [4, "module-torch.utils.benchmark.op_fuzzers"], [4, "module-torch.utils.benchmark.utils"], [4, "module-torch.utils.benchmark.utils.valgrind_wrapper"], [5, "module-torch.utils.bottleneck"], [31, "module-torch.__config__"], [34, "module-torch.cuda"], [35, "module-torch.cuda._sanitizer"], [38, "module-torch.utils.data"], [38, "module-torch.utils.data.datapipes"], [38, "module-torch.utils.data.datapipes.dataframe"], [38, "module-torch.utils.data.datapipes.iter"], [38, "module-torch.utils.data.datapipes.map"], [38, "module-torch.utils.data.datapipes.utils"], [41, "module-torch.distributed"], [41, "module-torch.distributed.algorithms"], [41, "module-torch.distributed.algorithms.ddp_comm_hooks"], [41, "module-torch.distributed.algorithms.model_averaging"], [41, "module-torch.distributed.elastic"], [41, "module-torch.distributed.elastic.utils"], [41, "module-torch.distributed.elastic.utils.data"], [41, "module-torch.distributed.launch"], [41, "module-torch.distributed.launcher"], [41, "module-torch.distributed.nn"], [41, "module-torch.distributed.nn.api"], [41, "module-torch.distributed.nn.jit"], [41, "module-torch.distributed.nn.jit.templates"], [41, "module-torch.distributed.pipeline"], [41, "module-torch.distributed.pipeline.sync"], [41, "module-torch.distributed.pipeline.sync.skip"], [41, "module-torch.distributed.tensor"], [43, "module-torch.distributed.checkpoint"], [45, "module-torch.distributed.optim"], [46, "module-torch.distributed.tensor.parallel"], [47, "module-torch.distributions"], [47, "module-torch.distributions.constraint_registry"], [47, "module-torch.distributions.constraints"], [47, "module-torch.distributions.kl"], [47, "module-torch.distributions.transforms"], [49, "module-torch.distributed.elastic.agent"], [49, "module-torch.distributed.elastic.agent.server"], [51, "module-torch.distributed.elastic.multiprocessing.errors"], [52, "module-torch.distributed.elastic.events"], [55, "module-torch.distributed.elastic.metrics"], [56, "module-torch.distributed.elastic.multiprocessing"], [58, "module-torch.distributed.elastic.rendezvous"], [58, "module-torch.distributed.elastic.rendezvous.registry"], [59, "module-torch.distributed.run"], [60, "module-torch.distributed.elastic.timer"], [62, "module-torch.fft"], [63, "module-torch.distributed.fsdp"], [65, "module-torch.func"], [70, "module-torch.futures"], [71, "module-torch.fx"], [71, "module-torch.fx.experimental"], [71, "module-torch.fx.experimental.migrate_gradual_types"], [71, "module-torch.fx.experimental.unification"], [71, "module-torch.fx.experimental.unification.multipledispatch"], [71, "module-torch.fx.passes"], [71, "module-torch.fx.passes.backends"], [71, "module-torch.fx.passes.dialect"], [71, "module-torch.fx.passes.dialect.common"], [71, "module-torch.fx.passes.infra"], [71, "module-torch.fx.passes.tests"], [71, "module-torch.fx.passes.utils"], [1857, "module-torch.hub"], [1860, "module-torch.jit"], [1860, "module-torch.jit.mobile"], [1861, "module-torch.jit.supported_ops"], [1865, "module-torch.jit.unsupported_tensor_ops"], [1866, "module-torch.utils.jit"], [1868, "module-torch.linalg"], [1869, "module-torch._logging"], [1870, "module-torch.masked"], [1870, "module-torch.masked.maskedtensor"], [1872, "module-torch.utils.model_zoo"], [1873, "module-torch.monitor"], [1874, "module-torch.mps"], [1875, "module-torch.multiprocessing"], [1878, "module-torch.nested"], [1879, "module-torch.nn"], [1879, "module-torch.nn.backends"], [1879, "module-torch.nn.modules"], [1879, "module-torch.nn.parallel"], [1879, "module-torch.nn.utils"], [1879, "module-torch.nn.utils.stateless"], [1901, "module-torch.onnx"], [1902, "module-torch.onnx._internal.diagnostics"], [1904, "module-torch.optim"], [1905, "module-torch.package"], [1905, "module-torch.package.analyze"], [1907, "module-torch.profiler"], [1908, "module-torch.ao"], [1908, "module-torch.ao.nn"], [1908, "module-torch.ao.nn.quantizable"], [1908, "module-torch.ao.nn.quantizable.modules"], [1908, "module-torch.ao.nn.quantized"], [1908, "module-torch.ao.nn.quantized.reference"], [1908, "module-torch.ao.nn.quantized.reference.modules"], [1908, "module-torch.ao.nn.sparse"], [1908, "module-torch.ao.nn.sparse.quantized"], [1908, "module-torch.ao.nn.sparse.quantized.dynamic"], [1908, "module-torch.ao.ns"], [1908, "module-torch.ao.ns.fx"], [1908, "module-torch.ao.pruning"], [1908, "module-torch.ao.pruning.scheduler"], [1908, "module-torch.ao.pruning.sparsifier"], [1908, "module-torch.ao.quantization"], [1908, "module-torch.ao.quantization.backend_config"], [1908, "module-torch.ao.quantization.fx"], [1911, "module-torch.ao.nn.intrinsic"], [1911, "module-torch.ao.nn.intrinsic.modules"], [1911, "module-torch.ao.nn.intrinsic.qat"], [1911, "module-torch.ao.nn.intrinsic.qat.modules"], [1911, "module-torch.ao.nn.intrinsic.quantized"], [1911, "module-torch.ao.nn.intrinsic.quantized.dynamic"], [1911, "module-torch.ao.nn.intrinsic.quantized.dynamic.modules"], [1911, "module-torch.ao.nn.intrinsic.quantized.modules"], [1911, "module-torch.ao.nn.qat"], [1911, "module-torch.ao.nn.qat.dynamic"], [1911, "module-torch.ao.nn.qat.dynamic.modules"], [1911, "module-torch.ao.nn.qat.modules"], [1911, "module-torch.ao.nn.quantized.dynamic"], [1911, "module-torch.ao.nn.quantized.dynamic.modules"], [1911, "module-torch.ao.nn.quantized.functional"], [1911, "module-torch.ao.nn.quantized.modules"], [1911, "module-torch.nn.intrinsic"], [1911, "module-torch.nn.intrinsic.modules"], [1911, "module-torch.nn.intrinsic.qat"], [1911, "module-torch.nn.intrinsic.qat.modules"], [1911, "module-torch.nn.intrinsic.quantized"], [1911, "module-torch.nn.intrinsic.quantized.dynamic"], [1911, "module-torch.nn.intrinsic.quantized.dynamic.modules"], [1911, "module-torch.nn.intrinsic.quantized.modules"], [1911, "module-torch.nn.qat"], [1911, "module-torch.nn.qat.dynamic"], [1911, "module-torch.nn.qat.dynamic.modules"], [1911, "module-torch.nn.qat.modules"], [1911, "module-torch.nn.quantizable"], [1911, "module-torch.nn.quantizable.modules"], [1911, "module-torch.nn.quantized"], [1911, "module-torch.nn.quantized.dynamic"], [1911, "module-torch.nn.quantized.dynamic.modules"], [1911, "module-torch.nn.quantized.modules"], [1911, "module-torch.quantization"], [1911, "module-torch.quantization.fx"], [1912, "module-torch.random"], [1913, "module-torch.distributed.autograd"], [1913, "module-torch.distributed.rpc"], [1916, "module-torch.signal"], [1916, "module-torch.signal.windows"], [1917, "module-torch.sparse"], [1918, "module-torch.special"], [1922, "module-torch.utils.tensorboard"], [1924, "module-torch.testing"], [1925, "module-torch"], [1925, "module-torch.autograd"], [1925, "module-torch.contrib"], [1925, "module-torch.utils"], [1925, "module-torch.utils.backcompat"], [1925, "module-torch.utils.hipify"], [1925, "module-torch.utils.model_dump"], [1926, "module-torch.ao.ns._numeric_suite"], [1927, "module-torch.ao.ns._numeric_suite_fx"]], "optimize() (in module torch._dynamo)": [[0, "torch._dynamo.optimize"]], "optimize_assert() (in module torch._dynamo)": [[0, "torch._dynamo.optimize_assert"]], "register_backend() (in module torch._dynamo)": [[0, "torch._dynamo.register_backend"]], "reset() (in module torch._dynamo)": [[0, "torch._dynamo.reset"]], "run() (in module torch._dynamo)": [[0, "torch._dynamo.run"]], "torch._dynamo": [[0, "module-torch._dynamo"]], "gradscaler (class in torch.cuda.amp)": [[1, "torch.cuda.amp.GradScaler"]], "autocast (class in torch)": [[1, "torch.autocast"]], "autocast (class in torch.cpu.amp)": [[1, "torch.cpu.amp.autocast"]], "autocast (class in torch.cuda.amp)": [[1, "torch.cuda.amp.autocast"]], "custom_bwd() (in module torch.cuda.amp)": [[1, "torch.cuda.amp.custom_bwd"]], "custom_fwd() (in module torch.cuda.amp)": [[1, "torch.cuda.amp.custom_fwd"]], "get_backoff_factor() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.get_backoff_factor"]], "get_growth_factor() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.get_growth_factor"]], "get_growth_interval() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.get_growth_interval"]], "get_scale() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.get_scale"]], "is_enabled() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.is_enabled"]], "load_state_dict() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.load_state_dict"]], "scale() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.scale"]], "set_backoff_factor() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.set_backoff_factor"]], "set_growth_factor() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.set_growth_factor"]], "set_growth_interval() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.set_growth_interval"]], "state_dict() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.state_dict"]], "step() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.step"]], "torch.amp": [[1, "module-torch.amp"]], "torch.cpu": [[1, "module-torch.cpu"]], "torch.cpu.amp": [[1, "module-torch.cpu.amp"]], "torch.cuda.amp": [[1, "module-torch.cuda.amp"]], "unscale_() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.unscale_"]], "update() (torch.cuda.amp.gradscaler method)": [[1, "torch.cuda.amp.GradScaler.update"]], "function (class in torch.autograd)": [[2, "torch.autograd.Function"]], "allow_mutation_on_saved_tensors (class in torch.autograd.graph)": [[2, "torch.autograd.graph.allow_mutation_on_saved_tensors"]], "detect_anomaly (class in torch.autograd)": [[2, "torch.autograd.detect_anomaly"]], "disable_saved_tensors_hooks (class in torch.autograd.graph)": [[2, "torch.autograd.graph.disable_saved_tensors_hooks"]], "emit_itt (class in torch.autograd.profiler)": [[2, "torch.autograd.profiler.emit_itt"]], "emit_nvtx (class in torch.autograd.profiler)": [[2, "torch.autograd.profiler.emit_nvtx"]], "profile (class in torch.autograd.profiler)": [[2, "torch.autograd.profiler.profile"]], "register_multi_grad_hook (class in torch.autograd.graph)": [[2, "torch.autograd.graph.register_multi_grad_hook"]], "save_on_cpu (class in torch.autograd.graph)": [[2, "torch.autograd.graph.save_on_cpu"]], "saved_tensors_hooks (class in torch.autograd.graph)": [[2, "torch.autograd.graph.saved_tensors_hooks"]], "set_detect_anomaly (class in torch.autograd)": [[2, "torch.autograd.set_detect_anomaly"]], "torch.autograd": [[2, "module-torch.autograd"], [1925, "module-torch.autograd"]], "sdpbackend (class in torch.backends.cuda)": [[3, "torch.backends.cuda.SDPBackend"]], "allow_bf16_reduced_precision_reduction (in module torch.backends.cuda.matmul)": [[3, "torch.backends.cuda.matmul.allow_bf16_reduced_precision_reduction"]], "allow_fp16_reduced_precision_reduction (in module torch.backends.cuda.matmul)": [[3, "torch.backends.cuda.matmul.allow_fp16_reduced_precision_reduction"]], "allow_tf32 (in module torch.backends.cuda.matmul)": [[3, "torch.backends.cuda.matmul.allow_tf32"]], "allow_tf32 (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.allow_tf32"]], "benchmark (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.benchmark"]], "benchmark_limit (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.benchmark_limit"]], "clear() (in module torch.backends.cuda.cufft_plan_cache)": [[3, "torch.backends.cuda.cufft_plan_cache.clear"]], "cufft_plan_cache (in module torch.backends.cuda)": [[3, "torch.backends.cuda.cufft_plan_cache"]], "deterministic (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.deterministic"]], "enable_flash_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.enable_flash_sdp"]], "enable_math_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.enable_math_sdp"]], "enable_mem_efficient_sdp() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.enable_mem_efficient_sdp"]], "enabled (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.enabled"]], "enabled (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.enabled"]], "flash_sdp_enabled() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.flash_sdp_enabled"]], "get_cpu_capability() (in module torch.backends.cpu)": [[3, "torch.backends.cpu.get_cpu_capability"]], "get_opt_einsum() (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.get_opt_einsum"]], "is_available() (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.is_available"]], "is_available() (in module torch.backends.mkl)": [[3, "torch.backends.mkl.is_available"]], "is_available() (in module torch.backends.mkldnn)": [[3, "torch.backends.mkldnn.is_available"]], "is_available() (in module torch.backends.mps)": [[3, "torch.backends.mps.is_available"]], "is_available() (in module torch.backends.openmp)": [[3, "torch.backends.openmp.is_available"]], "is_available() (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.is_available"]], "is_built() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.is_built"]], "is_built() (in module torch.backends.mps)": [[3, "torch.backends.mps.is_built"]], "math_sdp_enabled() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.math_sdp_enabled"]], "max_size (in module torch.backends.cuda.cufft_plan_cache)": [[3, "torch.backends.cuda.cufft_plan_cache.max_size"]], "mem_efficient_sdp_enabled() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.mem_efficient_sdp_enabled"]], "preferred_linalg_library() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.preferred_linalg_library"]], "sdp_kernel() (in module torch.backends.cuda)": [[3, "torch.backends.cuda.sdp_kernel"]], "size (in module torch.backends.cuda.cufft_plan_cache)": [[3, "torch.backends.cuda.cufft_plan_cache.size"]], "strategy (in module torch.backends.opt_einsum)": [[3, "torch.backends.opt_einsum.strategy"]], "torch.backends": [[3, "module-torch.backends"]], "torch.backends.cpu": [[3, "module-torch.backends.cpu"]], "torch.backends.cuda": [[3, "module-torch.backends.cuda"]], "torch.backends.cudnn": [[3, "module-torch.backends.cudnn"]], "torch.backends.mkl": [[3, "module-torch.backends.mkl"]], "torch.backends.mkldnn": [[3, "module-torch.backends.mkldnn"]], "torch.backends.mps": [[3, "module-torch.backends.mps"]], "torch.backends.openmp": [[3, "module-torch.backends.openmp"]], "torch.backends.opt_einsum": [[3, "module-torch.backends.opt_einsum"]], "torch.backends.quantized": [[3, "module-torch.backends.quantized"]], "torch.backends.xeon": [[3, "module-torch.backends.xeon"]], "torch.backends.xnnpack": [[3, "module-torch.backends.xnnpack"]], "verbose (class in torch.backends.mkl)": [[3, "torch.backends.mkl.verbose"]], "verbose (class in torch.backends.mkldnn)": [[3, "torch.backends.mkldnn.verbose"]], "version() (in module torch.backends.cudnn)": [[3, "torch.backends.cudnn.version"]], "callgrindstats (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.CallgrindStats"]], "functioncounts (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.FunctionCounts"]], "measurement (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.Measurement"]], "timer (class in torch.utils.benchmark)": [[4, "torch.utils.benchmark.Timer"]], "as_standardized() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.as_standardized"]], "blocked_autorange() (torch.utils.benchmark.timer method)": [[4, "torch.utils.benchmark.Timer.blocked_autorange"]], "collect_callgrind() (torch.utils.benchmark.timer method)": [[4, "torch.utils.benchmark.Timer.collect_callgrind"]], "counts() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.counts"]], "delta() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.delta"]], "denoise() (torch.utils.benchmark.functioncounts method)": [[4, "torch.utils.benchmark.FunctionCounts.denoise"]], "filter() (torch.utils.benchmark.functioncounts method)": [[4, "torch.utils.benchmark.FunctionCounts.filter"]], "merge() (torch.utils.benchmark.measurement static method)": [[4, "torch.utils.benchmark.Measurement.merge"]], "significant_figures (torch.utils.benchmark.measurement property)": [[4, "torch.utils.benchmark.Measurement.significant_figures"]], "stats() (torch.utils.benchmark.callgrindstats method)": [[4, "torch.utils.benchmark.CallgrindStats.stats"]], "timeit() (torch.utils.benchmark.timer method)": [[4, "torch.utils.benchmark.Timer.timeit"]], "torch.utils.benchmark": [[4, "module-torch.utils.benchmark"]], "torch.utils.benchmark.examples": [[4, "module-torch.utils.benchmark.examples"]], "torch.utils.benchmark.op_fuzzers": [[4, "module-torch.utils.benchmark.op_fuzzers"]], "torch.utils.benchmark.utils": [[4, "module-torch.utils.benchmark.utils"]], "torch.utils.benchmark.utils.valgrind_wrapper": [[4, "module-torch.utils.benchmark.utils.valgrind_wrapper"]], "transform() (torch.utils.benchmark.functioncounts method)": [[4, "torch.utils.benchmark.FunctionCounts.transform"]], "torch.utils.bottleneck": [[5, "module-torch.utils.bottleneck"]], "checkpoint() (in module torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.checkpoint"]], "checkpoint_sequential() (in module torch.utils.checkpoint)": [[6, "torch.utils.checkpoint.checkpoint_sequential"]], "compile() (in module torch)": [[19, "torch.compile"], [950, "torch.compile"]], "parallel_info() (in module torch.__config__)": [[31, "torch.__config__.parallel_info"]], "show() (in module torch.__config__)": [[31, "torch.__config__.show"]], "torch.__config__": [[31, "module-torch.__config__"]], "buildextension() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.BuildExtension"]], "cudaextension() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.CUDAExtension"]], "cppextension() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.CppExtension"]], "get_compiler_abi_compatibility_and_version() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.get_compiler_abi_compatibility_and_version"]], "include_paths() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.include_paths"]], "is_ninja_available() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.is_ninja_available"]], "load() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.load"]], "load_inline() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.load_inline"]], "verify_ninja_availability() (in module torch.utils.cpp_extension)": [[32, "torch.utils.cpp_extension.verify_ninja_availability"]], "torch.cuda": [[34, "module-torch.cuda"]], "enable_cuda_sanitizer() (in module torch.cuda._sanitizer)": [[35, "torch.cuda._sanitizer.enable_cuda_sanitizer"]], "torch.cuda._sanitizer": [[35, "module-torch.cuda._sanitizer"]], "batchsampler (class in torch.utils.data)": [[38, "torch.utils.data.BatchSampler"]], "chaindataset (class in torch.utils.data)": [[38, "torch.utils.data.ChainDataset"]], "concatdataset (class in torch.utils.data)": [[38, "torch.utils.data.ConcatDataset"]], "dataloader (class in torch.utils.data)": [[38, "torch.utils.data.DataLoader"]], "dataset (class in torch.utils.data)": [[38, "torch.utils.data.Dataset"]], "distributedsampler (class in torch.utils.data.distributed)": [[38, "torch.utils.data.distributed.DistributedSampler"]], "iterabledataset (class in torch.utils.data)": [[38, "torch.utils.data.IterableDataset"]], "randomsampler (class in torch.utils.data)": [[38, "torch.utils.data.RandomSampler"]], "sampler (class in torch.utils.data)": [[38, "torch.utils.data.Sampler"]], "sequentialsampler (class in torch.utils.data)": [[38, "torch.utils.data.SequentialSampler"]], "stackdataset (class in torch.utils.data)": [[38, "torch.utils.data.StackDataset"]], "subset (class in torch.utils.data)": [[38, "torch.utils.data.Subset"]], "subsetrandomsampler (class in torch.utils.data)": [[38, "torch.utils.data.SubsetRandomSampler"]], "tensordataset (class in torch.utils.data)": [[38, "torch.utils.data.TensorDataset"]], "weightedrandomsampler (class in torch.utils.data)": [[38, "torch.utils.data.WeightedRandomSampler"]], "collate() (in module torch.utils.data._utils.collate)": [[38, "torch.utils.data._utils.collate.collate"]], "default_collate() (in module torch.utils.data)": [[38, "torch.utils.data.default_collate"]], "default_convert() (in module torch.utils.data)": [[38, "torch.utils.data.default_convert"]], "get_worker_info() (in module torch.utils.data)": [[38, "torch.utils.data.get_worker_info"]], "random_split() (in module torch.utils.data)": [[38, "torch.utils.data.random_split"]], "torch.utils.data": [[38, "module-torch.utils.data"]], "torch.utils.data.datapipes": [[38, "module-torch.utils.data.datapipes"]], "torch.utils.data.datapipes.dataframe": [[38, "module-torch.utils.data.datapipes.dataframe"]], "torch.utils.data.datapipes.iter": [[38, "module-torch.utils.data.datapipes.iter"]], "torch.utils.data.datapipes.map": [[38, "module-torch.utils.data.datapipes.map"]], "torch.utils.data.datapipes.utils": [[38, "module-torch.utils.data.datapipes.utils"]], "gradbucket (class in torch.distributed)": [[39, "torch.distributed.GradBucket"]], "powersgdstate (class in torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState"]], "__getstate__() (torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook.powersgdstate method)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__getstate__"]], "__setstate__() (torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook.powersgdstate method)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.PowerSGDState.__setstate__"]], "allreduce_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.allreduce_hook"]], "batched_powersgd_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.batched_powerSGD_hook"]], "bf16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_hook"]], "bf16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.bf16_compress_wrapper"]], "buffer() (in module torch.distributed.gradbucket)": [[39, "torch.distributed.GradBucket.buffer"]], "fp16_compress_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_hook"]], "fp16_compress_wrapper() (in module torch.distributed.algorithms.ddp_comm_hooks.default_hooks)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.default_hooks.fp16_compress_wrapper"]], "gradients() (in module torch.distributed.gradbucket)": [[39, "torch.distributed.GradBucket.gradients"]], "index() (in module torch.distributed.gradbucket)": [[39, "torch.distributed.GradBucket.index"]], "is_last() (in module torch.distributed.gradbucket)": [[39, "torch.distributed.GradBucket.is_last"]], "noop_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.debugging_hooks.noop_hook"]], "parameters() (in module torch.distributed.gradbucket)": [[39, "torch.distributed.GradBucket.parameters"]], "powersgd_hook() (in module torch.distributed.algorithms.ddp_comm_hooks.powersgd_hook)": [[39, "torch.distributed.algorithms.ddp_comm_hooks.powerSGD_hook.powerSGD_hook"]], "set_buffer() (in module torch.distributed.gradbucket)": [[39, "torch.distributed.GradBucket.set_buffer"]], "backend (class in torch.distributed)": [[41, "torch.distributed.Backend"]], "distbackenderror (class in torch.distributed)": [[41, "torch.distributed.DistBackendError"]], "filestore (class in torch.distributed)": [[41, "torch.distributed.FileStore"]], "hashstore (class in torch.distributed)": [[41, "torch.distributed.HashStore"]], "p2pop (class in torch.distributed)": [[41, "torch.distributed.P2POp"]], "prefixstore (class in torch.distributed)": [[41, "torch.distributed.PrefixStore"]], "reduceop (class in torch.distributed)": [[41, "torch.distributed.ReduceOp"]], "store (class in torch.distributed)": [[41, "torch.distributed.Store"]], "tcpstore (class in torch.distributed)": [[41, "torch.distributed.TCPStore"]], "add() (in module torch.distributed.store)": [[41, "torch.distributed.Store.add"]], "all_gather() (in module torch.distributed)": [[41, "torch.distributed.all_gather"]], "all_gather_into_tensor() (in module torch.distributed)": [[41, "torch.distributed.all_gather_into_tensor"]], "all_gather_multigpu() (in module torch.distributed)": [[41, "torch.distributed.all_gather_multigpu"]], "all_gather_object() (in module torch.distributed)": [[41, "torch.distributed.all_gather_object"]], "all_reduce() (in module torch.distributed)": [[41, "torch.distributed.all_reduce"]], "all_reduce_multigpu() (in module torch.distributed)": [[41, "torch.distributed.all_reduce_multigpu"]], "all_to_all() (in module torch.distributed)": [[41, "torch.distributed.all_to_all"]], "all_to_all_single() (in module torch.distributed)": [[41, "torch.distributed.all_to_all_single"]], "barrier() (in module torch.distributed)": [[41, "torch.distributed.barrier"]], "batch_isend_irecv() (in module torch.distributed)": [[41, "torch.distributed.batch_isend_irecv"]], "broadcast() (in module torch.distributed)": [[41, "torch.distributed.broadcast"]], "broadcast_multigpu() (in module torch.distributed)": [[41, "torch.distributed.broadcast_multigpu"]], "broadcast_object_list() (in module torch.distributed)": [[41, "torch.distributed.broadcast_object_list"]], "compare_set() (in module torch.distributed.store)": [[41, "torch.distributed.Store.compare_set"]], "delete_key() (in module torch.distributed.store)": [[41, "torch.distributed.Store.delete_key"]], "gather() (in module torch.distributed)": [[41, "torch.distributed.gather"]], "gather_object() (in module torch.distributed)": [[41, "torch.distributed.gather_object"]], "get() (in module torch.distributed.store)": [[41, "torch.distributed.Store.get"]], "get_backend() (in module torch.distributed)": [[41, "torch.distributed.get_backend"]], "get_global_rank() (in module torch.distributed)": [[41, "torch.distributed.get_global_rank"]], "get_group_rank() (in module torch.distributed)": [[41, "torch.distributed.get_group_rank"]], "get_process_group_ranks() (in module torch.distributed)": [[41, "torch.distributed.get_process_group_ranks"]], "get_rank() (in module torch.distributed)": [[41, "torch.distributed.get_rank"]], "get_world_size() (in module torch.distributed)": [[41, "torch.distributed.get_world_size"]], "init_process_group() (in module torch.distributed)": [[41, "torch.distributed.init_process_group"]], "irecv() (in module torch.distributed)": [[41, "torch.distributed.irecv"]], "is_available() (in module torch.distributed)": [[41, "torch.distributed.is_available"]], "is_gloo_available() (in module torch.distributed)": [[41, "torch.distributed.is_gloo_available"]], "is_initialized() (in module torch.distributed)": [[41, "torch.distributed.is_initialized"]], "is_mpi_available() (in module torch.distributed)": [[41, "torch.distributed.is_mpi_available"]], "is_nccl_available() (in module torch.distributed)": [[41, "torch.distributed.is_nccl_available"]], "is_torchelastic_launched() (in module torch.distributed)": [[41, "torch.distributed.is_torchelastic_launched"]], "isend() (in module torch.distributed)": [[41, "torch.distributed.isend"]], "monitored_barrier() (in module torch.distributed)": [[41, "torch.distributed.monitored_barrier"]], "new_group() (in module torch.distributed)": [[41, "torch.distributed.new_group"]], "num_keys() (in module torch.distributed.store)": [[41, "torch.distributed.Store.num_keys"]], "recv() (in module torch.distributed)": [[41, "torch.distributed.recv"]], "reduce() (in module torch.distributed)": [[41, "torch.distributed.reduce"]], "reduce_multigpu() (in module torch.distributed)": [[41, "torch.distributed.reduce_multigpu"]], "reduce_op (class in torch.distributed)": [[41, "torch.distributed.reduce_op"]], "reduce_scatter() (in module torch.distributed)": [[41, "torch.distributed.reduce_scatter"]], "reduce_scatter_multigpu() (in module torch.distributed)": [[41, "torch.distributed.reduce_scatter_multigpu"]], "reduce_scatter_tensor() (in module torch.distributed)": [[41, "torch.distributed.reduce_scatter_tensor"]], "register_backend() (torch.distributed.backend class method)": [[41, "torch.distributed.Backend.register_backend"]], "scatter() (in module torch.distributed)": [[41, "torch.distributed.scatter"]], "scatter_object_list() (in module torch.distributed)": [[41, "torch.distributed.scatter_object_list"]], "send() (in module torch.distributed)": [[41, "torch.distributed.send"]], "set() (in module torch.distributed.store)": [[41, "torch.distributed.Store.set"]], "set_timeout() (in module torch.distributed.store)": [[41, "torch.distributed.Store.set_timeout"]], "torch.distributed": [[41, "module-torch.distributed"]], "torch.distributed.algorithms": [[41, "module-torch.distributed.algorithms"]], "torch.distributed.algorithms.ddp_comm_hooks": [[41, "module-torch.distributed.algorithms.ddp_comm_hooks"]], "torch.distributed.algorithms.model_averaging": [[41, "module-torch.distributed.algorithms.model_averaging"]], "torch.distributed.elastic": [[41, "module-torch.distributed.elastic"]], "torch.distributed.elastic.utils": [[41, "module-torch.distributed.elastic.utils"]], "torch.distributed.elastic.utils.data": [[41, "module-torch.distributed.elastic.utils.data"]], "torch.distributed.launch": [[41, "module-torch.distributed.launch"]], "torch.distributed.launcher": [[41, "module-torch.distributed.launcher"]], "torch.distributed.nn": [[41, "module-torch.distributed.nn"]], "torch.distributed.nn.api": [[41, "module-torch.distributed.nn.api"]], "torch.distributed.nn.jit": [[41, "module-torch.distributed.nn.jit"]], "torch.distributed.nn.jit.templates": [[41, "module-torch.distributed.nn.jit.templates"]], "torch.distributed.pipeline": [[41, "module-torch.distributed.pipeline"]], "torch.distributed.pipeline.sync": [[41, "module-torch.distributed.pipeline.sync"]], "torch.distributed.pipeline.sync.skip": [[41, "module-torch.distributed.pipeline.sync.skip"]], "torch.distributed.tensor": [[41, "module-torch.distributed.tensor"]], "wait() (in module torch.distributed.store)": [[41, "torch.distributed.Store.wait"]], "join (class in torch.distributed.algorithms)": [[42, "torch.distributed.algorithms.Join"]], "joinhook (class in torch.distributed.algorithms)": [[42, "torch.distributed.algorithms.JoinHook"]], "joinable (class in torch.distributed.algorithms)": [[42, "torch.distributed.algorithms.Joinable"]], "join_device (torch.distributed.algorithms.joinable property)": [[42, "torch.distributed.algorithms.Joinable.join_device"]], "join_hook() (torch.distributed.algorithms.joinable method)": [[42, "torch.distributed.algorithms.Joinable.join_hook"]], "join_process_group (torch.distributed.algorithms.joinable property)": [[42, "torch.distributed.algorithms.Joinable.join_process_group"]], "main_hook() (torch.distributed.algorithms.joinhook method)": [[42, "torch.distributed.algorithms.JoinHook.main_hook"]], "notify_join_context() (torch.distributed.algorithms.join static method)": [[42, "torch.distributed.algorithms.Join.notify_join_context"]], "post_hook() (torch.distributed.algorithms.joinhook method)": [[42, "torch.distributed.algorithms.JoinHook.post_hook"]], "defaultloadplanner (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.DefaultLoadPlanner"]], "defaultsaveplanner (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.DefaultSavePlanner"]], "filesystemreader (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.FileSystemReader"]], "filesystemwriter (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.FileSystemWriter"]], "loadplan (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.LoadPlan"]], "loadplanner (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.LoadPlanner"]], "readitem (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.ReadItem"]], "saveplan (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.SavePlan"]], "saveplanner (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.SavePlanner"]], "storagereader (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.StorageReader"]], "storagewriter (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.StorageWriter"]], "writeitem (class in torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.WriteItem"]], "commit_tensor() (torch.distributed.checkpoint.loadplanner method)": [[43, "torch.distributed.checkpoint.LoadPlanner.commit_tensor"]], "create_global_plan() (torch.distributed.checkpoint.loadplanner method)": [[43, "torch.distributed.checkpoint.LoadPlanner.create_global_plan"]], "create_global_plan() (torch.distributed.checkpoint.saveplanner method)": [[43, "torch.distributed.checkpoint.SavePlanner.create_global_plan"]], "create_local_plan() (torch.distributed.checkpoint.loadplanner method)": [[43, "torch.distributed.checkpoint.LoadPlanner.create_local_plan"]], "create_local_plan() (torch.distributed.checkpoint.saveplanner method)": [[43, "torch.distributed.checkpoint.SavePlanner.create_local_plan"]], "finish() (torch.distributed.checkpoint.storagewriter method)": [[43, "torch.distributed.checkpoint.StorageWriter.finish"]], "finish_plan() (torch.distributed.checkpoint.loadplanner method)": [[43, "torch.distributed.checkpoint.LoadPlanner.finish_plan"]], "finish_plan() (torch.distributed.checkpoint.saveplanner method)": [[43, "torch.distributed.checkpoint.SavePlanner.finish_plan"]], "load_bytes() (torch.distributed.checkpoint.loadplanner method)": [[43, "torch.distributed.checkpoint.LoadPlanner.load_bytes"]], "load_state_dict() (in module torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.load_state_dict"]], "lookup_object() (torch.distributed.checkpoint.defaultsaveplanner method)": [[43, "torch.distributed.checkpoint.DefaultSavePlanner.lookup_object"]], "lookup_tensor() (torch.distributed.checkpoint.defaultloadplanner method)": [[43, "torch.distributed.checkpoint.DefaultLoadPlanner.lookup_tensor"]], "prepare_global_plan() (torch.distributed.checkpoint.storagereader method)": [[43, "torch.distributed.checkpoint.StorageReader.prepare_global_plan"]], "prepare_global_plan() (torch.distributed.checkpoint.storagewriter method)": [[43, "torch.distributed.checkpoint.StorageWriter.prepare_global_plan"]], "prepare_local_plan() (torch.distributed.checkpoint.storagereader method)": [[43, "torch.distributed.checkpoint.StorageReader.prepare_local_plan"]], "prepare_local_plan() (torch.distributed.checkpoint.storagewriter method)": [[43, "torch.distributed.checkpoint.StorageWriter.prepare_local_plan"]], "read_data() (torch.distributed.checkpoint.storagereader method)": [[43, "torch.distributed.checkpoint.StorageReader.read_data"]], "read_metadata() (torch.distributed.checkpoint.storagereader method)": [[43, "torch.distributed.checkpoint.StorageReader.read_metadata"]], "resolve_data() (torch.distributed.checkpoint.saveplanner method)": [[43, "torch.distributed.checkpoint.SavePlanner.resolve_data"]], "resolve_tensor() (torch.distributed.checkpoint.loadplanner method)": [[43, "torch.distributed.checkpoint.LoadPlanner.resolve_tensor"]], "save_state_dict() (in module torch.distributed.checkpoint)": [[43, "torch.distributed.checkpoint.save_state_dict"]], "set_up_planner() (torch.distributed.checkpoint.loadplanner method)": [[43, "torch.distributed.checkpoint.LoadPlanner.set_up_planner"]], "set_up_planner() (torch.distributed.checkpoint.saveplanner method)": [[43, "torch.distributed.checkpoint.SavePlanner.set_up_planner"]], "set_up_storage_reader() (torch.distributed.checkpoint.storagereader method)": [[43, "torch.distributed.checkpoint.StorageReader.set_up_storage_reader"]], "set_up_storage_writer() (torch.distributed.checkpoint.storagewriter method)": [[43, "torch.distributed.checkpoint.StorageWriter.set_up_storage_writer"]], "torch.distributed.checkpoint": [[43, "module-torch.distributed.checkpoint"]], "transform_object() (torch.distributed.checkpoint.defaultsaveplanner method)": [[43, "torch.distributed.checkpoint.DefaultSavePlanner.transform_object"]], "transform_tensor() (torch.distributed.checkpoint.defaultloadplanner method)": [[43, "torch.distributed.checkpoint.DefaultLoadPlanner.transform_tensor"]], "write_data() (torch.distributed.checkpoint.storagewriter method)": [[43, "torch.distributed.checkpoint.StorageWriter.write_data"]], "distributedoptimizer (class in torch.distributed.optim)": [[45, "torch.distributed.optim.DistributedOptimizer"]], "postlocalsgdoptimizer (class in torch.distributed.optim)": [[45, "torch.distributed.optim.PostLocalSGDOptimizer"]], "zeroredundancyoptimizer (class in torch.distributed.optim)": [[45, "torch.distributed.optim.ZeroRedundancyOptimizer"]], "add_param_group() (torch.distributed.optim.zeroredundancyoptimizer method)": [[45, "torch.distributed.optim.ZeroRedundancyOptimizer.add_param_group"]], "consolidate_state_dict() (torch.distributed.optim.zeroredundancyoptimizer method)": [[45, "torch.distributed.optim.ZeroRedundancyOptimizer.consolidate_state_dict"]], "join_hook() (torch.distributed.optim.zeroredundancyoptimizer method)": [[45, "torch.distributed.optim.ZeroRedundancyOptimizer.join_hook"]], "load_state_dict() (torch.distributed.optim.postlocalsgdoptimizer method)": [[45, "torch.distributed.optim.PostLocalSGDOptimizer.load_state_dict"]], "load_state_dict() (torch.distributed.optim.zeroredundancyoptimizer method)": [[45, "torch.distributed.optim.ZeroRedundancyOptimizer.load_state_dict"]], "state_dict() (torch.distributed.optim.postlocalsgdoptimizer method)": [[45, "torch.distributed.optim.PostLocalSGDOptimizer.state_dict"]], "state_dict() (torch.distributed.optim.zeroredundancyoptimizer method)": [[45, "torch.distributed.optim.ZeroRedundancyOptimizer.state_dict"]], "step() (torch.distributed.optim.distributedoptimizer method)": [[45, "torch.distributed.optim.DistributedOptimizer.step"]], "step() (torch.distributed.optim.postlocalsgdoptimizer method)": [[45, "torch.distributed.optim.PostLocalSGDOptimizer.step"]], "step() (torch.distributed.optim.zeroredundancyoptimizer method)": [[45, "torch.distributed.optim.ZeroRedundancyOptimizer.step"]], "torch.distributed.optim": [[45, "module-torch.distributed.optim"]], "colwiseparallel (class in torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.ColwiseParallel"]], "pairwiseparallel (class in torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.PairwiseParallel"]], "rowwiseparallel (class in torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.RowwiseParallel"]], "sequenceparallel (class in torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.SequenceParallel"]], "tensorparallelmultiheadattention (class in torch.distributed.tensor.parallel.multihead_attention_tp)": [[46, "torch.distributed.tensor.parallel.multihead_attention_tp.TensorParallelMultiheadAttention"]], "enable_2d_with_fsdp() (in module torch.distributed.tensor.parallel.fsdp)": [[46, "torch.distributed.tensor.parallel.fsdp.enable_2d_with_fsdp"]], "make_input_replicate_1d() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_input_replicate_1d"]], "make_input_reshard_replicate() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_input_reshard_replicate"]], "make_input_shard_1d() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_input_shard_1d"]], "make_input_shard_1d_last_dim() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_input_shard_1d_last_dim"]], "make_output_replicate_1d() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_output_replicate_1d"]], "make_output_reshard_tensor() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_output_reshard_tensor"]], "make_output_shard_1d() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_output_shard_1d"]], "make_output_tensor() (in module torch.distributed.tensor.parallel.style)": [[46, "torch.distributed.tensor.parallel.style.make_output_tensor"]], "parallelize_module() (in module torch.distributed.tensor.parallel)": [[46, "torch.distributed.tensor.parallel.parallelize_module"]], "torch.distributed.tensor.parallel": [[46, "module-torch.distributed.tensor.parallel"]], "abstransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.AbsTransform"]], "affinetransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.AffineTransform"]], "bernoulli (class in torch.distributions.bernoulli)": [[47, "torch.distributions.bernoulli.Bernoulli"]], "beta (class in torch.distributions.beta)": [[47, "torch.distributions.beta.Beta"]], "binomial (class in torch.distributions.binomial)": [[47, "torch.distributions.binomial.Binomial"]], "cattransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.CatTransform"]], "categorical (class in torch.distributions.categorical)": [[47, "torch.distributions.categorical.Categorical"]], "cauchy (class in torch.distributions.cauchy)": [[47, "torch.distributions.cauchy.Cauchy"]], "chi2 (class in torch.distributions.chi2)": [[47, "torch.distributions.chi2.Chi2"]], "composetransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.ComposeTransform"]], "constraint (class in torch.distributions.constraints)": [[47, "torch.distributions.constraints.Constraint"]], "constraintregistry (class in torch.distributions.constraint_registry)": [[47, "torch.distributions.constraint_registry.ConstraintRegistry"]], "continuousbernoulli (class in torch.distributions.continuous_bernoulli)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli"]], "corrcholeskytransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.CorrCholeskyTransform"]], "cumulativedistributiontransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.CumulativeDistributionTransform"]], "dirichlet (class in torch.distributions.dirichlet)": [[47, "torch.distributions.dirichlet.Dirichlet"]], "distribution (class in torch.distributions.distribution)": [[47, "torch.distributions.distribution.Distribution"]], "exptransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.ExpTransform"]], "exponential (class in torch.distributions.exponential)": [[47, "torch.distributions.exponential.Exponential"]], "exponentialfamily (class in torch.distributions.exp_family)": [[47, "torch.distributions.exp_family.ExponentialFamily"]], "fishersnedecor (class in torch.distributions.fishersnedecor)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor"]], "gamma (class in torch.distributions.gamma)": [[47, "torch.distributions.gamma.Gamma"]], "geometric (class in torch.distributions.geometric)": [[47, "torch.distributions.geometric.Geometric"]], "gumbel (class in torch.distributions.gumbel)": [[47, "torch.distributions.gumbel.Gumbel"]], "halfcauchy (class in torch.distributions.half_cauchy)": [[47, "torch.distributions.half_cauchy.HalfCauchy"]], "halfnormal (class in torch.distributions.half_normal)": [[47, "torch.distributions.half_normal.HalfNormal"]], "independent (class in torch.distributions.independent)": [[47, "torch.distributions.independent.Independent"]], "independenttransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.IndependentTransform"]], "kumaraswamy (class in torch.distributions.kumaraswamy)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy"]], "lkjcholesky (class in torch.distributions.lkj_cholesky)": [[47, "torch.distributions.lkj_cholesky.LKJCholesky"]], "laplace (class in torch.distributions.laplace)": [[47, "torch.distributions.laplace.Laplace"]], "lognormal (class in torch.distributions.log_normal)": [[47, "torch.distributions.log_normal.LogNormal"]], "logitrelaxedbernoulli (class in torch.distributions.relaxed_bernoulli)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli"]], "lowrankmultivariatenormal (class in torch.distributions.lowrank_multivariate_normal)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal"]], "lowercholeskytransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.LowerCholeskyTransform"]], "mixturesamefamily (class in torch.distributions.mixture_same_family)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily"]], "multinomial (class in torch.distributions.multinomial)": [[47, "torch.distributions.multinomial.Multinomial"]], "multivariatenormal (class in torch.distributions.multivariate_normal)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal"]], "negativebinomial (class in torch.distributions.negative_binomial)": [[47, "torch.distributions.negative_binomial.NegativeBinomial"]], "normal (class in torch.distributions.normal)": [[47, "torch.distributions.normal.Normal"]], "onehotcategorical (class in torch.distributions.one_hot_categorical)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical"]], "pareto (class in torch.distributions.pareto)": [[47, "torch.distributions.pareto.Pareto"]], "poisson (class in torch.distributions.poisson)": [[47, "torch.distributions.poisson.Poisson"]], "positivedefinitetransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.PositiveDefiniteTransform"]], "powertransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.PowerTransform"]], "relaxedbernoulli (class in torch.distributions.relaxed_bernoulli)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli"]], "relaxedonehotcategorical (class in torch.distributions.relaxed_categorical)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical"]], "reshapetransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.ReshapeTransform"]], "sigmoidtransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.SigmoidTransform"]], "softmaxtransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.SoftmaxTransform"]], "softplustransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.SoftplusTransform"]], "stacktransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.StackTransform"]], "stickbreakingtransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.StickBreakingTransform"]], "studentt (class in torch.distributions.studentt)": [[47, "torch.distributions.studentT.StudentT"]], "tanhtransform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.TanhTransform"]], "transform (class in torch.distributions.transforms)": [[47, "torch.distributions.transforms.Transform"]], "transformeddistribution (class in torch.distributions.transformed_distribution)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution"]], "uniform (class in torch.distributions.uniform)": [[47, "torch.distributions.uniform.Uniform"]], "vonmises (class in torch.distributions.von_mises)": [[47, "torch.distributions.von_mises.VonMises"]], "weibull (class in torch.distributions.weibull)": [[47, "torch.distributions.weibull.Weibull"]], "wishart (class in torch.distributions.wishart)": [[47, "torch.distributions.wishart.Wishart"]], "arg_constraints (torch.distributions.bernoulli.bernoulli attribute)": [[47, "torch.distributions.bernoulli.Bernoulli.arg_constraints"]], "arg_constraints (torch.distributions.beta.beta attribute)": [[47, "torch.distributions.beta.Beta.arg_constraints"]], "arg_constraints (torch.distributions.binomial.binomial attribute)": [[47, "torch.distributions.binomial.Binomial.arg_constraints"]], "arg_constraints (torch.distributions.categorical.categorical attribute)": [[47, "torch.distributions.categorical.Categorical.arg_constraints"]], "arg_constraints (torch.distributions.cauchy.cauchy attribute)": [[47, "torch.distributions.cauchy.Cauchy.arg_constraints"]], "arg_constraints (torch.distributions.chi2.chi2 attribute)": [[47, "torch.distributions.chi2.Chi2.arg_constraints"]], "arg_constraints (torch.distributions.continuous_bernoulli.continuousbernoulli attribute)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.arg_constraints"]], "arg_constraints (torch.distributions.dirichlet.dirichlet attribute)": [[47, "torch.distributions.dirichlet.Dirichlet.arg_constraints"]], "arg_constraints (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.arg_constraints"]], "arg_constraints (torch.distributions.exponential.exponential attribute)": [[47, "torch.distributions.exponential.Exponential.arg_constraints"]], "arg_constraints (torch.distributions.fishersnedecor.fishersnedecor attribute)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.arg_constraints"]], "arg_constraints (torch.distributions.gamma.gamma attribute)": [[47, "torch.distributions.gamma.Gamma.arg_constraints"]], "arg_constraints (torch.distributions.geometric.geometric attribute)": [[47, "torch.distributions.geometric.Geometric.arg_constraints"]], "arg_constraints (torch.distributions.gumbel.gumbel attribute)": [[47, "torch.distributions.gumbel.Gumbel.arg_constraints"]], "arg_constraints (torch.distributions.half_cauchy.halfcauchy attribute)": [[47, "torch.distributions.half_cauchy.HalfCauchy.arg_constraints"]], "arg_constraints (torch.distributions.half_normal.halfnormal attribute)": [[47, "torch.distributions.half_normal.HalfNormal.arg_constraints"]], "arg_constraints (torch.distributions.independent.independent attribute)": [[47, "torch.distributions.independent.Independent.arg_constraints"]], "arg_constraints (torch.distributions.kumaraswamy.kumaraswamy attribute)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.arg_constraints"]], "arg_constraints (torch.distributions.laplace.laplace attribute)": [[47, "torch.distributions.laplace.Laplace.arg_constraints"]], "arg_constraints (torch.distributions.lkj_cholesky.lkjcholesky attribute)": [[47, "torch.distributions.lkj_cholesky.LKJCholesky.arg_constraints"]], "arg_constraints (torch.distributions.log_normal.lognormal attribute)": [[47, "torch.distributions.log_normal.LogNormal.arg_constraints"]], "arg_constraints (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal attribute)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.arg_constraints"]], "arg_constraints (torch.distributions.mixture_same_family.mixturesamefamily attribute)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.arg_constraints"]], "arg_constraints (torch.distributions.multinomial.multinomial attribute)": [[47, "torch.distributions.multinomial.Multinomial.arg_constraints"]], "arg_constraints (torch.distributions.multivariate_normal.multivariatenormal attribute)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.arg_constraints"]], "arg_constraints (torch.distributions.negative_binomial.negativebinomial attribute)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.arg_constraints"]], "arg_constraints (torch.distributions.normal.normal attribute)": [[47, "torch.distributions.normal.Normal.arg_constraints"]], "arg_constraints (torch.distributions.one_hot_categorical.onehotcategorical attribute)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.arg_constraints"]], "arg_constraints (torch.distributions.pareto.pareto attribute)": [[47, "torch.distributions.pareto.Pareto.arg_constraints"]], "arg_constraints (torch.distributions.poisson.poisson attribute)": [[47, "torch.distributions.poisson.Poisson.arg_constraints"]], "arg_constraints (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli attribute)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.arg_constraints"]], "arg_constraints (torch.distributions.relaxed_bernoulli.relaxedbernoulli attribute)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.arg_constraints"]], "arg_constraints (torch.distributions.relaxed_categorical.relaxedonehotcategorical attribute)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.arg_constraints"]], "arg_constraints (torch.distributions.studentt.studentt attribute)": [[47, "torch.distributions.studentT.StudentT.arg_constraints"]], "arg_constraints (torch.distributions.transformed_distribution.transformeddistribution attribute)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.arg_constraints"]], "arg_constraints (torch.distributions.uniform.uniform attribute)": [[47, "torch.distributions.uniform.Uniform.arg_constraints"]], "arg_constraints (torch.distributions.von_mises.vonmises attribute)": [[47, "torch.distributions.von_mises.VonMises.arg_constraints"]], "arg_constraints (torch.distributions.weibull.weibull attribute)": [[47, "torch.distributions.weibull.Weibull.arg_constraints"]], "arg_constraints (torch.distributions.wishart.wishart attribute)": [[47, "torch.distributions.wishart.Wishart.arg_constraints"]], "batch_shape (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.batch_shape"]], "cat (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.cat"]], "cdf() (torch.distributions.cauchy.cauchy method)": [[47, "torch.distributions.cauchy.Cauchy.cdf"]], "cdf() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.cdf"]], "cdf() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.cdf"]], "cdf() (torch.distributions.exponential.exponential method)": [[47, "torch.distributions.exponential.Exponential.cdf"]], "cdf() (torch.distributions.gamma.gamma method)": [[47, "torch.distributions.gamma.Gamma.cdf"]], "cdf() (torch.distributions.half_cauchy.halfcauchy method)": [[47, "torch.distributions.half_cauchy.HalfCauchy.cdf"]], "cdf() (torch.distributions.half_normal.halfnormal method)": [[47, "torch.distributions.half_normal.HalfNormal.cdf"]], "cdf() (torch.distributions.laplace.laplace method)": [[47, "torch.distributions.laplace.Laplace.cdf"]], "cdf() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.cdf"]], "cdf() (torch.distributions.normal.normal method)": [[47, "torch.distributions.normal.Normal.cdf"]], "cdf() (torch.distributions.transformed_distribution.transformeddistribution method)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.cdf"]], "cdf() (torch.distributions.uniform.uniform method)": [[47, "torch.distributions.uniform.Uniform.cdf"]], "check() (torch.distributions.constraints.constraint method)": [[47, "torch.distributions.constraints.Constraint.check"]], "component_distribution (torch.distributions.mixture_same_family.mixturesamefamily property)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.component_distribution"]], "concentration0 (torch.distributions.beta.beta property)": [[47, "torch.distributions.beta.Beta.concentration0"]], "concentration1 (torch.distributions.beta.beta property)": [[47, "torch.distributions.beta.Beta.concentration1"]], "covariance_matrix (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix"]], "covariance_matrix (torch.distributions.multivariate_normal.multivariatenormal property)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix"]], "covariance_matrix (torch.distributions.wishart.wishart property)": [[47, "torch.distributions.wishart.Wishart.covariance_matrix"]], "dependent_property (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.dependent_property"]], "df (torch.distributions.chi2.chi2 property)": [[47, "torch.distributions.chi2.Chi2.df"]], "entropy() (torch.distributions.bernoulli.bernoulli method)": [[47, "torch.distributions.bernoulli.Bernoulli.entropy"]], "entropy() (torch.distributions.beta.beta method)": [[47, "torch.distributions.beta.Beta.entropy"]], "entropy() (torch.distributions.binomial.binomial method)": [[47, "torch.distributions.binomial.Binomial.entropy"]], "entropy() (torch.distributions.categorical.categorical method)": [[47, "torch.distributions.categorical.Categorical.entropy"]], "entropy() (torch.distributions.cauchy.cauchy method)": [[47, "torch.distributions.cauchy.Cauchy.entropy"]], "entropy() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.entropy"]], "entropy() (torch.distributions.dirichlet.dirichlet method)": [[47, "torch.distributions.dirichlet.Dirichlet.entropy"]], "entropy() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.entropy"]], "entropy() (torch.distributions.exp_family.exponentialfamily method)": [[47, "torch.distributions.exp_family.ExponentialFamily.entropy"]], "entropy() (torch.distributions.exponential.exponential method)": [[47, "torch.distributions.exponential.Exponential.entropy"]], "entropy() (torch.distributions.gamma.gamma method)": [[47, "torch.distributions.gamma.Gamma.entropy"]], "entropy() (torch.distributions.geometric.geometric method)": [[47, "torch.distributions.geometric.Geometric.entropy"]], "entropy() (torch.distributions.gumbel.gumbel method)": [[47, "torch.distributions.gumbel.Gumbel.entropy"]], "entropy() (torch.distributions.half_cauchy.halfcauchy method)": [[47, "torch.distributions.half_cauchy.HalfCauchy.entropy"]], "entropy() (torch.distributions.half_normal.halfnormal method)": [[47, "torch.distributions.half_normal.HalfNormal.entropy"]], "entropy() (torch.distributions.independent.independent method)": [[47, "torch.distributions.independent.Independent.entropy"]], "entropy() (torch.distributions.kumaraswamy.kumaraswamy method)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.entropy"]], "entropy() (torch.distributions.laplace.laplace method)": [[47, "torch.distributions.laplace.Laplace.entropy"]], "entropy() (torch.distributions.log_normal.lognormal method)": [[47, "torch.distributions.log_normal.LogNormal.entropy"]], "entropy() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy"]], "entropy() (torch.distributions.multinomial.multinomial method)": [[47, "torch.distributions.multinomial.Multinomial.entropy"]], "entropy() (torch.distributions.multivariate_normal.multivariatenormal method)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.entropy"]], "entropy() (torch.distributions.normal.normal method)": [[47, "torch.distributions.normal.Normal.entropy"]], "entropy() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.entropy"]], "entropy() (torch.distributions.pareto.pareto method)": [[47, "torch.distributions.pareto.Pareto.entropy"]], "entropy() (torch.distributions.studentt.studentt method)": [[47, "torch.distributions.studentT.StudentT.entropy"]], "entropy() (torch.distributions.uniform.uniform method)": [[47, "torch.distributions.uniform.Uniform.entropy"]], "entropy() (torch.distributions.weibull.weibull method)": [[47, "torch.distributions.weibull.Weibull.entropy"]], "entropy() (torch.distributions.wishart.wishart method)": [[47, "torch.distributions.wishart.Wishart.entropy"]], "enumerate_support() (torch.distributions.bernoulli.bernoulli method)": [[47, "torch.distributions.bernoulli.Bernoulli.enumerate_support"]], "enumerate_support() (torch.distributions.binomial.binomial method)": [[47, "torch.distributions.binomial.Binomial.enumerate_support"]], "enumerate_support() (torch.distributions.categorical.categorical method)": [[47, "torch.distributions.categorical.Categorical.enumerate_support"]], "enumerate_support() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.enumerate_support"]], "enumerate_support() (torch.distributions.independent.independent method)": [[47, "torch.distributions.independent.Independent.enumerate_support"]], "enumerate_support() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support"]], "event_shape (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.event_shape"]], "expand() (torch.distributions.bernoulli.bernoulli method)": [[47, "torch.distributions.bernoulli.Bernoulli.expand"]], "expand() (torch.distributions.beta.beta method)": [[47, "torch.distributions.beta.Beta.expand"]], "expand() (torch.distributions.binomial.binomial method)": [[47, "torch.distributions.binomial.Binomial.expand"]], "expand() (torch.distributions.categorical.categorical method)": [[47, "torch.distributions.categorical.Categorical.expand"]], "expand() (torch.distributions.cauchy.cauchy method)": [[47, "torch.distributions.cauchy.Cauchy.expand"]], "expand() (torch.distributions.chi2.chi2 method)": [[47, "torch.distributions.chi2.Chi2.expand"]], "expand() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.expand"]], "expand() (torch.distributions.dirichlet.dirichlet method)": [[47, "torch.distributions.dirichlet.Dirichlet.expand"]], "expand() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.expand"]], "expand() (torch.distributions.exponential.exponential method)": [[47, "torch.distributions.exponential.Exponential.expand"]], "expand() (torch.distributions.fishersnedecor.fishersnedecor method)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.expand"]], "expand() (torch.distributions.gamma.gamma method)": [[47, "torch.distributions.gamma.Gamma.expand"]], "expand() (torch.distributions.geometric.geometric method)": [[47, "torch.distributions.geometric.Geometric.expand"]], "expand() (torch.distributions.gumbel.gumbel method)": [[47, "torch.distributions.gumbel.Gumbel.expand"]], "expand() (torch.distributions.half_cauchy.halfcauchy method)": [[47, "torch.distributions.half_cauchy.HalfCauchy.expand"]], "expand() (torch.distributions.half_normal.halfnormal method)": [[47, "torch.distributions.half_normal.HalfNormal.expand"]], "expand() (torch.distributions.independent.independent method)": [[47, "torch.distributions.independent.Independent.expand"]], "expand() (torch.distributions.kumaraswamy.kumaraswamy method)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.expand"]], "expand() (torch.distributions.laplace.laplace method)": [[47, "torch.distributions.laplace.Laplace.expand"]], "expand() (torch.distributions.lkj_cholesky.lkjcholesky method)": [[47, "torch.distributions.lkj_cholesky.LKJCholesky.expand"]], "expand() (torch.distributions.log_normal.lognormal method)": [[47, "torch.distributions.log_normal.LogNormal.expand"]], "expand() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand"]], "expand() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.expand"]], "expand() (torch.distributions.multinomial.multinomial method)": [[47, "torch.distributions.multinomial.Multinomial.expand"]], "expand() (torch.distributions.multivariate_normal.multivariatenormal method)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.expand"]], "expand() (torch.distributions.negative_binomial.negativebinomial method)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.expand"]], "expand() (torch.distributions.normal.normal method)": [[47, "torch.distributions.normal.Normal.expand"]], "expand() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.expand"]], "expand() (torch.distributions.pareto.pareto method)": [[47, "torch.distributions.pareto.Pareto.expand"]], "expand() (torch.distributions.poisson.poisson method)": [[47, "torch.distributions.poisson.Poisson.expand"]], "expand() (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli method)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand"]], "expand() (torch.distributions.relaxed_bernoulli.relaxedbernoulli method)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand"]], "expand() (torch.distributions.relaxed_categorical.relaxedonehotcategorical method)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand"]], "expand() (torch.distributions.studentt.studentt method)": [[47, "torch.distributions.studentT.StudentT.expand"]], "expand() (torch.distributions.transformed_distribution.transformeddistribution method)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.expand"]], "expand() (torch.distributions.uniform.uniform method)": [[47, "torch.distributions.uniform.Uniform.expand"]], "expand() (torch.distributions.von_mises.vonmises method)": [[47, "torch.distributions.von_mises.VonMises.expand"]], "expand() (torch.distributions.weibull.weibull method)": [[47, "torch.distributions.weibull.Weibull.expand"]], "expand() (torch.distributions.wishart.wishart method)": [[47, "torch.distributions.wishart.Wishart.expand"]], "forward_shape() (torch.distributions.transforms.transform method)": [[47, "torch.distributions.transforms.Transform.forward_shape"]], "greater_than (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.greater_than"]], "greater_than_eq (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.greater_than_eq"]], "half_open_interval (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.half_open_interval"]], "has_enumerate_support (torch.distributions.bernoulli.bernoulli attribute)": [[47, "torch.distributions.bernoulli.Bernoulli.has_enumerate_support"]], "has_enumerate_support (torch.distributions.binomial.binomial attribute)": [[47, "torch.distributions.binomial.Binomial.has_enumerate_support"]], "has_enumerate_support (torch.distributions.categorical.categorical attribute)": [[47, "torch.distributions.categorical.Categorical.has_enumerate_support"]], "has_enumerate_support (torch.distributions.independent.independent property)": [[47, "torch.distributions.independent.Independent.has_enumerate_support"]], "has_enumerate_support (torch.distributions.one_hot_categorical.onehotcategorical attribute)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.has_enumerate_support"]], "has_rsample (torch.distributions.beta.beta attribute)": [[47, "torch.distributions.beta.Beta.has_rsample"]], "has_rsample (torch.distributions.cauchy.cauchy attribute)": [[47, "torch.distributions.cauchy.Cauchy.has_rsample"]], "has_rsample (torch.distributions.continuous_bernoulli.continuousbernoulli attribute)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.has_rsample"]], "has_rsample (torch.distributions.dirichlet.dirichlet attribute)": [[47, "torch.distributions.dirichlet.Dirichlet.has_rsample"]], "has_rsample (torch.distributions.exponential.exponential attribute)": [[47, "torch.distributions.exponential.Exponential.has_rsample"]], "has_rsample (torch.distributions.fishersnedecor.fishersnedecor attribute)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.has_rsample"]], "has_rsample (torch.distributions.gamma.gamma attribute)": [[47, "torch.distributions.gamma.Gamma.has_rsample"]], "has_rsample (torch.distributions.half_cauchy.halfcauchy attribute)": [[47, "torch.distributions.half_cauchy.HalfCauchy.has_rsample"]], "has_rsample (torch.distributions.half_normal.halfnormal attribute)": [[47, "torch.distributions.half_normal.HalfNormal.has_rsample"]], "has_rsample (torch.distributions.independent.independent property)": [[47, "torch.distributions.independent.Independent.has_rsample"]], "has_rsample (torch.distributions.kumaraswamy.kumaraswamy attribute)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.has_rsample"]], "has_rsample (torch.distributions.laplace.laplace attribute)": [[47, "torch.distributions.laplace.Laplace.has_rsample"]], "has_rsample (torch.distributions.log_normal.lognormal attribute)": [[47, "torch.distributions.log_normal.LogNormal.has_rsample"]], "has_rsample (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal attribute)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.has_rsample"]], "has_rsample (torch.distributions.mixture_same_family.mixturesamefamily attribute)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.has_rsample"]], "has_rsample (torch.distributions.multivariate_normal.multivariatenormal attribute)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.has_rsample"]], "has_rsample (torch.distributions.normal.normal attribute)": [[47, "torch.distributions.normal.Normal.has_rsample"]], "has_rsample (torch.distributions.relaxed_bernoulli.relaxedbernoulli attribute)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.has_rsample"]], "has_rsample (torch.distributions.relaxed_categorical.relaxedonehotcategorical attribute)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.has_rsample"]], "has_rsample (torch.distributions.studentt.studentt attribute)": [[47, "torch.distributions.studentT.StudentT.has_rsample"]], "has_rsample (torch.distributions.transformed_distribution.transformeddistribution property)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.has_rsample"]], "has_rsample (torch.distributions.uniform.uniform attribute)": [[47, "torch.distributions.uniform.Uniform.has_rsample"]], "has_rsample (torch.distributions.von_mises.vonmises attribute)": [[47, "torch.distributions.von_mises.VonMises.has_rsample"]], "has_rsample (torch.distributions.wishart.wishart attribute)": [[47, "torch.distributions.wishart.Wishart.has_rsample"]], "icdf() (torch.distributions.cauchy.cauchy method)": [[47, "torch.distributions.cauchy.Cauchy.icdf"]], "icdf() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.icdf"]], "icdf() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.icdf"]], "icdf() (torch.distributions.exponential.exponential method)": [[47, "torch.distributions.exponential.Exponential.icdf"]], "icdf() (torch.distributions.half_cauchy.halfcauchy method)": [[47, "torch.distributions.half_cauchy.HalfCauchy.icdf"]], "icdf() (torch.distributions.half_normal.halfnormal method)": [[47, "torch.distributions.half_normal.HalfNormal.icdf"]], "icdf() (torch.distributions.laplace.laplace method)": [[47, "torch.distributions.laplace.Laplace.icdf"]], "icdf() (torch.distributions.normal.normal method)": [[47, "torch.distributions.normal.Normal.icdf"]], "icdf() (torch.distributions.transformed_distribution.transformeddistribution method)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.icdf"]], "icdf() (torch.distributions.uniform.uniform method)": [[47, "torch.distributions.uniform.Uniform.icdf"]], "independent (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.independent"]], "integer_interval (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.integer_interval"]], "interval (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.interval"]], "inv (torch.distributions.transforms.transform property)": [[47, "torch.distributions.transforms.Transform.inv"]], "inverse_shape() (torch.distributions.transforms.transform method)": [[47, "torch.distributions.transforms.Transform.inverse_shape"]], "kl_divergence() (in module torch.distributions.kl)": [[47, "torch.distributions.kl.kl_divergence"]], "less_than (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.less_than"]], "loc (torch.distributions.log_normal.lognormal property)": [[47, "torch.distributions.log_normal.LogNormal.loc"]], "log_abs_det_jacobian() (torch.distributions.transforms.transform method)": [[47, "torch.distributions.transforms.Transform.log_abs_det_jacobian"]], "log_prob() (torch.distributions.bernoulli.bernoulli method)": [[47, "torch.distributions.bernoulli.Bernoulli.log_prob"]], "log_prob() (torch.distributions.beta.beta method)": [[47, "torch.distributions.beta.Beta.log_prob"]], "log_prob() (torch.distributions.binomial.binomial method)": [[47, "torch.distributions.binomial.Binomial.log_prob"]], "log_prob() (torch.distributions.categorical.categorical method)": [[47, "torch.distributions.categorical.Categorical.log_prob"]], "log_prob() (torch.distributions.cauchy.cauchy method)": [[47, "torch.distributions.cauchy.Cauchy.log_prob"]], "log_prob() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.log_prob"]], "log_prob() (torch.distributions.dirichlet.dirichlet method)": [[47, "torch.distributions.dirichlet.Dirichlet.log_prob"]], "log_prob() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.log_prob"]], "log_prob() (torch.distributions.exponential.exponential method)": [[47, "torch.distributions.exponential.Exponential.log_prob"]], "log_prob() (torch.distributions.fishersnedecor.fishersnedecor method)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.log_prob"]], "log_prob() (torch.distributions.gamma.gamma method)": [[47, "torch.distributions.gamma.Gamma.log_prob"]], "log_prob() (torch.distributions.geometric.geometric method)": [[47, "torch.distributions.geometric.Geometric.log_prob"]], "log_prob() (torch.distributions.gumbel.gumbel method)": [[47, "torch.distributions.gumbel.Gumbel.log_prob"]], "log_prob() (torch.distributions.half_cauchy.halfcauchy method)": [[47, "torch.distributions.half_cauchy.HalfCauchy.log_prob"]], "log_prob() (torch.distributions.half_normal.halfnormal method)": [[47, "torch.distributions.half_normal.HalfNormal.log_prob"]], "log_prob() (torch.distributions.independent.independent method)": [[47, "torch.distributions.independent.Independent.log_prob"]], "log_prob() (torch.distributions.laplace.laplace method)": [[47, "torch.distributions.laplace.Laplace.log_prob"]], "log_prob() (torch.distributions.lkj_cholesky.lkjcholesky method)": [[47, "torch.distributions.lkj_cholesky.LKJCholesky.log_prob"]], "log_prob() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob"]], "log_prob() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.log_prob"]], "log_prob() (torch.distributions.multinomial.multinomial method)": [[47, "torch.distributions.multinomial.Multinomial.log_prob"]], "log_prob() (torch.distributions.multivariate_normal.multivariatenormal method)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.log_prob"]], "log_prob() (torch.distributions.negative_binomial.negativebinomial method)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.log_prob"]], "log_prob() (torch.distributions.normal.normal method)": [[47, "torch.distributions.normal.Normal.log_prob"]], "log_prob() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.log_prob"]], "log_prob() (torch.distributions.poisson.poisson method)": [[47, "torch.distributions.poisson.Poisson.log_prob"]], "log_prob() (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli method)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob"]], "log_prob() (torch.distributions.studentt.studentt method)": [[47, "torch.distributions.studentT.StudentT.log_prob"]], "log_prob() (torch.distributions.transformed_distribution.transformeddistribution method)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.log_prob"]], "log_prob() (torch.distributions.uniform.uniform method)": [[47, "torch.distributions.uniform.Uniform.log_prob"]], "log_prob() (torch.distributions.von_mises.vonmises method)": [[47, "torch.distributions.von_mises.VonMises.log_prob"]], "log_prob() (torch.distributions.wishart.wishart method)": [[47, "torch.distributions.wishart.Wishart.log_prob"]], "logits (torch.distributions.bernoulli.bernoulli property)": [[47, "torch.distributions.bernoulli.Bernoulli.logits"]], "logits (torch.distributions.binomial.binomial property)": [[47, "torch.distributions.binomial.Binomial.logits"]], "logits (torch.distributions.categorical.categorical property)": [[47, "torch.distributions.categorical.Categorical.logits"]], "logits (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.logits"]], "logits (torch.distributions.geometric.geometric property)": [[47, "torch.distributions.geometric.Geometric.logits"]], "logits (torch.distributions.multinomial.multinomial property)": [[47, "torch.distributions.multinomial.Multinomial.logits"]], "logits (torch.distributions.negative_binomial.negativebinomial property)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.logits"]], "logits (torch.distributions.one_hot_categorical.onehotcategorical property)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.logits"]], "logits (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli property)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits"]], "logits (torch.distributions.relaxed_bernoulli.relaxedbernoulli property)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits"]], "logits (torch.distributions.relaxed_categorical.relaxedonehotcategorical property)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits"]], "mean (torch.distributions.bernoulli.bernoulli property)": [[47, "torch.distributions.bernoulli.Bernoulli.mean"]], "mean (torch.distributions.beta.beta property)": [[47, "torch.distributions.beta.Beta.mean"]], "mean (torch.distributions.binomial.binomial property)": [[47, "torch.distributions.binomial.Binomial.mean"]], "mean (torch.distributions.categorical.categorical property)": [[47, "torch.distributions.categorical.Categorical.mean"]], "mean (torch.distributions.cauchy.cauchy property)": [[47, "torch.distributions.cauchy.Cauchy.mean"]], "mean (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.mean"]], "mean (torch.distributions.dirichlet.dirichlet property)": [[47, "torch.distributions.dirichlet.Dirichlet.mean"]], "mean (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.mean"]], "mean (torch.distributions.exponential.exponential property)": [[47, "torch.distributions.exponential.Exponential.mean"]], "mean (torch.distributions.fishersnedecor.fishersnedecor property)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.mean"]], "mean (torch.distributions.gamma.gamma property)": [[47, "torch.distributions.gamma.Gamma.mean"]], "mean (torch.distributions.geometric.geometric property)": [[47, "torch.distributions.geometric.Geometric.mean"]], "mean (torch.distributions.gumbel.gumbel property)": [[47, "torch.distributions.gumbel.Gumbel.mean"]], "mean (torch.distributions.half_cauchy.halfcauchy property)": [[47, "torch.distributions.half_cauchy.HalfCauchy.mean"]], "mean (torch.distributions.half_normal.halfnormal property)": [[47, "torch.distributions.half_normal.HalfNormal.mean"]], "mean (torch.distributions.independent.independent property)": [[47, "torch.distributions.independent.Independent.mean"]], "mean (torch.distributions.kumaraswamy.kumaraswamy property)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.mean"]], "mean (torch.distributions.laplace.laplace property)": [[47, "torch.distributions.laplace.Laplace.mean"]], "mean (torch.distributions.log_normal.lognormal property)": [[47, "torch.distributions.log_normal.LogNormal.mean"]], "mean (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean"]], "mean (torch.distributions.mixture_same_family.mixturesamefamily property)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.mean"]], "mean (torch.distributions.multinomial.multinomial property)": [[47, "torch.distributions.multinomial.Multinomial.mean"]], "mean (torch.distributions.multivariate_normal.multivariatenormal property)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.mean"]], "mean (torch.distributions.negative_binomial.negativebinomial property)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.mean"]], "mean (torch.distributions.normal.normal property)": [[47, "torch.distributions.normal.Normal.mean"]], "mean (torch.distributions.one_hot_categorical.onehotcategorical property)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.mean"]], "mean (torch.distributions.pareto.pareto property)": [[47, "torch.distributions.pareto.Pareto.mean"]], "mean (torch.distributions.poisson.poisson property)": [[47, "torch.distributions.poisson.Poisson.mean"]], "mean (torch.distributions.studentt.studentt property)": [[47, "torch.distributions.studentT.StudentT.mean"]], "mean (torch.distributions.uniform.uniform property)": [[47, "torch.distributions.uniform.Uniform.mean"]], "mean (torch.distributions.von_mises.vonmises property)": [[47, "torch.distributions.von_mises.VonMises.mean"]], "mean (torch.distributions.weibull.weibull property)": [[47, "torch.distributions.weibull.Weibull.mean"]], "mean (torch.distributions.wishart.wishart property)": [[47, "torch.distributions.wishart.Wishart.mean"]], "mixture_distribution (torch.distributions.mixture_same_family.mixturesamefamily property)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.mixture_distribution"]], "mode (torch.distributions.bernoulli.bernoulli property)": [[47, "torch.distributions.bernoulli.Bernoulli.mode"]], "mode (torch.distributions.beta.beta property)": [[47, "torch.distributions.beta.Beta.mode"]], "mode (torch.distributions.binomial.binomial property)": [[47, "torch.distributions.binomial.Binomial.mode"]], "mode (torch.distributions.categorical.categorical property)": [[47, "torch.distributions.categorical.Categorical.mode"]], "mode (torch.distributions.cauchy.cauchy property)": [[47, "torch.distributions.cauchy.Cauchy.mode"]], "mode (torch.distributions.dirichlet.dirichlet property)": [[47, "torch.distributions.dirichlet.Dirichlet.mode"]], "mode (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.mode"]], "mode (torch.distributions.exponential.exponential property)": [[47, "torch.distributions.exponential.Exponential.mode"]], "mode (torch.distributions.fishersnedecor.fishersnedecor property)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.mode"]], "mode (torch.distributions.gamma.gamma property)": [[47, "torch.distributions.gamma.Gamma.mode"]], "mode (torch.distributions.geometric.geometric property)": [[47, "torch.distributions.geometric.Geometric.mode"]], "mode (torch.distributions.gumbel.gumbel property)": [[47, "torch.distributions.gumbel.Gumbel.mode"]], "mode (torch.distributions.half_cauchy.halfcauchy property)": [[47, "torch.distributions.half_cauchy.HalfCauchy.mode"]], "mode (torch.distributions.half_normal.halfnormal property)": [[47, "torch.distributions.half_normal.HalfNormal.mode"]], "mode (torch.distributions.independent.independent property)": [[47, "torch.distributions.independent.Independent.mode"]], "mode (torch.distributions.kumaraswamy.kumaraswamy property)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.mode"]], "mode (torch.distributions.laplace.laplace property)": [[47, "torch.distributions.laplace.Laplace.mode"]], "mode (torch.distributions.log_normal.lognormal property)": [[47, "torch.distributions.log_normal.LogNormal.mode"]], "mode (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mode"]], "mode (torch.distributions.multivariate_normal.multivariatenormal property)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.mode"]], "mode (torch.distributions.negative_binomial.negativebinomial property)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.mode"]], "mode (torch.distributions.normal.normal property)": [[47, "torch.distributions.normal.Normal.mode"]], "mode (torch.distributions.one_hot_categorical.onehotcategorical property)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.mode"]], "mode (torch.distributions.pareto.pareto property)": [[47, "torch.distributions.pareto.Pareto.mode"]], "mode (torch.distributions.poisson.poisson property)": [[47, "torch.distributions.poisson.Poisson.mode"]], "mode (torch.distributions.studentt.studentt property)": [[47, "torch.distributions.studentT.StudentT.mode"]], "mode (torch.distributions.uniform.uniform property)": [[47, "torch.distributions.uniform.Uniform.mode"]], "mode (torch.distributions.von_mises.vonmises property)": [[47, "torch.distributions.von_mises.VonMises.mode"]], "mode (torch.distributions.weibull.weibull property)": [[47, "torch.distributions.weibull.Weibull.mode"]], "mode (torch.distributions.wishart.wishart property)": [[47, "torch.distributions.wishart.Wishart.mode"]], "multinomial (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.multinomial"]], "param_shape (torch.distributions.bernoulli.bernoulli property)": [[47, "torch.distributions.bernoulli.Bernoulli.param_shape"]], "param_shape (torch.distributions.binomial.binomial property)": [[47, "torch.distributions.binomial.Binomial.param_shape"]], "param_shape (torch.distributions.categorical.categorical property)": [[47, "torch.distributions.categorical.Categorical.param_shape"]], "param_shape (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.param_shape"]], "param_shape (torch.distributions.multinomial.multinomial property)": [[47, "torch.distributions.multinomial.Multinomial.param_shape"]], "param_shape (torch.distributions.negative_binomial.negativebinomial property)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.param_shape"]], "param_shape (torch.distributions.one_hot_categorical.onehotcategorical property)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.param_shape"]], "param_shape (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli property)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape"]], "perplexity() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.perplexity"]], "precision_matrix (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix"]], "precision_matrix (torch.distributions.multivariate_normal.multivariatenormal property)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix"]], "precision_matrix (torch.distributions.wishart.wishart property)": [[47, "torch.distributions.wishart.Wishart.precision_matrix"]], "probs (torch.distributions.bernoulli.bernoulli property)": [[47, "torch.distributions.bernoulli.Bernoulli.probs"]], "probs (torch.distributions.binomial.binomial property)": [[47, "torch.distributions.binomial.Binomial.probs"]], "probs (torch.distributions.categorical.categorical property)": [[47, "torch.distributions.categorical.Categorical.probs"]], "probs (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.probs"]], "probs (torch.distributions.geometric.geometric property)": [[47, "torch.distributions.geometric.Geometric.probs"]], "probs (torch.distributions.multinomial.multinomial property)": [[47, "torch.distributions.multinomial.Multinomial.probs"]], "probs (torch.distributions.negative_binomial.negativebinomial property)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.probs"]], "probs (torch.distributions.one_hot_categorical.onehotcategorical property)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.probs"]], "probs (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli property)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs"]], "probs (torch.distributions.relaxed_bernoulli.relaxedbernoulli property)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs"]], "probs (torch.distributions.relaxed_categorical.relaxedonehotcategorical property)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs"]], "register() (torch.distributions.constraint_registry.constraintregistry method)": [[47, "torch.distributions.constraint_registry.ConstraintRegistry.register"]], "register_kl() (in module torch.distributions.kl)": [[47, "torch.distributions.kl.register_kl"]], "rsample() (torch.distributions.beta.beta method)": [[47, "torch.distributions.beta.Beta.rsample"]], "rsample() (torch.distributions.cauchy.cauchy method)": [[47, "torch.distributions.cauchy.Cauchy.rsample"]], "rsample() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.rsample"]], "rsample() (torch.distributions.dirichlet.dirichlet method)": [[47, "torch.distributions.dirichlet.Dirichlet.rsample"]], "rsample() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.rsample"]], "rsample() (torch.distributions.exponential.exponential method)": [[47, "torch.distributions.exponential.Exponential.rsample"]], "rsample() (torch.distributions.fishersnedecor.fishersnedecor method)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.rsample"]], "rsample() (torch.distributions.gamma.gamma method)": [[47, "torch.distributions.gamma.Gamma.rsample"]], "rsample() (torch.distributions.independent.independent method)": [[47, "torch.distributions.independent.Independent.rsample"]], "rsample() (torch.distributions.laplace.laplace method)": [[47, "torch.distributions.laplace.Laplace.rsample"]], "rsample() (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal method)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample"]], "rsample() (torch.distributions.multivariate_normal.multivariatenormal method)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.rsample"]], "rsample() (torch.distributions.normal.normal method)": [[47, "torch.distributions.normal.Normal.rsample"]], "rsample() (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli method)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample"]], "rsample() (torch.distributions.studentt.studentt method)": [[47, "torch.distributions.studentT.StudentT.rsample"]], "rsample() (torch.distributions.transformed_distribution.transformeddistribution method)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.rsample"]], "rsample() (torch.distributions.uniform.uniform method)": [[47, "torch.distributions.uniform.Uniform.rsample"]], "rsample() (torch.distributions.wishart.wishart method)": [[47, "torch.distributions.wishart.Wishart.rsample"]], "sample() (torch.distributions.bernoulli.bernoulli method)": [[47, "torch.distributions.bernoulli.Bernoulli.sample"]], "sample() (torch.distributions.binomial.binomial method)": [[47, "torch.distributions.binomial.Binomial.sample"]], "sample() (torch.distributions.categorical.categorical method)": [[47, "torch.distributions.categorical.Categorical.sample"]], "sample() (torch.distributions.continuous_bernoulli.continuousbernoulli method)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.sample"]], "sample() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.sample"]], "sample() (torch.distributions.geometric.geometric method)": [[47, "torch.distributions.geometric.Geometric.sample"]], "sample() (torch.distributions.independent.independent method)": [[47, "torch.distributions.independent.Independent.sample"]], "sample() (torch.distributions.lkj_cholesky.lkjcholesky method)": [[47, "torch.distributions.lkj_cholesky.LKJCholesky.sample"]], "sample() (torch.distributions.mixture_same_family.mixturesamefamily method)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.sample"]], "sample() (torch.distributions.multinomial.multinomial method)": [[47, "torch.distributions.multinomial.Multinomial.sample"]], "sample() (torch.distributions.negative_binomial.negativebinomial method)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.sample"]], "sample() (torch.distributions.normal.normal method)": [[47, "torch.distributions.normal.Normal.sample"]], "sample() (torch.distributions.one_hot_categorical.onehotcategorical method)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.sample"]], "sample() (torch.distributions.poisson.poisson method)": [[47, "torch.distributions.poisson.Poisson.sample"]], "sample() (torch.distributions.transformed_distribution.transformeddistribution method)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.sample"]], "sample() (torch.distributions.von_mises.vonmises method)": [[47, "torch.distributions.von_mises.VonMises.sample"]], "sample_n() (torch.distributions.distribution.distribution method)": [[47, "torch.distributions.distribution.Distribution.sample_n"]], "scale (torch.distributions.half_cauchy.halfcauchy property)": [[47, "torch.distributions.half_cauchy.HalfCauchy.scale"]], "scale (torch.distributions.half_normal.halfnormal property)": [[47, "torch.distributions.half_normal.HalfNormal.scale"]], "scale (torch.distributions.log_normal.lognormal property)": [[47, "torch.distributions.log_normal.LogNormal.scale"]], "scale_tril (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril"]], "scale_tril (torch.distributions.multivariate_normal.multivariatenormal property)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.scale_tril"]], "scale_tril (torch.distributions.wishart.wishart property)": [[47, "torch.distributions.wishart.Wishart.scale_tril"]], "set_default_validate_args() (torch.distributions.distribution.distribution static method)": [[47, "torch.distributions.distribution.Distribution.set_default_validate_args"]], "sign (torch.distributions.transforms.transform property)": [[47, "torch.distributions.transforms.Transform.sign"]], "stack (in module torch.distributions.constraints)": [[47, "torch.distributions.constraints.stack"]], "stddev (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.stddev"]], "stddev (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.stddev"]], "stddev (torch.distributions.exponential.exponential property)": [[47, "torch.distributions.exponential.Exponential.stddev"]], "stddev (torch.distributions.gumbel.gumbel property)": [[47, "torch.distributions.gumbel.Gumbel.stddev"]], "stddev (torch.distributions.laplace.laplace property)": [[47, "torch.distributions.laplace.Laplace.stddev"]], "stddev (torch.distributions.normal.normal property)": [[47, "torch.distributions.normal.Normal.stddev"]], "stddev (torch.distributions.uniform.uniform property)": [[47, "torch.distributions.uniform.Uniform.stddev"]], "support (torch.distributions.bernoulli.bernoulli attribute)": [[47, "torch.distributions.bernoulli.Bernoulli.support"]], "support (torch.distributions.beta.beta attribute)": [[47, "torch.distributions.beta.Beta.support"]], "support (torch.distributions.binomial.binomial property)": [[47, "torch.distributions.binomial.Binomial.support"]], "support (torch.distributions.categorical.categorical property)": [[47, "torch.distributions.categorical.Categorical.support"]], "support (torch.distributions.cauchy.cauchy attribute)": [[47, "torch.distributions.cauchy.Cauchy.support"]], "support (torch.distributions.continuous_bernoulli.continuousbernoulli attribute)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.support"]], "support (torch.distributions.dirichlet.dirichlet attribute)": [[47, "torch.distributions.dirichlet.Dirichlet.support"]], "support (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.support"]], "support (torch.distributions.exponential.exponential attribute)": [[47, "torch.distributions.exponential.Exponential.support"]], "support (torch.distributions.fishersnedecor.fishersnedecor attribute)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.support"]], "support (torch.distributions.gamma.gamma attribute)": [[47, "torch.distributions.gamma.Gamma.support"]], "support (torch.distributions.geometric.geometric attribute)": [[47, "torch.distributions.geometric.Geometric.support"]], "support (torch.distributions.gumbel.gumbel attribute)": [[47, "torch.distributions.gumbel.Gumbel.support"]], "support (torch.distributions.half_cauchy.halfcauchy attribute)": [[47, "torch.distributions.half_cauchy.HalfCauchy.support"]], "support (torch.distributions.half_normal.halfnormal attribute)": [[47, "torch.distributions.half_normal.HalfNormal.support"]], "support (torch.distributions.independent.independent property)": [[47, "torch.distributions.independent.Independent.support"]], "support (torch.distributions.kumaraswamy.kumaraswamy attribute)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.support"]], "support (torch.distributions.laplace.laplace attribute)": [[47, "torch.distributions.laplace.Laplace.support"]], "support (torch.distributions.lkj_cholesky.lkjcholesky attribute)": [[47, "torch.distributions.lkj_cholesky.LKJCholesky.support"]], "support (torch.distributions.log_normal.lognormal attribute)": [[47, "torch.distributions.log_normal.LogNormal.support"]], "support (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal attribute)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.support"]], "support (torch.distributions.mixture_same_family.mixturesamefamily property)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.support"]], "support (torch.distributions.multinomial.multinomial property)": [[47, "torch.distributions.multinomial.Multinomial.support"]], "support (torch.distributions.multivariate_normal.multivariatenormal attribute)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.support"]], "support (torch.distributions.negative_binomial.negativebinomial attribute)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.support"]], "support (torch.distributions.normal.normal attribute)": [[47, "torch.distributions.normal.Normal.support"]], "support (torch.distributions.one_hot_categorical.onehotcategorical attribute)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.support"]], "support (torch.distributions.pareto.pareto property)": [[47, "torch.distributions.pareto.Pareto.support"]], "support (torch.distributions.poisson.poisson attribute)": [[47, "torch.distributions.poisson.Poisson.support"]], "support (torch.distributions.relaxed_bernoulli.logitrelaxedbernoulli attribute)": [[47, "torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.support"]], "support (torch.distributions.relaxed_bernoulli.relaxedbernoulli attribute)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.support"]], "support (torch.distributions.relaxed_categorical.relaxedonehotcategorical attribute)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.support"]], "support (torch.distributions.studentt.studentt attribute)": [[47, "torch.distributions.studentT.StudentT.support"]], "support (torch.distributions.transformed_distribution.transformeddistribution property)": [[47, "torch.distributions.transformed_distribution.TransformedDistribution.support"]], "support (torch.distributions.uniform.uniform property)": [[47, "torch.distributions.uniform.Uniform.support"]], "support (torch.distributions.von_mises.vonmises attribute)": [[47, "torch.distributions.von_mises.VonMises.support"]], "support (torch.distributions.weibull.weibull attribute)": [[47, "torch.distributions.weibull.Weibull.support"]], "support (torch.distributions.wishart.wishart attribute)": [[47, "torch.distributions.wishart.Wishart.support"]], "temperature (torch.distributions.relaxed_bernoulli.relaxedbernoulli property)": [[47, "torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature"]], "temperature (torch.distributions.relaxed_categorical.relaxedonehotcategorical property)": [[47, "torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature"]], "torch.distributions": [[47, "module-torch.distributions"]], "torch.distributions.constraint_registry": [[47, "module-torch.distributions.constraint_registry"]], "torch.distributions.constraints": [[47, "module-torch.distributions.constraints"]], "torch.distributions.kl": [[47, "module-torch.distributions.kl"]], "torch.distributions.transforms": [[47, "module-torch.distributions.transforms"]], "total_count (torch.distributions.multinomial.multinomial attribute)": [[47, "torch.distributions.multinomial.Multinomial.total_count"]], "variance (torch.distributions.bernoulli.bernoulli property)": [[47, "torch.distributions.bernoulli.Bernoulli.variance"]], "variance (torch.distributions.beta.beta property)": [[47, "torch.distributions.beta.Beta.variance"]], "variance (torch.distributions.binomial.binomial property)": [[47, "torch.distributions.binomial.Binomial.variance"]], "variance (torch.distributions.categorical.categorical property)": [[47, "torch.distributions.categorical.Categorical.variance"]], "variance (torch.distributions.cauchy.cauchy property)": [[47, "torch.distributions.cauchy.Cauchy.variance"]], "variance (torch.distributions.continuous_bernoulli.continuousbernoulli property)": [[47, "torch.distributions.continuous_bernoulli.ContinuousBernoulli.variance"]], "variance (torch.distributions.dirichlet.dirichlet property)": [[47, "torch.distributions.dirichlet.Dirichlet.variance"]], "variance (torch.distributions.distribution.distribution property)": [[47, "torch.distributions.distribution.Distribution.variance"]], "variance (torch.distributions.exponential.exponential property)": [[47, "torch.distributions.exponential.Exponential.variance"]], "variance (torch.distributions.fishersnedecor.fishersnedecor property)": [[47, "torch.distributions.fishersnedecor.FisherSnedecor.variance"]], "variance (torch.distributions.gamma.gamma property)": [[47, "torch.distributions.gamma.Gamma.variance"]], "variance (torch.distributions.geometric.geometric property)": [[47, "torch.distributions.geometric.Geometric.variance"]], "variance (torch.distributions.gumbel.gumbel property)": [[47, "torch.distributions.gumbel.Gumbel.variance"]], "variance (torch.distributions.half_cauchy.halfcauchy property)": [[47, "torch.distributions.half_cauchy.HalfCauchy.variance"]], "variance (torch.distributions.half_normal.halfnormal property)": [[47, "torch.distributions.half_normal.HalfNormal.variance"]], "variance (torch.distributions.independent.independent property)": [[47, "torch.distributions.independent.Independent.variance"]], "variance (torch.distributions.kumaraswamy.kumaraswamy property)": [[47, "torch.distributions.kumaraswamy.Kumaraswamy.variance"]], "variance (torch.distributions.laplace.laplace property)": [[47, "torch.distributions.laplace.Laplace.variance"]], "variance (torch.distributions.log_normal.lognormal property)": [[47, "torch.distributions.log_normal.LogNormal.variance"]], "variance (torch.distributions.lowrank_multivariate_normal.lowrankmultivariatenormal property)": [[47, "torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance"]], "variance (torch.distributions.mixture_same_family.mixturesamefamily property)": [[47, "torch.distributions.mixture_same_family.MixtureSameFamily.variance"]], "variance (torch.distributions.multinomial.multinomial property)": [[47, "torch.distributions.multinomial.Multinomial.variance"]], "variance (torch.distributions.multivariate_normal.multivariatenormal property)": [[47, "torch.distributions.multivariate_normal.MultivariateNormal.variance"]], "variance (torch.distributions.negative_binomial.negativebinomial property)": [[47, "torch.distributions.negative_binomial.NegativeBinomial.variance"]], "variance (torch.distributions.normal.normal property)": [[47, "torch.distributions.normal.Normal.variance"]], "variance (torch.distributions.one_hot_categorical.onehotcategorical property)": [[47, "torch.distributions.one_hot_categorical.OneHotCategorical.variance"]], "variance (torch.distributions.pareto.pareto property)": [[47, "torch.distributions.pareto.Pareto.variance"]], "variance (torch.distributions.poisson.poisson property)": [[47, "torch.distributions.poisson.Poisson.variance"]], "variance (torch.distributions.studentt.studentt property)": [[47, "torch.distributions.studentT.StudentT.variance"]], "variance (torch.distributions.uniform.uniform property)": [[47, "torch.distributions.uniform.Uniform.variance"]], "variance (torch.distributions.von_mises.vonmises property)": [[47, "torch.distributions.von_mises.VonMises.variance"]], "variance (torch.distributions.weibull.weibull property)": [[47, "torch.distributions.weibull.Weibull.variance"]], "variance (torch.distributions.wishart.wishart property)": [[47, "torch.distributions.wishart.Wishart.variance"]], "from_dlpack() (in module torch.utils.dlpack)": [[48, "torch.utils.dlpack.from_dlpack"]], "to_dlpack() (in module torch.utils.dlpack)": [[48, "torch.utils.dlpack.to_dlpack"]], "elasticagent (class in torch.distributed.elastic.agent.server)": [[49, "torch.distributed.elastic.agent.server.ElasticAgent"]], "localelasticagent (class in torch.distributed.elastic.agent.server.local_elastic_agent)": [[49, "torch.distributed.elastic.agent.server.local_elastic_agent.LocalElasticAgent"]], "runresult (class in torch.distributed.elastic.agent.server.api)": [[49, "torch.distributed.elastic.agent.server.api.RunResult"]], "simpleelasticagent (class in torch.distributed.elastic.agent.server)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent"]], "worker (class in torch.distributed.elastic.agent.server)": [[49, "torch.distributed.elastic.agent.server.Worker"]], "workergroup (class in torch.distributed.elastic.agent.server)": [[49, "torch.distributed.elastic.agent.server.WorkerGroup"]], "workerspec (class in torch.distributed.elastic.agent.server)": [[49, "torch.distributed.elastic.agent.server.WorkerSpec"]], "workerstate (class in torch.distributed.elastic.agent.server)": [[49, "torch.distributed.elastic.agent.server.WorkerState"]], "_assign_worker_ranks() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._assign_worker_ranks"]], "_exit_barrier() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._exit_barrier"]], "_initialize_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._initialize_workers"]], "_monitor_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._monitor_workers"]], "_rendezvous() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._rendezvous"]], "_restart_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._restart_workers"]], "_shutdown() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._shutdown"]], "_start_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._start_workers"]], "_stop_workers() (torch.distributed.elastic.agent.server.simpleelasticagent method)": [[49, "torch.distributed.elastic.agent.server.SimpleElasticAgent._stop_workers"]], "get_entrypoint_name() (torch.distributed.elastic.agent.server.workerspec method)": [[49, "torch.distributed.elastic.agent.server.WorkerSpec.get_entrypoint_name"]], "get_worker_group() (torch.distributed.elastic.agent.server.elasticagent method)": [[49, "torch.distributed.elastic.agent.server.ElasticAgent.get_worker_group"]], "is_running() (torch.distributed.elastic.agent.server.workerstate static method)": [[49, "torch.distributed.elastic.agent.server.WorkerState.is_running"]], "run() (torch.distributed.elastic.agent.server.elasticagent method)": [[49, "torch.distributed.elastic.agent.server.ElasticAgent.run"]], "torch.distributed.elastic.agent": [[49, "module-torch.distributed.elastic.agent"]], "torch.distributed.elastic.agent.server": [[49, "module-torch.distributed.elastic.agent.server"]], "childfailederror (class in torch.distributed.elastic.multiprocessing.errors)": [[51, "torch.distributed.elastic.multiprocessing.errors.ChildFailedError"]], "errorhandler (class in torch.distributed.elastic.multiprocessing.errors)": [[51, "torch.distributed.elastic.multiprocessing.errors.ErrorHandler"]], "processfailure (class in torch.distributed.elastic.multiprocessing.errors)": [[51, "torch.distributed.elastic.multiprocessing.errors.ProcessFailure"]], "record() (in module torch.distributed.elastic.multiprocessing.errors)": [[51, "torch.distributed.elastic.multiprocessing.errors.record"]], "torch.distributed.elastic.multiprocessing.errors": [[51, "module-torch.distributed.elastic.multiprocessing.errors"]], "event (class in torch.distributed.elastic.events.api)": [[52, "torch.distributed.elastic.events.api.Event"]], "eventmetadatavalue (in module torch.distributed.elastic.events.api)": [[52, "torch.distributed.elastic.events.api.EventMetadataValue"]], "eventsource (class in torch.distributed.elastic.events.api)": [[52, "torch.distributed.elastic.events.api.EventSource"]], "get_logging_handler() (in module torch.distributed.elastic.events)": [[52, "torch.distributed.elastic.events.get_logging_handler"]], "record() (in module torch.distributed.elastic.events)": [[52, "torch.distributed.elastic.events.record"]], "torch.distributed.elastic.events": [[52, "module-torch.distributed.elastic.events"]], "consolemetrichandler (class in torch.distributed.elastic.metrics.api)": [[55, "torch.distributed.elastic.metrics.api.ConsoleMetricHandler"]], "metrichandler (class in torch.distributed.elastic.metrics.api)": [[55, "torch.distributed.elastic.metrics.api.MetricHandler"]], "nullmetrichandler (class in torch.distributed.elastic.metrics.api)": [[55, "torch.distributed.elastic.metrics.api.NullMetricHandler"]], "configure() (in module torch.distributed.elastic.metrics)": [[55, "torch.distributed.elastic.metrics.configure"]], "prof() (in module torch.distributed.elastic.metrics)": [[55, "torch.distributed.elastic.metrics.prof"]], "put_metric() (in module torch.distributed.elastic.metrics)": [[55, "torch.distributed.elastic.metrics.put_metric"]], "torch.distributed.elastic.metrics": [[55, "module-torch.distributed.elastic.metrics"]], "multiprocesscontext (class in torch.distributed.elastic.multiprocessing.api)": [[56, "torch.distributed.elastic.multiprocessing.api.MultiprocessContext"]], "pcontext (class in torch.distributed.elastic.multiprocessing.api)": [[56, "torch.distributed.elastic.multiprocessing.api.PContext"]], "runprocsresult (class in torch.distributed.elastic.multiprocessing.api)": [[56, "torch.distributed.elastic.multiprocessing.api.RunProcsResult"]], "subprocesscontext (class in torch.distributed.elastic.multiprocessing.api)": [[56, "torch.distributed.elastic.multiprocessing.api.SubprocessContext"]], "start_processes() (in module torch.distributed.elastic.multiprocessing)": [[56, "torch.distributed.elastic.multiprocessing.start_processes"]], "torch.distributed.elastic.multiprocessing": [[56, "module-torch.distributed.elastic.multiprocessing"]], "c10drendezvousbackend (class in torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)": [[58, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend"]], "dynamicrendezvoushandler (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler"]], "etcdrendezvousbackend (class in torch.distributed.elastic.rendezvous.etcd_rendezvous_backend)": [[58, "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend"]], "etcdrendezvoushandler (class in torch.distributed.elastic.rendezvous.etcd_rendezvous)": [[58, "torch.distributed.elastic.rendezvous.etcd_rendezvous.EtcdRendezvousHandler"]], "etcdserver (class in torch.distributed.elastic.rendezvous.etcd_server)": [[58, "torch.distributed.elastic.rendezvous.etcd_server.EtcdServer"]], "etcdstore (class in torch.distributed.elastic.rendezvous.etcd_store)": [[58, "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore"]], "rendezvousbackend (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend"]], "rendezvousclosederror (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousClosedError"]], "rendezvousconnectionerror (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousConnectionError"]], "rendezvouserror (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousError"]], "rendezvoushandler (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler"]], "rendezvoushandlerregistry (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry"]], "rendezvousparameters (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousParameters"]], "rendezvousstateerror (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousStateError"]], "rendezvoustimeout (class in torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout"]], "rendezvoustimeouterror (class in torch.distributed.elastic.rendezvous)": [[58, "torch.distributed.elastic.rendezvous.RendezvousTimeoutError"]], "add() (torch.distributed.elastic.rendezvous.etcd_store.etcdstore method)": [[58, "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.add"]], "check() (torch.distributed.elastic.rendezvous.etcd_store.etcdstore method)": [[58, "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.check"]], "close (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.close"]], "create_backend() (in module torch.distributed.elastic.rendezvous.c10d_rendezvous_backend)": [[58, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.create_backend"]], "create_backend() (in module torch.distributed.elastic.rendezvous.etcd_rendezvous_backend)": [[58, "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.create_backend"]], "create_handler() (in module torch.distributed.elastic.rendezvous.dynamic_rendezvous)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.create_handler"]], "create_handler() (torch.distributed.elastic.rendezvous.rendezvoushandlerregistry method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry.create_handler"]], "from_backend() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.dynamicrendezvoushandler class method)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.DynamicRendezvousHandler.from_backend"]], "get() (torch.distributed.elastic.rendezvous.rendezvousparameters method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousParameters.get"]], "get() (torch.distributed.elastic.rendezvous.etcd_store.etcdstore method)": [[58, "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.get"]], "get_as_bool() (torch.distributed.elastic.rendezvous.rendezvousparameters method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_bool"]], "get_as_int() (torch.distributed.elastic.rendezvous.rendezvousparameters method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousParameters.get_as_int"]], "get_backend() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler.get_backend"]], "get_run_id() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler.get_run_id"]], "get_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.c10drendezvousbackend method)": [[58, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.get_state"]], "get_state() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvousbackend method)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.get_state"]], "get_state() (torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.etcdrendezvousbackend method)": [[58, "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.get_state"]], "heartbeat (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.heartbeat"]], "is_closed() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler.is_closed"]], "join (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.join"]], "last_call (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvoustimeout property)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousTimeout.last_call"]], "name (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.c10drendezvousbackend property)": [[58, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.name"]], "name (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvousbackend property)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.name"]], "name (torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.etcdrendezvousbackend property)": [[58, "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.name"]], "next_rendezvous() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler.next_rendezvous"]], "num_nodes_waiting() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler.num_nodes_waiting"]], "register() (torch.distributed.elastic.rendezvous.rendezvoushandlerregistry method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandlerRegistry.register"]], "set() (torch.distributed.elastic.rendezvous.etcd_store.etcdstore method)": [[58, "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.set"]], "set_closed() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler.set_closed"]], "set_state() (torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.c10drendezvousbackend method)": [[58, "torch.distributed.elastic.rendezvous.c10d_rendezvous_backend.C10dRendezvousBackend.set_state"]], "set_state() (torch.distributed.elastic.rendezvous.dynamic_rendezvous.rendezvousbackend method)": [[58, "torch.distributed.elastic.rendezvous.dynamic_rendezvous.RendezvousBackend.set_state"]], "set_state() (torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.etcdrendezvousbackend method)": [[58, "torch.distributed.elastic.rendezvous.etcd_rendezvous_backend.EtcdRendezvousBackend.set_state"]], "shutdown() (torch.distributed.elastic.rendezvous.rendezvoushandler method)": [[58, "torch.distributed.elastic.rendezvous.RendezvousHandler.shutdown"]], "torch.distributed.elastic.rendezvous": [[58, "module-torch.distributed.elastic.rendezvous"]], "torch.distributed.elastic.rendezvous.registry": [[58, "module-torch.distributed.elastic.rendezvous.registry"]], "wait() (torch.distributed.elastic.rendezvous.etcd_store.etcdstore method)": [[58, "torch.distributed.elastic.rendezvous.etcd_store.EtcdStore.wait"]], "torch.distributed.run": [[59, "module-torch.distributed.run"]], "filetimerclient (class in torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.FileTimerClient"]], "filetimerserver (class in torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.FileTimerServer"]], "localtimerclient (class in torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.LocalTimerClient"]], "localtimerserver (class in torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.LocalTimerServer"]], "timerclient (class in torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.TimerClient"]], "timerrequest (class in torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.TimerRequest"]], "timerserver (class in torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.TimerServer"]], "acquire() (torch.distributed.elastic.timer.timerclient method)": [[60, "torch.distributed.elastic.timer.TimerClient.acquire"]], "clear_timers() (torch.distributed.elastic.timer.timerserver method)": [[60, "torch.distributed.elastic.timer.TimerServer.clear_timers"]], "configure() (in module torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.configure"]], "expires() (in module torch.distributed.elastic.timer)": [[60, "torch.distributed.elastic.timer.expires"]], "get_expired_timers() (torch.distributed.elastic.timer.timerserver method)": [[60, "torch.distributed.elastic.timer.TimerServer.get_expired_timers"]], "register_timers() (torch.distributed.elastic.timer.timerserver method)": [[60, "torch.distributed.elastic.timer.TimerServer.register_timers"]], "release() (torch.distributed.elastic.timer.timerclient method)": [[60, "torch.distributed.elastic.timer.TimerClient.release"]], "torch.distributed.elastic.timer": [[60, "module-torch.distributed.elastic.timer"]], "torch.fft": [[62, "module-torch.fft"]], "backwardprefetch (class in torch.distributed.fsdp)": [[63, "torch.distributed.fsdp.BackwardPrefetch"]], "cpuoffload (class in torch.distributed.fsdp)": [[63, "torch.distributed.fsdp.CPUOffload"]], "fullyshardeddataparallel (class in torch.distributed.fsdp)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel"]], "mixedprecision (class in torch.distributed.fsdp)": [[63, "torch.distributed.fsdp.MixedPrecision"]], "shardingstrategy (class in torch.distributed.fsdp)": [[63, "torch.distributed.fsdp.ShardingStrategy"]], "apply() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.apply"]], "clip_grad_norm_() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.clip_grad_norm_"]], "flatten_sharded_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.flatten_sharded_optim_state_dict"]], "forward() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.forward"]], "fsdp_modules() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.fsdp_modules"]], "full_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.full_optim_state_dict"]], "load_optim_state_dict_pre_hook() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.load_optim_state_dict_pre_hook"]], "module (torch.distributed.fsdp.fullyshardeddataparallel property)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.module"]], "named_buffers() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.named_buffers"]], "named_parameters() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.named_parameters"]], "no_sync() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.no_sync"]], "optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict"]], "optim_state_dict_post_hook() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict_post_hook"]], "optim_state_dict_to_load() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.optim_state_dict_to_load"]], "register_comm_hook() (torch.distributed.fsdp.fullyshardeddataparallel method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.register_comm_hook"]], "rekey_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.rekey_optim_state_dict"]], "scatter_full_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.scatter_full_optim_state_dict"]], "set_state_dict_type() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.set_state_dict_type"]], "shard_full_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.shard_full_optim_state_dict"]], "sharded_optim_state_dict() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.sharded_optim_state_dict"]], "state_dict_type() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.state_dict_type"]], "summon_full_params() (torch.distributed.fsdp.fullyshardeddataparallel static method)": [[63, "torch.distributed.fsdp.FullyShardedDataParallel.summon_full_params"]], "torch.distributed.fsdp": [[63, "module-torch.distributed.fsdp"]], "torch.func": [[65, "module-torch.func"]], "future (class in torch.futures)": [[70, "torch.futures.Future"]], "add_done_callback() (torch.futures.future method)": [[70, "torch.futures.Future.add_done_callback"]], "collect_all() (in module torch.futures)": [[70, "torch.futures.collect_all"]], "done() (torch.futures.future method)": [[70, "torch.futures.Future.done"]], "set_exception() (torch.futures.future method)": [[70, "torch.futures.Future.set_exception"]], "set_result() (torch.futures.future method)": [[70, "torch.futures.Future.set_result"]], "then() (torch.futures.future method)": [[70, "torch.futures.Future.then"]], "torch.futures": [[70, "module-torch.futures"]], "value() (torch.futures.future method)": [[70, "torch.futures.Future.value"]], "wait() (torch.futures.future method)": [[70, "torch.futures.Future.wait"]], "wait_all() (in module torch.futures)": [[70, "torch.futures.wait_all"]], "graph (class in torch.fx)": [[71, "torch.fx.Graph"]], "graphmodule (class in torch.fx)": [[71, "torch.fx.GraphModule"]], "interpreter (class in torch.fx)": [[71, "torch.fx.Interpreter"]], "node (class in torch.fx)": [[71, "torch.fx.Node"]], "proxy (class in torch.fx)": [[71, "torch.fx.Proxy"]], "tracer (class in torch.fx)": [[71, "torch.fx.Tracer"]], "transformer (class in torch.fx)": [[71, "torch.fx.Transformer"]], "__init__() (torch.fx.graph method)": [[71, "torch.fx.Graph.__init__"]], "__init__() (torch.fx.graphmodule method)": [[71, "torch.fx.GraphModule.__init__"]], "add_submodule() (torch.fx.graphmodule method)": [[71, "torch.fx.GraphModule.add_submodule"]], "all_input_nodes (torch.fx.node property)": [[71, "torch.fx.Node.all_input_nodes"]], "append() (torch.fx.node method)": [[71, "torch.fx.Node.append"]], "args (torch.fx.node property)": [[71, "torch.fx.Node.args"]], "boxed_run() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.boxed_run"]], "call_function() (torch.fx.graph method)": [[71, "torch.fx.Graph.call_function"]], "call_function() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.call_function"]], "call_function() (torch.fx.transformer method)": [[71, "torch.fx.Transformer.call_function"]], "call_method() (torch.fx.graph method)": [[71, "torch.fx.Graph.call_method"]], "call_method() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.call_method"]], "call_module() (torch.fx.graph method)": [[71, "torch.fx.Graph.call_module"]], "call_module() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.call_module"]], "call_module() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.call_module"]], "call_module() (torch.fx.transformer method)": [[71, "torch.fx.Transformer.call_module"]], "code (torch.fx.graphmodule property)": [[71, "torch.fx.GraphModule.code"]], "create_arg() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.create_arg"]], "create_args_for_root() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.create_args_for_root"]], "create_node() (torch.fx.graph method)": [[71, "torch.fx.Graph.create_node"]], "create_node() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.create_node"]], "create_proxy() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.create_proxy"]], "delete_all_unused_submodules() (torch.fx.graphmodule method)": [[71, "torch.fx.GraphModule.delete_all_unused_submodules"]], "delete_submodule() (torch.fx.graphmodule method)": [[71, "torch.fx.GraphModule.delete_submodule"]], "eliminate_dead_code() (torch.fx.graph method)": [[71, "torch.fx.Graph.eliminate_dead_code"]], "erase_node() (torch.fx.graph method)": [[71, "torch.fx.Graph.erase_node"]], "fetch_args_kwargs_from_env() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.fetch_args_kwargs_from_env"]], "fetch_attr() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.fetch_attr"]], "format_node() (torch.fx.node method)": [[71, "torch.fx.Node.format_node"]], "get_attr() (torch.fx.graph method)": [[71, "torch.fx.Graph.get_attr"]], "get_attr() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.get_attr"]], "get_attr() (torch.fx.transformer method)": [[71, "torch.fx.Transformer.get_attr"]], "getattr() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.getattr"]], "graph (torch.fx.graphmodule property)": [[71, "torch.fx.GraphModule.graph"]], "graph_copy() (torch.fx.graph method)": [[71, "torch.fx.Graph.graph_copy"]], "inserting_after() (torch.fx.graph method)": [[71, "torch.fx.Graph.inserting_after"]], "inserting_before() (torch.fx.graph method)": [[71, "torch.fx.Graph.inserting_before"]], "is_impure() (torch.fx.node method)": [[71, "torch.fx.Node.is_impure"]], "is_leaf_module() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.is_leaf_module"]], "iter() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.iter"]], "keys() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.keys"]], "kwargs (torch.fx.node property)": [[71, "torch.fx.Node.kwargs"]], "lint() (torch.fx.graph method)": [[71, "torch.fx.Graph.lint"]], "map_nodes_to_values() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.map_nodes_to_values"]], "next (torch.fx.node property)": [[71, "torch.fx.Node.next"]], "node_copy() (torch.fx.graph method)": [[71, "torch.fx.Graph.node_copy"]], "nodes (torch.fx.graph property)": [[71, "torch.fx.Graph.nodes"]], "normalized_arguments() (torch.fx.node method)": [[71, "torch.fx.Node.normalized_arguments"]], "on_generate_code() (torch.fx.graph method)": [[71, "torch.fx.Graph.on_generate_code"]], "output() (torch.fx.graph method)": [[71, "torch.fx.Graph.output"]], "output() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.output"]], "path_of_module() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.path_of_module"]], "placeholder() (torch.fx.graph method)": [[71, "torch.fx.Graph.placeholder"]], "placeholder() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.placeholder"]], "placeholder() (torch.fx.transformer method)": [[71, "torch.fx.Transformer.placeholder"]], "prepend() (torch.fx.node method)": [[71, "torch.fx.Node.prepend"]], "prev (torch.fx.node property)": [[71, "torch.fx.Node.prev"]], "print_readable() (torch.fx.graphmodule method)": [[71, "torch.fx.GraphModule.print_readable"]], "print_tabular() (torch.fx.graph method)": [[71, "torch.fx.Graph.print_tabular"]], "process_inputs() (torch.fx.graph method)": [[71, "torch.fx.Graph.process_inputs"]], "process_outputs() (torch.fx.graph method)": [[71, "torch.fx.Graph.process_outputs"]], "proxy() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.proxy"]], "python_code() (torch.fx.graph method)": [[71, "torch.fx.Graph.python_code"]], "recompile() (torch.fx.graphmodule method)": [[71, "torch.fx.GraphModule.recompile"]], "replace_all_uses_with() (torch.fx.node method)": [[71, "torch.fx.Node.replace_all_uses_with"]], "replace_input_with() (torch.fx.node method)": [[71, "torch.fx.Node.replace_input_with"]], "replace_pattern() (in module torch.fx)": [[71, "torch.fx.replace_pattern"]], "run() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.run"]], "run_node() (torch.fx.interpreter method)": [[71, "torch.fx.Interpreter.run_node"]], "set_codegen() (torch.fx.graph method)": [[71, "torch.fx.Graph.set_codegen"]], "stack_trace (torch.fx.node property)": [[71, "torch.fx.Node.stack_trace"]], "symbolic_trace() (in module torch.fx)": [[71, "torch.fx.symbolic_trace"]], "to_bool() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.to_bool"]], "to_folder() (torch.fx.graphmodule method)": [[71, "torch.fx.GraphModule.to_folder"]], "torch.fx": [[71, "module-torch.fx"]], "torch.fx.experimental": [[71, "module-torch.fx.experimental"]], "torch.fx.experimental.migrate_gradual_types": [[71, "module-torch.fx.experimental.migrate_gradual_types"]], "torch.fx.experimental.unification": [[71, "module-torch.fx.experimental.unification"]], "torch.fx.experimental.unification.multipledispatch": [[71, "module-torch.fx.experimental.unification.multipledispatch"]], "torch.fx.passes": [[71, "module-torch.fx.passes"]], "torch.fx.passes.backends": [[71, "module-torch.fx.passes.backends"]], "torch.fx.passes.dialect": [[71, "module-torch.fx.passes.dialect"]], "torch.fx.passes.dialect.common": [[71, "module-torch.fx.passes.dialect.common"]], "torch.fx.passes.infra": [[71, "module-torch.fx.passes.infra"]], "torch.fx.passes.tests": [[71, "module-torch.fx.passes.tests"]], "torch.fx.passes.utils": [[71, "module-torch.fx.passes.utils"]], "trace() (torch.fx.tracer method)": [[71, "torch.fx.Tracer.trace"]], "transform() (torch.fx.transformer method)": [[71, "torch.fx.Transformer.transform"]], "update_arg() (torch.fx.node method)": [[71, "torch.fx.Node.update_arg"]], "update_kwarg() (torch.fx.node method)": [[71, "torch.fx.Node.update_kwarg"]], "wrap() (in module torch.fx)": [[71, "torch.fx.wrap"]], "generator (class in torch)": [[89, "torch.Generator"]], "device (torch.generator attribute)": [[89, "torch.Generator.device"]], "get_state() (torch.generator method)": [[89, "torch.Generator.get_state"]], "initial_seed() (torch.generator method)": [[89, "torch.Generator.initial_seed"]], "manual_seed() (torch.generator method)": [[89, "torch.Generator.manual_seed"]], "seed() (torch.generator method)": [[89, "torch.Generator.seed"]], "set_state() (torch.generator method)": [[89, "torch.Generator.set_state"]], "abs() (torch.tensor method)": [[90, "torch.Tensor.abs"]], "abs_() (torch.tensor method)": [[91, "torch.Tensor.abs_"]], "absolute() (torch.tensor method)": [[92, "torch.Tensor.absolute"]], "absolute_() (torch.tensor method)": [[93, "torch.Tensor.absolute_"]], "acos() (torch.tensor method)": [[94, "torch.Tensor.acos"]], "acos_() (torch.tensor method)": [[95, "torch.Tensor.acos_"]], "acosh() (torch.tensor method)": [[96, "torch.Tensor.acosh"]], "acosh_() (torch.tensor method)": [[97, "torch.Tensor.acosh_"]], "add() (torch.tensor method)": [[98, "torch.Tensor.add"]], "add_() (torch.tensor method)": [[99, "torch.Tensor.add_"]], "addbmm() (torch.tensor method)": [[100, "torch.Tensor.addbmm"]], "addbmm_() (torch.tensor method)": [[101, "torch.Tensor.addbmm_"]], "addcdiv() (torch.tensor method)": [[102, "torch.Tensor.addcdiv"]], "addcdiv_() (torch.tensor method)": [[103, "torch.Tensor.addcdiv_"]], "addcmul() (torch.tensor method)": [[104, "torch.Tensor.addcmul"]], "addcmul_() (torch.tensor method)": [[105, "torch.Tensor.addcmul_"]], "addmm() (torch.tensor method)": [[106, "torch.Tensor.addmm"]], "addmm_() (torch.tensor method)": [[107, "torch.Tensor.addmm_"]], "addmv() (torch.tensor method)": [[108, "torch.Tensor.addmv"]], "addmv_() (torch.tensor method)": [[109, "torch.Tensor.addmv_"]], "addr() (torch.tensor method)": [[110, "torch.Tensor.addr"]], "addr_() (torch.tensor method)": [[111, "torch.Tensor.addr_"]], "adjoint() (torch.tensor method)": [[112, "torch.Tensor.adjoint"]], "all() (torch.tensor method)": [[113, "torch.Tensor.all"]], "allclose() (torch.tensor method)": [[114, "torch.Tensor.allclose"]], "amax() (torch.tensor method)": [[115, "torch.Tensor.amax"]], "amin() (torch.tensor method)": [[116, "torch.Tensor.amin"]], "aminmax() (torch.tensor method)": [[117, "torch.Tensor.aminmax"]], "angle() (torch.tensor method)": [[118, "torch.Tensor.angle"]], "any() (torch.tensor method)": [[119, "torch.Tensor.any"]], "apply_() (torch.tensor method)": [[120, "torch.Tensor.apply_"]], "arccos() (torch.tensor method)": [[121, "torch.Tensor.arccos"]], "arccos_() (torch.tensor method)": [[122, "torch.Tensor.arccos_"]], "arccosh() (torch.tensor method)": [[123, "torch.Tensor.arccosh"]], "arccosh_() (torch.tensor method)": [[124, "torch.Tensor.arccosh_"]], "arcsin() (torch.tensor method)": [[125, "torch.Tensor.arcsin"]], "arcsin_() (torch.tensor method)": [[126, "torch.Tensor.arcsin_"]], "arcsinh() (torch.tensor method)": [[127, "torch.Tensor.arcsinh"]], "arcsinh_() (torch.tensor method)": [[128, "torch.Tensor.arcsinh_"]], "arctan() (torch.tensor method)": [[129, "torch.Tensor.arctan"]], "arctan2() (torch.tensor method)": [[130, "torch.Tensor.arctan2"]], "arctan2_() (torch.tensor method)": [[131, "torch.Tensor.arctan2_"]], "arctan_() (torch.tensor method)": [[132, "torch.Tensor.arctan_"]], "arctanh() (torch.tensor method)": [[133, "torch.Tensor.arctanh"]], "arctanh_() (torch.tensor method)": [[134, "torch.Tensor.arctanh_"]], "argmax() (torch.tensor method)": [[135, "torch.Tensor.argmax"]], "argmin() (torch.tensor method)": [[136, "torch.Tensor.argmin"]], "argsort() (torch.tensor method)": [[137, "torch.Tensor.argsort"]], "argwhere() (torch.tensor method)": [[138, "torch.Tensor.argwhere"]], "as_strided() (torch.tensor method)": [[139, "torch.Tensor.as_strided"]], "as_subclass() (torch.tensor method)": [[140, "torch.Tensor.as_subclass"]], "asin() (torch.tensor method)": [[141, "torch.Tensor.asin"]], "asin_() (torch.tensor method)": [[142, "torch.Tensor.asin_"]], "asinh() (torch.tensor method)": [[143, "torch.Tensor.asinh"]], "asinh_() (torch.tensor method)": [[144, "torch.Tensor.asinh_"]], "atan() (torch.tensor method)": [[145, "torch.Tensor.atan"]], "atan2() (torch.tensor method)": [[146, "torch.Tensor.atan2"]], "atan2_() (torch.tensor method)": [[147, "torch.Tensor.atan2_"]], "atan_() (torch.tensor method)": [[148, "torch.Tensor.atan_"]], "atanh() (torch.tensor method)": [[149, "torch.Tensor.atanh"]], "atanh_() (torch.tensor method)": [[150, "torch.Tensor.atanh_"]], "backward() (torch.tensor method)": [[151, "torch.Tensor.backward"]], "baddbmm() (torch.tensor method)": [[152, "torch.Tensor.baddbmm"]], "baddbmm_() (torch.tensor method)": [[153, "torch.Tensor.baddbmm_"]], "bernoulli() (torch.tensor method)": [[154, "torch.Tensor.bernoulli"]], "bernoulli_() (torch.tensor method)": [[155, "torch.Tensor.bernoulli_"]], "bfloat16() (torch.tensor method)": [[156, "torch.Tensor.bfloat16"]], "bincount() (torch.tensor method)": [[157, "torch.Tensor.bincount"]], "bitwise_and() (torch.tensor method)": [[158, "torch.Tensor.bitwise_and"]], "bitwise_and_() (torch.tensor method)": [[159, "torch.Tensor.bitwise_and_"]], "bitwise_left_shift() (torch.tensor method)": [[160, "torch.Tensor.bitwise_left_shift"]], "bitwise_left_shift_() (torch.tensor method)": [[161, "torch.Tensor.bitwise_left_shift_"]], "bitwise_not() (torch.tensor method)": [[162, "torch.Tensor.bitwise_not"]], "bitwise_not_() (torch.tensor method)": [[163, "torch.Tensor.bitwise_not_"]], "bitwise_or() (torch.tensor method)": [[164, "torch.Tensor.bitwise_or"]], "bitwise_or_() (torch.tensor method)": [[165, "torch.Tensor.bitwise_or_"]], "bitwise_right_shift() (torch.tensor method)": [[166, "torch.Tensor.bitwise_right_shift"]], "bitwise_right_shift_() (torch.tensor method)": [[167, "torch.Tensor.bitwise_right_shift_"]], "bitwise_xor() (torch.tensor method)": [[168, "torch.Tensor.bitwise_xor"]], "bitwise_xor_() (torch.tensor method)": [[169, "torch.Tensor.bitwise_xor_"]], "bmm() (torch.tensor method)": [[170, "torch.Tensor.bmm"]], "bool() (torch.tensor method)": [[171, "torch.Tensor.bool"]], "broadcast_to() (torch.tensor method)": [[172, "torch.Tensor.broadcast_to"]], "byte() (torch.tensor method)": [[173, "torch.Tensor.byte"]], "cauchy_() (torch.tensor method)": [[174, "torch.Tensor.cauchy_"]], "ccol_indices() (torch.tensor method)": [[175, "torch.Tensor.ccol_indices"]], "cdouble() (torch.tensor method)": [[176, "torch.Tensor.cdouble"]], "ceil() (torch.tensor method)": [[177, "torch.Tensor.ceil"]], "ceil_() (torch.tensor method)": [[178, "torch.Tensor.ceil_"]], "cfloat() (torch.tensor method)": [[179, "torch.Tensor.cfloat"]], "chalf() (torch.tensor method)": [[180, "torch.Tensor.chalf"]], "char() (torch.tensor method)": [[181, "torch.Tensor.char"]], "cholesky() (torch.tensor method)": [[182, "torch.Tensor.cholesky"]], "cholesky_inverse() (torch.tensor method)": [[183, "torch.Tensor.cholesky_inverse"]], "cholesky_solve() (torch.tensor method)": [[184, "torch.Tensor.cholesky_solve"]], "chunk() (torch.tensor method)": [[185, "torch.Tensor.chunk"]], "clamp() (torch.tensor method)": [[186, "torch.Tensor.clamp"]], "clamp_() (torch.tensor method)": [[187, "torch.Tensor.clamp_"]], "clip() (torch.tensor method)": [[188, "torch.Tensor.clip"]], "clip_() (torch.tensor method)": [[189, "torch.Tensor.clip_"]], "clone() (torch.tensor method)": [[190, "torch.Tensor.clone"]], "coalesce() (torch.tensor method)": [[191, "torch.Tensor.coalesce"]], "col_indices() (torch.tensor method)": [[192, "torch.Tensor.col_indices"]], "conj() (torch.tensor method)": [[193, "torch.Tensor.conj"]], "conj_physical() (torch.tensor method)": [[194, "torch.Tensor.conj_physical"]], "conj_physical_() (torch.tensor method)": [[195, "torch.Tensor.conj_physical_"]], "contiguous() (torch.tensor method)": [[196, "torch.Tensor.contiguous"]], "copy_() (torch.tensor method)": [[197, "torch.Tensor.copy_"]], "copysign() (torch.tensor method)": [[198, "torch.Tensor.copysign"]], "copysign_() (torch.tensor method)": [[199, "torch.Tensor.copysign_"]], "corrcoef() (torch.tensor method)": [[200, "torch.Tensor.corrcoef"]], "cos() (torch.tensor method)": [[201, "torch.Tensor.cos"]], "cos_() (torch.tensor method)": [[202, "torch.Tensor.cos_"]], "cosh() (torch.tensor method)": [[203, "torch.Tensor.cosh"]], "cosh_() (torch.tensor method)": [[204, "torch.Tensor.cosh_"]], "count_nonzero() (torch.tensor method)": [[205, "torch.Tensor.count_nonzero"]], "cov() (torch.tensor method)": [[206, "torch.Tensor.cov"]], "cpu() (torch.tensor method)": [[207, "torch.Tensor.cpu"]], "cross() (torch.tensor method)": [[208, "torch.Tensor.cross"]], "crow_indices() (torch.tensor method)": [[209, "torch.Tensor.crow_indices"]], "cuda() (torch.tensor method)": [[210, "torch.Tensor.cuda"]], "cummax() (torch.tensor method)": [[211, "torch.Tensor.cummax"]], "cummin() (torch.tensor method)": [[212, "torch.Tensor.cummin"]], "cumprod() (torch.tensor method)": [[213, "torch.Tensor.cumprod"]], "cumprod_() (torch.tensor method)": [[214, "torch.Tensor.cumprod_"]], "cumsum() (torch.tensor method)": [[215, "torch.Tensor.cumsum"]], "cumsum_() (torch.tensor method)": [[216, "torch.Tensor.cumsum_"]], "data_ptr() (torch.tensor method)": [[217, "torch.Tensor.data_ptr"]], "deg2rad() (torch.tensor method)": [[218, "torch.Tensor.deg2rad"]], "dense_dim() (torch.tensor method)": [[219, "torch.Tensor.dense_dim"]], "dequantize() (torch.tensor method)": [[220, "torch.Tensor.dequantize"]], "det() (torch.tensor method)": [[221, "torch.Tensor.det"]], "detach() (torch.tensor method)": [[222, "torch.Tensor.detach"]], "detach_() (torch.tensor method)": [[223, "torch.Tensor.detach_"]], "device (torch.tensor attribute)": [[224, "torch.Tensor.device"]], "diag() (torch.tensor method)": [[225, "torch.Tensor.diag"]], "diag_embed() (torch.tensor method)": [[226, "torch.Tensor.diag_embed"]], "diagflat() (torch.tensor method)": [[227, "torch.Tensor.diagflat"]], "diagonal() (torch.tensor method)": [[228, "torch.Tensor.diagonal"]], "diagonal_scatter() (torch.tensor method)": [[229, "torch.Tensor.diagonal_scatter"]], "diff() (torch.tensor method)": [[230, "torch.Tensor.diff"]], "digamma() (torch.tensor method)": [[231, "torch.Tensor.digamma"]], "digamma_() (torch.tensor method)": [[232, "torch.Tensor.digamma_"]], "dim() (torch.tensor method)": [[233, "torch.Tensor.dim"]], "dist() (torch.tensor method)": [[234, "torch.Tensor.dist"]], "div() (torch.tensor method)": [[235, "torch.Tensor.div"]], "div_() (torch.tensor method)": [[236, "torch.Tensor.div_"]], "divide() (torch.tensor method)": [[237, "torch.Tensor.divide"]], "divide_() (torch.tensor method)": [[238, "torch.Tensor.divide_"]], "dot() (torch.tensor method)": [[239, "torch.Tensor.dot"]], "double() (torch.tensor method)": [[240, "torch.Tensor.double"]], "dsplit() (torch.tensor method)": [[241, "torch.Tensor.dsplit"]], "element_size() (torch.tensor method)": [[242, "torch.Tensor.element_size"]], "eq() (torch.tensor method)": [[243, "torch.Tensor.eq"]], "eq_() (torch.tensor method)": [[244, "torch.Tensor.eq_"]], "equal() (torch.tensor method)": [[245, "torch.Tensor.equal"]], "erf() (torch.tensor method)": [[246, "torch.Tensor.erf"]], "erf_() (torch.tensor method)": [[247, "torch.Tensor.erf_"]], "erfc() (torch.tensor method)": [[248, "torch.Tensor.erfc"]], "erfc_() (torch.tensor method)": [[249, "torch.Tensor.erfc_"]], "erfinv() (torch.tensor method)": [[250, "torch.Tensor.erfinv"]], "erfinv_() (torch.tensor method)": [[251, "torch.Tensor.erfinv_"]], "exp() (torch.tensor method)": [[252, "torch.Tensor.exp"]], "exp_() (torch.tensor method)": [[253, "torch.Tensor.exp_"]], "expand() (torch.tensor method)": [[254, "torch.Tensor.expand"]], "expand_as() (torch.tensor method)": [[255, "torch.Tensor.expand_as"]], "expm1() (torch.tensor method)": [[256, "torch.Tensor.expm1"]], "expm1_() (torch.tensor method)": [[257, "torch.Tensor.expm1_"]], "exponential_() (torch.tensor method)": [[258, "torch.Tensor.exponential_"]], "fill_() (torch.tensor method)": [[259, "torch.Tensor.fill_"]], "fill_diagonal_() (torch.tensor method)": [[260, "torch.Tensor.fill_diagonal_"]], "fix() (torch.tensor method)": [[261, "torch.Tensor.fix"]], "fix_() (torch.tensor method)": [[262, "torch.Tensor.fix_"]], "flatten() (torch.tensor method)": [[263, "torch.Tensor.flatten"]], "flip() (torch.tensor method)": [[264, "torch.Tensor.flip"]], "fliplr() (torch.tensor method)": [[265, "torch.Tensor.fliplr"]], "flipud() (torch.tensor method)": [[266, "torch.Tensor.flipud"]], "float() (torch.tensor method)": [[267, "torch.Tensor.float"]], "float_power() (torch.tensor method)": [[268, "torch.Tensor.float_power"]], "float_power_() (torch.tensor method)": [[269, "torch.Tensor.float_power_"]], "floor() (torch.tensor method)": [[270, "torch.Tensor.floor"]], "floor_() (torch.tensor method)": [[271, "torch.Tensor.floor_"]], "floor_divide() (torch.tensor method)": [[272, "torch.Tensor.floor_divide"]], "floor_divide_() (torch.tensor method)": [[273, "torch.Tensor.floor_divide_"]], "fmax() (torch.tensor method)": [[274, "torch.Tensor.fmax"]], "fmin() (torch.tensor method)": [[275, "torch.Tensor.fmin"]], "fmod() (torch.tensor method)": [[276, "torch.Tensor.fmod"]], "fmod_() (torch.tensor method)": [[277, "torch.Tensor.fmod_"]], "frac() (torch.tensor method)": [[278, "torch.Tensor.frac"]], "frac_() (torch.tensor method)": [[279, "torch.Tensor.frac_"]], "frexp() (torch.tensor method)": [[280, "torch.Tensor.frexp"]], "gather() (torch.tensor method)": [[281, "torch.Tensor.gather"]], "gcd() (torch.tensor method)": [[282, "torch.Tensor.gcd"]], "gcd_() (torch.tensor method)": [[283, "torch.Tensor.gcd_"]], "ge() (torch.tensor method)": [[284, "torch.Tensor.ge"]], "ge_() (torch.tensor method)": [[285, "torch.Tensor.ge_"]], "geometric_() (torch.tensor method)": [[286, "torch.Tensor.geometric_"]], "geqrf() (torch.tensor method)": [[287, "torch.Tensor.geqrf"]], "ger() (torch.tensor method)": [[288, "torch.Tensor.ger"]], "get_device() (torch.tensor method)": [[289, "torch.Tensor.get_device"]], "grad (torch.tensor attribute)": [[290, "torch.Tensor.grad"]], "greater() (torch.tensor method)": [[291, "torch.Tensor.greater"]], "greater_() (torch.tensor method)": [[292, "torch.Tensor.greater_"]], "greater_equal() (torch.tensor method)": [[293, "torch.Tensor.greater_equal"]], "greater_equal_() (torch.tensor method)": [[294, "torch.Tensor.greater_equal_"]], "gt() (torch.tensor method)": [[295, "torch.Tensor.gt"]], "gt_() (torch.tensor method)": [[296, "torch.Tensor.gt_"]], "half() (torch.tensor method)": [[297, "torch.Tensor.half"]], "hardshrink() (torch.tensor method)": [[298, "torch.Tensor.hardshrink"]], "heaviside() (torch.tensor method)": [[299, "torch.Tensor.heaviside"]], "histc() (torch.tensor method)": [[300, "torch.Tensor.histc"]], "histogram() (torch.tensor method)": [[301, "torch.Tensor.histogram"]], "hsplit() (torch.tensor method)": [[302, "torch.Tensor.hsplit"]], "hypot() (torch.tensor method)": [[303, "torch.Tensor.hypot"]], "hypot_() (torch.tensor method)": [[304, "torch.Tensor.hypot_"]], "i0() (torch.tensor method)": [[305, "torch.Tensor.i0"]], "i0_() (torch.tensor method)": [[306, "torch.Tensor.i0_"]], "igamma() (torch.tensor method)": [[307, "torch.Tensor.igamma"]], "igamma_() (torch.tensor method)": [[308, "torch.Tensor.igamma_"]], "igammac() (torch.tensor method)": [[309, "torch.Tensor.igammac"]], "igammac_() (torch.tensor method)": [[310, "torch.Tensor.igammac_"]], "imag (torch.tensor attribute)": [[311, "torch.Tensor.imag"]], "index_add() (torch.tensor method)": [[312, "torch.Tensor.index_add"]], "index_add_() (torch.tensor method)": [[313, "torch.Tensor.index_add_"]], "index_copy() (torch.tensor method)": [[314, "torch.Tensor.index_copy"]], "index_copy_() (torch.tensor method)": [[315, "torch.Tensor.index_copy_"]], "index_fill() (torch.tensor method)": [[316, "torch.Tensor.index_fill"]], "index_fill_() (torch.tensor method)": [[317, "torch.Tensor.index_fill_"]], "index_put() (torch.tensor method)": [[318, "torch.Tensor.index_put"]], "index_put_() (torch.tensor method)": [[319, "torch.Tensor.index_put_"]], "index_reduce() (torch.tensor method)": [[320, "torch.Tensor.index_reduce"]], "index_reduce_() (torch.tensor method)": [[321, "torch.Tensor.index_reduce_"]], "index_select() (torch.tensor method)": [[322, "torch.Tensor.index_select"]], "indices() (torch.tensor method)": [[323, "torch.Tensor.indices"]], "inner() (torch.tensor method)": [[324, "torch.Tensor.inner"]], "int() (torch.tensor method)": [[325, "torch.Tensor.int"]], "int_repr() (torch.tensor method)": [[326, "torch.Tensor.int_repr"]], "inverse() (torch.tensor method)": [[327, "torch.Tensor.inverse"]], "is_coalesced() (torch.tensor method)": [[328, "torch.Tensor.is_coalesced"]], "is_complex() (torch.tensor method)": [[329, "torch.Tensor.is_complex"]], "is_conj() (torch.tensor method)": [[330, "torch.Tensor.is_conj"]], "is_contiguous() (torch.tensor method)": [[331, "torch.Tensor.is_contiguous"]], "is_cuda (torch.tensor attribute)": [[332, "torch.Tensor.is_cuda"]], "is_floating_point() (torch.tensor method)": [[333, "torch.Tensor.is_floating_point"]], "is_inference() (torch.tensor method)": [[334, "torch.Tensor.is_inference"]], "is_leaf (torch.tensor attribute)": [[335, "torch.Tensor.is_leaf"]], "is_meta (torch.tensor attribute)": [[336, "torch.Tensor.is_meta"]], "is_pinned() (torch.tensor method)": [[337, "torch.Tensor.is_pinned"]], "is_quantized (torch.tensor attribute)": [[338, "torch.Tensor.is_quantized"]], "is_set_to() (torch.tensor method)": [[339, "torch.Tensor.is_set_to"]], "is_shared() (torch.tensor method)": [[340, "torch.Tensor.is_shared"]], "is_signed() (torch.tensor method)": [[341, "torch.Tensor.is_signed"]], "is_sparse (torch.tensor attribute)": [[342, "torch.Tensor.is_sparse"]], "is_sparse_csr (torch.tensor attribute)": [[343, "torch.Tensor.is_sparse_csr"]], "isclose() (torch.tensor method)": [[344, "torch.Tensor.isclose"]], "isfinite() (torch.tensor method)": [[345, "torch.Tensor.isfinite"]], "isinf() (torch.tensor method)": [[346, "torch.Tensor.isinf"]], "isnan() (torch.tensor method)": [[347, "torch.Tensor.isnan"]], "isneginf() (torch.tensor method)": [[348, "torch.Tensor.isneginf"]], "isposinf() (torch.tensor method)": [[349, "torch.Tensor.isposinf"]], "isreal() (torch.tensor method)": [[350, "torch.Tensor.isreal"]], "istft() (torch.tensor method)": [[351, "torch.Tensor.istft"]], "item() (torch.tensor method)": [[352, "torch.Tensor.item"]], "itemsize (torch.tensor attribute)": [[353, "torch.Tensor.itemsize"]], "kthvalue() (torch.tensor method)": [[354, "torch.Tensor.kthvalue"]], "lcm() (torch.tensor method)": [[355, "torch.Tensor.lcm"]], "lcm_() (torch.tensor method)": [[356, "torch.Tensor.lcm_"]], "ldexp() (torch.tensor method)": [[357, "torch.Tensor.ldexp"]], "ldexp_() (torch.tensor method)": [[358, "torch.Tensor.ldexp_"]], "le() (torch.tensor method)": [[359, "torch.Tensor.le"]], "le_() (torch.tensor method)": [[360, "torch.Tensor.le_"]], "lerp() (torch.tensor method)": [[361, "torch.Tensor.lerp"]], "lerp_() (torch.tensor method)": [[362, "torch.Tensor.lerp_"]], "less() (torch.tensor method)": [[363, "torch.Tensor.less"]], "less_() (torch.tensor method)": [[364, "torch.Tensor.less_"]], "less_equal() (torch.tensor method)": [[365, "torch.Tensor.less_equal"]], "less_equal_() (torch.tensor method)": [[366, "torch.Tensor.less_equal_"]], "lgamma() (torch.tensor method)": [[367, "torch.Tensor.lgamma"]], "lgamma_() (torch.tensor method)": [[368, "torch.Tensor.lgamma_"]], "log() (torch.tensor method)": [[369, "torch.Tensor.log"]], "log10() (torch.tensor method)": [[370, "torch.Tensor.log10"]], "log10_() (torch.tensor method)": [[371, "torch.Tensor.log10_"]], "log1p() (torch.tensor method)": [[372, "torch.Tensor.log1p"]], "log1p_() (torch.tensor method)": [[373, "torch.Tensor.log1p_"]], "log2() (torch.tensor method)": [[374, "torch.Tensor.log2"]], "log2_() (torch.tensor method)": [[375, "torch.Tensor.log2_"]], "log_() (torch.tensor method)": [[376, "torch.Tensor.log_"]], "log_normal_() (torch.tensor method)": [[377, "torch.Tensor.log_normal_"]], "logaddexp() (torch.tensor method)": [[378, "torch.Tensor.logaddexp"]], "logaddexp2() (torch.tensor method)": [[379, "torch.Tensor.logaddexp2"]], "logcumsumexp() (torch.tensor method)": [[380, "torch.Tensor.logcumsumexp"]], "logdet() (torch.tensor method)": [[381, "torch.Tensor.logdet"]], "logical_and() (torch.tensor method)": [[382, "torch.Tensor.logical_and"]], "logical_and_() (torch.tensor method)": [[383, "torch.Tensor.logical_and_"]], "logical_not() (torch.tensor method)": [[384, "torch.Tensor.logical_not"]], "logical_not_() (torch.tensor method)": [[385, "torch.Tensor.logical_not_"]], "logical_or() (torch.tensor method)": [[386, "torch.Tensor.logical_or"]], "logical_or_() (torch.tensor method)": [[387, "torch.Tensor.logical_or_"]], "logical_xor() (torch.tensor method)": [[388, "torch.Tensor.logical_xor"]], "logical_xor_() (torch.tensor method)": [[389, "torch.Tensor.logical_xor_"]], "logit() (torch.tensor method)": [[390, "torch.Tensor.logit"]], "logit_() (torch.tensor method)": [[391, "torch.Tensor.logit_"]], "logsumexp() (torch.tensor method)": [[392, "torch.Tensor.logsumexp"]], "long() (torch.tensor method)": [[393, "torch.Tensor.long"]], "lt() (torch.tensor method)": [[394, "torch.Tensor.lt"]], "lt_() (torch.tensor method)": [[395, "torch.Tensor.lt_"]], "lu() (torch.tensor method)": [[396, "torch.Tensor.lu"]], "lu_solve() (torch.tensor method)": [[397, "torch.Tensor.lu_solve"]], "map_() (torch.tensor method)": [[398, "torch.Tensor.map_"]], "masked_fill() (torch.tensor method)": [[399, "torch.Tensor.masked_fill"]], "masked_fill_() (torch.tensor method)": [[400, "torch.Tensor.masked_fill_"]], "masked_scatter() (torch.tensor method)": [[401, "torch.Tensor.masked_scatter"]], "masked_scatter_() (torch.tensor method)": [[402, "torch.Tensor.masked_scatter_"]], "masked_select() (torch.tensor method)": [[403, "torch.Tensor.masked_select"]], "matmul() (torch.tensor method)": [[404, "torch.Tensor.matmul"]], "matrix_exp() (torch.tensor method)": [[405, "torch.Tensor.matrix_exp"]], "matrix_power() (torch.tensor method)": [[406, "torch.Tensor.matrix_power"]], "max() (torch.tensor method)": [[407, "torch.Tensor.max"]], "maximum() (torch.tensor method)": [[408, "torch.Tensor.maximum"]], "mean() (torch.tensor method)": [[409, "torch.Tensor.mean"]], "median() (torch.tensor method)": [[410, "torch.Tensor.median"]], "min() (torch.tensor method)": [[411, "torch.Tensor.min"]], "minimum() (torch.tensor method)": [[412, "torch.Tensor.minimum"]], "mm() (torch.tensor method)": [[413, "torch.Tensor.mm"]], "mode() (torch.tensor method)": [[414, "torch.Tensor.mode"]], "moveaxis() (torch.tensor method)": [[415, "torch.Tensor.moveaxis"]], "movedim() (torch.tensor method)": [[416, "torch.Tensor.movedim"]], "msort() (torch.tensor method)": [[417, "torch.Tensor.msort"]], "mul() (torch.tensor method)": [[418, "torch.Tensor.mul"]], "mul_() (torch.tensor method)": [[419, "torch.Tensor.mul_"]], "multinomial() (torch.tensor method)": [[420, "torch.Tensor.multinomial"]], "multiply() (torch.tensor method)": [[421, "torch.Tensor.multiply"]], "multiply_() (torch.tensor method)": [[422, "torch.Tensor.multiply_"]], "mv() (torch.tensor method)": [[423, "torch.Tensor.mv"]], "mvlgamma() (torch.tensor method)": [[424, "torch.Tensor.mvlgamma"]], "mvlgamma_() (torch.tensor method)": [[425, "torch.Tensor.mvlgamma_"]], "nan_to_num() (torch.tensor method)": [[426, "torch.Tensor.nan_to_num"]], "nan_to_num_() (torch.tensor method)": [[427, "torch.Tensor.nan_to_num_"]], "nanmean() (torch.tensor method)": [[428, "torch.Tensor.nanmean"]], "nanmedian() (torch.tensor method)": [[429, "torch.Tensor.nanmedian"]], "nanquantile() (torch.tensor method)": [[430, "torch.Tensor.nanquantile"]], "nansum() (torch.tensor method)": [[431, "torch.Tensor.nansum"]], "narrow() (torch.tensor method)": [[432, "torch.Tensor.narrow"]], "narrow_copy() (torch.tensor method)": [[433, "torch.Tensor.narrow_copy"]], "nbytes (torch.tensor attribute)": [[434, "torch.Tensor.nbytes"]], "ndim (torch.tensor attribute)": [[435, "torch.Tensor.ndim"]], "ndimension() (torch.tensor method)": [[436, "torch.Tensor.ndimension"]], "ne() (torch.tensor method)": [[437, "torch.Tensor.ne"]], "ne_() (torch.tensor method)": [[438, "torch.Tensor.ne_"]], "neg() (torch.tensor method)": [[439, "torch.Tensor.neg"]], "neg_() (torch.tensor method)": [[440, "torch.Tensor.neg_"]], "negative() (torch.tensor method)": [[441, "torch.Tensor.negative"]], "negative_() (torch.tensor method)": [[442, "torch.Tensor.negative_"]], "nelement() (torch.tensor method)": [[443, "torch.Tensor.nelement"]], "new_empty() (torch.tensor method)": [[444, "torch.Tensor.new_empty"]], "new_full() (torch.tensor method)": [[445, "torch.Tensor.new_full"]], "new_ones() (torch.tensor method)": [[446, "torch.Tensor.new_ones"]], "new_tensor() (torch.tensor method)": [[447, "torch.Tensor.new_tensor"]], "new_zeros() (torch.tensor method)": [[448, "torch.Tensor.new_zeros"]], "nextafter() (torch.tensor method)": [[449, "torch.Tensor.nextafter"]], "nextafter_() (torch.tensor method)": [[450, "torch.Tensor.nextafter_"]], "nonzero() (torch.tensor method)": [[451, "torch.Tensor.nonzero"]], "norm() (torch.tensor method)": [[452, "torch.Tensor.norm"]], "normal_() (torch.tensor method)": [[453, "torch.Tensor.normal_"]], "not_equal() (torch.tensor method)": [[454, "torch.Tensor.not_equal"]], "not_equal_() (torch.tensor method)": [[455, "torch.Tensor.not_equal_"]], "numel() (torch.tensor method)": [[456, "torch.Tensor.numel"]], "numpy() (torch.tensor method)": [[457, "torch.Tensor.numpy"]], "orgqr() (torch.tensor method)": [[458, "torch.Tensor.orgqr"]], "ormqr() (torch.tensor method)": [[459, "torch.Tensor.ormqr"]], "outer() (torch.tensor method)": [[460, "torch.Tensor.outer"]], "permute() (torch.tensor method)": [[461, "torch.Tensor.permute"]], "pin_memory() (torch.tensor method)": [[462, "torch.Tensor.pin_memory"]], "pinverse() (torch.tensor method)": [[463, "torch.Tensor.pinverse"]], "polygamma() (torch.tensor method)": [[464, "torch.Tensor.polygamma"]], "polygamma_() (torch.tensor method)": [[465, "torch.Tensor.polygamma_"]], "positive() (torch.tensor method)": [[466, "torch.Tensor.positive"]], "pow() (torch.tensor method)": [[467, "torch.Tensor.pow"]], "pow_() (torch.tensor method)": [[468, "torch.Tensor.pow_"]], "prod() (torch.tensor method)": [[469, "torch.Tensor.prod"]], "put_() (torch.tensor method)": [[470, "torch.Tensor.put_"]], "q_per_channel_axis() (torch.tensor method)": [[471, "torch.Tensor.q_per_channel_axis"]], "q_per_channel_scales() (torch.tensor method)": [[472, "torch.Tensor.q_per_channel_scales"]], "q_per_channel_zero_points() (torch.tensor method)": [[473, "torch.Tensor.q_per_channel_zero_points"]], "q_scale() (torch.tensor method)": [[474, "torch.Tensor.q_scale"]], "q_zero_point() (torch.tensor method)": [[475, "torch.Tensor.q_zero_point"]], "qr() (torch.tensor method)": [[476, "torch.Tensor.qr"]], "qscheme() (torch.tensor method)": [[477, "torch.Tensor.qscheme"]], "quantile() (torch.tensor method)": [[478, "torch.Tensor.quantile"]], "rad2deg() (torch.tensor method)": [[479, "torch.Tensor.rad2deg"]], "random_() (torch.tensor method)": [[480, "torch.Tensor.random_"]], "ravel() (torch.tensor method)": [[481, "torch.Tensor.ravel"]], "real (torch.tensor attribute)": [[482, "torch.Tensor.real"]], "reciprocal() (torch.tensor method)": [[483, "torch.Tensor.reciprocal"]], "reciprocal_() (torch.tensor method)": [[484, "torch.Tensor.reciprocal_"]], "record_stream() (torch.tensor method)": [[485, "torch.Tensor.record_stream"]], "register_hook() (torch.tensor method)": [[486, "torch.Tensor.register_hook"]], "remainder() (torch.tensor method)": [[487, "torch.Tensor.remainder"]], "remainder_() (torch.tensor method)": [[488, "torch.Tensor.remainder_"]], "renorm() (torch.tensor method)": [[489, "torch.Tensor.renorm"]], "renorm_() (torch.tensor method)": [[490, "torch.Tensor.renorm_"]], "repeat() (torch.tensor method)": [[491, "torch.Tensor.repeat"]], "repeat_interleave() (torch.tensor method)": [[492, "torch.Tensor.repeat_interleave"]], "requires_grad (torch.tensor attribute)": [[493, "torch.Tensor.requires_grad"]], "requires_grad_() (torch.tensor method)": [[494, "torch.Tensor.requires_grad_"]], "reshape() (torch.tensor method)": [[495, "torch.Tensor.reshape"]], "reshape_as() (torch.tensor method)": [[496, "torch.Tensor.reshape_as"]], "resize_() (torch.tensor method)": [[497, "torch.Tensor.resize_"]], "resize_as_() (torch.tensor method)": [[498, "torch.Tensor.resize_as_"]], "resolve_conj() (torch.tensor method)": [[499, "torch.Tensor.resolve_conj"]], "resolve_neg() (torch.tensor method)": [[500, "torch.Tensor.resolve_neg"]], "retain_grad() (torch.tensor method)": [[501, "torch.Tensor.retain_grad"]], "retains_grad (torch.tensor attribute)": [[502, "torch.Tensor.retains_grad"]], "roll() (torch.tensor method)": [[503, "torch.Tensor.roll"]], "rot90() (torch.tensor method)": [[504, "torch.Tensor.rot90"]], "round() (torch.tensor method)": [[505, "torch.Tensor.round"]], "round_() (torch.tensor method)": [[506, "torch.Tensor.round_"]], "row_indices() (torch.tensor method)": [[507, "torch.Tensor.row_indices"]], "rsqrt() (torch.tensor method)": [[508, "torch.Tensor.rsqrt"]], "rsqrt_() (torch.tensor method)": [[509, "torch.Tensor.rsqrt_"]], "scatter() (torch.tensor method)": [[510, "torch.Tensor.scatter"]], "scatter_() (torch.tensor method)": [[511, "torch.Tensor.scatter_"]], "scatter_add() (torch.tensor method)": [[512, "torch.Tensor.scatter_add"]], "scatter_add_() (torch.tensor method)": [[513, "torch.Tensor.scatter_add_"]], "scatter_reduce() (torch.tensor method)": [[514, "torch.Tensor.scatter_reduce"]], "scatter_reduce_() (torch.tensor method)": [[515, "torch.Tensor.scatter_reduce_"]], "select() (torch.tensor method)": [[516, "torch.Tensor.select"]], "select_scatter() (torch.tensor method)": [[517, "torch.Tensor.select_scatter"]], "set_() (torch.tensor method)": [[518, "torch.Tensor.set_"]], "sgn() (torch.tensor method)": [[519, "torch.Tensor.sgn"]], "sgn_() (torch.tensor method)": [[520, "torch.Tensor.sgn_"]], "share_memory_() (torch.tensor method)": [[521, "torch.Tensor.share_memory_"]], "short() (torch.tensor method)": [[522, "torch.Tensor.short"]], "sigmoid() (torch.tensor method)": [[523, "torch.Tensor.sigmoid"]], "sigmoid_() (torch.tensor method)": [[524, "torch.Tensor.sigmoid_"]], "sign() (torch.tensor method)": [[525, "torch.Tensor.sign"]], "sign_() (torch.tensor method)": [[526, "torch.Tensor.sign_"]], "signbit() (torch.tensor method)": [[527, "torch.Tensor.signbit"]], "sin() (torch.tensor method)": [[528, "torch.Tensor.sin"]], "sin_() (torch.tensor method)": [[529, "torch.Tensor.sin_"]], "sinc() (torch.tensor method)": [[530, "torch.Tensor.sinc"]], "sinc_() (torch.tensor method)": [[531, "torch.Tensor.sinc_"]], "sinh() (torch.tensor method)": [[532, "torch.Tensor.sinh"]], "sinh_() (torch.tensor method)": [[533, "torch.Tensor.sinh_"]], "size() (torch.tensor method)": [[534, "torch.Tensor.size"]], "slice_scatter() (torch.tensor method)": [[535, "torch.Tensor.slice_scatter"]], "slogdet() (torch.tensor method)": [[536, "torch.Tensor.slogdet"]], "smm() (torch.tensor method)": [[537, "torch.Tensor.smm"]], "softmax() (torch.tensor method)": [[538, "torch.Tensor.softmax"]], "sort() (torch.tensor method)": [[539, "torch.Tensor.sort"]], "sparse_dim() (torch.tensor method)": [[540, "torch.Tensor.sparse_dim"]], "sparse_mask() (torch.tensor method)": [[541, "torch.Tensor.sparse_mask"]], "sparse_resize_() (torch.tensor method)": [[542, "torch.Tensor.sparse_resize_"]], "sparse_resize_and_clear_() (torch.tensor method)": [[543, "torch.Tensor.sparse_resize_and_clear_"]], "split() (torch.tensor method)": [[544, "torch.Tensor.split"]], "sqrt() (torch.tensor method)": [[545, "torch.Tensor.sqrt"]], "sqrt_() (torch.tensor method)": [[546, "torch.Tensor.sqrt_"]], "square() (torch.tensor method)": [[547, "torch.Tensor.square"]], "square_() (torch.tensor method)": [[548, "torch.Tensor.square_"]], "squeeze() (torch.tensor method)": [[549, "torch.Tensor.squeeze"]], "squeeze_() (torch.tensor method)": [[550, "torch.Tensor.squeeze_"]], "sspaddmm() (torch.tensor method)": [[551, "torch.Tensor.sspaddmm"]], "std() (torch.tensor method)": [[552, "torch.Tensor.std"]], "stft() (torch.tensor method)": [[553, "torch.Tensor.stft"]], "storage() (torch.tensor method)": [[554, "torch.Tensor.storage"]], "storage_offset() (torch.tensor method)": [[555, "torch.Tensor.storage_offset"]], "storage_type() (torch.tensor method)": [[556, "torch.Tensor.storage_type"]], "stride() (torch.tensor method)": [[557, "torch.Tensor.stride"]], "sub() (torch.tensor method)": [[558, "torch.Tensor.sub"]], "sub_() (torch.tensor method)": [[559, "torch.Tensor.sub_"]], "subtract() (torch.tensor method)": [[560, "torch.Tensor.subtract"]], "subtract_() (torch.tensor method)": [[561, "torch.Tensor.subtract_"]], "sum() (torch.tensor method)": [[562, "torch.Tensor.sum"]], "sum_to_size() (torch.tensor method)": [[563, "torch.Tensor.sum_to_size"]], "svd() (torch.tensor method)": [[564, "torch.Tensor.svd"]], "swapaxes() (torch.tensor method)": [[565, "torch.Tensor.swapaxes"]], "swapdims() (torch.tensor method)": [[566, "torch.Tensor.swapdims"]], "t() (torch.tensor method)": [[567, "torch.Tensor.t"]], "t_() (torch.tensor method)": [[568, "torch.Tensor.t_"]], "take() (torch.tensor method)": [[569, "torch.Tensor.take"]], "take_along_dim() (torch.tensor method)": [[570, "torch.Tensor.take_along_dim"]], "tan() (torch.tensor method)": [[571, "torch.Tensor.tan"]], "tan_() (torch.tensor method)": [[572, "torch.Tensor.tan_"]], "tanh() (torch.tensor method)": [[573, "torch.Tensor.tanh"]], "tanh_() (torch.tensor method)": [[574, "torch.Tensor.tanh_"]], "tensor_split() (torch.tensor method)": [[575, "torch.Tensor.tensor_split"]], "tile() (torch.tensor method)": [[576, "torch.Tensor.tile"]], "to() (torch.tensor method)": [[577, "torch.Tensor.to"]], "to_dense() (torch.tensor method)": [[578, "torch.Tensor.to_dense"]], "to_mkldnn() (torch.tensor method)": [[579, "torch.Tensor.to_mkldnn"]], "to_sparse() (torch.tensor method)": [[580, "torch.Tensor.to_sparse"]], "to_sparse_bsc() (torch.tensor method)": [[581, "torch.Tensor.to_sparse_bsc"]], "to_sparse_bsr() (torch.tensor method)": [[582, "torch.Tensor.to_sparse_bsr"]], "to_sparse_coo() (torch.tensor method)": [[583, "torch.Tensor.to_sparse_coo"]], "to_sparse_csc() (torch.tensor method)": [[584, "torch.Tensor.to_sparse_csc"]], "to_sparse_csr() (torch.tensor method)": [[585, "torch.Tensor.to_sparse_csr"]], "tolist() (torch.tensor method)": [[586, "torch.Tensor.tolist"]], "topk() (torch.tensor method)": [[587, "torch.Tensor.topk"]], "trace() (torch.tensor method)": [[588, "torch.Tensor.trace"]], "transpose() (torch.tensor method)": [[589, "torch.Tensor.transpose"]], "transpose_() (torch.tensor method)": [[590, "torch.Tensor.transpose_"]], "triangular_solve() (torch.tensor method)": [[591, "torch.Tensor.triangular_solve"]], "tril() (torch.tensor method)": [[592, "torch.Tensor.tril"]], "tril_() (torch.tensor method)": [[593, "torch.Tensor.tril_"]], "triu() (torch.tensor method)": [[594, "torch.Tensor.triu"]], "triu_() (torch.tensor method)": [[595, "torch.Tensor.triu_"]], "true_divide() (torch.tensor method)": [[596, "torch.Tensor.true_divide"]], "true_divide_() (torch.tensor method)": [[597, "torch.Tensor.true_divide_"]], "trunc() (torch.tensor method)": [[598, "torch.Tensor.trunc"]], "trunc_() (torch.tensor method)": [[599, "torch.Tensor.trunc_"]], "type() (torch.tensor method)": [[600, "torch.Tensor.type"]], "type_as() (torch.tensor method)": [[601, "torch.Tensor.type_as"]], "unbind() (torch.tensor method)": [[602, "torch.Tensor.unbind"]], "unflatten() (torch.tensor method)": [[603, "torch.Tensor.unflatten"]], "unfold() (torch.tensor method)": [[604, "torch.Tensor.unfold"]], "uniform_() (torch.tensor method)": [[605, "torch.Tensor.uniform_"]], "unique() (torch.tensor method)": [[606, "torch.Tensor.unique"]], "unique_consecutive() (torch.tensor method)": [[607, "torch.Tensor.unique_consecutive"]], "unsqueeze() (torch.tensor method)": [[608, "torch.Tensor.unsqueeze"]], "unsqueeze_() (torch.tensor method)": [[609, "torch.Tensor.unsqueeze_"]], "untyped_storage() (torch.tensor method)": [[610, "torch.Tensor.untyped_storage"]], "values() (torch.tensor method)": [[611, "torch.Tensor.values"]], "var() (torch.tensor method)": [[612, "torch.Tensor.var"]], "vdot() (torch.tensor method)": [[613, "torch.Tensor.vdot"]], "view() (torch.tensor method)": [[614, "torch.Tensor.view"]], "view_as() (torch.tensor method)": [[615, "torch.Tensor.view_as"]], "vsplit() (torch.tensor method)": [[616, "torch.Tensor.vsplit"]], "where() (torch.tensor method)": [[617, "torch.Tensor.where"]], "xlogy() (torch.tensor method)": [[618, "torch.Tensor.xlogy"]], "xlogy_() (torch.tensor method)": [[619, "torch.Tensor.xlogy_"]], "zero_() (torch.tensor method)": [[620, "torch.Tensor.zero_"]], "_assert() (in module torch)": [[621, "torch._assert"]], "_foreach_abs() (in module torch)": [[622, "torch._foreach_abs"]], "_foreach_abs_() (in module torch)": [[623, "torch._foreach_abs_"]], "_foreach_acos() (in module torch)": [[624, "torch._foreach_acos"]], "_foreach_acos_() (in module torch)": [[625, "torch._foreach_acos_"]], "_foreach_asin() (in module torch)": [[626, "torch._foreach_asin"]], "_foreach_asin_() (in module torch)": [[627, "torch._foreach_asin_"]], "_foreach_atan() (in module torch)": [[628, "torch._foreach_atan"]], "_foreach_atan_() (in module torch)": [[629, "torch._foreach_atan_"]], "_foreach_ceil() (in module torch)": [[630, "torch._foreach_ceil"]], "_foreach_ceil_() (in module torch)": [[631, "torch._foreach_ceil_"]], "_foreach_cos() (in module torch)": [[632, "torch._foreach_cos"]], "_foreach_cos_() (in module torch)": [[633, "torch._foreach_cos_"]], "_foreach_cosh() (in module torch)": [[634, "torch._foreach_cosh"]], "_foreach_cosh_() (in module torch)": [[635, "torch._foreach_cosh_"]], "_foreach_erf() (in module torch)": [[636, "torch._foreach_erf"]], "_foreach_erf_() (in module torch)": [[637, "torch._foreach_erf_"]], "_foreach_erfc() (in module torch)": [[638, "torch._foreach_erfc"]], "_foreach_erfc_() (in module torch)": [[639, "torch._foreach_erfc_"]], "_foreach_exp() (in module torch)": [[640, "torch._foreach_exp"]], "_foreach_exp_() (in module torch)": [[641, "torch._foreach_exp_"]], "_foreach_expm1() (in module torch)": [[642, "torch._foreach_expm1"]], "_foreach_expm1_() (in module torch)": [[643, "torch._foreach_expm1_"]], "_foreach_floor() (in module torch)": [[644, "torch._foreach_floor"]], "_foreach_floor_() (in module torch)": [[645, "torch._foreach_floor_"]], "_foreach_frac() (in module torch)": [[646, "torch._foreach_frac"]], "_foreach_frac_() (in module torch)": [[647, "torch._foreach_frac_"]], "_foreach_lgamma() (in module torch)": [[648, "torch._foreach_lgamma"]], "_foreach_lgamma_() (in module torch)": [[649, "torch._foreach_lgamma_"]], "_foreach_log() (in module torch)": [[650, "torch._foreach_log"]], "_foreach_log10() (in module torch)": [[651, "torch._foreach_log10"]], "_foreach_log10_() (in module torch)": [[652, "torch._foreach_log10_"]], "_foreach_log1p() (in module torch)": [[653, "torch._foreach_log1p"]], "_foreach_log1p_() (in module torch)": [[654, "torch._foreach_log1p_"]], "_foreach_log2() (in module torch)": [[655, "torch._foreach_log2"]], "_foreach_log2_() (in module torch)": [[656, "torch._foreach_log2_"]], "_foreach_log_() (in module torch)": [[657, "torch._foreach_log_"]], "_foreach_neg() (in module torch)": [[658, "torch._foreach_neg"]], "_foreach_neg_() (in module torch)": [[659, "torch._foreach_neg_"]], "_foreach_reciprocal() (in module torch)": [[660, "torch._foreach_reciprocal"]], "_foreach_reciprocal_() (in module torch)": [[661, "torch._foreach_reciprocal_"]], "_foreach_round() (in module torch)": [[662, "torch._foreach_round"]], "_foreach_round_() (in module torch)": [[663, "torch._foreach_round_"]], "_foreach_sigmoid() (in module torch)": [[664, "torch._foreach_sigmoid"]], "_foreach_sigmoid_() (in module torch)": [[665, "torch._foreach_sigmoid_"]], "_foreach_sin() (in module torch)": [[666, "torch._foreach_sin"]], "_foreach_sin_() (in module torch)": [[667, "torch._foreach_sin_"]], "_foreach_sinh() (in module torch)": [[668, "torch._foreach_sinh"]], "_foreach_sinh_() (in module torch)": [[669, "torch._foreach_sinh_"]], "_foreach_sqrt() (in module torch)": [[670, "torch._foreach_sqrt"]], "_foreach_sqrt_() (in module torch)": [[671, "torch._foreach_sqrt_"]], "_foreach_tan() (in module torch)": [[672, "torch._foreach_tan"]], "_foreach_tan_() (in module torch)": [[673, "torch._foreach_tan_"]], "_foreach_trunc() (in module torch)": [[674, "torch._foreach_trunc"]], "_foreach_trunc_() (in module torch)": [[675, "torch._foreach_trunc_"]], "_foreach_zero_() (in module torch)": [[676, "torch._foreach_zero_"]], "set_logs() (in module torch._logging)": [[677, "torch._logging.set_logs"]], "abs() (in module torch)": [[678, "torch.abs"]], "absolute() (in module torch)": [[679, "torch.absolute"]], "acos() (in module torch)": [[680, "torch.acos"]], "acosh() (in module torch)": [[681, "torch.acosh"]], "add() (in module torch)": [[682, "torch.add"]], "addbmm() (in module torch)": [[683, "torch.addbmm"]], "addcdiv() (in module torch)": [[684, "torch.addcdiv"]], "addcmul() (in module torch)": [[685, "torch.addcmul"]], "addmm() (in module torch)": [[686, "torch.addmm"]], "addmv() (in module torch)": [[687, "torch.addmv"]], "addr() (in module torch)": [[688, "torch.addr"]], "adjoint() (in module torch)": [[689, "torch.adjoint"]], "all() (in module torch)": [[690, "torch.all"]], "allclose() (in module torch)": [[691, "torch.allclose"]], "amax() (in module torch)": [[692, "torch.amax"]], "amin() (in module torch)": [[693, "torch.amin"]], "aminmax() (in module torch)": [[694, "torch.aminmax"]], "angle() (in module torch)": [[695, "torch.angle"]], "any() (in module torch)": [[696, "torch.any"]], "bnrelu2d (class in torch.ao.nn.intrinsic)": [[697, "torch.ao.nn.intrinsic.BNReLU2d"]], "bnrelu3d (class in torch.ao.nn.intrinsic)": [[698, "torch.ao.nn.intrinsic.BNReLU3d"]], "convbn1d (class in torch.ao.nn.intrinsic)": [[699, "torch.ao.nn.intrinsic.ConvBn1d"]], "convbn2d (class in torch.ao.nn.intrinsic)": [[700, "torch.ao.nn.intrinsic.ConvBn2d"]], "convbn3d (class in torch.ao.nn.intrinsic)": [[701, "torch.ao.nn.intrinsic.ConvBn3d"]], "convbnrelu1d (class in torch.ao.nn.intrinsic)": [[702, "torch.ao.nn.intrinsic.ConvBnReLU1d"]], "convbnrelu2d (class in torch.ao.nn.intrinsic)": [[703, "torch.ao.nn.intrinsic.ConvBnReLU2d"]], "convbnrelu3d (class in torch.ao.nn.intrinsic)": [[704, "torch.ao.nn.intrinsic.ConvBnReLU3d"]], "convrelu1d (class in torch.ao.nn.intrinsic)": [[705, "torch.ao.nn.intrinsic.ConvReLU1d"]], "convrelu2d (class in torch.ao.nn.intrinsic)": [[706, "torch.ao.nn.intrinsic.ConvReLU2d"]], "convrelu3d (class in torch.ao.nn.intrinsic)": [[707, "torch.ao.nn.intrinsic.ConvReLU3d"]], "linearrelu (class in torch.ao.nn.intrinsic)": [[708, "torch.ao.nn.intrinsic.LinearReLU"]], "convbn1d (class in torch.ao.nn.intrinsic.qat)": [[709, "torch.ao.nn.intrinsic.qat.ConvBn1d"]], "convbn2d (class in torch.ao.nn.intrinsic.qat)": [[710, "torch.ao.nn.intrinsic.qat.ConvBn2d"]], "convbn3d (class in torch.ao.nn.intrinsic.qat)": [[711, "torch.ao.nn.intrinsic.qat.ConvBn3d"]], "convbnrelu1d (class in torch.ao.nn.intrinsic.qat)": [[712, "torch.ao.nn.intrinsic.qat.ConvBnReLU1d"]], "convbnrelu2d (class in torch.ao.nn.intrinsic.qat)": [[713, "torch.ao.nn.intrinsic.qat.ConvBnReLU2d"]], "convbnrelu3d (class in torch.ao.nn.intrinsic.qat)": [[714, "torch.ao.nn.intrinsic.qat.ConvBnReLU3d"]], "convrelu2d (class in torch.ao.nn.intrinsic.qat)": [[715, "torch.ao.nn.intrinsic.qat.ConvReLU2d"]], "convrelu3d (class in torch.ao.nn.intrinsic.qat)": [[716, "torch.ao.nn.intrinsic.qat.ConvReLU3d"]], "linearrelu (class in torch.ao.nn.intrinsic.qat)": [[717, "torch.ao.nn.intrinsic.qat.LinearReLU"]], "freeze_bn_stats (class in torch.ao.nn.intrinsic.qat)": [[718, "torch.ao.nn.intrinsic.qat.freeze_bn_stats"]], "update_bn_stats (class in torch.ao.nn.intrinsic.qat)": [[719, "torch.ao.nn.intrinsic.qat.update_bn_stats"]], "bnrelu2d (class in torch.ao.nn.intrinsic.quantized)": [[720, "torch.ao.nn.intrinsic.quantized.BNReLU2d"]], "bnrelu3d (class in torch.ao.nn.intrinsic.quantized)": [[721, "torch.ao.nn.intrinsic.quantized.BNReLU3d"]], "convrelu1d (class in torch.ao.nn.intrinsic.quantized)": [[722, "torch.ao.nn.intrinsic.quantized.ConvReLU1d"]], "convrelu2d (class in torch.ao.nn.intrinsic.quantized)": [[723, "torch.ao.nn.intrinsic.quantized.ConvReLU2d"]], "convrelu3d (class in torch.ao.nn.intrinsic.quantized)": [[724, "torch.ao.nn.intrinsic.quantized.ConvReLU3d"]], "linearrelu (class in torch.ao.nn.intrinsic.quantized)": [[725, "torch.ao.nn.intrinsic.quantized.LinearReLU"]], "linearrelu (class in torch.ao.nn.intrinsic.quantized.dynamic)": [[726, "torch.ao.nn.intrinsic.quantized.dynamic.LinearReLU"]], "conv2d (class in torch.ao.nn.qat)": [[727, "torch.ao.nn.qat.Conv2d"]], "conv3d (class in torch.ao.nn.qat)": [[728, "torch.ao.nn.qat.Conv3d"]], "linear (class in torch.ao.nn.qat)": [[729, "torch.ao.nn.qat.Linear"]], "from_float() (torch.ao.nn.qat.linear class method)": [[729, "torch.ao.nn.qat.Linear.from_float"]], "linear (class in torch.ao.nn.qat.dynamic)": [[730, "torch.ao.nn.qat.dynamic.Linear"]], "lstm (class in torch.ao.nn.quantizable)": [[731, "torch.ao.nn.quantizable.LSTM"]], "multiheadattention (class in torch.ao.nn.quantizable)": [[732, "torch.ao.nn.quantizable.MultiheadAttention"]], "dequantize() (torch.ao.nn.quantizable.multiheadattention method)": [[732, "torch.ao.nn.quantizable.MultiheadAttention.dequantize"]], "forward() (torch.ao.nn.quantizable.multiheadattention method)": [[732, "torch.ao.nn.quantizable.MultiheadAttention.forward"]], "batchnorm2d (class in torch.ao.nn.quantized)": [[733, "torch.ao.nn.quantized.BatchNorm2d"]], "batchnorm3d (class in torch.ao.nn.quantized)": [[734, "torch.ao.nn.quantized.BatchNorm3d"]], "conv1d (class in torch.ao.nn.quantized)": [[735, "torch.ao.nn.quantized.Conv1d"]], "from_float() (torch.ao.nn.quantized.conv1d class method)": [[735, "torch.ao.nn.quantized.Conv1d.from_float"]], "conv2d (class in torch.ao.nn.quantized)": [[736, "torch.ao.nn.quantized.Conv2d"]], "from_float() (torch.ao.nn.quantized.conv2d class method)": [[736, "torch.ao.nn.quantized.Conv2d.from_float"]], "conv3d (class in torch.ao.nn.quantized)": [[737, "torch.ao.nn.quantized.Conv3d"]], "from_float() (torch.ao.nn.quantized.conv3d class method)": [[737, "torch.ao.nn.quantized.Conv3d.from_float"]], "convtranspose1d (class in torch.ao.nn.quantized)": [[738, "torch.ao.nn.quantized.ConvTranspose1d"]], "convtranspose2d (class in torch.ao.nn.quantized)": [[739, "torch.ao.nn.quantized.ConvTranspose2d"]], "convtranspose3d (class in torch.ao.nn.quantized)": [[740, "torch.ao.nn.quantized.ConvTranspose3d"]], "elu (class in torch.ao.nn.quantized)": [[741, "torch.ao.nn.quantized.ELU"]], "embedding (class in torch.ao.nn.quantized)": [[742, "torch.ao.nn.quantized.Embedding"]], "from_float() (torch.ao.nn.quantized.embedding class method)": [[742, "torch.ao.nn.quantized.Embedding.from_float"]], "embeddingbag (class in torch.ao.nn.quantized)": [[743, "torch.ao.nn.quantized.EmbeddingBag"]], "from_float() (torch.ao.nn.quantized.embeddingbag class method)": [[743, "torch.ao.nn.quantized.EmbeddingBag.from_float"]], "fxfloatfunctional (class in torch.ao.nn.quantized)": [[744, "torch.ao.nn.quantized.FXFloatFunctional"]], "floatfunctional (class in torch.ao.nn.quantized)": [[745, "torch.ao.nn.quantized.FloatFunctional"]], "groupnorm (class in torch.ao.nn.quantized)": [[746, "torch.ao.nn.quantized.GroupNorm"]], "hardswish (class in torch.ao.nn.quantized)": [[747, "torch.ao.nn.quantized.Hardswish"]], "instancenorm1d (class in torch.ao.nn.quantized)": [[748, "torch.ao.nn.quantized.InstanceNorm1d"]], "instancenorm2d (class in torch.ao.nn.quantized)": [[749, "torch.ao.nn.quantized.InstanceNorm2d"]], "instancenorm3d (class in torch.ao.nn.quantized)": [[750, "torch.ao.nn.quantized.InstanceNorm3d"]], "layernorm (class in torch.ao.nn.quantized)": [[751, "torch.ao.nn.quantized.LayerNorm"]], "leakyrelu (class in torch.ao.nn.quantized)": [[752, "torch.ao.nn.quantized.LeakyReLU"]], "linear (class in torch.ao.nn.quantized)": [[753, "torch.ao.nn.quantized.Linear"]], "from_float() (torch.ao.nn.quantized.linear class method)": [[753, "torch.ao.nn.quantized.Linear.from_float"]], "from_reference() (torch.ao.nn.quantized.linear class method)": [[753, "torch.ao.nn.quantized.Linear.from_reference"]], "qfunctional (class in torch.ao.nn.quantized)": [[754, "torch.ao.nn.quantized.QFunctional"]], "relu6 (class in torch.ao.nn.quantized)": [[755, "torch.ao.nn.quantized.ReLU6"]], "sigmoid (class in torch.ao.nn.quantized)": [[756, "torch.ao.nn.quantized.Sigmoid"]], "gru (class in torch.ao.nn.quantized.dynamic)": [[757, "torch.ao.nn.quantized.dynamic.GRU"]], "grucell (class in torch.ao.nn.quantized.dynamic)": [[758, "torch.ao.nn.quantized.dynamic.GRUCell"]], "lstm (class in torch.ao.nn.quantized.dynamic)": [[759, "torch.ao.nn.quantized.dynamic.LSTM"]], "lstmcell (class in torch.ao.nn.quantized.dynamic)": [[760, "torch.ao.nn.quantized.dynamic.LSTMCell"]], "linear (class in torch.ao.nn.quantized.dynamic)": [[761, "torch.ao.nn.quantized.dynamic.Linear"]], "from_float() (torch.ao.nn.quantized.dynamic.linear class method)": [[761, "torch.ao.nn.quantized.dynamic.Linear.from_float"]], "from_reference() (torch.ao.nn.quantized.dynamic.linear class method)": [[761, "torch.ao.nn.quantized.dynamic.Linear.from_reference"]], "rnncell (class in torch.ao.nn.quantized.dynamic)": [[762, "torch.ao.nn.quantized.dynamic.RNNCell"]], "adaptive_avg_pool2d (class in torch.ao.nn.quantized.functional)": [[763, "torch.ao.nn.quantized.functional.adaptive_avg_pool2d"]], "adaptive_avg_pool3d (class in torch.ao.nn.quantized.functional)": [[764, "torch.ao.nn.quantized.functional.adaptive_avg_pool3d"]], "avg_pool2d (class in torch.ao.nn.quantized.functional)": [[765, "torch.ao.nn.quantized.functional.avg_pool2d"]], "avg_pool3d (class in torch.ao.nn.quantized.functional)": [[766, "torch.ao.nn.quantized.functional.avg_pool3d"]], "celu (class in torch.ao.nn.quantized.functional)": [[767, "torch.ao.nn.quantized.functional.celu"]], "clamp (class in torch.ao.nn.quantized.functional)": [[768, "torch.ao.nn.quantized.functional.clamp"]], "conv1d (class in torch.ao.nn.quantized.functional)": [[769, "torch.ao.nn.quantized.functional.conv1d"]], "conv2d (class in torch.ao.nn.quantized.functional)": [[770, "torch.ao.nn.quantized.functional.conv2d"]], "conv3d (class in torch.ao.nn.quantized.functional)": [[771, "torch.ao.nn.quantized.functional.conv3d"]], "elu (class in torch.ao.nn.quantized.functional)": [[772, "torch.ao.nn.quantized.functional.elu"]], "hardsigmoid (class in torch.ao.nn.quantized.functional)": [[773, "torch.ao.nn.quantized.functional.hardsigmoid"]], "hardswish (class in torch.ao.nn.quantized.functional)": [[774, "torch.ao.nn.quantized.functional.hardswish"]], "hardtanh (class in torch.ao.nn.quantized.functional)": [[775, "torch.ao.nn.quantized.functional.hardtanh"]], "interpolate (class in torch.ao.nn.quantized.functional)": [[776, "torch.ao.nn.quantized.functional.interpolate"]], "leaky_relu (class in torch.ao.nn.quantized.functional)": [[777, "torch.ao.nn.quantized.functional.leaky_relu"]], "linear (class in torch.ao.nn.quantized.functional)": [[778, "torch.ao.nn.quantized.functional.linear"]], "max_pool1d (class in torch.ao.nn.quantized.functional)": [[779, "torch.ao.nn.quantized.functional.max_pool1d"]], "max_pool2d (class in torch.ao.nn.quantized.functional)": [[780, "torch.ao.nn.quantized.functional.max_pool2d"]], "threshold (class in torch.ao.nn.quantized.functional)": [[781, "torch.ao.nn.quantized.functional.threshold"]], "upsample (class in torch.ao.nn.quantized.functional)": [[782, "torch.ao.nn.quantized.functional.upsample"]], "upsample_bilinear (class in torch.ao.nn.quantized.functional)": [[783, "torch.ao.nn.quantized.functional.upsample_bilinear"]], "upsample_nearest (class in torch.ao.nn.quantized.functional)": [[784, "torch.ao.nn.quantized.functional.upsample_nearest"]], "dequantstub (class in torch.ao.quantization)": [[785, "torch.ao.quantization.DeQuantStub"]], "quantstub (class in torch.ao.quantization)": [[786, "torch.ao.quantization.QuantStub"]], "quantwrapper (class in torch.ao.quantization)": [[787, "torch.ao.quantization.QuantWrapper"]], "add_quant_dequant (class in torch.ao.quantization)": [[788, "torch.ao.quantization.add_quant_dequant"]], "backendconfig (class in torch.ao.quantization.backend_config)": [[789, "torch.ao.quantization.backend_config.BackendConfig"]], "configs (torch.ao.quantization.backend_config.backendconfig property)": [[789, "torch.ao.quantization.backend_config.BackendConfig.configs"]], "from_dict() (torch.ao.quantization.backend_config.backendconfig class method)": [[789, "torch.ao.quantization.backend_config.BackendConfig.from_dict"]], "set_backend_pattern_config() (torch.ao.quantization.backend_config.backendconfig method)": [[789, "torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_config"]], "set_backend_pattern_configs() (torch.ao.quantization.backend_config.backendconfig method)": [[789, "torch.ao.quantization.backend_config.BackendConfig.set_backend_pattern_configs"]], "set_name() (torch.ao.quantization.backend_config.backendconfig method)": [[789, "torch.ao.quantization.backend_config.BackendConfig.set_name"]], "to_dict() (torch.ao.quantization.backend_config.backendconfig method)": [[789, "torch.ao.quantization.backend_config.BackendConfig.to_dict"]], "backendpatternconfig (class in torch.ao.quantization.backend_config)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig"]], "add_dtype_config() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.add_dtype_config"]], "from_dict() (torch.ao.quantization.backend_config.backendpatternconfig class method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.from_dict"]], "set_dtype_configs() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_dtype_configs"]], "set_fused_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_fused_module"]], "set_fuser_method() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_fuser_method"]], "set_observation_type() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_observation_type"]], "set_pattern() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_pattern"]], "set_qat_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_qat_module"]], "set_reference_quantized_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_reference_quantized_module"]], "set_root_module() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.set_root_module"]], "to_dict() (torch.ao.quantization.backend_config.backendpatternconfig method)": [[790, "torch.ao.quantization.backend_config.BackendPatternConfig.to_dict"]], "dtypeconfig (class in torch.ao.quantization.backend_config)": [[791, "torch.ao.quantization.backend_config.DTypeConfig"]], "from_dict() (torch.ao.quantization.backend_config.dtypeconfig class method)": [[791, "torch.ao.quantization.backend_config.DTypeConfig.from_dict"]], "to_dict() (torch.ao.quantization.backend_config.dtypeconfig method)": [[791, "torch.ao.quantization.backend_config.DTypeConfig.to_dict"]], "dtypewithconstraints (class in torch.ao.quantization.backend_config)": [[792, "torch.ao.quantization.backend_config.DTypeWithConstraints"]], "input_output_not_observed (torch.ao.quantization.backend_config.observationtype attribute)": [[793, "torch.ao.quantization.backend_config.ObservationType.INPUT_OUTPUT_NOT_OBSERVED"]], "output_share_observer_with_input (torch.ao.quantization.backend_config.observationtype attribute)": [[793, "torch.ao.quantization.backend_config.ObservationType.OUTPUT_SHARE_OBSERVER_WITH_INPUT"]], "output_use_different_observer_as_input (torch.ao.quantization.backend_config.observationtype attribute)": [[793, "torch.ao.quantization.backend_config.ObservationType.OUTPUT_USE_DIFFERENT_OBSERVER_AS_INPUT"]], "observationtype (class in torch.ao.quantization.backend_config)": [[793, "torch.ao.quantization.backend_config.ObservationType"]], "convert (class in torch.ao.quantization)": [[794, "torch.ao.quantization.convert"]], "default_eval_fn (class in torch.ao.quantization)": [[795, "torch.ao.quantization.default_eval_fn"]], "fakequantize (class in torch.ao.quantization.fake_quantize)": [[796, "torch.ao.quantization.fake_quantize.FakeQuantize"]], "fakequantizebase (class in torch.ao.quantization.fake_quantize)": [[797, "torch.ao.quantization.fake_quantize.FakeQuantizeBase"]], "fixedqparamsfakequantize (class in torch.ao.quantization.fake_quantize)": [[798, "torch.ao.quantization.fake_quantize.FixedQParamsFakeQuantize"]], "fusedmovingavgobsfakequantize (class in torch.ao.quantization.fake_quantize)": [[799, "torch.ao.quantization.fake_quantize.FusedMovingAvgObsFakeQuantize"]], "default_fake_quant (in module torch.ao.quantization.fake_quantize)": [[800, "torch.ao.quantization.fake_quantize.default_fake_quant"]], "default_fused_act_fake_quant (in module torch.ao.quantization.fake_quantize)": [[801, "torch.ao.quantization.fake_quantize.default_fused_act_fake_quant"]], "default_fused_per_channel_wt_fake_quant (in module torch.ao.quantization.fake_quantize)": [[802, "torch.ao.quantization.fake_quantize.default_fused_per_channel_wt_fake_quant"]], "default_fused_wt_fake_quant (in module torch.ao.quantization.fake_quantize)": [[803, "torch.ao.quantization.fake_quantize.default_fused_wt_fake_quant"]], "default_histogram_fake_quant (in module torch.ao.quantization.fake_quantize)": [[804, "torch.ao.quantization.fake_quantize.default_histogram_fake_quant"]], "default_per_channel_weight_fake_quant (in module torch.ao.quantization.fake_quantize)": [[805, "torch.ao.quantization.fake_quantize.default_per_channel_weight_fake_quant"]], "default_weight_fake_quant (in module torch.ao.quantization.fake_quantize)": [[806, "torch.ao.quantization.fake_quantize.default_weight_fake_quant"]], "disable_fake_quant (class in torch.ao.quantization.fake_quantize)": [[807, "torch.ao.quantization.fake_quantize.disable_fake_quant"]], "disable_observer (class in torch.ao.quantization.fake_quantize)": [[808, "torch.ao.quantization.fake_quantize.disable_observer"]], "enable_fake_quant (class in torch.ao.quantization.fake_quantize)": [[809, "torch.ao.quantization.fake_quantize.enable_fake_quant"]], "enable_observer (class in torch.ao.quantization.fake_quantize)": [[810, "torch.ao.quantization.fake_quantize.enable_observer"]], "fuse_modules (class in torch.ao.quantization)": [[811, "torch.ao.quantization.fuse_modules"]], "convertcustomconfig (class in torch.ao.quantization.fx.custom_config)": [[812, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig"]], "from_dict() (torch.ao.quantization.fx.custom_config.convertcustomconfig class method)": [[812, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.from_dict"]], "set_observed_to_quantized_mapping() (torch.ao.quantization.fx.custom_config.convertcustomconfig method)": [[812, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_observed_to_quantized_mapping"]], "set_preserved_attributes() (torch.ao.quantization.fx.custom_config.convertcustomconfig method)": [[812, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.set_preserved_attributes"]], "to_dict() (torch.ao.quantization.fx.custom_config.convertcustomconfig method)": [[812, "torch.ao.quantization.fx.custom_config.ConvertCustomConfig.to_dict"]], "fusecustomconfig (class in torch.ao.quantization.fx.custom_config)": [[813, "torch.ao.quantization.fx.custom_config.FuseCustomConfig"]], "from_dict() (torch.ao.quantization.fx.custom_config.fusecustomconfig class method)": [[813, "torch.ao.quantization.fx.custom_config.FuseCustomConfig.from_dict"]], "set_preserved_attributes() (torch.ao.quantization.fx.custom_config.fusecustomconfig method)": [[813, "torch.ao.quantization.fx.custom_config.FuseCustomConfig.set_preserved_attributes"]], "to_dict() (torch.ao.quantization.fx.custom_config.fusecustomconfig method)": [[813, "torch.ao.quantization.fx.custom_config.FuseCustomConfig.to_dict"]], "preparecustomconfig (class in torch.ao.quantization.fx.custom_config)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig"]], "from_dict() (torch.ao.quantization.fx.custom_config.preparecustomconfig class method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.from_dict"]], "set_float_to_observed_mapping() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_float_to_observed_mapping"]], "set_input_quantized_indexes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_input_quantized_indexes"]], "set_non_traceable_module_classes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_classes"]], "set_non_traceable_module_names() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_non_traceable_module_names"]], "set_output_quantized_indexes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_output_quantized_indexes"]], "set_preserved_attributes() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_preserved_attributes"]], "set_standalone_module_class() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_class"]], "set_standalone_module_name() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.set_standalone_module_name"]], "to_dict() (torch.ao.quantization.fx.custom_config.preparecustomconfig method)": [[814, "torch.ao.quantization.fx.custom_config.PrepareCustomConfig.to_dict"]], "standalonemoduleconfigentry (class in torch.ao.quantization.fx.custom_config)": [[815, "torch.ao.quantization.fx.custom_config.StandaloneModuleConfigEntry"]], "histogramobserver (class in torch.ao.quantization.observer)": [[816, "torch.ao.quantization.observer.HistogramObserver"]], "minmaxobserver (class in torch.ao.quantization.observer)": [[817, "torch.ao.quantization.observer.MinMaxObserver"]], "calculate_qparams() (torch.ao.quantization.observer.minmaxobserver method)": [[817, "torch.ao.quantization.observer.MinMaxObserver.calculate_qparams"]], "forward() (torch.ao.quantization.observer.minmaxobserver method)": [[817, "torch.ao.quantization.observer.MinMaxObserver.forward"]], "reset_min_max_vals() (torch.ao.quantization.observer.minmaxobserver method)": [[817, "torch.ao.quantization.observer.MinMaxObserver.reset_min_max_vals"]], "movingaverageminmaxobserver (class in torch.ao.quantization.observer)": [[818, "torch.ao.quantization.observer.MovingAverageMinMaxObserver"]], "movingaverageperchannelminmaxobserver (class in torch.ao.quantization.observer)": [[819, "torch.ao.quantization.observer.MovingAveragePerChannelMinMaxObserver"]], "noopobserver (class in torch.ao.quantization.observer)": [[820, "torch.ao.quantization.observer.NoopObserver"]], "observerbase (class in torch.ao.quantization.observer)": [[821, "torch.ao.quantization.observer.ObserverBase"]], "with_args() (torch.ao.quantization.observer.observerbase class method)": [[821, "torch.ao.quantization.observer.ObserverBase.with_args"]], "with_callable_args() (torch.ao.quantization.observer.observerbase class method)": [[821, "torch.ao.quantization.observer.ObserverBase.with_callable_args"]], "perchannelminmaxobserver (class in torch.ao.quantization.observer)": [[822, "torch.ao.quantization.observer.PerChannelMinMaxObserver"]], "reset_min_max_vals() (torch.ao.quantization.observer.perchannelminmaxobserver method)": [[822, "torch.ao.quantization.observer.PerChannelMinMaxObserver.reset_min_max_vals"]], "placeholderobserver (class in torch.ao.quantization.observer)": [[823, "torch.ao.quantization.observer.PlaceholderObserver"]], "recordingobserver (class in torch.ao.quantization.observer)": [[824, "torch.ao.quantization.observer.RecordingObserver"]], "default_debug_observer (in module torch.ao.quantization.observer)": [[825, "torch.ao.quantization.observer.default_debug_observer"]], "default_dynamic_quant_observer (in module torch.ao.quantization.observer)": [[826, "torch.ao.quantization.observer.default_dynamic_quant_observer"]], "default_float_qparams_observer (in module torch.ao.quantization.observer)": [[827, "torch.ao.quantization.observer.default_float_qparams_observer"]], "default_histogram_observer (in module torch.ao.quantization.observer)": [[828, "torch.ao.quantization.observer.default_histogram_observer"]], "default_observer (in module torch.ao.quantization.observer)": [[829, "torch.ao.quantization.observer.default_observer"]], "default_per_channel_weight_observer (in module torch.ao.quantization.observer)": [[830, "torch.ao.quantization.observer.default_per_channel_weight_observer"]], "default_placeholder_observer (in module torch.ao.quantization.observer)": [[831, "torch.ao.quantization.observer.default_placeholder_observer"]], "default_weight_observer (in module torch.ao.quantization.observer)": [[832, "torch.ao.quantization.observer.default_weight_observer"]], "get_observer_state_dict (class in torch.ao.quantization.observer)": [[833, "torch.ao.quantization.observer.get_observer_state_dict"]], "load_observer_state_dict (class in torch.ao.quantization.observer)": [[834, "torch.ao.quantization.observer.load_observer_state_dict"]], "prepare (class in torch.ao.quantization)": [[835, "torch.ao.quantization.prepare"]], "prepare_qat (class in torch.ao.quantization)": [[836, "torch.ao.quantization.prepare_qat"]], "propagate_qconfig_ (class in torch.ao.quantization)": [[837, "torch.ao.quantization.propagate_qconfig_"]], "qconfig (class in torch.ao.quantization.qconfig)": [[838, "torch.ao.quantization.qconfig.QConfig"]], "default_activation_only_qconfig (in module torch.ao.quantization.qconfig)": [[839, "torch.ao.quantization.qconfig.default_activation_only_qconfig"]], "default_debug_qconfig (in module torch.ao.quantization.qconfig)": [[840, "torch.ao.quantization.qconfig.default_debug_qconfig"]], "default_dynamic_qconfig (in module torch.ao.quantization.qconfig)": [[841, "torch.ao.quantization.qconfig.default_dynamic_qconfig"]], "default_per_channel_qconfig (in module torch.ao.quantization.qconfig)": [[842, "torch.ao.quantization.qconfig.default_per_channel_qconfig"]], "default_qat_qconfig (in module torch.ao.quantization.qconfig)": [[843, "torch.ao.quantization.qconfig.default_qat_qconfig"]], "default_qat_qconfig_v2 (in module torch.ao.quantization.qconfig)": [[844, "torch.ao.quantization.qconfig.default_qat_qconfig_v2"]], "default_qconfig (in module torch.ao.quantization.qconfig)": [[845, "torch.ao.quantization.qconfig.default_qconfig"]], "default_weight_only_qconfig (in module torch.ao.quantization.qconfig)": [[846, "torch.ao.quantization.qconfig.default_weight_only_qconfig"]], "float16_dynamic_qconfig (in module torch.ao.quantization.qconfig)": [[847, "torch.ao.quantization.qconfig.float16_dynamic_qconfig"]], "float16_static_qconfig (in module torch.ao.quantization.qconfig)": [[848, "torch.ao.quantization.qconfig.float16_static_qconfig"]], "float_qparams_weight_only_qconfig (in module torch.ao.quantization.qconfig)": [[849, "torch.ao.quantization.qconfig.float_qparams_weight_only_qconfig"]], "per_channel_dynamic_qconfig (in module torch.ao.quantization.qconfig)": [[850, "torch.ao.quantization.qconfig.per_channel_dynamic_qconfig"]], "qconfigmapping (class in torch.ao.quantization.qconfig_mapping)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping"]], "from_dict() (torch.ao.quantization.qconfig_mapping.qconfigmapping class method)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping.from_dict"]], "set_global() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_global"]], "set_module_name() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name"]], "set_module_name_object_type_order() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_object_type_order"]], "set_module_name_regex() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_module_name_regex"]], "set_object_type() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping.set_object_type"]], "to_dict() (torch.ao.quantization.qconfig_mapping.qconfigmapping method)": [[851, "torch.ao.quantization.qconfig_mapping.QConfigMapping.to_dict"]], "get_default_qat_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)": [[852, "torch.ao.quantization.qconfig_mapping.get_default_qat_qconfig_mapping"]], "get_default_qconfig_mapping (class in torch.ao.quantization.qconfig_mapping)": [[853, "torch.ao.quantization.qconfig_mapping.get_default_qconfig_mapping"]], "quantize (class in torch.ao.quantization)": [[854, "torch.ao.quantization.quantize"]], "quantize_dynamic (class in torch.ao.quantization)": [[855, "torch.ao.quantization.quantize_dynamic"]], "convert_fx (class in torch.ao.quantization.quantize_fx)": [[856, "torch.ao.quantization.quantize_fx.convert_fx"]], "fuse_fx (class in torch.ao.quantization.quantize_fx)": [[857, "torch.ao.quantization.quantize_fx.fuse_fx"]], "prepare_fx (class in torch.ao.quantization.quantize_fx)": [[858, "torch.ao.quantization.quantize_fx.prepare_fx"]], "prepare_qat_fx (class in torch.ao.quantization.quantize_fx)": [[859, "torch.ao.quantization.quantize_fx.prepare_qat_fx"]], "quantize_qat (class in torch.ao.quantization)": [[860, "torch.ao.quantization.quantize_qat"]], "swap_module (class in torch.ao.quantization)": [[861, "torch.ao.quantization.swap_module"]], "arange() (in module torch)": [[862, "torch.arange"]], "arccos() (in module torch)": [[863, "torch.arccos"]], "arccosh() (in module torch)": [[864, "torch.arccosh"]], "arcsin() (in module torch)": [[865, "torch.arcsin"]], "arcsinh() (in module torch)": [[866, "torch.arcsinh"]], "arctan() (in module torch)": [[867, "torch.arctan"]], "arctan2() (in module torch)": [[868, "torch.arctan2"]], "arctanh() (in module torch)": [[869, "torch.arctanh"]], "are_deterministic_algorithms_enabled() (in module torch)": [[870, "torch.are_deterministic_algorithms_enabled"]], "argmax() (in module torch)": [[871, "torch.argmax"]], "argmin() (in module torch)": [[872, "torch.argmin"]], "argsort() (in module torch)": [[873, "torch.argsort"]], "argwhere() (in module torch)": [[874, "torch.argwhere"]], "as_strided() (in module torch)": [[875, "torch.as_strided"]], "as_tensor() (in module torch)": [[876, "torch.as_tensor"]], "asarray() (in module torch)": [[877, "torch.asarray"]], "asin() (in module torch)": [[878, "torch.asin"]], "asinh() (in module torch)": [[879, "torch.asinh"]], "atan() (in module torch)": [[880, "torch.atan"]], "atan2() (in module torch)": [[881, "torch.atan2"]], "atanh() (in module torch)": [[882, "torch.atanh"]], "atleast_1d() (in module torch)": [[883, "torch.atleast_1d"]], "atleast_2d() (in module torch)": [[884, "torch.atleast_2d"]], "atleast_3d() (in module torch)": [[885, "torch.atleast_3d"]], "backward() (torch.autograd.function static method)": [[886, "torch.autograd.Function.backward"]], "forward() (torch.autograd.function static method)": [[887, "torch.autograd.Function.forward"]], "jvp() (torch.autograd.function static method)": [[888, "torch.autograd.Function.jvp"]], "vmap() (torch.autograd.function static method)": [[889, "torch.autograd.Function.vmap"]], "backward() (in module torch.autograd)": [[890, "torch.autograd.backward"]], "dual_level (class in torch.autograd.forward_ad)": [[891, "torch.autograd.forward_ad.dual_level"]], "make_dual() (in module torch.autograd.forward_ad)": [[892, "torch.autograd.forward_ad.make_dual"]], "unpack_dual() (in module torch.autograd.forward_ad)": [[893, "torch.autograd.forward_ad.unpack_dual"]], "mark_dirty() (torch.autograd.function.functionctx method)": [[894, "torch.autograd.function.FunctionCtx.mark_dirty"]], "mark_non_differentiable() (torch.autograd.function.functionctx method)": [[895, "torch.autograd.function.FunctionCtx.mark_non_differentiable"]], "save_for_backward() (torch.autograd.function.functionctx method)": [[896, "torch.autograd.function.FunctionCtx.save_for_backward"]], "set_materialize_grads() (torch.autograd.function.functionctx method)": [[897, "torch.autograd.function.FunctionCtx.set_materialize_grads"]], "hessian() (in module torch.autograd.functional)": [[898, "torch.autograd.functional.hessian"]], "hvp() (in module torch.autograd.functional)": [[899, "torch.autograd.functional.hvp"]], "jacobian() (in module torch.autograd.functional)": [[900, "torch.autograd.functional.jacobian"]], "jvp() (in module torch.autograd.functional)": [[901, "torch.autograd.functional.jvp"]], "vhp() (in module torch.autograd.functional)": [[902, "torch.autograd.functional.vhp"]], "vjp() (in module torch.autograd.functional)": [[903, "torch.autograd.functional.vjp"]], "grad() (in module torch.autograd)": [[904, "torch.autograd.grad"]], "gradcheck() (in module torch.autograd)": [[905, "torch.autograd.gradcheck"]], "gradgradcheck() (in module torch.autograd)": [[906, "torch.autograd.gradgradcheck"]], "metadata() (torch.autograd.graph.node method)": [[907, "torch.autograd.graph.Node.metadata"]], "name() (torch.autograd.graph.node method)": [[908, "torch.autograd.graph.Node.name"]], "next_functions (torch.autograd.graph.node property)": [[909, "torch.autograd.graph.Node.next_functions"]], "register_hook() (torch.autograd.graph.node method)": [[910, "torch.autograd.graph.Node.register_hook"]], "register_prehook() (torch.autograd.graph.node method)": [[911, "torch.autograd.graph.Node.register_prehook"]], "load_nvprof() (in module torch.autograd.profiler)": [[912, "torch.autograd.profiler.load_nvprof"]], "export_chrome_trace() (torch.autograd.profiler.profile method)": [[913, "torch.autograd.profiler.profile.export_chrome_trace"]], "key_averages() (torch.autograd.profiler.profile method)": [[914, "torch.autograd.profiler.profile.key_averages"]], "self_cpu_time_total (torch.autograd.profiler.profile property)": [[915, "torch.autograd.profiler.profile.self_cpu_time_total"]], "total_average() (torch.autograd.profiler.profile method)": [[916, "torch.autograd.profiler.profile.total_average"]], "set_multithreading_enabled (class in torch.autograd)": [[917, "torch.autograd.set_multithreading_enabled"]], "baddbmm() (in module torch)": [[918, "torch.baddbmm"]], "bartlett_window() (in module torch)": [[919, "torch.bartlett_window"]], "bernoulli() (in module torch)": [[920, "torch.bernoulli"]], "bincount() (in module torch)": [[921, "torch.bincount"]], "bitwise_and() (in module torch)": [[922, "torch.bitwise_and"]], "bitwise_left_shift() (in module torch)": [[923, "torch.bitwise_left_shift"]], "bitwise_not() (in module torch)": [[924, "torch.bitwise_not"]], "bitwise_or() (in module torch)": [[925, "torch.bitwise_or"]], "bitwise_right_shift() (in module torch)": [[926, "torch.bitwise_right_shift"]], "bitwise_xor() (in module torch)": [[927, "torch.bitwise_xor"]], "blackman_window() (in module torch)": [[928, "torch.blackman_window"]], "block_diag() (in module torch)": [[929, "torch.block_diag"]], "bmm() (in module torch)": [[930, "torch.bmm"]], "broadcast_shapes() (in module torch)": [[931, "torch.broadcast_shapes"]], "broadcast_tensors() (in module torch)": [[932, "torch.broadcast_tensors"]], "broadcast_to() (in module torch)": [[933, "torch.broadcast_to"]], "bucketize() (in module torch)": [[934, "torch.bucketize"]], "can_cast() (in module torch)": [[935, "torch.can_cast"]], "cartesian_prod() (in module torch)": [[936, "torch.cartesian_prod"]], "cat() (in module torch)": [[937, "torch.cat"]], "cdist() (in module torch)": [[938, "torch.cdist"]], "ceil() (in module torch)": [[939, "torch.ceil"]], "chain_matmul() (in module torch)": [[940, "torch.chain_matmul"]], "cholesky() (in module torch)": [[941, "torch.cholesky"]], "cholesky_inverse() (in module torch)": [[942, "torch.cholesky_inverse"]], "cholesky_solve() (in module torch)": [[943, "torch.cholesky_solve"]], "chunk() (in module torch)": [[944, "torch.chunk"]], "clamp() (in module torch)": [[945, "torch.clamp"]], "clip() (in module torch)": [[946, "torch.clip"]], "clone() (in module torch)": [[947, "torch.clone"]], "column_stack() (in module torch)": [[948, "torch.column_stack"]], "combinations() (in module torch)": [[949, "torch.combinations"]], "compiled_with_cxx11_abi() (in module torch)": [[951, "torch.compiled_with_cxx11_abi"]], "complex() (in module torch)": [[952, "torch.complex"]], "concat() (in module torch)": [[953, "torch.concat"]], "concatenate() (in module torch)": [[954, "torch.concatenate"]], "conj() (in module torch)": [[955, "torch.conj"]], "conj_physical() (in module torch)": [[956, "torch.conj_physical"]], "copysign() (in module torch)": [[957, "torch.copysign"]], "corrcoef() (in module torch)": [[958, "torch.corrcoef"]], "cos() (in module torch)": [[959, "torch.cos"]], "cosh() (in module torch)": [[960, "torch.cosh"]], "count_nonzero() (in module torch)": [[961, "torch.count_nonzero"]], "cov() (in module torch)": [[962, "torch.cov"]], "cross() (in module torch)": [[963, "torch.cross"]], "cudagraph (class in torch.cuda)": [[964, "torch.cuda.CUDAGraph"]], "capture_begin() (torch.cuda.cudagraph method)": [[964, "torch.cuda.CUDAGraph.capture_begin"]], "capture_end() (torch.cuda.cudagraph method)": [[964, "torch.cuda.CUDAGraph.capture_end"]], "debug_dump() (torch.cuda.cudagraph method)": [[964, "torch.cuda.CUDAGraph.debug_dump"]], "enable_debug_mode() (torch.cuda.cudagraph method)": [[964, "torch.cuda.CUDAGraph.enable_debug_mode"]], "pool() (torch.cuda.cudagraph method)": [[964, "torch.cuda.CUDAGraph.pool"]], "replay() (torch.cuda.cudagraph method)": [[964, "torch.cuda.CUDAGraph.replay"]], "reset() (torch.cuda.cudagraph method)": [[964, "torch.cuda.CUDAGraph.reset"]], "cudapluggableallocator (class in torch.cuda)": [[965, "torch.cuda.CUDAPluggableAllocator"]], "event (class in torch.cuda)": [[966, "torch.cuda.Event"]], "elapsed_time() (torch.cuda.event method)": [[966, "torch.cuda.Event.elapsed_time"]], "from_ipc_handle() (torch.cuda.event class method)": [[966, "torch.cuda.Event.from_ipc_handle"]], "ipc_handle() (torch.cuda.event method)": [[966, "torch.cuda.Event.ipc_handle"]], "query() (torch.cuda.event method)": [[966, "torch.cuda.Event.query"]], "record() (torch.cuda.event method)": [[966, "torch.cuda.Event.record"]], "synchronize() (torch.cuda.event method)": [[966, "torch.cuda.Event.synchronize"]], "wait() (torch.cuda.event method)": [[966, "torch.cuda.Event.wait"]], "externalstream (class in torch.cuda)": [[967, "torch.cuda.ExternalStream"]], "query() (torch.cuda.externalstream method)": [[967, "torch.cuda.ExternalStream.query"]], "record_event() (torch.cuda.externalstream method)": [[967, "torch.cuda.ExternalStream.record_event"]], "synchronize() (torch.cuda.externalstream method)": [[967, "torch.cuda.ExternalStream.synchronize"]], "wait_event() (torch.cuda.externalstream method)": [[967, "torch.cuda.ExternalStream.wait_event"]], "wait_stream() (torch.cuda.externalstream method)": [[967, "torch.cuda.ExternalStream.wait_stream"]], "outofmemoryerror": [[968, "torch.cuda.OutOfMemoryError"]], "stream (class in torch.cuda)": [[969, "torch.cuda.Stream"]], "query() (torch.cuda.stream method)": [[969, "torch.cuda.Stream.query"]], "record_event() (torch.cuda.stream method)": [[969, "torch.cuda.Stream.record_event"]], "synchronize() (torch.cuda.stream method)": [[969, "torch.cuda.Stream.synchronize"]], "wait_event() (torch.cuda.stream method)": [[969, "torch.cuda.Stream.wait_event"]], "wait_stream() (torch.cuda.stream method)": [[969, "torch.cuda.Stream.wait_stream"]], "streamcontext (class in torch.cuda)": [[970, "torch.cuda.StreamContext"]], "caching_allocator_alloc() (in module torch.cuda)": [[971, "torch.cuda.caching_allocator_alloc"]], "caching_allocator_delete() (in module torch.cuda)": [[972, "torch.cuda.caching_allocator_delete"]], "can_device_access_peer() (in module torch.cuda)": [[973, "torch.cuda.can_device_access_peer"]], "change_current_allocator() (in module torch.cuda)": [[974, "torch.cuda.change_current_allocator"]], "clock_rate() (in module torch.cuda)": [[975, "torch.cuda.clock_rate"]], "broadcast() (in module torch.cuda.comm)": [[976, "torch.cuda.comm.broadcast"]], "broadcast_coalesced() (in module torch.cuda.comm)": [[977, "torch.cuda.comm.broadcast_coalesced"]], "gather() (in module torch.cuda.comm)": [[978, "torch.cuda.comm.gather"]], "reduce_add() (in module torch.cuda.comm)": [[979, "torch.cuda.comm.reduce_add"]], "scatter() (in module torch.cuda.comm)": [[980, "torch.cuda.comm.scatter"]], "current_blas_handle() (in module torch.cuda)": [[981, "torch.cuda.current_blas_handle"]], "current_device() (in module torch.cuda)": [[982, "torch.cuda.current_device"]], "current_stream() (in module torch.cuda)": [[983, "torch.cuda.current_stream"]], "default_stream() (in module torch.cuda)": [[984, "torch.cuda.default_stream"]], "device (class in torch.cuda)": [[985, "torch.cuda.device"]], "device_count() (in module torch.cuda)": [[986, "torch.cuda.device_count"]], "device_of (class in torch.cuda)": [[987, "torch.cuda.device_of"]], "empty_cache() (in module torch.cuda)": [[988, "torch.cuda.empty_cache"]], "get_allocator_backend() (in module torch.cuda)": [[989, "torch.cuda.get_allocator_backend"]], "get_arch_list() (in module torch.cuda)": [[990, "torch.cuda.get_arch_list"]], "get_device_capability() (in module torch.cuda)": [[991, "torch.cuda.get_device_capability"]], "get_device_name() (in module torch.cuda)": [[992, "torch.cuda.get_device_name"]], "get_device_properties() (in module torch.cuda)": [[993, "torch.cuda.get_device_properties"]], "get_gencode_flags() (in module torch.cuda)": [[994, "torch.cuda.get_gencode_flags"]], "get_rng_state() (in module torch.cuda)": [[995, "torch.cuda.get_rng_state"]], "get_rng_state_all() (in module torch.cuda)": [[996, "torch.cuda.get_rng_state_all"]], "get_sync_debug_mode() (in module torch.cuda)": [[997, "torch.cuda.get_sync_debug_mode"]], "graph (class in torch.cuda)": [[998, "torch.cuda.graph"]], "graph_pool_handle() (in module torch.cuda)": [[999, "torch.cuda.graph_pool_handle"]], "init() (in module torch.cuda)": [[1000, "torch.cuda.init"]], "initial_seed() (in module torch.cuda)": [[1001, "torch.cuda.initial_seed"]], "ipc_collect() (in module torch.cuda)": [[1002, "torch.cuda.ipc_collect"]], "is_available() (in module torch.cuda)": [[1003, "torch.cuda.is_available"]], "is_current_stream_capturing() (in module torch.cuda)": [[1004, "torch.cuda.is_current_stream_capturing"]], "is_initialized() (in module torch.cuda)": [[1005, "torch.cuda.is_initialized"]], "_create_jit_fn() (in module torch.cuda.jiterator)": [[1006, "torch.cuda.jiterator._create_jit_fn"]], "_create_multi_output_jit_fn() (in module torch.cuda.jiterator)": [[1007, "torch.cuda.jiterator._create_multi_output_jit_fn"]], "list_gpu_processes() (in module torch.cuda)": [[1008, "torch.cuda.list_gpu_processes"]], "make_graphed_callables() (in module torch.cuda)": [[1009, "torch.cuda.make_graphed_callables"]], "manual_seed() (in module torch.cuda)": [[1010, "torch.cuda.manual_seed"]], "manual_seed_all() (in module torch.cuda)": [[1011, "torch.cuda.manual_seed_all"]], "max_memory_allocated() (in module torch.cuda)": [[1012, "torch.cuda.max_memory_allocated"]], "max_memory_cached() (in module torch.cuda)": [[1013, "torch.cuda.max_memory_cached"]], "max_memory_reserved() (in module torch.cuda)": [[1014, "torch.cuda.max_memory_reserved"]], "mem_get_info() (in module torch.cuda)": [[1015, "torch.cuda.mem_get_info"]], "memory_allocated() (in module torch.cuda)": [[1016, "torch.cuda.memory_allocated"]], "memory_cached() (in module torch.cuda)": [[1017, "torch.cuda.memory_cached"]], "memory_reserved() (in module torch.cuda)": [[1018, "torch.cuda.memory_reserved"]], "memory_snapshot() (in module torch.cuda)": [[1019, "torch.cuda.memory_snapshot"]], "memory_stats() (in module torch.cuda)": [[1020, "torch.cuda.memory_stats"]], "memory_summary() (in module torch.cuda)": [[1021, "torch.cuda.memory_summary"]], "memory_usage() (in module torch.cuda)": [[1022, "torch.cuda.memory_usage"]], "mark() (in module torch.cuda.nvtx)": [[1023, "torch.cuda.nvtx.mark"]], "range_pop() (in module torch.cuda.nvtx)": [[1024, "torch.cuda.nvtx.range_pop"]], "range_push() (in module torch.cuda.nvtx)": [[1025, "torch.cuda.nvtx.range_push"]], "power_draw() (in module torch.cuda)": [[1026, "torch.cuda.power_draw"]], "reset_max_memory_allocated() (in module torch.cuda)": [[1027, "torch.cuda.reset_max_memory_allocated"]], "reset_max_memory_cached() (in module torch.cuda)": [[1028, "torch.cuda.reset_max_memory_cached"]], "reset_peak_memory_stats() (in module torch.cuda)": [[1029, "torch.cuda.reset_peak_memory_stats"]], "seed() (in module torch.cuda)": [[1030, "torch.cuda.seed"]], "seed_all() (in module torch.cuda)": [[1031, "torch.cuda.seed_all"]], "set_device() (in module torch.cuda)": [[1032, "torch.cuda.set_device"]], "set_per_process_memory_fraction() (in module torch.cuda)": [[1033, "torch.cuda.set_per_process_memory_fraction"]], "set_rng_state() (in module torch.cuda)": [[1034, "torch.cuda.set_rng_state"]], "set_rng_state_all() (in module torch.cuda)": [[1035, "torch.cuda.set_rng_state_all"]], "set_stream() (in module torch.cuda)": [[1036, "torch.cuda.set_stream"]], "set_sync_debug_mode() (in module torch.cuda)": [[1037, "torch.cuda.set_sync_debug_mode"]], "stream() (in module torch.cuda)": [[1038, "torch.cuda.stream"]], "synchronize() (in module torch.cuda)": [[1039, "torch.cuda.synchronize"]], "temperature() (in module torch.cuda)": [[1040, "torch.cuda.temperature"]], "utilization() (in module torch.cuda)": [[1041, "torch.cuda.utilization"]], "cummax() (in module torch)": [[1042, "torch.cummax"]], "cummin() (in module torch)": [[1043, "torch.cummin"]], "cumprod() (in module torch)": [[1044, "torch.cumprod"]], "cumsum() (in module torch)": [[1045, "torch.cumsum"]], "cumulative_trapezoid() (in module torch)": [[1046, "torch.cumulative_trapezoid"]], "deg2rad() (in module torch)": [[1047, "torch.deg2rad"]], "dequantize() (in module torch)": [[1048, "torch.dequantize"]], "det() (in module torch)": [[1049, "torch.det"]], "diag() (in module torch)": [[1050, "torch.diag"]], "diag_embed() (in module torch)": [[1051, "torch.diag_embed"]], "diagflat() (in module torch)": [[1052, "torch.diagflat"]], "diagonal() (in module torch)": [[1053, "torch.diagonal"]], "diagonal_scatter() (in module torch)": [[1054, "torch.diagonal_scatter"]], "diff() (in module torch)": [[1055, "torch.diff"]], "digamma() (in module torch)": [[1056, "torch.digamma"]], "dist() (in module torch)": [[1057, "torch.dist"]], "div() (in module torch)": [[1058, "torch.div"]], "divide() (in module torch)": [[1059, "torch.divide"]], "dot() (in module torch)": [[1060, "torch.dot"]], "dsplit() (in module torch)": [[1061, "torch.dsplit"]], "dstack() (in module torch)": [[1062, "torch.dstack"]], "einsum() (in module torch)": [[1063, "torch.einsum"]], "empty() (in module torch)": [[1064, "torch.empty"]], "empty_like() (in module torch)": [[1065, "torch.empty_like"]], "empty_strided() (in module torch)": [[1066, "torch.empty_strided"]], "enable_grad (class in torch)": [[1067, "torch.enable_grad"]], "eq() (in module torch)": [[1068, "torch.eq"]], "equal() (in module torch)": [[1069, "torch.equal"]], "erf() (in module torch)": [[1070, "torch.erf"]], "erfc() (in module torch)": [[1071, "torch.erfc"]], "erfinv() (in module torch)": [[1072, "torch.erfinv"]], "exp() (in module torch)": [[1073, "torch.exp"]], "exp2() (in module torch)": [[1074, "torch.exp2"]], "expm1() (in module torch)": [[1075, "torch.expm1"]], "eye() (in module torch)": [[1076, "torch.eye"]], "fake_quantize_per_channel_affine() (in module torch)": [[1077, "torch.fake_quantize_per_channel_affine"]], "fake_quantize_per_tensor_affine() (in module torch)": [[1078, "torch.fake_quantize_per_tensor_affine"]], "fft() (in module torch.fft)": [[1079, "torch.fft.fft"]], "fft2() (in module torch.fft)": [[1080, "torch.fft.fft2"]], "fftfreq() (in module torch.fft)": [[1081, "torch.fft.fftfreq"]], "fftn() (in module torch.fft)": [[1082, "torch.fft.fftn"]], "fftshift() (in module torch.fft)": [[1083, "torch.fft.fftshift"]], "hfft() (in module torch.fft)": [[1084, "torch.fft.hfft"]], "hfft2() (in module torch.fft)": [[1085, "torch.fft.hfft2"]], "hfftn() (in module torch.fft)": [[1086, "torch.fft.hfftn"]], "ifft() (in module torch.fft)": [[1087, "torch.fft.ifft"]], "ifft2() (in module torch.fft)": [[1088, "torch.fft.ifft2"]], "ifftn() (in module torch.fft)": [[1089, "torch.fft.ifftn"]], "ifftshift() (in module torch.fft)": [[1090, "torch.fft.ifftshift"]], "ihfft() (in module torch.fft)": [[1091, "torch.fft.ihfft"]], "ihfft2() (in module torch.fft)": [[1092, "torch.fft.ihfft2"]], "ihfftn() (in module torch.fft)": [[1093, "torch.fft.ihfftn"]], "irfft() (in module torch.fft)": [[1094, "torch.fft.irfft"]], "irfft2() (in module torch.fft)": [[1095, "torch.fft.irfft2"]], "irfftn() (in module torch.fft)": [[1096, "torch.fft.irfftn"]], "rfft() (in module torch.fft)": [[1097, "torch.fft.rfft"]], "rfft2() (in module torch.fft)": [[1098, "torch.fft.rfft2"]], "rfftfreq() (in module torch.fft)": [[1099, "torch.fft.rfftfreq"]], "rfftn() (in module torch.fft)": [[1100, "torch.fft.rfftn"]], "fix() (in module torch)": [[1101, "torch.fix"]], "flatten() (in module torch)": [[1102, "torch.flatten"]], "flip() (in module torch)": [[1103, "torch.flip"]], "fliplr() (in module torch)": [[1104, "torch.fliplr"]], "flipud() (in module torch)": [[1105, "torch.flipud"]], "float_power() (in module torch)": [[1106, "torch.float_power"]], "floor() (in module torch)": [[1107, "torch.floor"]], "floor_divide() (in module torch)": [[1108, "torch.floor_divide"]], "fmax() (in module torch)": [[1109, "torch.fmax"]], "fmin() (in module torch)": [[1110, "torch.fmin"]], "fmod() (in module torch)": [[1111, "torch.fmod"]], "frac() (in module torch)": [[1112, "torch.frac"]], "frexp() (in module torch)": [[1113, "torch.frexp"]], "from_dlpack() (in module torch)": [[1114, "torch.from_dlpack"]], "from_numpy() (in module torch)": [[1115, "torch.from_numpy"]], "frombuffer() (in module torch)": [[1116, "torch.frombuffer"]], "full() (in module torch)": [[1117, "torch.full"]], "full_like() (in module torch)": [[1118, "torch.full_like"]], "functional_call() (in module torch.func)": [[1119, "torch.func.functional_call"]], "functionalize() (in module torch.func)": [[1120, "torch.func.functionalize"]], "grad() (in module torch.func)": [[1121, "torch.func.grad"]], "grad_and_value() (in module torch.func)": [[1122, "torch.func.grad_and_value"]], "hessian() (in module torch.func)": [[1123, "torch.func.hessian"]], "jacfwd() (in module torch.func)": [[1124, "torch.func.jacfwd"]], "jacrev() (in module torch.func)": [[1125, "torch.func.jacrev"]], "jvp() (in module torch.func)": [[1126, "torch.func.jvp"]], "linearize() (in module torch.func)": [[1127, "torch.func.linearize"]], "replace_all_batch_norm_modules_() (in module torch.func)": [[1128, "torch.func.replace_all_batch_norm_modules_"]], "stack_module_state() (in module torch.func)": [[1129, "torch.func.stack_module_state"]], "vjp() (in module torch.func)": [[1130, "torch.func.vjp"]], "vmap() (in module torch.func)": [[1131, "torch.func.vmap"]], "gather() (in module torch)": [[1132, "torch.gather"]], "gcd() (in module torch)": [[1133, "torch.gcd"]], "ge() (in module torch)": [[1134, "torch.ge"]], "geqrf() (in module torch)": [[1135, "torch.geqrf"]], "ger() (in module torch)": [[1136, "torch.ger"]], "get_default_dtype() (in module torch)": [[1137, "torch.get_default_dtype"]], "get_deterministic_debug_mode() (in module torch)": [[1138, "torch.get_deterministic_debug_mode"]], "get_float32_matmul_precision() (in module torch)": [[1139, "torch.get_float32_matmul_precision"]], "get_num_interop_threads() (in module torch)": [[1140, "torch.get_num_interop_threads"]], "get_num_threads() (in module torch)": [[1141, "torch.get_num_threads"]], "get_rng_state() (in module torch)": [[1142, "torch.get_rng_state"]], "gradient() (in module torch)": [[1143, "torch.gradient"]], "greater() (in module torch)": [[1144, "torch.greater"]], "greater_equal() (in module torch)": [[1145, "torch.greater_equal"]], "gt() (in module torch)": [[1146, "torch.gt"]], "hamming_window() (in module torch)": [[1147, "torch.hamming_window"]], "hann_window() (in module torch)": [[1148, "torch.hann_window"]], "heaviside() (in module torch)": [[1149, "torch.heaviside"]], "histc() (in module torch)": [[1150, "torch.histc"]], "histogram() (in module torch)": [[1151, "torch.histogram"]], "histogramdd() (in module torch)": [[1152, "torch.histogramdd"]], "hsplit() (in module torch)": [[1153, "torch.hsplit"]], "hspmm() (in module torch)": [[1154, "torch.hspmm"]], "hstack() (in module torch)": [[1155, "torch.hstack"]], "hypot() (in module torch)": [[1156, "torch.hypot"]], "i0() (in module torch)": [[1157, "torch.i0"]], "igamma() (in module torch)": [[1158, "torch.igamma"]], "igammac() (in module torch)": [[1159, "torch.igammac"]], "imag() (in module torch)": [[1160, "torch.imag"]], "index_add() (in module torch)": [[1161, "torch.index_add"]], "index_copy() (in module torch)": [[1162, "torch.index_copy"]], "index_reduce() (in module torch)": [[1163, "torch.index_reduce"]], "index_select() (in module torch)": [[1164, "torch.index_select"]], "inference_mode (class in torch)": [[1165, "torch.inference_mode"]], "initial_seed() (in module torch)": [[1166, "torch.initial_seed"]], "inner() (in module torch)": [[1167, "torch.inner"]], "inverse() (in module torch)": [[1168, "torch.inverse"]], "is_complex() (in module torch)": [[1169, "torch.is_complex"]], "is_conj() (in module torch)": [[1170, "torch.is_conj"]], "is_deterministic_algorithms_warn_only_enabled() (in module torch)": [[1171, "torch.is_deterministic_algorithms_warn_only_enabled"]], "is_floating_point() (in module torch)": [[1172, "torch.is_floating_point"]], "is_grad_enabled() (in module torch)": [[1173, "torch.is_grad_enabled"]], "is_inference_mode_enabled() (in module torch)": [[1174, "torch.is_inference_mode_enabled"]], "is_nonzero() (in module torch)": [[1175, "torch.is_nonzero"]], "is_storage() (in module torch)": [[1176, "torch.is_storage"]], "is_tensor() (in module torch)": [[1177, "torch.is_tensor"]], "is_warn_always_enabled() (in module torch)": [[1178, "torch.is_warn_always_enabled"]], "isclose() (in module torch)": [[1179, "torch.isclose"]], "isfinite() (in module torch)": [[1180, "torch.isfinite"]], "isin() (in module torch)": [[1181, "torch.isin"]], "isinf() (in module torch)": [[1182, "torch.isinf"]], "isnan() (in module torch)": [[1183, "torch.isnan"]], "isneginf() (in module torch)": [[1184, "torch.isneginf"]], "isposinf() (in module torch)": [[1185, "torch.isposinf"]], "isreal() (in module torch)": [[1186, "torch.isreal"]], "istft() (in module torch)": [[1187, "torch.istft"]], "attribute (class in torch.jit)": [[1188, "torch.jit.Attribute"]], "count() (torch.jit.attribute method)": [[1188, "torch.jit.Attribute.count"]], "index() (torch.jit.attribute method)": [[1188, "torch.jit.Attribute.index"]], "type (torch.jit.attribute attribute)": [[1188, "torch.jit.Attribute.type"]], "value (torch.jit.attribute attribute)": [[1188, "torch.jit.Attribute.value"]], "scriptfunction (class in torch.jit)": [[1189, "torch.jit.ScriptFunction"]], "get_debug_state() (torch.jit.scriptfunction method)": [[1189, "torch.jit.ScriptFunction.get_debug_state"]], "save() (torch.jit.scriptfunction method)": [[1189, "torch.jit.ScriptFunction.save"]], "save_to_buffer() (torch.jit.scriptfunction method)": [[1189, "torch.jit.ScriptFunction.save_to_buffer"]], "scriptmodule (class in torch.jit)": [[1190, "torch.jit.ScriptModule"]], "add_module() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.add_module"]], "apply() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.apply"]], "bfloat16() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.bfloat16"]], "buffers() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.buffers"]], "children() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.children"]], "code (torch.jit.scriptmodule property)": [[1190, "torch.jit.ScriptModule.code"]], "code_with_constants (torch.jit.scriptmodule property)": [[1190, "torch.jit.ScriptModule.code_with_constants"]], "compile() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.compile"]], "cpu() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.cpu"]], "cuda() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.cuda"]], "double() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.double"]], "eval() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.eval"]], "extra_repr() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.extra_repr"]], "float() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.float"]], "get_buffer() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.get_buffer"]], "get_extra_state() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.get_extra_state"]], "get_parameter() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.get_parameter"]], "get_submodule() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.get_submodule"]], "graph (torch.jit.scriptmodule property)": [[1190, "torch.jit.ScriptModule.graph"]], "half() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.half"]], "inlined_graph (torch.jit.scriptmodule property)": [[1190, "torch.jit.ScriptModule.inlined_graph"]], "ipu() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.ipu"]], "load_state_dict() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.load_state_dict"]], "modules() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.modules"]], "named_buffers() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.named_buffers"]], "named_children() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.named_children"]], "named_modules() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.named_modules"]], "named_parameters() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.named_parameters"]], "parameters() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.parameters"]], "register_backward_hook() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_backward_hook"]], "register_buffer() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_buffer"]], "register_forward_hook() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_forward_hook"]], "register_forward_pre_hook() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_forward_pre_hook"]], "register_full_backward_hook() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_full_backward_hook"]], "register_full_backward_pre_hook() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_load_state_dict_post_hook"]], "register_module() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_module"]], "register_parameter() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_parameter"]], "register_state_dict_pre_hook() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.register_state_dict_pre_hook"]], "requires_grad_() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.requires_grad_"]], "save() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.save"]], "set_extra_state() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.set_extra_state"]], "share_memory() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.share_memory"]], "state_dict() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.state_dict"]], "to() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.to"]], "to_empty() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.to_empty"]], "train() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.train"]], "type() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.type"]], "xpu() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.xpu"]], "zero_grad() (torch.jit.scriptmodule method)": [[1190, "torch.jit.ScriptModule.zero_grad"]], "annotate() (in module torch.jit)": [[1191, "torch.jit.annotate"]], "enable_onednn_fusion() (in module torch.jit)": [[1192, "torch.jit.enable_onednn_fusion"]], "fork() (in module torch.jit)": [[1193, "torch.jit.fork"]], "freeze() (in module torch.jit)": [[1194, "torch.jit.freeze"]], "ignore() (in module torch.jit)": [[1195, "torch.jit.ignore"]], "isinstance() (in module torch.jit)": [[1196, "torch.jit.isinstance"]], "load() (in module torch.jit)": [[1197, "torch.jit.load"]], "onednn_fusion_enabled() (in module torch.jit)": [[1198, "torch.jit.onednn_fusion_enabled"]], "optimize_for_inference() (in module torch.jit)": [[1199, "torch.jit.optimize_for_inference"]], "save() (in module torch.jit)": [[1200, "torch.jit.save"]], "script() (in module torch.jit)": [[1201, "torch.jit.script"]], "script_if_tracing() (in module torch.jit)": [[1202, "torch.jit.script_if_tracing"]], "set_fusion_strategy() (in module torch.jit)": [[1203, "torch.jit.set_fusion_strategy"]], "strict_fusion (class in torch.jit)": [[1204, "torch.jit.strict_fusion"]], "trace() (in module torch.jit)": [[1205, "torch.jit.trace"]], "trace_module() (in module torch.jit)": [[1206, "torch.jit.trace_module"]], "unused() (in module torch.jit)": [[1207, "torch.jit.unused"]], "wait() (in module torch.jit)": [[1208, "torch.jit.wait"]], "kaiser_window() (in module torch)": [[1209, "torch.kaiser_window"]], "kron() (in module torch)": [[1210, "torch.kron"]], "kthvalue() (in module torch)": [[1211, "torch.kthvalue"]], "lcm() (in module torch)": [[1212, "torch.lcm"]], "ldexp() (in module torch)": [[1213, "torch.ldexp"]], "le() (in module torch)": [[1214, "torch.le"]], "lerp() (in module torch)": [[1215, "torch.lerp"]], "less() (in module torch)": [[1216, "torch.less"]], "less_equal() (in module torch)": [[1217, "torch.less_equal"]], "lgamma() (in module torch)": [[1218, "torch.lgamma"]], "cholesky() (in module torch.linalg)": [[1219, "torch.linalg.cholesky"]], "cholesky_ex() (in module torch.linalg)": [[1220, "torch.linalg.cholesky_ex"]], "cond() (in module torch.linalg)": [[1221, "torch.linalg.cond"]], "cross() (in module torch.linalg)": [[1222, "torch.linalg.cross"]], "det() (in module torch.linalg)": [[1223, "torch.linalg.det"]], "diagonal() (in module torch.linalg)": [[1224, "torch.linalg.diagonal"]], "eig() (in module torch.linalg)": [[1225, "torch.linalg.eig"]], "eigh() (in module torch.linalg)": [[1226, "torch.linalg.eigh"]], "eigvals() (in module torch.linalg)": [[1227, "torch.linalg.eigvals"]], "eigvalsh() (in module torch.linalg)": [[1228, "torch.linalg.eigvalsh"]], "householder_product() (in module torch.linalg)": [[1229, "torch.linalg.householder_product"]], "inv() (in module torch.linalg)": [[1230, "torch.linalg.inv"]], "inv_ex() (in module torch.linalg)": [[1231, "torch.linalg.inv_ex"]], "ldl_factor() (in module torch.linalg)": [[1232, "torch.linalg.ldl_factor"]], "ldl_factor_ex() (in module torch.linalg)": [[1233, "torch.linalg.ldl_factor_ex"]], "ldl_solve() (in module torch.linalg)": [[1234, "torch.linalg.ldl_solve"]], "lstsq() (in module torch.linalg)": [[1235, "torch.linalg.lstsq"]], "lu() (in module torch.linalg)": [[1236, "torch.linalg.lu"]], "lu_factor() (in module torch.linalg)": [[1237, "torch.linalg.lu_factor"]], "lu_factor_ex() (in module torch.linalg)": [[1238, "torch.linalg.lu_factor_ex"]], "lu_solve() (in module torch.linalg)": [[1239, "torch.linalg.lu_solve"]], "matmul() (in module torch.linalg)": [[1240, "torch.linalg.matmul"]], "matrix_exp() (in module torch.linalg)": [[1241, "torch.linalg.matrix_exp"]], "matrix_norm() (in module torch.linalg)": [[1242, "torch.linalg.matrix_norm"]], "matrix_power() (in module torch.linalg)": [[1243, "torch.linalg.matrix_power"]], "matrix_rank() (in module torch.linalg)": [[1244, "torch.linalg.matrix_rank"]], "multi_dot() (in module torch.linalg)": [[1245, "torch.linalg.multi_dot"]], "norm() (in module torch.linalg)": [[1246, "torch.linalg.norm"]], "pinv() (in module torch.linalg)": [[1247, "torch.linalg.pinv"]], "qr() (in module torch.linalg)": [[1248, "torch.linalg.qr"]], "slogdet() (in module torch.linalg)": [[1249, "torch.linalg.slogdet"]], "solve() (in module torch.linalg)": [[1250, "torch.linalg.solve"]], "solve_ex() (in module torch.linalg)": [[1251, "torch.linalg.solve_ex"]], "solve_triangular() (in module torch.linalg)": [[1252, "torch.linalg.solve_triangular"]], "svd() (in module torch.linalg)": [[1253, "torch.linalg.svd"]], "svdvals() (in module torch.linalg)": [[1254, "torch.linalg.svdvals"]], "tensorinv() (in module torch.linalg)": [[1255, "torch.linalg.tensorinv"]], "tensorsolve() (in module torch.linalg)": [[1256, "torch.linalg.tensorsolve"]], "vander() (in module torch.linalg)": [[1257, "torch.linalg.vander"]], "vecdot() (in module torch.linalg)": [[1258, "torch.linalg.vecdot"]], "vector_norm() (in module torch.linalg)": [[1259, "torch.linalg.vector_norm"]], "linspace() (in module torch)": [[1260, "torch.linspace"]], "load() (in module torch)": [[1261, "torch.load"]], "lobpcg() (in module torch)": [[1262, "torch.lobpcg"]], "log() (in module torch)": [[1263, "torch.log"]], "log10() (in module torch)": [[1264, "torch.log10"]], "log1p() (in module torch)": [[1265, "torch.log1p"]], "log2() (in module torch)": [[1266, "torch.log2"]], "logaddexp() (in module torch)": [[1267, "torch.logaddexp"]], "logaddexp2() (in module torch)": [[1268, "torch.logaddexp2"]], "logcumsumexp() (in module torch)": [[1269, "torch.logcumsumexp"]], "logdet() (in module torch)": [[1270, "torch.logdet"]], "logical_and() (in module torch)": [[1271, "torch.logical_and"]], "logical_not() (in module torch)": [[1272, "torch.logical_not"]], "logical_or() (in module torch)": [[1273, "torch.logical_or"]], "logical_xor() (in module torch)": [[1274, "torch.logical_xor"]], "logit() (in module torch)": [[1275, "torch.logit"]], "logspace() (in module torch)": [[1276, "torch.logspace"]], "logsumexp() (in module torch)": [[1277, "torch.logsumexp"]], "lt() (in module torch)": [[1278, "torch.lt"]], "lu() (in module torch)": [[1279, "torch.lu"]], "lu_solve() (in module torch)": [[1280, "torch.lu_solve"]], "lu_unpack() (in module torch)": [[1281, "torch.lu_unpack"]], "manual_seed() (in module torch)": [[1282, "torch.manual_seed"]], "masked_select() (in module torch)": [[1283, "torch.masked_select"]], "matmul() (in module torch)": [[1284, "torch.matmul"]], "matrix_exp() (in module torch)": [[1285, "torch.matrix_exp"]], "matrix_power() (in module torch)": [[1286, "torch.matrix_power"]], "max() (in module torch)": [[1287, "torch.max"]], "maximum() (in module torch)": [[1288, "torch.maximum"]], "mean() (in module torch)": [[1289, "torch.mean"]], "median() (in module torch)": [[1290, "torch.median"]], "meshgrid() (in module torch)": [[1291, "torch.meshgrid"]], "min() (in module torch)": [[1292, "torch.min"]], "minimum() (in module torch)": [[1293, "torch.minimum"]], "mm() (in module torch)": [[1294, "torch.mm"]], "mode() (in module torch)": [[1295, "torch.mode"]], "moveaxis() (in module torch)": [[1296, "torch.moveaxis"]], "movedim() (in module torch)": [[1297, "torch.movedim"]], "current_allocated_memory() (in module torch.mps)": [[1298, "torch.mps.current_allocated_memory"]], "driver_allocated_memory() (in module torch.mps)": [[1299, "torch.mps.driver_allocated_memory"]], "empty_cache() (in module torch.mps)": [[1300, "torch.mps.empty_cache"]], "get_rng_state() (in module torch.mps)": [[1301, "torch.mps.get_rng_state"]], "manual_seed() (in module torch.mps)": [[1302, "torch.mps.manual_seed"]], "profile() (in module torch.mps.profiler)": [[1303, "torch.mps.profiler.profile"]], "start() (in module torch.mps.profiler)": [[1304, "torch.mps.profiler.start"]], "stop() (in module torch.mps.profiler)": [[1305, "torch.mps.profiler.stop"]], "seed() (in module torch.mps)": [[1306, "torch.mps.seed"]], "set_per_process_memory_fraction() (in module torch.mps)": [[1307, "torch.mps.set_per_process_memory_fraction"]], "set_rng_state() (in module torch.mps)": [[1308, "torch.mps.set_rng_state"]], "synchronize() (in module torch.mps)": [[1309, "torch.mps.synchronize"]], "msort() (in module torch)": [[1310, "torch.msort"]], "mul() (in module torch)": [[1311, "torch.mul"]], "multinomial() (in module torch)": [[1312, "torch.multinomial"]], "multiply() (in module torch)": [[1313, "torch.multiply"]], "mv() (in module torch)": [[1314, "torch.mv"]], "mvlgamma() (in module torch)": [[1315, "torch.mvlgamma"]], "nan_to_num() (in module torch)": [[1316, "torch.nan_to_num"]], "nanmean() (in module torch)": [[1317, "torch.nanmean"]], "nanmedian() (in module torch)": [[1318, "torch.nanmedian"]], "nanquantile() (in module torch)": [[1319, "torch.nanquantile"]], "nansum() (in module torch)": [[1320, "torch.nansum"]], "narrow() (in module torch)": [[1321, "torch.narrow"]], "narrow_copy() (in module torch)": [[1322, "torch.narrow_copy"]], "ne() (in module torch)": [[1323, "torch.ne"]], "neg() (in module torch)": [[1324, "torch.neg"]], "negative() (in module torch)": [[1325, "torch.negative"]], "nextafter() (in module torch)": [[1326, "torch.nextafter"]], "adaptiveavgpool1d (class in torch.nn)": [[1327, "torch.nn.AdaptiveAvgPool1d"]], "adaptiveavgpool2d (class in torch.nn)": [[1328, "torch.nn.AdaptiveAvgPool2d"]], "adaptiveavgpool3d (class in torch.nn)": [[1329, "torch.nn.AdaptiveAvgPool3d"]], "adaptivelogsoftmaxwithloss (class in torch.nn)": [[1330, "torch.nn.AdaptiveLogSoftmaxWithLoss"]], "log_prob() (torch.nn.adaptivelogsoftmaxwithloss method)": [[1330, "torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob"]], "predict() (torch.nn.adaptivelogsoftmaxwithloss method)": [[1330, "torch.nn.AdaptiveLogSoftmaxWithLoss.predict"]], "adaptivemaxpool1d (class in torch.nn)": [[1331, "torch.nn.AdaptiveMaxPool1d"]], "adaptivemaxpool2d (class in torch.nn)": [[1332, "torch.nn.AdaptiveMaxPool2d"]], "adaptivemaxpool3d (class in torch.nn)": [[1333, "torch.nn.AdaptiveMaxPool3d"]], "alphadropout (class in torch.nn)": [[1334, "torch.nn.AlphaDropout"]], "avgpool1d (class in torch.nn)": [[1335, "torch.nn.AvgPool1d"]], "avgpool2d (class in torch.nn)": [[1336, "torch.nn.AvgPool2d"]], "avgpool3d (class in torch.nn)": [[1337, "torch.nn.AvgPool3d"]], "bceloss (class in torch.nn)": [[1338, "torch.nn.BCELoss"]], "bcewithlogitsloss (class in torch.nn)": [[1339, "torch.nn.BCEWithLogitsLoss"]], "batchnorm1d (class in torch.nn)": [[1340, "torch.nn.BatchNorm1d"]], "batchnorm2d (class in torch.nn)": [[1341, "torch.nn.BatchNorm2d"]], "batchnorm3d (class in torch.nn)": [[1342, "torch.nn.BatchNorm3d"]], "bilinear (class in torch.nn)": [[1343, "torch.nn.Bilinear"]], "celu (class in torch.nn)": [[1344, "torch.nn.CELU"]], "ctcloss (class in torch.nn)": [[1345, "torch.nn.CTCLoss"]], "channelshuffle (class in torch.nn)": [[1346, "torch.nn.ChannelShuffle"]], "constantpad1d (class in torch.nn)": [[1347, "torch.nn.ConstantPad1d"]], "constantpad2d (class in torch.nn)": [[1348, "torch.nn.ConstantPad2d"]], "constantpad3d (class in torch.nn)": [[1349, "torch.nn.ConstantPad3d"]], "conv1d (class in torch.nn)": [[1350, "torch.nn.Conv1d"]], "conv2d (class in torch.nn)": [[1351, "torch.nn.Conv2d"]], "conv3d (class in torch.nn)": [[1352, "torch.nn.Conv3d"]], "convtranspose1d (class in torch.nn)": [[1353, "torch.nn.ConvTranspose1d"]], "convtranspose2d (class in torch.nn)": [[1354, "torch.nn.ConvTranspose2d"]], "convtranspose3d (class in torch.nn)": [[1355, "torch.nn.ConvTranspose3d"]], "cosineembeddingloss (class in torch.nn)": [[1356, "torch.nn.CosineEmbeddingLoss"]], "cosinesimilarity (class in torch.nn)": [[1357, "torch.nn.CosineSimilarity"]], "crossentropyloss (class in torch.nn)": [[1358, "torch.nn.CrossEntropyLoss"]], "dataparallel (class in torch.nn)": [[1359, "torch.nn.DataParallel"]], "dropout (class in torch.nn)": [[1360, "torch.nn.Dropout"]], "dropout1d (class in torch.nn)": [[1361, "torch.nn.Dropout1d"]], "dropout2d (class in torch.nn)": [[1362, "torch.nn.Dropout2d"]], "dropout3d (class in torch.nn)": [[1363, "torch.nn.Dropout3d"]], "elu (class in torch.nn)": [[1364, "torch.nn.ELU"]], "embedding (class in torch.nn)": [[1365, "torch.nn.Embedding"]], "from_pretrained() (torch.nn.embedding class method)": [[1365, "torch.nn.Embedding.from_pretrained"]], "embeddingbag (class in torch.nn)": [[1366, "torch.nn.EmbeddingBag"]], "forward() (torch.nn.embeddingbag method)": [[1366, "torch.nn.EmbeddingBag.forward"]], "from_pretrained() (torch.nn.embeddingbag class method)": [[1366, "torch.nn.EmbeddingBag.from_pretrained"]], "featurealphadropout (class in torch.nn)": [[1367, "torch.nn.FeatureAlphaDropout"]], "flatten (class in torch.nn)": [[1368, "torch.nn.Flatten"]], "fold (class in torch.nn)": [[1369, "torch.nn.Fold"]], "fractionalmaxpool2d (class in torch.nn)": [[1370, "torch.nn.FractionalMaxPool2d"]], "fractionalmaxpool3d (class in torch.nn)": [[1371, "torch.nn.FractionalMaxPool3d"]], "gelu (class in torch.nn)": [[1372, "torch.nn.GELU"]], "glu (class in torch.nn)": [[1373, "torch.nn.GLU"]], "gru (class in torch.nn)": [[1374, "torch.nn.GRU"]], "grucell (class in torch.nn)": [[1375, "torch.nn.GRUCell"]], "gaussiannllloss (class in torch.nn)": [[1376, "torch.nn.GaussianNLLLoss"]], "groupnorm (class in torch.nn)": [[1377, "torch.nn.GroupNorm"]], "hardshrink (class in torch.nn)": [[1378, "torch.nn.Hardshrink"]], "hardsigmoid (class in torch.nn)": [[1379, "torch.nn.Hardsigmoid"]], "hardswish (class in torch.nn)": [[1380, "torch.nn.Hardswish"]], "hardtanh (class in torch.nn)": [[1381, "torch.nn.Hardtanh"]], "hingeembeddingloss (class in torch.nn)": [[1382, "torch.nn.HingeEmbeddingLoss"]], "huberloss (class in torch.nn)": [[1383, "torch.nn.HuberLoss"]], "identity (class in torch.nn)": [[1384, "torch.nn.Identity"]], "instancenorm1d (class in torch.nn)": [[1385, "torch.nn.InstanceNorm1d"]], "instancenorm2d (class in torch.nn)": [[1386, "torch.nn.InstanceNorm2d"]], "instancenorm3d (class in torch.nn)": [[1387, "torch.nn.InstanceNorm3d"]], "kldivloss (class in torch.nn)": [[1388, "torch.nn.KLDivLoss"]], "l1loss (class in torch.nn)": [[1389, "torch.nn.L1Loss"]], "lppool1d (class in torch.nn)": [[1390, "torch.nn.LPPool1d"]], "lppool2d (class in torch.nn)": [[1391, "torch.nn.LPPool2d"]], "lstm (class in torch.nn)": [[1392, "torch.nn.LSTM"]], "lstmcell (class in torch.nn)": [[1393, "torch.nn.LSTMCell"]], "layernorm (class in torch.nn)": [[1394, "torch.nn.LayerNorm"]], "lazybatchnorm1d (class in torch.nn)": [[1395, "torch.nn.LazyBatchNorm1d"]], "cls_to_become (torch.nn.lazybatchnorm1d attribute)": [[1395, "torch.nn.LazyBatchNorm1d.cls_to_become"]], "lazybatchnorm2d (class in torch.nn)": [[1396, "torch.nn.LazyBatchNorm2d"]], "cls_to_become (torch.nn.lazybatchnorm2d attribute)": [[1396, "torch.nn.LazyBatchNorm2d.cls_to_become"]], "lazybatchnorm3d (class in torch.nn)": [[1397, "torch.nn.LazyBatchNorm3d"]], "cls_to_become (torch.nn.lazybatchnorm3d attribute)": [[1397, "torch.nn.LazyBatchNorm3d.cls_to_become"]], "lazyconv1d (class in torch.nn)": [[1398, "torch.nn.LazyConv1d"]], "cls_to_become (torch.nn.lazyconv1d attribute)": [[1398, "torch.nn.LazyConv1d.cls_to_become"]], "lazyconv2d (class in torch.nn)": [[1399, "torch.nn.LazyConv2d"]], "cls_to_become (torch.nn.lazyconv2d attribute)": [[1399, "torch.nn.LazyConv2d.cls_to_become"]], "lazyconv3d (class in torch.nn)": [[1400, "torch.nn.LazyConv3d"]], "cls_to_become (torch.nn.lazyconv3d attribute)": [[1400, "torch.nn.LazyConv3d.cls_to_become"]], "lazyconvtranspose1d (class in torch.nn)": [[1401, "torch.nn.LazyConvTranspose1d"]], "cls_to_become (torch.nn.lazyconvtranspose1d attribute)": [[1401, "torch.nn.LazyConvTranspose1d.cls_to_become"]], "lazyconvtranspose2d (class in torch.nn)": [[1402, "torch.nn.LazyConvTranspose2d"]], "cls_to_become (torch.nn.lazyconvtranspose2d attribute)": [[1402, "torch.nn.LazyConvTranspose2d.cls_to_become"]], "lazyconvtranspose3d (class in torch.nn)": [[1403, "torch.nn.LazyConvTranspose3d"]], "cls_to_become (torch.nn.lazyconvtranspose3d attribute)": [[1403, "torch.nn.LazyConvTranspose3d.cls_to_become"]], "lazyinstancenorm1d (class in torch.nn)": [[1404, "torch.nn.LazyInstanceNorm1d"]], "cls_to_become (torch.nn.lazyinstancenorm1d attribute)": [[1404, "torch.nn.LazyInstanceNorm1d.cls_to_become"]], "lazyinstancenorm2d (class in torch.nn)": [[1405, "torch.nn.LazyInstanceNorm2d"]], "cls_to_become (torch.nn.lazyinstancenorm2d attribute)": [[1405, "torch.nn.LazyInstanceNorm2d.cls_to_become"]], "lazyinstancenorm3d (class in torch.nn)": [[1406, "torch.nn.LazyInstanceNorm3d"]], "cls_to_become (torch.nn.lazyinstancenorm3d attribute)": [[1406, "torch.nn.LazyInstanceNorm3d.cls_to_become"]], "lazylinear (class in torch.nn)": [[1407, "torch.nn.LazyLinear"]], "cls_to_become (torch.nn.lazylinear attribute)": [[1407, "torch.nn.LazyLinear.cls_to_become"]], "leakyrelu (class in torch.nn)": [[1408, "torch.nn.LeakyReLU"]], "linear (class in torch.nn)": [[1409, "torch.nn.Linear"]], "localresponsenorm (class in torch.nn)": [[1410, "torch.nn.LocalResponseNorm"]], "logsigmoid (class in torch.nn)": [[1411, "torch.nn.LogSigmoid"]], "logsoftmax (class in torch.nn)": [[1412, "torch.nn.LogSoftmax"]], "mseloss (class in torch.nn)": [[1413, "torch.nn.MSELoss"]], "marginrankingloss (class in torch.nn)": [[1414, "torch.nn.MarginRankingLoss"]], "maxpool1d (class in torch.nn)": [[1415, "torch.nn.MaxPool1d"]], "maxpool2d (class in torch.nn)": [[1416, "torch.nn.MaxPool2d"]], "maxpool3d (class in torch.nn)": [[1417, "torch.nn.MaxPool3d"]], "maxunpool1d (class in torch.nn)": [[1418, "torch.nn.MaxUnpool1d"]], "maxunpool2d (class in torch.nn)": [[1419, "torch.nn.MaxUnpool2d"]], "maxunpool3d (class in torch.nn)": [[1420, "torch.nn.MaxUnpool3d"]], "mish (class in torch.nn)": [[1421, "torch.nn.Mish"]], "module (class in torch.nn)": [[1422, "torch.nn.Module"]], "add_module() (torch.nn.module method)": [[1422, "torch.nn.Module.add_module"]], "apply() (torch.nn.module method)": [[1422, "torch.nn.Module.apply"]], "bfloat16() (torch.nn.module method)": [[1422, "torch.nn.Module.bfloat16"]], "buffers() (torch.nn.module method)": [[1422, "torch.nn.Module.buffers"]], "children() (torch.nn.module method)": [[1422, "torch.nn.Module.children"]], "compile() (torch.nn.module method)": [[1422, "torch.nn.Module.compile"]], "cpu() (torch.nn.module method)": [[1422, "torch.nn.Module.cpu"]], "cuda() (torch.nn.module method)": [[1422, "torch.nn.Module.cuda"]], "double() (torch.nn.module method)": [[1422, "torch.nn.Module.double"]], "eval() (torch.nn.module method)": [[1422, "torch.nn.Module.eval"]], "extra_repr() (torch.nn.module method)": [[1422, "torch.nn.Module.extra_repr"]], "float() (torch.nn.module method)": [[1422, "torch.nn.Module.float"]], "forward() (torch.nn.module method)": [[1422, "torch.nn.Module.forward"]], "get_buffer() (torch.nn.module method)": [[1422, "torch.nn.Module.get_buffer"]], "get_extra_state() (torch.nn.module method)": [[1422, "torch.nn.Module.get_extra_state"]], "get_parameter() (torch.nn.module method)": [[1422, "torch.nn.Module.get_parameter"]], "get_submodule() (torch.nn.module method)": [[1422, "torch.nn.Module.get_submodule"]], "half() (torch.nn.module method)": [[1422, "torch.nn.Module.half"]], "ipu() (torch.nn.module method)": [[1422, "torch.nn.Module.ipu"]], "load_state_dict() (torch.nn.module method)": [[1422, "torch.nn.Module.load_state_dict"]], "modules() (torch.nn.module method)": [[1422, "torch.nn.Module.modules"]], "named_buffers() (torch.nn.module method)": [[1422, "torch.nn.Module.named_buffers"]], "named_children() (torch.nn.module method)": [[1422, "torch.nn.Module.named_children"]], "named_modules() (torch.nn.module method)": [[1422, "torch.nn.Module.named_modules"]], "named_parameters() (torch.nn.module method)": [[1422, "torch.nn.Module.named_parameters"]], "parameters() (torch.nn.module method)": [[1422, "torch.nn.Module.parameters"]], "register_backward_hook() (torch.nn.module method)": [[1422, "torch.nn.Module.register_backward_hook"]], "register_buffer() (torch.nn.module method)": [[1422, "torch.nn.Module.register_buffer"]], "register_forward_hook() (torch.nn.module method)": [[1422, "torch.nn.Module.register_forward_hook"]], "register_forward_pre_hook() (torch.nn.module method)": [[1422, "torch.nn.Module.register_forward_pre_hook"]], "register_full_backward_hook() (torch.nn.module method)": [[1422, "torch.nn.Module.register_full_backward_hook"]], "register_full_backward_pre_hook() (torch.nn.module method)": [[1422, "torch.nn.Module.register_full_backward_pre_hook"]], "register_load_state_dict_post_hook() (torch.nn.module method)": [[1422, "torch.nn.Module.register_load_state_dict_post_hook"]], "register_module() (torch.nn.module method)": [[1422, "torch.nn.Module.register_module"]], "register_parameter() (torch.nn.module method)": [[1422, "torch.nn.Module.register_parameter"]], "register_state_dict_pre_hook() (torch.nn.module method)": [[1422, "torch.nn.Module.register_state_dict_pre_hook"]], "requires_grad_() (torch.nn.module method)": [[1422, "torch.nn.Module.requires_grad_"]], "set_extra_state() (torch.nn.module method)": [[1422, "torch.nn.Module.set_extra_state"]], "share_memory() (torch.nn.module method)": [[1422, "torch.nn.Module.share_memory"]], "state_dict() (torch.nn.module method)": [[1422, "torch.nn.Module.state_dict"]], "to() (torch.nn.module method)": [[1422, "torch.nn.Module.to"]], "to_empty() (torch.nn.module method)": [[1422, "torch.nn.Module.to_empty"]], "train() (torch.nn.module method)": [[1422, "torch.nn.Module.train"]], "type() (torch.nn.module method)": [[1422, "torch.nn.Module.type"]], "xpu() (torch.nn.module method)": [[1422, "torch.nn.Module.xpu"]], "zero_grad() (torch.nn.module method)": [[1422, "torch.nn.Module.zero_grad"]], "moduledict (class in torch.nn)": [[1423, "torch.nn.ModuleDict"]], "clear() (torch.nn.moduledict method)": [[1423, "torch.nn.ModuleDict.clear"]], "items() (torch.nn.moduledict method)": [[1423, "torch.nn.ModuleDict.items"]], "keys() (torch.nn.moduledict method)": [[1423, "torch.nn.ModuleDict.keys"]], "pop() (torch.nn.moduledict method)": [[1423, "torch.nn.ModuleDict.pop"]], "update() (torch.nn.moduledict method)": [[1423, "torch.nn.ModuleDict.update"]], "values() (torch.nn.moduledict method)": [[1423, "torch.nn.ModuleDict.values"]], "modulelist (class in torch.nn)": [[1424, "torch.nn.ModuleList"]], "append() (torch.nn.modulelist method)": [[1424, "torch.nn.ModuleList.append"]], "extend() (torch.nn.modulelist method)": [[1424, "torch.nn.ModuleList.extend"]], "insert() (torch.nn.modulelist method)": [[1424, "torch.nn.ModuleList.insert"]], "multilabelmarginloss (class in torch.nn)": [[1425, "torch.nn.MultiLabelMarginLoss"]], "multilabelsoftmarginloss (class in torch.nn)": [[1426, "torch.nn.MultiLabelSoftMarginLoss"]], "multimarginloss (class in torch.nn)": [[1427, "torch.nn.MultiMarginLoss"]], "multiheadattention (class in torch.nn)": [[1428, "torch.nn.MultiheadAttention"]], "forward() (torch.nn.multiheadattention method)": [[1428, "torch.nn.MultiheadAttention.forward"]], "merge_masks() (torch.nn.multiheadattention method)": [[1428, "torch.nn.MultiheadAttention.merge_masks"]], "nllloss (class in torch.nn)": [[1429, "torch.nn.NLLLoss"]], "prelu (class in torch.nn)": [[1430, "torch.nn.PReLU"]], "pairwisedistance (class in torch.nn)": [[1431, "torch.nn.PairwiseDistance"]], "parameterdict (class in torch.nn)": [[1432, "torch.nn.ParameterDict"]], "clear() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.clear"]], "copy() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.copy"]], "fromkeys() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.fromkeys"]], "get() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.get"]], "items() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.items"]], "keys() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.keys"]], "pop() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.pop"]], "popitem() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.popitem"]], "setdefault() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.setdefault"]], "update() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.update"]], "values() (torch.nn.parameterdict method)": [[1432, "torch.nn.ParameterDict.values"]], "parameterlist (class in torch.nn)": [[1433, "torch.nn.ParameterList"]], "append() (torch.nn.parameterlist method)": [[1433, "torch.nn.ParameterList.append"]], "extend() (torch.nn.parameterlist method)": [[1433, "torch.nn.ParameterList.extend"]], "pixelshuffle (class in torch.nn)": [[1434, "torch.nn.PixelShuffle"]], "pixelunshuffle (class in torch.nn)": [[1435, "torch.nn.PixelUnshuffle"]], "poissonnllloss (class in torch.nn)": [[1436, "torch.nn.PoissonNLLLoss"]], "rnn (class in torch.nn)": [[1437, "torch.nn.RNN"]], "rnnbase (class in torch.nn)": [[1438, "torch.nn.RNNBase"]], "flatten_parameters() (torch.nn.rnnbase method)": [[1438, "torch.nn.RNNBase.flatten_parameters"]], "rnncell (class in torch.nn)": [[1439, "torch.nn.RNNCell"]], "rrelu (class in torch.nn)": [[1440, "torch.nn.RReLU"]], "relu (class in torch.nn)": [[1441, "torch.nn.ReLU"]], "relu6 (class in torch.nn)": [[1442, "torch.nn.ReLU6"]], "reflectionpad1d (class in torch.nn)": [[1443, "torch.nn.ReflectionPad1d"]], "reflectionpad2d (class in torch.nn)": [[1444, "torch.nn.ReflectionPad2d"]], "reflectionpad3d (class in torch.nn)": [[1445, "torch.nn.ReflectionPad3d"]], "replicationpad1d (class in torch.nn)": [[1446, "torch.nn.ReplicationPad1d"]], "replicationpad2d (class in torch.nn)": [[1447, "torch.nn.ReplicationPad2d"]], "replicationpad3d (class in torch.nn)": [[1448, "torch.nn.ReplicationPad3d"]], "selu (class in torch.nn)": [[1449, "torch.nn.SELU"]], "sequential (class in torch.nn)": [[1450, "torch.nn.Sequential"]], "append() (torch.nn.sequential method)": [[1450, "torch.nn.Sequential.append"]], "silu (class in torch.nn)": [[1451, "torch.nn.SiLU"]], "sigmoid (class in torch.nn)": [[1452, "torch.nn.Sigmoid"]], "smoothl1loss (class in torch.nn)": [[1453, "torch.nn.SmoothL1Loss"]], "softmarginloss (class in torch.nn)": [[1454, "torch.nn.SoftMarginLoss"]], "softmax (class in torch.nn)": [[1455, "torch.nn.Softmax"]], "softmax2d (class in torch.nn)": [[1456, "torch.nn.Softmax2d"]], "softmin (class in torch.nn)": [[1457, "torch.nn.Softmin"]], "softplus (class in torch.nn)": [[1458, "torch.nn.Softplus"]], "softshrink (class in torch.nn)": [[1459, "torch.nn.Softshrink"]], "softsign (class in torch.nn)": [[1460, "torch.nn.Softsign"]], "syncbatchnorm (class in torch.nn)": [[1461, "torch.nn.SyncBatchNorm"]], "convert_sync_batchnorm() (torch.nn.syncbatchnorm class method)": [[1461, "torch.nn.SyncBatchNorm.convert_sync_batchnorm"]], "tanh (class in torch.nn)": [[1462, "torch.nn.Tanh"]], "tanhshrink (class in torch.nn)": [[1463, "torch.nn.Tanhshrink"]], "threshold (class in torch.nn)": [[1464, "torch.nn.Threshold"]], "transformer (class in torch.nn)": [[1465, "torch.nn.Transformer"]], "forward() (torch.nn.transformer method)": [[1465, "torch.nn.Transformer.forward"]], "generate_square_subsequent_mask() (torch.nn.transformer static method)": [[1465, "torch.nn.Transformer.generate_square_subsequent_mask"]], "transformerdecoder (class in torch.nn)": [[1466, "torch.nn.TransformerDecoder"]], "forward() (torch.nn.transformerdecoder method)": [[1466, "torch.nn.TransformerDecoder.forward"]], "transformerdecoderlayer (class in torch.nn)": [[1467, "torch.nn.TransformerDecoderLayer"]], "forward() (torch.nn.transformerdecoderlayer method)": [[1467, "torch.nn.TransformerDecoderLayer.forward"]], "transformerencoder (class in torch.nn)": [[1468, "torch.nn.TransformerEncoder"]], "forward() (torch.nn.transformerencoder method)": [[1468, "torch.nn.TransformerEncoder.forward"]], "transformerencoderlayer (class in torch.nn)": [[1469, "torch.nn.TransformerEncoderLayer"]], "forward() (torch.nn.transformerencoderlayer method)": [[1469, "torch.nn.TransformerEncoderLayer.forward"]], "tripletmarginloss (class in torch.nn)": [[1470, "torch.nn.TripletMarginLoss"]], "tripletmarginwithdistanceloss (class in torch.nn)": [[1471, "torch.nn.TripletMarginWithDistanceLoss"]], "unflatten (class in torch.nn)": [[1472, "torch.nn.Unflatten"]], "unfold (class in torch.nn)": [[1473, "torch.nn.Unfold"]], "upsample (class in torch.nn)": [[1474, "torch.nn.Upsample"]], "upsamplingbilinear2d (class in torch.nn)": [[1475, "torch.nn.UpsamplingBilinear2d"]], "upsamplingnearest2d (class in torch.nn)": [[1476, "torch.nn.UpsamplingNearest2d"]], "zeropad1d (class in torch.nn)": [[1477, "torch.nn.ZeroPad1d"]], "zeropad2d (class in torch.nn)": [[1478, "torch.nn.ZeroPad2d"]], "zeropad3d (class in torch.nn)": [[1479, "torch.nn.ZeroPad3d"]], "adaptive_avg_pool1d() (in module torch.nn.functional)": [[1480, "torch.nn.functional.adaptive_avg_pool1d"]], "adaptive_avg_pool2d() (in module torch.nn.functional)": [[1481, "torch.nn.functional.adaptive_avg_pool2d"]], "adaptive_avg_pool3d() (in module torch.nn.functional)": [[1482, "torch.nn.functional.adaptive_avg_pool3d"]], "adaptive_max_pool1d() (in module torch.nn.functional)": [[1483, "torch.nn.functional.adaptive_max_pool1d"]], "adaptive_max_pool2d() (in module torch.nn.functional)": [[1484, "torch.nn.functional.adaptive_max_pool2d"]], "adaptive_max_pool3d() (in module torch.nn.functional)": [[1485, "torch.nn.functional.adaptive_max_pool3d"]], "affine_grid() (in module torch.nn.functional)": [[1486, "torch.nn.functional.affine_grid"]], "alpha_dropout() (in module torch.nn.functional)": [[1487, "torch.nn.functional.alpha_dropout"]], "avg_pool1d() (in module torch.nn.functional)": [[1488, "torch.nn.functional.avg_pool1d"]], "avg_pool2d() (in module torch.nn.functional)": [[1489, "torch.nn.functional.avg_pool2d"]], "avg_pool3d() (in module torch.nn.functional)": [[1490, "torch.nn.functional.avg_pool3d"]], "batch_norm() (in module torch.nn.functional)": [[1491, "torch.nn.functional.batch_norm"]], "bilinear() (in module torch.nn.functional)": [[1492, "torch.nn.functional.bilinear"]], "binary_cross_entropy() (in module torch.nn.functional)": [[1493, "torch.nn.functional.binary_cross_entropy"]], "binary_cross_entropy_with_logits() (in module torch.nn.functional)": [[1494, "torch.nn.functional.binary_cross_entropy_with_logits"]], "celu() (in module torch.nn.functional)": [[1495, "torch.nn.functional.celu"]], "conv1d() (in module torch.nn.functional)": [[1496, "torch.nn.functional.conv1d"]], "conv2d() (in module torch.nn.functional)": [[1497, "torch.nn.functional.conv2d"]], "conv3d() (in module torch.nn.functional)": [[1498, "torch.nn.functional.conv3d"]], "conv_transpose1d() (in module torch.nn.functional)": [[1499, "torch.nn.functional.conv_transpose1d"]], "conv_transpose2d() (in module torch.nn.functional)": [[1500, "torch.nn.functional.conv_transpose2d"]], "conv_transpose3d() (in module torch.nn.functional)": [[1501, "torch.nn.functional.conv_transpose3d"]], "cosine_embedding_loss() (in module torch.nn.functional)": [[1502, "torch.nn.functional.cosine_embedding_loss"]], "cosine_similarity() (in module torch.nn.functional)": [[1503, "torch.nn.functional.cosine_similarity"]], "cross_entropy() (in module torch.nn.functional)": [[1504, "torch.nn.functional.cross_entropy"]], "ctc_loss() (in module torch.nn.functional)": [[1505, "torch.nn.functional.ctc_loss"]], "dropout() (in module torch.nn.functional)": [[1506, "torch.nn.functional.dropout"]], "dropout1d() (in module torch.nn.functional)": [[1507, "torch.nn.functional.dropout1d"]], "dropout2d() (in module torch.nn.functional)": [[1508, "torch.nn.functional.dropout2d"]], "dropout3d() (in module torch.nn.functional)": [[1509, "torch.nn.functional.dropout3d"]], "elu() (in module torch.nn.functional)": [[1510, "torch.nn.functional.elu"]], "elu_() (in module torch.nn.functional)": [[1511, "torch.nn.functional.elu_"]], "embedding() (in module torch.nn.functional)": [[1512, "torch.nn.functional.embedding"]], "embedding_bag() (in module torch.nn.functional)": [[1513, "torch.nn.functional.embedding_bag"]], "feature_alpha_dropout() (in module torch.nn.functional)": [[1514, "torch.nn.functional.feature_alpha_dropout"]], "fold() (in module torch.nn.functional)": [[1515, "torch.nn.functional.fold"]], "fractional_max_pool2d() (in module torch.nn.functional)": [[1516, "torch.nn.functional.fractional_max_pool2d"]], "fractional_max_pool3d() (in module torch.nn.functional)": [[1517, "torch.nn.functional.fractional_max_pool3d"]], "gaussian_nll_loss() (in module torch.nn.functional)": [[1518, "torch.nn.functional.gaussian_nll_loss"]], "gelu() (in module torch.nn.functional)": [[1519, "torch.nn.functional.gelu"]], "glu() (in module torch.nn.functional)": [[1520, "torch.nn.functional.glu"]], "grid_sample() (in module torch.nn.functional)": [[1521, "torch.nn.functional.grid_sample"]], "group_norm() (in module torch.nn.functional)": [[1522, "torch.nn.functional.group_norm"]], "gumbel_softmax() (in module torch.nn.functional)": [[1523, "torch.nn.functional.gumbel_softmax"]], "hardshrink() (in module torch.nn.functional)": [[1524, "torch.nn.functional.hardshrink"]], "hardsigmoid() (in module torch.nn.functional)": [[1525, "torch.nn.functional.hardsigmoid"]], "hardswish() (in module torch.nn.functional)": [[1526, "torch.nn.functional.hardswish"]], "hardtanh() (in module torch.nn.functional)": [[1527, "torch.nn.functional.hardtanh"]], "hardtanh_() (in module torch.nn.functional)": [[1528, "torch.nn.functional.hardtanh_"]], "hinge_embedding_loss() (in module torch.nn.functional)": [[1529, "torch.nn.functional.hinge_embedding_loss"]], "huber_loss() (in module torch.nn.functional)": [[1530, "torch.nn.functional.huber_loss"]], "instance_norm() (in module torch.nn.functional)": [[1531, "torch.nn.functional.instance_norm"]], "interpolate() (in module torch.nn.functional)": [[1532, "torch.nn.functional.interpolate"]], "kl_div() (in module torch.nn.functional)": [[1533, "torch.nn.functional.kl_div"]], "l1_loss() (in module torch.nn.functional)": [[1534, "torch.nn.functional.l1_loss"]], "layer_norm() (in module torch.nn.functional)": [[1535, "torch.nn.functional.layer_norm"]], "leaky_relu() (in module torch.nn.functional)": [[1536, "torch.nn.functional.leaky_relu"]], "leaky_relu_() (in module torch.nn.functional)": [[1537, "torch.nn.functional.leaky_relu_"]], "linear() (in module torch.nn.functional)": [[1538, "torch.nn.functional.linear"]], "local_response_norm() (in module torch.nn.functional)": [[1539, "torch.nn.functional.local_response_norm"]], "log_softmax() (in module torch.nn.functional)": [[1540, "torch.nn.functional.log_softmax"]], "logsigmoid() (in module torch.nn.functional)": [[1541, "torch.nn.functional.logsigmoid"]], "lp_pool1d() (in module torch.nn.functional)": [[1542, "torch.nn.functional.lp_pool1d"]], "lp_pool2d() (in module torch.nn.functional)": [[1543, "torch.nn.functional.lp_pool2d"]], "margin_ranking_loss() (in module torch.nn.functional)": [[1544, "torch.nn.functional.margin_ranking_loss"]], "max_pool1d() (in module torch.nn.functional)": [[1545, "torch.nn.functional.max_pool1d"]], "max_pool2d() (in module torch.nn.functional)": [[1546, "torch.nn.functional.max_pool2d"]], "max_pool3d() (in module torch.nn.functional)": [[1547, "torch.nn.functional.max_pool3d"]], "max_unpool1d() (in module torch.nn.functional)": [[1548, "torch.nn.functional.max_unpool1d"]], "max_unpool2d() (in module torch.nn.functional)": [[1549, "torch.nn.functional.max_unpool2d"]], "max_unpool3d() (in module torch.nn.functional)": [[1550, "torch.nn.functional.max_unpool3d"]], "mish() (in module torch.nn.functional)": [[1551, "torch.nn.functional.mish"]], "mse_loss() (in module torch.nn.functional)": [[1552, "torch.nn.functional.mse_loss"]], "multi_margin_loss() (in module torch.nn.functional)": [[1553, "torch.nn.functional.multi_margin_loss"]], "multilabel_margin_loss() (in module torch.nn.functional)": [[1554, "torch.nn.functional.multilabel_margin_loss"]], "multilabel_soft_margin_loss() (in module torch.nn.functional)": [[1555, "torch.nn.functional.multilabel_soft_margin_loss"]], "nll_loss() (in module torch.nn.functional)": [[1556, "torch.nn.functional.nll_loss"]], "normalize() (in module torch.nn.functional)": [[1557, "torch.nn.functional.normalize"]], "one_hot() (in module torch.nn.functional)": [[1558, "torch.nn.functional.one_hot"]], "pad() (in module torch.nn.functional)": [[1559, "torch.nn.functional.pad"]], "pairwise_distance() (in module torch.nn.functional)": [[1560, "torch.nn.functional.pairwise_distance"]], "pdist() (in module torch.nn.functional)": [[1561, "torch.nn.functional.pdist"]], "pixel_shuffle() (in module torch.nn.functional)": [[1562, "torch.nn.functional.pixel_shuffle"]], "pixel_unshuffle() (in module torch.nn.functional)": [[1563, "torch.nn.functional.pixel_unshuffle"]], "poisson_nll_loss() (in module torch.nn.functional)": [[1564, "torch.nn.functional.poisson_nll_loss"]], "prelu() (in module torch.nn.functional)": [[1565, "torch.nn.functional.prelu"]], "relu() (in module torch.nn.functional)": [[1566, "torch.nn.functional.relu"]], "relu6() (in module torch.nn.functional)": [[1567, "torch.nn.functional.relu6"]], "relu_() (in module torch.nn.functional)": [[1568, "torch.nn.functional.relu_"]], "rrelu() (in module torch.nn.functional)": [[1569, "torch.nn.functional.rrelu"]], "rrelu_() (in module torch.nn.functional)": [[1570, "torch.nn.functional.rrelu_"]], "scaled_dot_product_attention() (in module torch.nn.functional)": [[1571, "torch.nn.functional.scaled_dot_product_attention"]], "selu() (in module torch.nn.functional)": [[1572, "torch.nn.functional.selu"]], "sigmoid() (in module torch.nn.functional)": [[1573, "torch.nn.functional.sigmoid"]], "silu() (in module torch.nn.functional)": [[1574, "torch.nn.functional.silu"]], "smooth_l1_loss() (in module torch.nn.functional)": [[1575, "torch.nn.functional.smooth_l1_loss"]], "soft_margin_loss() (in module torch.nn.functional)": [[1576, "torch.nn.functional.soft_margin_loss"]], "softmax() (in module torch.nn.functional)": [[1577, "torch.nn.functional.softmax"]], "softmin() (in module torch.nn.functional)": [[1578, "torch.nn.functional.softmin"]], "softplus() (in module torch.nn.functional)": [[1579, "torch.nn.functional.softplus"]], "softshrink() (in module torch.nn.functional)": [[1580, "torch.nn.functional.softshrink"]], "softsign() (in module torch.nn.functional)": [[1581, "torch.nn.functional.softsign"]], "tanh() (in module torch.nn.functional)": [[1582, "torch.nn.functional.tanh"]], "tanhshrink() (in module torch.nn.functional)": [[1583, "torch.nn.functional.tanhshrink"]], "threshold() (in module torch.nn.functional)": [[1584, "torch.nn.functional.threshold"]], "threshold_() (in module torch.nn.functional)": [[1585, "torch.nn.functional.threshold_"]], "data_parallel() (in module torch.nn.parallel)": [[1586, "torch.nn.parallel.data_parallel"]], "triplet_margin_loss() (in module torch.nn.functional)": [[1587, "torch.nn.functional.triplet_margin_loss"]], "triplet_margin_with_distance_loss() (in module torch.nn.functional)": [[1588, "torch.nn.functional.triplet_margin_with_distance_loss"]], "unfold() (in module torch.nn.functional)": [[1589, "torch.nn.functional.unfold"]], "upsample() (in module torch.nn.functional)": [[1590, "torch.nn.functional.upsample"]], "upsample_bilinear() (in module torch.nn.functional)": [[1591, "torch.nn.functional.upsample_bilinear"]], "upsample_nearest() (in module torch.nn.functional)": [[1592, "torch.nn.functional.upsample_nearest"]], "lazymodulemixin (class in torch.nn.modules.lazy)": [[1593, "torch.nn.modules.lazy.LazyModuleMixin"]], "has_uninitialized_params() (torch.nn.modules.lazy.lazymodulemixin method)": [[1593, "torch.nn.modules.lazy.LazyModuleMixin.has_uninitialized_params"]], "initialize_parameters() (torch.nn.modules.lazy.lazymodulemixin method)": [[1593, "torch.nn.modules.lazy.LazyModuleMixin.initialize_parameters"]], "register_module_backward_hook() (in module torch.nn.modules.module)": [[1594, "torch.nn.modules.module.register_module_backward_hook"]], "register_module_buffer_registration_hook() (in module torch.nn.modules.module)": [[1595, "torch.nn.modules.module.register_module_buffer_registration_hook"]], "register_module_forward_hook() (in module torch.nn.modules.module)": [[1596, "torch.nn.modules.module.register_module_forward_hook"]], "register_module_forward_pre_hook() (in module torch.nn.modules.module)": [[1597, "torch.nn.modules.module.register_module_forward_pre_hook"]], "register_module_full_backward_hook() (in module torch.nn.modules.module)": [[1598, "torch.nn.modules.module.register_module_full_backward_hook"]], "register_module_full_backward_pre_hook() (in module torch.nn.modules.module)": [[1599, "torch.nn.modules.module.register_module_full_backward_pre_hook"]], "register_module_module_registration_hook() (in module torch.nn.modules.module)": [[1600, "torch.nn.modules.module.register_module_module_registration_hook"]], "register_module_parameter_registration_hook() (in module torch.nn.modules.module)": [[1601, "torch.nn.modules.module.register_module_parameter_registration_hook"]], "distributeddataparallel (class in torch.nn.parallel)": [[1602, "torch.nn.parallel.DistributedDataParallel"]], "join() (torch.nn.parallel.distributeddataparallel method)": [[1602, "torch.nn.parallel.DistributedDataParallel.join"]], "join_hook() (torch.nn.parallel.distributeddataparallel method)": [[1602, "torch.nn.parallel.DistributedDataParallel.join_hook"]], "no_sync() (torch.nn.parallel.distributeddataparallel method)": [[1602, "torch.nn.parallel.DistributedDataParallel.no_sync"]], "register_comm_hook() (torch.nn.parallel.distributeddataparallel method)": [[1602, "torch.nn.parallel.DistributedDataParallel.register_comm_hook"]], "parameter (class in torch.nn.parameter)": [[1603, "torch.nn.parameter.Parameter"]], "uninitializedbuffer (class in torch.nn.parameter)": [[1604, "torch.nn.parameter.UninitializedBuffer"]], "uninitializedparameter (class in torch.nn.parameter)": [[1605, "torch.nn.parameter.UninitializedParameter"]], "cls_to_become (torch.nn.parameter.uninitializedparameter attribute)": [[1605, "torch.nn.parameter.UninitializedParameter.cls_to_become"]], "clip_grad_norm_() (in module torch.nn.utils)": [[1606, "torch.nn.utils.clip_grad_norm_"]], "clip_grad_value_() (in module torch.nn.utils)": [[1607, "torch.nn.utils.clip_grad_value_"]], "parameters_to_vector() (in module torch.nn.utils)": [[1608, "torch.nn.utils.parameters_to_vector"]], "orthogonal() (in module torch.nn.utils.parametrizations)": [[1609, "torch.nn.utils.parametrizations.orthogonal"]], "spectral_norm() (in module torch.nn.utils.parametrizations)": [[1610, "torch.nn.utils.parametrizations.spectral_norm"]], "parametrizationlist (class in torch.nn.utils.parametrize)": [[1611, "torch.nn.utils.parametrize.ParametrizationList"]], "right_inverse() (torch.nn.utils.parametrize.parametrizationlist method)": [[1611, "torch.nn.utils.parametrize.ParametrizationList.right_inverse"]], "cached() (in module torch.nn.utils.parametrize)": [[1612, "torch.nn.utils.parametrize.cached"]], "is_parametrized() (in module torch.nn.utils.parametrize)": [[1613, "torch.nn.utils.parametrize.is_parametrized"]], "register_parametrization() (in module torch.nn.utils.parametrize)": [[1614, "torch.nn.utils.parametrize.register_parametrization"]], "remove_parametrizations() (in module torch.nn.utils.parametrize)": [[1615, "torch.nn.utils.parametrize.remove_parametrizations"]], "basepruningmethod (class in torch.nn.utils.prune)": [[1616, "torch.nn.utils.prune.BasePruningMethod"]], "apply() (torch.nn.utils.prune.basepruningmethod class method)": [[1616, "torch.nn.utils.prune.BasePruningMethod.apply"]], "apply_mask() (torch.nn.utils.prune.basepruningmethod method)": [[1616, "torch.nn.utils.prune.BasePruningMethod.apply_mask"]], "compute_mask() (torch.nn.utils.prune.basepruningmethod method)": [[1616, "torch.nn.utils.prune.BasePruningMethod.compute_mask"]], "prune() (torch.nn.utils.prune.basepruningmethod method)": [[1616, "torch.nn.utils.prune.BasePruningMethod.prune"]], "remove() (torch.nn.utils.prune.basepruningmethod method)": [[1616, "torch.nn.utils.prune.BasePruningMethod.remove"]], "customfrommask (class in torch.nn.utils.prune)": [[1617, "torch.nn.utils.prune.CustomFromMask"]], "apply() (torch.nn.utils.prune.customfrommask class method)": [[1617, "torch.nn.utils.prune.CustomFromMask.apply"]], "apply_mask() (torch.nn.utils.prune.customfrommask method)": [[1617, "torch.nn.utils.prune.CustomFromMask.apply_mask"]], "prune() (torch.nn.utils.prune.customfrommask method)": [[1617, "torch.nn.utils.prune.CustomFromMask.prune"]], "remove() (torch.nn.utils.prune.customfrommask method)": [[1617, "torch.nn.utils.prune.CustomFromMask.remove"]], "identity (class in torch.nn.utils.prune)": [[1618, "torch.nn.utils.prune.Identity"]], "apply() (torch.nn.utils.prune.identity class method)": [[1618, "torch.nn.utils.prune.Identity.apply"]], "apply_mask() (torch.nn.utils.prune.identity method)": [[1618, "torch.nn.utils.prune.Identity.apply_mask"]], "prune() (torch.nn.utils.prune.identity method)": [[1618, "torch.nn.utils.prune.Identity.prune"]], "remove() (torch.nn.utils.prune.identity method)": [[1618, "torch.nn.utils.prune.Identity.remove"]], "l1unstructured (class in torch.nn.utils.prune)": [[1619, "torch.nn.utils.prune.L1Unstructured"]], "apply() (torch.nn.utils.prune.l1unstructured class method)": [[1619, "torch.nn.utils.prune.L1Unstructured.apply"]], "apply_mask() (torch.nn.utils.prune.l1unstructured method)": [[1619, "torch.nn.utils.prune.L1Unstructured.apply_mask"]], "prune() (torch.nn.utils.prune.l1unstructured method)": [[1619, "torch.nn.utils.prune.L1Unstructured.prune"]], "remove() (torch.nn.utils.prune.l1unstructured method)": [[1619, "torch.nn.utils.prune.L1Unstructured.remove"]], "lnstructured (class in torch.nn.utils.prune)": [[1620, "torch.nn.utils.prune.LnStructured"]], "apply() (torch.nn.utils.prune.lnstructured class method)": [[1620, "torch.nn.utils.prune.LnStructured.apply"]], "apply_mask() (torch.nn.utils.prune.lnstructured method)": [[1620, "torch.nn.utils.prune.LnStructured.apply_mask"]], "compute_mask() (torch.nn.utils.prune.lnstructured method)": [[1620, "torch.nn.utils.prune.LnStructured.compute_mask"]], "prune() (torch.nn.utils.prune.lnstructured method)": [[1620, "torch.nn.utils.prune.LnStructured.prune"]], "remove() (torch.nn.utils.prune.lnstructured method)": [[1620, "torch.nn.utils.prune.LnStructured.remove"]], "pruningcontainer (class in torch.nn.utils.prune)": [[1621, "torch.nn.utils.prune.PruningContainer"]], "add_pruning_method() (torch.nn.utils.prune.pruningcontainer method)": [[1621, "torch.nn.utils.prune.PruningContainer.add_pruning_method"]], "apply() (torch.nn.utils.prune.pruningcontainer class method)": [[1621, "torch.nn.utils.prune.PruningContainer.apply"]], "apply_mask() (torch.nn.utils.prune.pruningcontainer method)": [[1621, "torch.nn.utils.prune.PruningContainer.apply_mask"]], "compute_mask() (torch.nn.utils.prune.pruningcontainer method)": [[1621, "torch.nn.utils.prune.PruningContainer.compute_mask"]], "prune() (torch.nn.utils.prune.pruningcontainer method)": [[1621, "torch.nn.utils.prune.PruningContainer.prune"]], "remove() (torch.nn.utils.prune.pruningcontainer method)": [[1621, "torch.nn.utils.prune.PruningContainer.remove"]], "randomstructured (class in torch.nn.utils.prune)": [[1622, "torch.nn.utils.prune.RandomStructured"]], "apply() (torch.nn.utils.prune.randomstructured class method)": [[1622, "torch.nn.utils.prune.RandomStructured.apply"]], "apply_mask() (torch.nn.utils.prune.randomstructured method)": [[1622, "torch.nn.utils.prune.RandomStructured.apply_mask"]], "compute_mask() (torch.nn.utils.prune.randomstructured method)": [[1622, "torch.nn.utils.prune.RandomStructured.compute_mask"]], "prune() (torch.nn.utils.prune.randomstructured method)": [[1622, "torch.nn.utils.prune.RandomStructured.prune"]], "remove() (torch.nn.utils.prune.randomstructured method)": [[1622, "torch.nn.utils.prune.RandomStructured.remove"]], "randomunstructured (class in torch.nn.utils.prune)": [[1623, "torch.nn.utils.prune.RandomUnstructured"]], "apply() (torch.nn.utils.prune.randomunstructured class method)": [[1623, "torch.nn.utils.prune.RandomUnstructured.apply"]], "apply_mask() (torch.nn.utils.prune.randomunstructured method)": [[1623, "torch.nn.utils.prune.RandomUnstructured.apply_mask"]], "prune() (torch.nn.utils.prune.randomunstructured method)": [[1623, "torch.nn.utils.prune.RandomUnstructured.prune"]], "remove() (torch.nn.utils.prune.randomunstructured method)": [[1623, "torch.nn.utils.prune.RandomUnstructured.remove"]], "custom_from_mask() (in module torch.nn.utils.prune)": [[1624, "torch.nn.utils.prune.custom_from_mask"]], "global_unstructured() (in module torch.nn.utils.prune)": [[1625, "torch.nn.utils.prune.global_unstructured"]], "identity() (in module torch.nn.utils.prune)": [[1626, "torch.nn.utils.prune.identity"]], "is_pruned() (in module torch.nn.utils.prune)": [[1627, "torch.nn.utils.prune.is_pruned"]], "l1_unstructured() (in module torch.nn.utils.prune)": [[1628, "torch.nn.utils.prune.l1_unstructured"]], "ln_structured() (in module torch.nn.utils.prune)": [[1629, "torch.nn.utils.prune.ln_structured"]], "random_structured() (in module torch.nn.utils.prune)": [[1630, "torch.nn.utils.prune.random_structured"]], "random_unstructured() (in module torch.nn.utils.prune)": [[1631, "torch.nn.utils.prune.random_unstructured"]], "remove() (in module torch.nn.utils.prune)": [[1632, "torch.nn.utils.prune.remove"]], "remove_spectral_norm() (in module torch.nn.utils)": [[1633, "torch.nn.utils.remove_spectral_norm"]], "remove_weight_norm() (in module torch.nn.utils)": [[1634, "torch.nn.utils.remove_weight_norm"]], "packedsequence (class in torch.nn.utils.rnn)": [[1635, "torch.nn.utils.rnn.PackedSequence"]], "batch_sizes (torch.nn.utils.rnn.packedsequence attribute)": [[1635, "torch.nn.utils.rnn.PackedSequence.batch_sizes"]], "count() (torch.nn.utils.rnn.packedsequence method)": [[1635, "torch.nn.utils.rnn.PackedSequence.count"]], "data (torch.nn.utils.rnn.packedsequence attribute)": [[1635, "torch.nn.utils.rnn.PackedSequence.data"]], "index() (torch.nn.utils.rnn.packedsequence method)": [[1635, "torch.nn.utils.rnn.PackedSequence.index"]], "is_cuda (torch.nn.utils.rnn.packedsequence property)": [[1635, "torch.nn.utils.rnn.PackedSequence.is_cuda"]], "is_pinned() (torch.nn.utils.rnn.packedsequence method)": [[1635, "torch.nn.utils.rnn.PackedSequence.is_pinned"]], "sorted_indices (torch.nn.utils.rnn.packedsequence attribute)": [[1635, "torch.nn.utils.rnn.PackedSequence.sorted_indices"]], "to() (torch.nn.utils.rnn.packedsequence method)": [[1635, "torch.nn.utils.rnn.PackedSequence.to"]], "unsorted_indices (torch.nn.utils.rnn.packedsequence attribute)": [[1635, "torch.nn.utils.rnn.PackedSequence.unsorted_indices"]], "pack_padded_sequence() (in module torch.nn.utils.rnn)": [[1636, "torch.nn.utils.rnn.pack_padded_sequence"]], "pack_sequence() (in module torch.nn.utils.rnn)": [[1637, "torch.nn.utils.rnn.pack_sequence"]], "pad_packed_sequence() (in module torch.nn.utils.rnn)": [[1638, "torch.nn.utils.rnn.pad_packed_sequence"]], "pad_sequence() (in module torch.nn.utils.rnn)": [[1639, "torch.nn.utils.rnn.pad_sequence"]], "unpack_sequence() (in module torch.nn.utils.rnn)": [[1640, "torch.nn.utils.rnn.unpack_sequence"]], "unpad_sequence() (in module torch.nn.utils.rnn)": [[1641, "torch.nn.utils.rnn.unpad_sequence"]], "skip_init() (in module torch.nn.utils)": [[1642, "torch.nn.utils.skip_init"]], "spectral_norm() (in module torch.nn.utils)": [[1643, "torch.nn.utils.spectral_norm"]], "functional_call() (in module torch.nn.utils.stateless)": [[1644, "torch.nn.utils.stateless.functional_call"]], "vector_to_parameters() (in module torch.nn.utils)": [[1645, "torch.nn.utils.vector_to_parameters"]], "weight_norm() (in module torch.nn.utils)": [[1646, "torch.nn.utils.weight_norm"]], "no_grad (class in torch)": [[1647, "torch.no_grad"]], "nonzero() (in module torch)": [[1648, "torch.nonzero"]], "norm() (in module torch)": [[1649, "torch.norm"]], "normal() (in module torch)": [[1650, "torch.normal"]], "not_equal() (in module torch)": [[1651, "torch.not_equal"]], "numel() (in module torch)": [[1652, "torch.numel"]], "ones() (in module torch)": [[1653, "torch.ones"]], "ones_like() (in module torch)": [[1654, "torch.ones_like"]], "exportoptions (class in torch.onnx)": [[1655, "torch.onnx.ExportOptions"]], "exportoutput (class in torch.onnx)": [[1656, "torch.onnx.ExportOutput"]], "adapt_torch_inputs_to_onnx() (torch.onnx.exportoutput method)": [[1656, "torch.onnx.ExportOutput.adapt_torch_inputs_to_onnx"]], "adapt_torch_outputs_to_onnx() (torch.onnx.exportoutput method)": [[1656, "torch.onnx.ExportOutput.adapt_torch_outputs_to_onnx"]], "diagnostic_context (torch.onnx.exportoutput property)": [[1656, "torch.onnx.ExportOutput.diagnostic_context"]], "model_proto (torch.onnx.exportoutput property)": [[1656, "torch.onnx.ExportOutput.model_proto"]], "save() (torch.onnx.exportoutput method)": [[1656, "torch.onnx.ExportOutput.save"]], "exportoutputserializer (class in torch.onnx)": [[1657, "torch.onnx.ExportOutputSerializer"]], "serialize() (torch.onnx.exportoutputserializer method)": [[1657, "torch.onnx.ExportOutputSerializer.serialize"]], "jitscalartype (class in torch.onnx)": [[1658, "torch.onnx.JitScalarType"]], "dtype() (torch.onnx.jitscalartype method)": [[1658, "torch.onnx.JitScalarType.dtype"]], "from_dtype() (torch.onnx.jitscalartype class method)": [[1658, "torch.onnx.JitScalarType.from_dtype"]], "from_value() (torch.onnx.jitscalartype class method)": [[1658, "torch.onnx.JitScalarType.from_value"]], "onnx_compatible() (torch.onnx.jitscalartype method)": [[1658, "torch.onnx.JitScalarType.onnx_compatible"]], "onnx_type() (torch.onnx.jitscalartype method)": [[1658, "torch.onnx.JitScalarType.onnx_type"]], "scalar_name() (torch.onnx.jitscalartype method)": [[1658, "torch.onnx.JitScalarType.scalar_name"]], "torch_name() (torch.onnx.jitscalartype method)": [[1658, "torch.onnx.JitScalarType.torch_name"]], "graphinfo (class in torch.onnx.verification)": [[1659, "torch.onnx.verification.GraphInfo"]], "all_mismatch_leaf_graph_info() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.all_mismatch_leaf_graph_info"]], "clear() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.clear"]], "essential_node_count() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.essential_node_count"]], "essential_node_kinds() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.essential_node_kinds"]], "export_repro() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.export_repro"]], "find_mismatch() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.find_mismatch"]], "find_partition() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.find_partition"]], "has_mismatch() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.has_mismatch"]], "pretty_print_mismatch() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.pretty_print_mismatch"]], "pretty_print_tree() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.pretty_print_tree"]], "verify_export() (torch.onnx.verification.graphinfo method)": [[1659, "torch.onnx.verification.GraphInfo.verify_export"]], "verificationoptions (class in torch.onnx.verification)": [[1660, "torch.onnx.verification.VerificationOptions"]], "asgd (class in torch.optim)": [[1661, "torch.optim.ASGD"]], "add_param_group() (torch.optim.asgd method)": [[1661, "torch.optim.ASGD.add_param_group"]], "load_state_dict() (torch.optim.asgd method)": [[1661, "torch.optim.ASGD.load_state_dict"]], "register_step_post_hook() (torch.optim.asgd method)": [[1661, "torch.optim.ASGD.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.asgd method)": [[1661, "torch.optim.ASGD.register_step_pre_hook"]], "state_dict() (torch.optim.asgd method)": [[1661, "torch.optim.ASGD.state_dict"]], "zero_grad() (torch.optim.asgd method)": [[1661, "torch.optim.ASGD.zero_grad"]], "adadelta (class in torch.optim)": [[1662, "torch.optim.Adadelta"]], "add_param_group() (torch.optim.adadelta method)": [[1662, "torch.optim.Adadelta.add_param_group"]], "load_state_dict() (torch.optim.adadelta method)": [[1662, "torch.optim.Adadelta.load_state_dict"]], "register_step_post_hook() (torch.optim.adadelta method)": [[1662, "torch.optim.Adadelta.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adadelta method)": [[1662, "torch.optim.Adadelta.register_step_pre_hook"]], "state_dict() (torch.optim.adadelta method)": [[1662, "torch.optim.Adadelta.state_dict"]], "zero_grad() (torch.optim.adadelta method)": [[1662, "torch.optim.Adadelta.zero_grad"]], "adagrad (class in torch.optim)": [[1663, "torch.optim.Adagrad"]], "add_param_group() (torch.optim.adagrad method)": [[1663, "torch.optim.Adagrad.add_param_group"]], "load_state_dict() (torch.optim.adagrad method)": [[1663, "torch.optim.Adagrad.load_state_dict"]], "register_step_post_hook() (torch.optim.adagrad method)": [[1663, "torch.optim.Adagrad.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adagrad method)": [[1663, "torch.optim.Adagrad.register_step_pre_hook"]], "state_dict() (torch.optim.adagrad method)": [[1663, "torch.optim.Adagrad.state_dict"]], "zero_grad() (torch.optim.adagrad method)": [[1663, "torch.optim.Adagrad.zero_grad"]], "adam (class in torch.optim)": [[1664, "torch.optim.Adam"]], "add_param_group() (torch.optim.adam method)": [[1664, "torch.optim.Adam.add_param_group"]], "load_state_dict() (torch.optim.adam method)": [[1664, "torch.optim.Adam.load_state_dict"]], "register_step_post_hook() (torch.optim.adam method)": [[1664, "torch.optim.Adam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adam method)": [[1664, "torch.optim.Adam.register_step_pre_hook"]], "state_dict() (torch.optim.adam method)": [[1664, "torch.optim.Adam.state_dict"]], "zero_grad() (torch.optim.adam method)": [[1664, "torch.optim.Adam.zero_grad"]], "adamw (class in torch.optim)": [[1665, "torch.optim.AdamW"]], "add_param_group() (torch.optim.adamw method)": [[1665, "torch.optim.AdamW.add_param_group"]], "load_state_dict() (torch.optim.adamw method)": [[1665, "torch.optim.AdamW.load_state_dict"]], "register_step_post_hook() (torch.optim.adamw method)": [[1665, "torch.optim.AdamW.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adamw method)": [[1665, "torch.optim.AdamW.register_step_pre_hook"]], "state_dict() (torch.optim.adamw method)": [[1665, "torch.optim.AdamW.state_dict"]], "zero_grad() (torch.optim.adamw method)": [[1665, "torch.optim.AdamW.zero_grad"]], "adamax (class in torch.optim)": [[1666, "torch.optim.Adamax"]], "add_param_group() (torch.optim.adamax method)": [[1666, "torch.optim.Adamax.add_param_group"]], "load_state_dict() (torch.optim.adamax method)": [[1666, "torch.optim.Adamax.load_state_dict"]], "register_step_post_hook() (torch.optim.adamax method)": [[1666, "torch.optim.Adamax.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.adamax method)": [[1666, "torch.optim.Adamax.register_step_pre_hook"]], "state_dict() (torch.optim.adamax method)": [[1666, "torch.optim.Adamax.state_dict"]], "zero_grad() (torch.optim.adamax method)": [[1666, "torch.optim.Adamax.zero_grad"]], "lbfgs (class in torch.optim)": [[1667, "torch.optim.LBFGS"]], "add_param_group() (torch.optim.lbfgs method)": [[1667, "torch.optim.LBFGS.add_param_group"]], "load_state_dict() (torch.optim.lbfgs method)": [[1667, "torch.optim.LBFGS.load_state_dict"]], "register_step_post_hook() (torch.optim.lbfgs method)": [[1667, "torch.optim.LBFGS.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.lbfgs method)": [[1667, "torch.optim.LBFGS.register_step_pre_hook"]], "state_dict() (torch.optim.lbfgs method)": [[1667, "torch.optim.LBFGS.state_dict"]], "step() (torch.optim.lbfgs method)": [[1667, "torch.optim.LBFGS.step"]], "zero_grad() (torch.optim.lbfgs method)": [[1667, "torch.optim.LBFGS.zero_grad"]], "nadam (class in torch.optim)": [[1668, "torch.optim.NAdam"]], "add_param_group() (torch.optim.nadam method)": [[1668, "torch.optim.NAdam.add_param_group"]], "load_state_dict() (torch.optim.nadam method)": [[1668, "torch.optim.NAdam.load_state_dict"]], "register_step_post_hook() (torch.optim.nadam method)": [[1668, "torch.optim.NAdam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.nadam method)": [[1668, "torch.optim.NAdam.register_step_pre_hook"]], "state_dict() (torch.optim.nadam method)": [[1668, "torch.optim.NAdam.state_dict"]], "zero_grad() (torch.optim.nadam method)": [[1668, "torch.optim.NAdam.zero_grad"]], "add_param_group() (torch.optim.optimizer method)": [[1669, "torch.optim.Optimizer.add_param_group"]], "load_state_dict() (torch.optim.optimizer method)": [[1670, "torch.optim.Optimizer.load_state_dict"]], "state_dict() (torch.optim.optimizer method)": [[1671, "torch.optim.Optimizer.state_dict"]], "step() (torch.optim.optimizer method)": [[1672, "torch.optim.Optimizer.step"]], "zero_grad() (torch.optim.optimizer method)": [[1673, "torch.optim.Optimizer.zero_grad"]], "radam (class in torch.optim)": [[1674, "torch.optim.RAdam"]], "add_param_group() (torch.optim.radam method)": [[1674, "torch.optim.RAdam.add_param_group"]], "load_state_dict() (torch.optim.radam method)": [[1674, "torch.optim.RAdam.load_state_dict"]], "register_step_post_hook() (torch.optim.radam method)": [[1674, "torch.optim.RAdam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.radam method)": [[1674, "torch.optim.RAdam.register_step_pre_hook"]], "state_dict() (torch.optim.radam method)": [[1674, "torch.optim.RAdam.state_dict"]], "zero_grad() (torch.optim.radam method)": [[1674, "torch.optim.RAdam.zero_grad"]], "rmsprop (class in torch.optim)": [[1675, "torch.optim.RMSprop"]], "add_param_group() (torch.optim.rmsprop method)": [[1675, "torch.optim.RMSprop.add_param_group"]], "load_state_dict() (torch.optim.rmsprop method)": [[1675, "torch.optim.RMSprop.load_state_dict"]], "register_step_post_hook() (torch.optim.rmsprop method)": [[1675, "torch.optim.RMSprop.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.rmsprop method)": [[1675, "torch.optim.RMSprop.register_step_pre_hook"]], "state_dict() (torch.optim.rmsprop method)": [[1675, "torch.optim.RMSprop.state_dict"]], "zero_grad() (torch.optim.rmsprop method)": [[1675, "torch.optim.RMSprop.zero_grad"]], "rprop (class in torch.optim)": [[1676, "torch.optim.Rprop"]], "add_param_group() (torch.optim.rprop method)": [[1676, "torch.optim.Rprop.add_param_group"]], "load_state_dict() (torch.optim.rprop method)": [[1676, "torch.optim.Rprop.load_state_dict"]], "register_step_post_hook() (torch.optim.rprop method)": [[1676, "torch.optim.Rprop.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.rprop method)": [[1676, "torch.optim.Rprop.register_step_pre_hook"]], "state_dict() (torch.optim.rprop method)": [[1676, "torch.optim.Rprop.state_dict"]], "zero_grad() (torch.optim.rprop method)": [[1676, "torch.optim.Rprop.zero_grad"]], "sgd (class in torch.optim)": [[1677, "torch.optim.SGD"]], "add_param_group() (torch.optim.sgd method)": [[1677, "torch.optim.SGD.add_param_group"]], "load_state_dict() (torch.optim.sgd method)": [[1677, "torch.optim.SGD.load_state_dict"]], "register_step_post_hook() (torch.optim.sgd method)": [[1677, "torch.optim.SGD.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.sgd method)": [[1677, "torch.optim.SGD.register_step_pre_hook"]], "state_dict() (torch.optim.sgd method)": [[1677, "torch.optim.SGD.state_dict"]], "zero_grad() (torch.optim.sgd method)": [[1677, "torch.optim.SGD.zero_grad"]], "sparseadam (class in torch.optim)": [[1678, "torch.optim.SparseAdam"]], "add_param_group() (torch.optim.sparseadam method)": [[1678, "torch.optim.SparseAdam.add_param_group"]], "load_state_dict() (torch.optim.sparseadam method)": [[1678, "torch.optim.SparseAdam.load_state_dict"]], "register_step_post_hook() (torch.optim.sparseadam method)": [[1678, "torch.optim.SparseAdam.register_step_post_hook"]], "register_step_pre_hook() (torch.optim.sparseadam method)": [[1678, "torch.optim.SparseAdam.register_step_pre_hook"]], "state_dict() (torch.optim.sparseadam method)": [[1678, "torch.optim.SparseAdam.state_dict"]], "step() (torch.optim.sparseadam method)": [[1678, "torch.optim.SparseAdam.step"]], "zero_grad() (torch.optim.sparseadam method)": [[1678, "torch.optim.SparseAdam.zero_grad"]], "chainedscheduler (class in torch.optim.lr_scheduler)": [[1679, "torch.optim.lr_scheduler.ChainedScheduler"]], "get_last_lr() (torch.optim.lr_scheduler.chainedscheduler method)": [[1679, "torch.optim.lr_scheduler.ChainedScheduler.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.chainedscheduler method)": [[1679, "torch.optim.lr_scheduler.ChainedScheduler.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.chainedscheduler method)": [[1679, "torch.optim.lr_scheduler.ChainedScheduler.print_lr"]], "state_dict() (torch.optim.lr_scheduler.chainedscheduler method)": [[1679, "torch.optim.lr_scheduler.ChainedScheduler.state_dict"]], "constantlr (class in torch.optim.lr_scheduler)": [[1680, "torch.optim.lr_scheduler.ConstantLR"]], "get_last_lr() (torch.optim.lr_scheduler.constantlr method)": [[1680, "torch.optim.lr_scheduler.ConstantLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.constantlr method)": [[1680, "torch.optim.lr_scheduler.ConstantLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.constantlr method)": [[1680, "torch.optim.lr_scheduler.ConstantLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.constantlr method)": [[1680, "torch.optim.lr_scheduler.ConstantLR.state_dict"]], "cosineannealinglr (class in torch.optim.lr_scheduler)": [[1681, "torch.optim.lr_scheduler.CosineAnnealingLR"]], "get_last_lr() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1681, "torch.optim.lr_scheduler.CosineAnnealingLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1681, "torch.optim.lr_scheduler.CosineAnnealingLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1681, "torch.optim.lr_scheduler.CosineAnnealingLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.cosineannealinglr method)": [[1681, "torch.optim.lr_scheduler.CosineAnnealingLR.state_dict"]], "cosineannealingwarmrestarts (class in torch.optim.lr_scheduler)": [[1682, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts"]], "get_last_lr() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1682, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1682, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1682, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.print_lr"]], "state_dict() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1682, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.state_dict"]], "step() (torch.optim.lr_scheduler.cosineannealingwarmrestarts method)": [[1682, "torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step"]], "cycliclr (class in torch.optim.lr_scheduler)": [[1683, "torch.optim.lr_scheduler.CyclicLR"]], "get_last_lr() (torch.optim.lr_scheduler.cycliclr method)": [[1683, "torch.optim.lr_scheduler.CyclicLR.get_last_lr"]], "get_lr() (torch.optim.lr_scheduler.cycliclr method)": [[1683, "torch.optim.lr_scheduler.CyclicLR.get_lr"]], "print_lr() (torch.optim.lr_scheduler.cycliclr method)": [[1683, "torch.optim.lr_scheduler.CyclicLR.print_lr"]], "exponentiallr (class in torch.optim.lr_scheduler)": [[1684, "torch.optim.lr_scheduler.ExponentialLR"]], "get_last_lr() (torch.optim.lr_scheduler.exponentiallr method)": [[1684, "torch.optim.lr_scheduler.ExponentialLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.exponentiallr method)": [[1684, "torch.optim.lr_scheduler.ExponentialLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.exponentiallr method)": [[1684, "torch.optim.lr_scheduler.ExponentialLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.exponentiallr method)": [[1684, "torch.optim.lr_scheduler.ExponentialLR.state_dict"]], "lambdalr (class in torch.optim.lr_scheduler)": [[1685, "torch.optim.lr_scheduler.LambdaLR"]], "get_last_lr() (torch.optim.lr_scheduler.lambdalr method)": [[1685, "torch.optim.lr_scheduler.LambdaLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.lambdalr method)": [[1685, "torch.optim.lr_scheduler.LambdaLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.lambdalr method)": [[1685, "torch.optim.lr_scheduler.LambdaLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.lambdalr method)": [[1685, "torch.optim.lr_scheduler.LambdaLR.state_dict"]], "linearlr (class in torch.optim.lr_scheduler)": [[1686, "torch.optim.lr_scheduler.LinearLR"]], "get_last_lr() (torch.optim.lr_scheduler.linearlr method)": [[1686, "torch.optim.lr_scheduler.LinearLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.linearlr method)": [[1686, "torch.optim.lr_scheduler.LinearLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.linearlr method)": [[1686, "torch.optim.lr_scheduler.LinearLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.linearlr method)": [[1686, "torch.optim.lr_scheduler.LinearLR.state_dict"]], "multisteplr (class in torch.optim.lr_scheduler)": [[1687, "torch.optim.lr_scheduler.MultiStepLR"]], "get_last_lr() (torch.optim.lr_scheduler.multisteplr method)": [[1687, "torch.optim.lr_scheduler.MultiStepLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.multisteplr method)": [[1687, "torch.optim.lr_scheduler.MultiStepLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.multisteplr method)": [[1687, "torch.optim.lr_scheduler.MultiStepLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.multisteplr method)": [[1687, "torch.optim.lr_scheduler.MultiStepLR.state_dict"]], "multiplicativelr (class in torch.optim.lr_scheduler)": [[1688, "torch.optim.lr_scheduler.MultiplicativeLR"]], "get_last_lr() (torch.optim.lr_scheduler.multiplicativelr method)": [[1688, "torch.optim.lr_scheduler.MultiplicativeLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.multiplicativelr method)": [[1688, "torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.multiplicativelr method)": [[1688, "torch.optim.lr_scheduler.MultiplicativeLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.multiplicativelr method)": [[1688, "torch.optim.lr_scheduler.MultiplicativeLR.state_dict"]], "onecyclelr (class in torch.optim.lr_scheduler)": [[1689, "torch.optim.lr_scheduler.OneCycleLR"]], "get_last_lr() (torch.optim.lr_scheduler.onecyclelr method)": [[1689, "torch.optim.lr_scheduler.OneCycleLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.onecyclelr method)": [[1689, "torch.optim.lr_scheduler.OneCycleLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.onecyclelr method)": [[1689, "torch.optim.lr_scheduler.OneCycleLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.onecyclelr method)": [[1689, "torch.optim.lr_scheduler.OneCycleLR.state_dict"]], "polynomiallr (class in torch.optim.lr_scheduler)": [[1690, "torch.optim.lr_scheduler.PolynomialLR"]], "get_last_lr() (torch.optim.lr_scheduler.polynomiallr method)": [[1690, "torch.optim.lr_scheduler.PolynomialLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.polynomiallr method)": [[1690, "torch.optim.lr_scheduler.PolynomialLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.polynomiallr method)": [[1690, "torch.optim.lr_scheduler.PolynomialLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.polynomiallr method)": [[1690, "torch.optim.lr_scheduler.PolynomialLR.state_dict"]], "reducelronplateau (class in torch.optim.lr_scheduler)": [[1691, "torch.optim.lr_scheduler.ReduceLROnPlateau"]], "sequentiallr (class in torch.optim.lr_scheduler)": [[1692, "torch.optim.lr_scheduler.SequentialLR"]], "get_last_lr() (torch.optim.lr_scheduler.sequentiallr method)": [[1692, "torch.optim.lr_scheduler.SequentialLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.sequentiallr method)": [[1692, "torch.optim.lr_scheduler.SequentialLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.sequentiallr method)": [[1692, "torch.optim.lr_scheduler.SequentialLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.sequentiallr method)": [[1692, "torch.optim.lr_scheduler.SequentialLR.state_dict"]], "steplr (class in torch.optim.lr_scheduler)": [[1693, "torch.optim.lr_scheduler.StepLR"]], "get_last_lr() (torch.optim.lr_scheduler.steplr method)": [[1693, "torch.optim.lr_scheduler.StepLR.get_last_lr"]], "load_state_dict() (torch.optim.lr_scheduler.steplr method)": [[1693, "torch.optim.lr_scheduler.StepLR.load_state_dict"]], "print_lr() (torch.optim.lr_scheduler.steplr method)": [[1693, "torch.optim.lr_scheduler.StepLR.print_lr"]], "state_dict() (torch.optim.lr_scheduler.steplr method)": [[1693, "torch.optim.lr_scheduler.StepLR.state_dict"]], "orgqr() (in module torch)": [[1694, "torch.orgqr"]], "ormqr() (in module torch)": [[1695, "torch.ormqr"]], "outer() (in module torch)": [[1696, "torch.outer"]], "pca_lowrank() (in module torch)": [[1697, "torch.pca_lowrank"]], "permute() (in module torch)": [[1698, "torch.permute"]], "pinverse() (in module torch)": [[1699, "torch.pinverse"]], "poisson() (in module torch)": [[1700, "torch.poisson"]], "polar() (in module torch)": [[1701, "torch.polar"]], "polygamma() (in module torch)": [[1702, "torch.polygamma"]], "positive() (in module torch)": [[1703, "torch.positive"]], "pow() (in module torch)": [[1704, "torch.pow"]], "prod() (in module torch)": [[1705, "torch.prod"]], "promote_types() (in module torch)": [[1706, "torch.promote_types"]], "qr() (in module torch)": [[1707, "torch.qr"]], "quantile() (in module torch)": [[1708, "torch.quantile"]], "quantize_per_channel() (in module torch)": [[1709, "torch.quantize_per_channel"]], "quantize_per_tensor() (in module torch)": [[1710, "torch.quantize_per_tensor"]], "quantized_batch_norm() (in module torch)": [[1711, "torch.quantized_batch_norm"]], "quantized_max_pool1d() (in module torch)": [[1712, "torch.quantized_max_pool1d"]], "quantized_max_pool2d() (in module torch)": [[1713, "torch.quantized_max_pool2d"]], "sobolengine (class in torch.quasirandom)": [[1714, "torch.quasirandom.SobolEngine"]], "draw() (torch.quasirandom.sobolengine method)": [[1714, "torch.quasirandom.SobolEngine.draw"]], "draw_base2() (torch.quasirandom.sobolengine method)": [[1714, "torch.quasirandom.SobolEngine.draw_base2"]], "fast_forward() (torch.quasirandom.sobolengine method)": [[1714, "torch.quasirandom.SobolEngine.fast_forward"]], "reset() (torch.quasirandom.sobolengine method)": [[1714, "torch.quasirandom.SobolEngine.reset"]], "rad2deg() (in module torch)": [[1715, "torch.rad2deg"]], "rand() (in module torch)": [[1716, "torch.rand"]], "rand_like() (in module torch)": [[1717, "torch.rand_like"]], "randint() (in module torch)": [[1718, "torch.randint"]], "randint_like() (in module torch)": [[1719, "torch.randint_like"]], "randn() (in module torch)": [[1720, "torch.randn"]], "randn_like() (in module torch)": [[1721, "torch.randn_like"]], "randperm() (in module torch)": [[1722, "torch.randperm"]], "range() (in module torch)": [[1723, "torch.range"]], "ravel() (in module torch)": [[1724, "torch.ravel"]], "real() (in module torch)": [[1725, "torch.real"]], "reciprocal() (in module torch)": [[1726, "torch.reciprocal"]], "remainder() (in module torch)": [[1727, "torch.remainder"]], "renorm() (in module torch)": [[1728, "torch.renorm"]], "repeat_interleave() (in module torch)": [[1729, "torch.repeat_interleave"]], "reshape() (in module torch)": [[1730, "torch.reshape"]], "resolve_conj() (in module torch)": [[1731, "torch.resolve_conj"]], "resolve_neg() (in module torch)": [[1732, "torch.resolve_neg"]], "result_type() (in module torch)": [[1733, "torch.result_type"]], "roll() (in module torch)": [[1734, "torch.roll"]], "rot90() (in module torch)": [[1735, "torch.rot90"]], "round() (in module torch)": [[1736, "torch.round"]], "row_stack() (in module torch)": [[1737, "torch.row_stack"]], "rsqrt() (in module torch)": [[1738, "torch.rsqrt"]], "save() (in module torch)": [[1739, "torch.save"]], "scatter() (in module torch)": [[1740, "torch.scatter"]], "scatter_add() (in module torch)": [[1741, "torch.scatter_add"]], "scatter_reduce() (in module torch)": [[1742, "torch.scatter_reduce"]], "searchsorted() (in module torch)": [[1743, "torch.searchsorted"]], "seed() (in module torch)": [[1744, "torch.seed"]], "select() (in module torch)": [[1745, "torch.select"]], "select_scatter() (in module torch)": [[1746, "torch.select_scatter"]], "set_default_device() (in module torch)": [[1747, "torch.set_default_device"]], "set_default_dtype() (in module torch)": [[1748, "torch.set_default_dtype"]], "set_default_tensor_type() (in module torch)": [[1749, "torch.set_default_tensor_type"]], "set_deterministic_debug_mode() (in module torch)": [[1750, "torch.set_deterministic_debug_mode"]], "set_float32_matmul_precision() (in module torch)": [[1751, "torch.set_float32_matmul_precision"]], "set_flush_denormal() (in module torch)": [[1752, "torch.set_flush_denormal"]], "set_grad_enabled (class in torch)": [[1753, "torch.set_grad_enabled"]], "set_num_interop_threads() (in module torch)": [[1754, "torch.set_num_interop_threads"]], "set_num_threads() (in module torch)": [[1755, "torch.set_num_threads"]], "set_printoptions() (in module torch)": [[1756, "torch.set_printoptions"]], "set_rng_state() (in module torch)": [[1757, "torch.set_rng_state"]], "set_warn_always() (in module torch)": [[1758, "torch.set_warn_always"]], "sgn() (in module torch)": [[1759, "torch.sgn"]], "sigmoid() (in module torch)": [[1760, "torch.sigmoid"]], "sign() (in module torch)": [[1761, "torch.sign"]], "bartlett() (in module torch.signal.windows)": [[1762, "torch.signal.windows.bartlett"]], "blackman() (in module torch.signal.windows)": [[1763, "torch.signal.windows.blackman"]], "cosine() (in module torch.signal.windows)": [[1764, "torch.signal.windows.cosine"]], "exponential() (in module torch.signal.windows)": [[1765, "torch.signal.windows.exponential"]], "gaussian() (in module torch.signal.windows)": [[1766, "torch.signal.windows.gaussian"]], "general_cosine() (in module torch.signal.windows)": [[1767, "torch.signal.windows.general_cosine"]], "general_hamming() (in module torch.signal.windows)": [[1768, "torch.signal.windows.general_hamming"]], "hamming() (in module torch.signal.windows)": [[1769, "torch.signal.windows.hamming"]], "hann() (in module torch.signal.windows)": [[1770, "torch.signal.windows.hann"]], "kaiser() (in module torch.signal.windows)": [[1771, "torch.signal.windows.kaiser"]], "nuttall() (in module torch.signal.windows)": [[1772, "torch.signal.windows.nuttall"]], "signbit() (in module torch)": [[1773, "torch.signbit"]], "sin() (in module torch)": [[1774, "torch.sin"]], "sinc() (in module torch)": [[1775, "torch.sinc"]], "sinh() (in module torch)": [[1776, "torch.sinh"]], "slice_scatter() (in module torch)": [[1777, "torch.slice_scatter"]], "slogdet() (in module torch)": [[1778, "torch.slogdet"]], "smm() (in module torch)": [[1779, "torch.smm"]], "softmax() (in module torch)": [[1780, "torch.softmax"]], "sort() (in module torch)": [[1781, "torch.sort"]], "addmm() (in module torch.sparse)": [[1782, "torch.sparse.addmm"]], "check_sparse_tensor_invariants (class in torch.sparse)": [[1783, "torch.sparse.check_sparse_tensor_invariants"]], "disable() (torch.sparse.check_sparse_tensor_invariants static method)": [[1783, "torch.sparse.check_sparse_tensor_invariants.disable"]], "enable() (torch.sparse.check_sparse_tensor_invariants static method)": [[1783, "torch.sparse.check_sparse_tensor_invariants.enable"]], "is_enabled() (torch.sparse.check_sparse_tensor_invariants static method)": [[1783, "torch.sparse.check_sparse_tensor_invariants.is_enabled"]], "log_softmax() (in module torch.sparse)": [[1784, "torch.sparse.log_softmax"]], "mm() (in module torch.sparse)": [[1785, "torch.sparse.mm"]], "sampled_addmm() (in module torch.sparse)": [[1786, "torch.sparse.sampled_addmm"]], "softmax() (in module torch.sparse)": [[1787, "torch.sparse.softmax"]], "spdiags() (in module torch.sparse)": [[1788, "torch.sparse.spdiags"]], "sum() (in module torch.sparse)": [[1789, "torch.sparse.sum"]], "sparse_bsc_tensor() (in module torch)": [[1790, "torch.sparse_bsc_tensor"]], "sparse_bsr_tensor() (in module torch)": [[1791, "torch.sparse_bsr_tensor"]], "sparse_compressed_tensor() (in module torch)": [[1792, "torch.sparse_compressed_tensor"]], "sparse_coo_tensor() (in module torch)": [[1793, "torch.sparse_coo_tensor"]], "sparse_csc_tensor() (in module torch)": [[1794, "torch.sparse_csc_tensor"]], "sparse_csr_tensor() (in module torch)": [[1795, "torch.sparse_csr_tensor"]], "split() (in module torch)": [[1796, "torch.split"]], "sqrt() (in module torch)": [[1797, "torch.sqrt"]], "square() (in module torch)": [[1798, "torch.square"]], "squeeze() (in module torch)": [[1799, "torch.squeeze"]], "sspaddmm() (in module torch)": [[1800, "torch.sspaddmm"]], "stack() (in module torch)": [[1801, "torch.stack"]], "std() (in module torch)": [[1802, "torch.std"]], "std_mean() (in module torch)": [[1803, "torch.std_mean"]], "stft() (in module torch)": [[1804, "torch.stft"]], "sub() (in module torch)": [[1805, "torch.sub"]], "subtract() (in module torch)": [[1806, "torch.subtract"]], "sum() (in module torch)": [[1807, "torch.sum"]], "svd() (in module torch)": [[1808, "torch.svd"]], "svd_lowrank() (in module torch)": [[1809, "torch.svd_lowrank"]], "swapaxes() (in module torch)": [[1810, "torch.swapaxes"]], "swapdims() (in module torch)": [[1811, "torch.swapdims"]], "sym_float() (in module torch)": [[1812, "torch.sym_float"]], "sym_int() (in module torch)": [[1813, "torch.sym_int"]], "sym_max() (in module torch)": [[1814, "torch.sym_max"]], "sym_min() (in module torch)": [[1815, "torch.sym_min"]], "sym_not() (in module torch)": [[1816, "torch.sym_not"]], "t() (in module torch)": [[1817, "torch.t"]], "take() (in module torch)": [[1818, "torch.take"]], "take_along_dim() (in module torch)": [[1819, "torch.take_along_dim"]], "tan() (in module torch)": [[1820, "torch.tan"]], "tanh() (in module torch)": [[1821, "torch.tanh"]], "tensor() (in module torch)": [[1822, "torch.tensor"]], "tensor_split() (in module torch)": [[1823, "torch.tensor_split"]], "tensordot() (in module torch)": [[1824, "torch.tensordot"]], "tile() (in module torch)": [[1825, "torch.tile"]], "topk() (in module torch)": [[1826, "torch.topk"]], "trace() (in module torch)": [[1827, "torch.trace"]], "transpose() (in module torch)": [[1828, "torch.transpose"]], "trapezoid() (in module torch)": [[1829, "torch.trapezoid"]], "trapz() (in module torch)": [[1830, "torch.trapz"]], "triangular_solve() (in module torch)": [[1831, "torch.triangular_solve"]], "tril() (in module torch)": [[1832, "torch.tril"]], "tril_indices() (in module torch)": [[1833, "torch.tril_indices"]], "triu() (in module torch)": [[1834, "torch.triu"]], "triu_indices() (in module torch)": [[1835, "torch.triu_indices"]], "true_divide() (in module torch)": [[1836, "torch.true_divide"]], "trunc() (in module torch)": [[1837, "torch.trunc"]], "unbind() (in module torch)": [[1838, "torch.unbind"]], "unflatten() (in module torch)": [[1839, "torch.unflatten"]], "unique() (in module torch)": [[1840, "torch.unique"]], "unique_consecutive() (in module torch)": [[1841, "torch.unique_consecutive"]], "unsqueeze() (in module torch)": [[1842, "torch.unsqueeze"]], "use_deterministic_algorithms() (in module torch)": [[1843, "torch.use_deterministic_algorithms"]], "vander() (in module torch)": [[1844, "torch.vander"]], "var() (in module torch)": [[1845, "torch.var"]], "var_mean() (in module torch)": [[1846, "torch.var_mean"]], "vdot() (in module torch)": [[1847, "torch.vdot"]], "view_as_complex() (in module torch)": [[1848, "torch.view_as_complex"]], "view_as_real() (in module torch)": [[1849, "torch.view_as_real"]], "vmap() (in module torch)": [[1850, "torch.vmap"]], "vsplit() (in module torch)": [[1851, "torch.vsplit"]], "vstack() (in module torch)": [[1852, "torch.vstack"]], "where() (in module torch)": [[1853, "torch.where"]], "xlogy() (in module torch)": [[1854, "torch.xlogy"]], "zeros() (in module torch)": [[1855, "torch.zeros"]], "zeros_like() (in module torch)": [[1856, "torch.zeros_like"]], "download_url_to_file() (in module torch.hub)": [[1857, "torch.hub.download_url_to_file"]], "get_dir() (in module torch.hub)": [[1857, "torch.hub.get_dir"]], "help() (in module torch.hub)": [[1857, "torch.hub.help"]], "list() (in module torch.hub)": [[1857, "torch.hub.list"]], "load() (in module torch.hub)": [[1857, "torch.hub.load"]], "load_state_dict_from_url() (in module torch.hub)": [[1857, "torch.hub.load_state_dict_from_url"]], "set_dir() (in module torch.hub)": [[1857, "torch.hub.set_dir"]], "torch.hub": [[1857, "module-torch.hub"]], "pytorch_jit": [[1860, "envvar-PYTORCH_JIT"]], "environment variable": [[1860, "envvar-PYTORCH_JIT"]], "export() (in module torch.jit)": [[1860, "torch.jit.export"]], "torch.jit": [[1860, "module-torch.jit"]], "torch.jit.mobile": [[1860, "module-torch.jit.mobile"]], "torch.jit.supported_ops": [[1861, "module-torch.jit.supported_ops"]], "is_scripting() (in module torch.jit)": [[1862, "torch.jit.is_scripting"]], "is_tracing() (in module torch.jit)": [[1862, "torch.jit.is_tracing"]], "torch.jit.unsupported_tensor_ops": [[1865, "module-torch.jit.unsupported_tensor_ops"]], "torch.utils.jit": [[1866, "module-torch.utils.jit"]], "library (class in torch.library)": [[1867, "torch.library.Library"]], "define() (torch.library.library method)": [[1867, "torch.library.Library.define"]], "impl() (torch.library.library method)": [[1867, "torch.library.Library.impl"]], "torch.linalg": [[1868, "module-torch.linalg"]], "torch._logging": [[1869, "module-torch._logging"]], "torch.masked": [[1870, "module-torch.masked"]], "torch.masked.maskedtensor": [[1870, "module-torch.masked.maskedtensor"]], "optimize_for_mobile() (in module torch.utils.mobile_optimizer)": [[1871, "torch.utils.mobile_optimizer.optimize_for_mobile"]], "load_url() (in module torch.utils.model_zoo)": [[1872, "torch.utils.model_zoo.load_url"]], "torch.utils.model_zoo": [[1872, "module-torch.utils.model_zoo"]], "aggregation (class in torch.monitor)": [[1873, "torch.monitor.Aggregation"]], "event (class in torch.monitor)": [[1873, "torch.monitor.Event"]], "eventhandlerhandle (class in torch.monitor)": [[1873, "torch.monitor.EventHandlerHandle"]], "stat (class in torch.monitor)": [[1873, "torch.monitor.Stat"]], "tensorboardeventhandler (class in torch.monitor)": [[1873, "torch.monitor.TensorboardEventHandler"]], "__init__() (torch.monitor.event method)": [[1873, "torch.monitor.Event.__init__"]], "__init__() (torch.monitor.stat method)": [[1873, "torch.monitor.Stat.__init__"]], "__init__() (torch.monitor.tensorboardeventhandler method)": [[1873, "torch.monitor.TensorboardEventHandler.__init__"]], "add() (torch.monitor.stat method)": [[1873, "torch.monitor.Stat.add"]], "count (torch.monitor.stat property)": [[1873, "torch.monitor.Stat.count"]], "data (torch.monitor.event property)": [[1873, "torch.monitor.Event.data"]], "data_value_t (class in torch.monitor)": [[1873, "torch.monitor.data_value_t"]], "get() (torch.monitor.stat method)": [[1873, "torch.monitor.Stat.get"]], "log_event() (in module torch.monitor)": [[1873, "torch.monitor.log_event"]], "name (torch.monitor.aggregation property)": [[1873, "torch.monitor.Aggregation.name"]], "name (torch.monitor.event property)": [[1873, "torch.monitor.Event.name"]], "name (torch.monitor.stat property)": [[1873, "torch.monitor.Stat.name"]], "register_event_handler() (in module torch.monitor)": [[1873, "torch.monitor.register_event_handler"]], "timestamp (torch.monitor.event property)": [[1873, "torch.monitor.Event.timestamp"]], "torch.monitor": [[1873, "module-torch.monitor"]], "unregister_event_handler() (in module torch.monitor)": [[1873, "torch.monitor.unregister_event_handler"]], "torch.mps": [[1874, "module-torch.mps"]], "spawncontext (class in torch.multiprocessing)": [[1875, "torch.multiprocessing.SpawnContext"]], "get_all_sharing_strategies() (in module torch.multiprocessing)": [[1875, "torch.multiprocessing.get_all_sharing_strategies"]], "get_sharing_strategy() (in module torch.multiprocessing)": [[1875, "torch.multiprocessing.get_sharing_strategy"]], "join() (torch.multiprocessing.spawncontext method)": [[1875, "torch.multiprocessing.SpawnContext.join"]], "set_sharing_strategy() (in module torch.multiprocessing)": [[1875, "torch.multiprocessing.set_sharing_strategy"]], "spawn() (in module torch.multiprocessing)": [[1875, "torch.multiprocessing.spawn"]], "torch.multiprocessing": [[1875, "module-torch.multiprocessing"]], "align_as() (torch.tensor method)": [[1877, "torch.Tensor.align_as"]], "align_to() (torch.tensor method)": [[1877, "torch.Tensor.align_to"]], "names (torch.tensor attribute)": [[1877, "torch.Tensor.names"]], "refine_names() (torch.tensor method)": [[1877, "torch.Tensor.refine_names"]], "rename() (torch.tensor method)": [[1877, "torch.Tensor.rename"]], "rename_() (torch.tensor method)": [[1877, "torch.Tensor.rename_"]], "as_nested_tensor() (in module torch.nested)": [[1878, "torch.nested.as_nested_tensor"]], "nested_tensor() (in module torch.nested)": [[1878, "torch.nested.nested_tensor"]], "to_padded_tensor() (in module torch.nested)": [[1878, "torch.nested.to_padded_tensor"]], "torch.nested": [[1878, "module-torch.nested"]], "torch.nn": [[1879, "module-torch.nn"]], "torch.nn.backends": [[1879, "module-torch.nn.backends"]], "torch.nn.modules": [[1879, "module-torch.nn.modules"]], "torch.nn.parallel": [[1879, "module-torch.nn.parallel"]], "torch.nn.utils": [[1879, "module-torch.nn.utils"]], "torch.nn.utils.stateless": [[1879, "module-torch.nn.utils.stateless"]], "calculate_gain() (in module torch.nn.init)": [[1881, "torch.nn.init.calculate_gain"]], "constant_() (in module torch.nn.init)": [[1881, "torch.nn.init.constant_"]], "dirac_() (in module torch.nn.init)": [[1881, "torch.nn.init.dirac_"]], "eye_() (in module torch.nn.init)": [[1881, "torch.nn.init.eye_"]], "kaiming_normal_() (in module torch.nn.init)": [[1881, "torch.nn.init.kaiming_normal_"]], "kaiming_uniform_() (in module torch.nn.init)": [[1881, "torch.nn.init.kaiming_uniform_"]], "normal_() (in module torch.nn.init)": [[1881, "torch.nn.init.normal_"]], "ones_() (in module torch.nn.init)": [[1881, "torch.nn.init.ones_"]], "orthogonal_() (in module torch.nn.init)": [[1881, "torch.nn.init.orthogonal_"]], "sparse_() (in module torch.nn.init)": [[1881, "torch.nn.init.sparse_"]], "trunc_normal_() (in module torch.nn.init)": [[1881, "torch.nn.init.trunc_normal_"]], "uniform_() (in module torch.nn.init)": [[1881, "torch.nn.init.uniform_"]], "xavier_normal_() (in module torch.nn.init)": [[1881, "torch.nn.init.xavier_normal_"]], "xavier_uniform_() (in module torch.nn.init)": [[1881, "torch.nn.init.xavier_uniform_"]], "zeros_() (in module torch.nn.init)": [[1881, "torch.nn.init.zeros_"]], "disable_log() (in module torch.onnx)": [[1901, "torch.onnx.disable_log"]], "dynamo_export() (in module torch.onnx)": [[1901, "torch.onnx.dynamo_export"]], "enable_log() (in module torch.onnx)": [[1901, "torch.onnx.enable_log"]], "export() (in module torch.onnx)": [[1901, "torch.onnx.export"]], "export_to_pretty_string() (in module torch.onnx)": [[1901, "torch.onnx.export_to_pretty_string"]], "find_mismatch() (in module torch.onnx.verification)": [[1901, "torch.onnx.verification.find_mismatch"]], "is_in_onnx_export() (in module torch.onnx)": [[1901, "torch.onnx.is_in_onnx_export"]], "register_custom_op_symbolic() (in module torch.onnx)": [[1901, "torch.onnx.register_custom_op_symbolic"]], "select_model_mode_for_export() (in module torch.onnx)": [[1901, "torch.onnx.select_model_mode_for_export"]], "torch.onnx": [[1901, "module-torch.onnx"]], "unregister_custom_op_symbolic() (in module torch.onnx)": [[1901, "torch.onnx.unregister_custom_op_symbolic"]], "exportdiagnostic (class in torch.onnx._internal.diagnostics)": [[1902, "torch.onnx._internal.diagnostics.ExportDiagnostic"]], "record_cpp_call_stack() (torch.onnx._internal.diagnostics.exportdiagnostic method)": [[1902, "torch.onnx._internal.diagnostics.ExportDiagnostic.record_cpp_call_stack"]], "torch.onnx._internal.diagnostics": [[1902, "module-torch.onnx._internal.diagnostics"]], "optimizer (class in torch.optim)": [[1904, "torch.optim.Optimizer"]], "torch.optim": [[1904, "module-torch.optim"]], "directory (class in torch.package)": [[1905, "torch.package.Directory"]], "emptymatcherror (class in torch.package)": [[1905, "torch.package.EmptyMatchError"]], "packageexporter (class in torch.package)": [[1905, "torch.package.PackageExporter"]], "packageimporter (class in torch.package)": [[1905, "torch.package.PackageImporter"]], "packagingerror (class in torch.package)": [[1905, "torch.package.PackagingError"]], "__init__() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.__init__"]], "__init__() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.__init__"]], "add_dependency() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.add_dependency"]], "all_paths() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.all_paths"]], "close() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.close"]], "denied_modules() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.denied_modules"]], "deny() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.deny"]], "dependency_graph_string() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.dependency_graph_string"]], "extern() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.extern"]], "externed_modules() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.externed_modules"]], "file_structure() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.file_structure"]], "get_rdeps() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.get_rdeps"]], "get_unique_id() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.get_unique_id"]], "has_file() (torch.package.directory method)": [[1905, "torch.package.Directory.has_file"]], "id() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.id"]], "import_module() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.import_module"]], "intern() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.intern"]], "interned_modules() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.interned_modules"]], "load_binary() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.load_binary"]], "load_pickle() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.load_pickle"]], "load_text() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.load_text"]], "mock() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.mock"]], "mocked_modules() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.mocked_modules"]], "python_version() (torch.package.packageimporter method)": [[1905, "torch.package.PackageImporter.python_version"]], "register_extern_hook() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.register_extern_hook"]], "register_intern_hook() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.register_intern_hook"]], "register_mock_hook() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.register_mock_hook"]], "save_binary() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.save_binary"]], "save_module() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.save_module"]], "save_pickle() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.save_pickle"]], "save_source_file() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.save_source_file"]], "save_source_string() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.save_source_string"]], "save_text() (torch.package.packageexporter method)": [[1905, "torch.package.PackageExporter.save_text"]], "torch.package": [[1905, "module-torch.package"]], "torch.package.analyze": [[1905, "module-torch.package.analyze"]], "pipe (class in torch.distributed.pipeline.sync)": [[1906, "torch.distributed.pipeline.sync.Pipe"]], "forward() (torch.distributed.pipeline.sync.pipe method)": [[1906, "torch.distributed.pipeline.sync.Pipe.forward"]], "pop (class in torch.distributed.pipeline.sync.skip.skippable)": [[1906, "torch.distributed.pipeline.sync.skip.skippable.pop"]], "skippable() (in module torch.distributed.pipeline.sync.skip.skippable)": [[1906, "torch.distributed.pipeline.sync.skip.skippable.skippable"]], "stash (class in torch.distributed.pipeline.sync.skip.skippable)": [[1906, "torch.distributed.pipeline.sync.skip.skippable.stash"]], "verify_skippables() (in module torch.distributed.pipeline.sync.skip.skippable)": [[1906, "torch.distributed.pipeline.sync.skip.skippable.verify_skippables"]], "profileraction (class in torch.profiler)": [[1907, "torch.profiler.ProfilerAction"]], "profileractivity (class in torch.profiler)": [[1907, "torch.profiler.ProfilerActivity"]], "_kinetoprofile (class in torch.profiler)": [[1907, "torch.profiler._KinetoProfile"]], "add_metadata() (torch.profiler._kinetoprofile method)": [[1907, "torch.profiler._KinetoProfile.add_metadata"]], "add_metadata_json() (torch.profiler._kinetoprofile method)": [[1907, "torch.profiler._KinetoProfile.add_metadata_json"]], "events() (torch.profiler._kinetoprofile method)": [[1907, "torch.profiler._KinetoProfile.events"]], "export_chrome_trace() (torch.profiler._kinetoprofile method)": [[1907, "torch.profiler._KinetoProfile.export_chrome_trace"]], "export_memory_timeline() (torch.profiler._kinetoprofile method)": [[1907, "torch.profiler._KinetoProfile.export_memory_timeline"]], "export_stacks() (torch.profiler._kinetoprofile method)": [[1907, "torch.profiler._KinetoProfile.export_stacks"]], "is_available() (in module torch.profiler.itt)": [[1907, "torch.profiler.itt.is_available"]], "key_averages() (torch.profiler._kinetoprofile method)": [[1907, "torch.profiler._KinetoProfile.key_averages"]], "mark() (in module torch.profiler.itt)": [[1907, "torch.profiler.itt.mark"]], "name (torch.profiler.profileractivity property)": [[1907, "torch.profiler.ProfilerActivity.name"]], "profile (class in torch.profiler)": [[1907, "torch.profiler.profile"]], "range_pop() (in module torch.profiler.itt)": [[1907, "torch.profiler.itt.range_pop"]], "range_push() (in module torch.profiler.itt)": [[1907, "torch.profiler.itt.range_push"]], "schedule() (in module torch.profiler)": [[1907, "torch.profiler.schedule"]], "step() (torch.profiler.profile method)": [[1907, "torch.profiler.profile.step"]], "tensorboard_trace_handler() (in module torch.profiler)": [[1907, "torch.profiler.tensorboard_trace_handler"]], "torch.profiler": [[1907, "module-torch.profiler"]], "torch.ao": [[1908, "module-torch.ao"]], "torch.ao.nn": [[1908, "module-torch.ao.nn"]], "torch.ao.nn.quantizable": [[1908, "module-torch.ao.nn.quantizable"]], "torch.ao.nn.quantizable.modules": [[1908, "module-torch.ao.nn.quantizable.modules"]], "torch.ao.nn.quantized": [[1908, "module-torch.ao.nn.quantized"]], "torch.ao.nn.quantized.reference": [[1908, "module-torch.ao.nn.quantized.reference"]], "torch.ao.nn.quantized.reference.modules": [[1908, "module-torch.ao.nn.quantized.reference.modules"]], "torch.ao.nn.sparse": [[1908, "module-torch.ao.nn.sparse"]], "torch.ao.nn.sparse.quantized": [[1908, "module-torch.ao.nn.sparse.quantized"]], "torch.ao.nn.sparse.quantized.dynamic": [[1908, "module-torch.ao.nn.sparse.quantized.dynamic"]], "torch.ao.ns": [[1908, "module-torch.ao.ns"]], "torch.ao.ns.fx": [[1908, "module-torch.ao.ns.fx"]], "torch.ao.pruning": [[1908, "module-torch.ao.pruning"]], "torch.ao.pruning.scheduler": [[1908, "module-torch.ao.pruning.scheduler"]], "torch.ao.pruning.sparsifier": [[1908, "module-torch.ao.pruning.sparsifier"]], "torch.ao.quantization": [[1908, "module-torch.ao.quantization"]], "torch.ao.quantization.backend_config": [[1908, "module-torch.ao.quantization.backend_config"]], "torch.ao.quantization.fx": [[1908, "module-torch.ao.quantization.fx"]], "torch.ao.nn.intrinsic": [[1911, "module-torch.ao.nn.intrinsic"]], "torch.ao.nn.intrinsic.modules": [[1911, "module-torch.ao.nn.intrinsic.modules"]], "torch.ao.nn.intrinsic.qat": [[1911, "module-torch.ao.nn.intrinsic.qat"]], "torch.ao.nn.intrinsic.qat.modules": [[1911, "module-torch.ao.nn.intrinsic.qat.modules"]], "torch.ao.nn.intrinsic.quantized": [[1911, "module-torch.ao.nn.intrinsic.quantized"]], "torch.ao.nn.intrinsic.quantized.dynamic": [[1911, "module-torch.ao.nn.intrinsic.quantized.dynamic"]], "torch.ao.nn.intrinsic.quantized.dynamic.modules": [[1911, "module-torch.ao.nn.intrinsic.quantized.dynamic.modules"]], "torch.ao.nn.intrinsic.quantized.modules": [[1911, "module-torch.ao.nn.intrinsic.quantized.modules"]], "torch.ao.nn.qat": [[1911, "module-torch.ao.nn.qat"]], "torch.ao.nn.qat.dynamic": [[1911, "module-torch.ao.nn.qat.dynamic"]], "torch.ao.nn.qat.dynamic.modules": [[1911, "module-torch.ao.nn.qat.dynamic.modules"]], "torch.ao.nn.qat.modules": [[1911, "module-torch.ao.nn.qat.modules"]], "torch.ao.nn.quantized.dynamic": [[1911, "module-torch.ao.nn.quantized.dynamic"]], "torch.ao.nn.quantized.dynamic.modules": [[1911, "module-torch.ao.nn.quantized.dynamic.modules"]], "torch.ao.nn.quantized.functional": [[1911, "module-torch.ao.nn.quantized.functional"]], "torch.ao.nn.quantized.modules": [[1911, "module-torch.ao.nn.quantized.modules"]], "torch.nn.intrinsic": [[1911, "module-torch.nn.intrinsic"]], "torch.nn.intrinsic.modules": [[1911, "module-torch.nn.intrinsic.modules"]], "torch.nn.intrinsic.qat": [[1911, "module-torch.nn.intrinsic.qat"]], "torch.nn.intrinsic.qat.modules": [[1911, "module-torch.nn.intrinsic.qat.modules"]], "torch.nn.intrinsic.quantized": [[1911, "module-torch.nn.intrinsic.quantized"]], "torch.nn.intrinsic.quantized.dynamic": [[1911, "module-torch.nn.intrinsic.quantized.dynamic"]], "torch.nn.intrinsic.quantized.dynamic.modules": [[1911, "module-torch.nn.intrinsic.quantized.dynamic.modules"]], "torch.nn.intrinsic.quantized.modules": [[1911, "module-torch.nn.intrinsic.quantized.modules"]], "torch.nn.qat": [[1911, "module-torch.nn.qat"]], "torch.nn.qat.dynamic": [[1911, "module-torch.nn.qat.dynamic"]], "torch.nn.qat.dynamic.modules": [[1911, "module-torch.nn.qat.dynamic.modules"]], "torch.nn.qat.modules": [[1911, "module-torch.nn.qat.modules"]], "torch.nn.quantizable": [[1911, "module-torch.nn.quantizable"]], "torch.nn.quantizable.modules": [[1911, "module-torch.nn.quantizable.modules"]], "torch.nn.quantized": [[1911, "module-torch.nn.quantized"]], "torch.nn.quantized.dynamic": [[1911, "module-torch.nn.quantized.dynamic"]], "torch.nn.quantized.dynamic.modules": [[1911, "module-torch.nn.quantized.dynamic.modules"]], "torch.nn.quantized.modules": [[1911, "module-torch.nn.quantized.modules"]], "torch.quantization": [[1911, "module-torch.quantization"]], "torch.quantization.fx": [[1911, "module-torch.quantization.fx"]], "fork_rng() (in module torch.random)": [[1912, "torch.random.fork_rng"]], "get_rng_state() (in module torch.random)": [[1912, "torch.random.get_rng_state"]], "initial_seed() (in module torch.random)": [[1912, "torch.random.initial_seed"]], "manual_seed() (in module torch.random)": [[1912, "torch.random.manual_seed"]], "seed() (in module torch.random)": [[1912, "torch.random.seed"]], "set_rng_state() (in module torch.random)": [[1912, "torch.random.set_rng_state"]], "torch.random": [[1912, "module-torch.random"]], "backendtype (class in torch.distributed.rpc)": [[1913, "torch.distributed.rpc.BackendType"]], "rref (class in torch.distributed.rpc)": [[1913, "torch.distributed.rpc.RRef"]], "remotemodule (class in torch.distributed.nn.api.remote_module)": [[1913, "torch.distributed.nn.api.remote_module.RemoteModule"]], "rpcbackendoptions (class in torch.distributed.rpc)": [[1913, "torch.distributed.rpc.RpcBackendOptions"]], "tensorpiperpcbackendoptions (class in torch.distributed.rpc)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions"]], "workerinfo (class in torch.distributed.rpc)": [[1913, "torch.distributed.rpc.WorkerInfo"]], "async_execution() (in module torch.distributed.rpc.functions)": [[1913, "torch.distributed.rpc.functions.async_execution"]], "backward() (in module torch.distributed.autograd)": [[1913, "torch.distributed.autograd.backward"]], "context (class in torch.distributed.autograd)": [[1913, "torch.distributed.autograd.context"]], "device_maps (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions.device_maps"]], "devices (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions.devices"]], "get_gradients() (in module torch.distributed.autograd)": [[1913, "torch.distributed.autograd.get_gradients"]], "get_module_rref() (torch.distributed.nn.api.remote_module.remotemodule method)": [[1913, "torch.distributed.nn.api.remote_module.RemoteModule.get_module_rref"]], "get_worker_info() (in module torch.distributed.rpc)": [[1913, "torch.distributed.rpc.get_worker_info"]], "id (torch.distributed.rpc.workerinfo property)": [[1913, "torch.distributed.rpc.WorkerInfo.id"]], "init_method (torch.distributed.rpc.rpcbackendoptions property)": [[1913, "torch.distributed.rpc.RpcBackendOptions.init_method"]], "init_method (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions.init_method"]], "init_rpc() (in module torch.distributed.rpc)": [[1913, "torch.distributed.rpc.init_rpc"]], "name (torch.distributed.rpc.workerinfo property)": [[1913, "torch.distributed.rpc.WorkerInfo.name"]], "num_worker_threads (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions.num_worker_threads"]], "remote() (in module torch.distributed.rpc)": [[1913, "torch.distributed.rpc.remote"]], "remote_parameters() (torch.distributed.nn.api.remote_module.remotemodule method)": [[1913, "torch.distributed.nn.api.remote_module.RemoteModule.remote_parameters"]], "rpc_async() (in module torch.distributed.rpc)": [[1913, "torch.distributed.rpc.rpc_async"]], "rpc_sync() (in module torch.distributed.rpc)": [[1913, "torch.distributed.rpc.rpc_sync"]], "rpc_timeout (torch.distributed.rpc.rpcbackendoptions property)": [[1913, "torch.distributed.rpc.RpcBackendOptions.rpc_timeout"]], "rpc_timeout (torch.distributed.rpc.tensorpiperpcbackendoptions property)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions.rpc_timeout"]], "set_device_map() (torch.distributed.rpc.tensorpiperpcbackendoptions method)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions.set_device_map"]], "set_devices() (torch.distributed.rpc.tensorpiperpcbackendoptions method)": [[1913, "torch.distributed.rpc.TensorPipeRpcBackendOptions.set_devices"]], "shutdown() (in module torch.distributed.rpc)": [[1913, "torch.distributed.rpc.shutdown"]], "torch.distributed.autograd": [[1913, "module-torch.distributed.autograd"]], "torch.distributed.rpc": [[1913, "module-torch.distributed.rpc"]], "torch.signal": [[1916, "module-torch.signal"]], "torch.signal.windows": [[1916, "module-torch.signal.windows"]], "torch.sparse": [[1917, "module-torch.sparse"]], "airy_ai() (in module torch.special)": [[1918, "torch.special.airy_ai"]], "bessel_j0() (in module torch.special)": [[1918, "torch.special.bessel_j0"]], "bessel_j1() (in module torch.special)": [[1918, "torch.special.bessel_j1"]], "digamma() (in module torch.special)": [[1918, "torch.special.digamma"]], "entr() (in module torch.special)": [[1918, "torch.special.entr"]], "erf() (in module torch.special)": [[1918, "torch.special.erf"]], "erfc() (in module torch.special)": [[1918, "torch.special.erfc"]], "erfcx() (in module torch.special)": [[1918, "torch.special.erfcx"]], "erfinv() (in module torch.special)": [[1918, "torch.special.erfinv"]], "exp2() (in module torch.special)": [[1918, "torch.special.exp2"]], "expit() (in module torch.special)": [[1918, "torch.special.expit"]], "expm1() (in module torch.special)": [[1918, "torch.special.expm1"]], "gammainc() (in module torch.special)": [[1918, "torch.special.gammainc"]], "gammaincc() (in module torch.special)": [[1918, "torch.special.gammaincc"]], "gammaln() (in module torch.special)": [[1918, "torch.special.gammaln"]], "i0() (in module torch.special)": [[1918, "torch.special.i0"]], "i0e() (in module torch.special)": [[1918, "torch.special.i0e"]], "i1() (in module torch.special)": [[1918, "torch.special.i1"]], "i1e() (in module torch.special)": [[1918, "torch.special.i1e"]], "log1p() (in module torch.special)": [[1918, "torch.special.log1p"]], "log_ndtr() (in module torch.special)": [[1918, "torch.special.log_ndtr"]], "log_softmax() (in module torch.special)": [[1918, "torch.special.log_softmax"]], "logit() (in module torch.special)": [[1918, "torch.special.logit"]], "logsumexp() (in module torch.special)": [[1918, "torch.special.logsumexp"]], "multigammaln() (in module torch.special)": [[1918, "torch.special.multigammaln"]], "ndtr() (in module torch.special)": [[1918, "torch.special.ndtr"]], "ndtri() (in module torch.special)": [[1918, "torch.special.ndtri"]], "polygamma() (in module torch.special)": [[1918, "torch.special.polygamma"]], "psi() (in module torch.special)": [[1918, "torch.special.psi"]], "round() (in module torch.special)": [[1918, "torch.special.round"]], "scaled_modified_bessel_k0() (in module torch.special)": [[1918, "torch.special.scaled_modified_bessel_k0"]], "scaled_modified_bessel_k1() (in module torch.special)": [[1918, "torch.special.scaled_modified_bessel_k1"]], "sinc() (in module torch.special)": [[1918, "torch.special.sinc"]], "softmax() (in module torch.special)": [[1918, "torch.special.softmax"]], "spherical_bessel_j0() (in module torch.special)": [[1918, "torch.special.spherical_bessel_j0"]], "torch.special": [[1918, "module-torch.special"]], "xlog1py() (in module torch.special)": [[1918, "torch.special.xlog1py"]], "xlogy() (in module torch.special)": [[1918, "torch.special.xlogy"]], "zeta() (in module torch.special)": [[1918, "torch.special.zeta"]], "bfloat16storage (class in torch)": [[1919, "torch.BFloat16Storage"]], "boolstorage (class in torch)": [[1919, "torch.BoolStorage"]], "bytestorage (class in torch)": [[1919, "torch.ByteStorage"]], "charstorage (class in torch)": [[1919, "torch.CharStorage"]], "complexdoublestorage (class in torch)": [[1919, "torch.ComplexDoubleStorage"]], "complexfloatstorage (class in torch)": [[1919, "torch.ComplexFloatStorage"]], "doublestorage (class in torch)": [[1919, "torch.DoubleStorage"]], "floatstorage (class in torch)": [[1919, "torch.FloatStorage"]], "halfstorage (class in torch)": [[1919, "torch.HalfStorage"]], "intstorage (class in torch)": [[1919, "torch.IntStorage"]], "longstorage (class in torch)": [[1919, "torch.LongStorage"]], "qint32storage (class in torch)": [[1919, "torch.QInt32Storage"]], "qint8storage (class in torch)": [[1919, "torch.QInt8Storage"]], "quint2x4storage (class in torch)": [[1919, "torch.QUInt2x4Storage"]], "quint4x2storage (class in torch)": [[1919, "torch.QUInt4x2Storage"]], "quint8storage (class in torch)": [[1919, "torch.QUInt8Storage"]], "shortstorage (class in torch)": [[1919, "torch.ShortStorage"]], "typedstorage (class in torch)": [[1919, "torch.TypedStorage"]], "untypedstorage (class in torch)": [[1919, "torch.UntypedStorage"]], "bfloat16() (torch.typedstorage method)": [[1919, "torch.TypedStorage.bfloat16"]], "bfloat16() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.bfloat16"]], "bool() (torch.typedstorage method)": [[1919, "torch.TypedStorage.bool"]], "bool() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.bool"]], "byte() (torch.typedstorage method)": [[1919, "torch.TypedStorage.byte"]], "byte() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.byte"]], "byteswap() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.byteswap"]], "char() (torch.typedstorage method)": [[1919, "torch.TypedStorage.char"]], "char() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.char"]], "clone() (torch.typedstorage method)": [[1919, "torch.TypedStorage.clone"]], "clone() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.clone"]], "complex_double() (torch.typedstorage method)": [[1919, "torch.TypedStorage.complex_double"]], "complex_double() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.complex_double"]], "complex_float() (torch.typedstorage method)": [[1919, "torch.TypedStorage.complex_float"]], "complex_float() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.complex_float"]], "copy_() (torch.typedstorage method)": [[1919, "torch.TypedStorage.copy_"]], "copy_() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.copy_"]], "cpu() (torch.typedstorage method)": [[1919, "torch.TypedStorage.cpu"]], "cpu() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.cpu"]], "cuda() (torch.typedstorage method)": [[1919, "torch.TypedStorage.cuda"]], "cuda() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.cuda"]], "data_ptr() (torch.typedstorage method)": [[1919, "torch.TypedStorage.data_ptr"]], "data_ptr() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.data_ptr"]], "device (torch.typedstorage property)": [[1919, "torch.TypedStorage.device"]], "device (torch.untypedstorage attribute)": [[1919, "torch.UntypedStorage.device"]], "double() (torch.typedstorage method)": [[1919, "torch.TypedStorage.double"]], "double() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.double"]], "dtype (torch.bfloat16storage attribute)": [[1919, "torch.BFloat16Storage.dtype"]], "dtype (torch.boolstorage attribute)": [[1919, "torch.BoolStorage.dtype"]], "dtype (torch.bytestorage attribute)": [[1919, "torch.ByteStorage.dtype"]], "dtype (torch.charstorage attribute)": [[1919, "torch.CharStorage.dtype"]], "dtype (torch.complexdoublestorage attribute)": [[1919, "torch.ComplexDoubleStorage.dtype"]], "dtype (torch.complexfloatstorage attribute)": [[1919, "torch.ComplexFloatStorage.dtype"]], "dtype (torch.doublestorage attribute)": [[1919, "torch.DoubleStorage.dtype"]], "dtype (torch.floatstorage attribute)": [[1919, "torch.FloatStorage.dtype"]], "dtype (torch.halfstorage attribute)": [[1919, "torch.HalfStorage.dtype"]], "dtype (torch.intstorage attribute)": [[1919, "torch.IntStorage.dtype"]], "dtype (torch.longstorage attribute)": [[1919, "torch.LongStorage.dtype"]], "dtype (torch.qint32storage attribute)": [[1919, "torch.QInt32Storage.dtype"]], "dtype (torch.qint8storage attribute)": [[1919, "torch.QInt8Storage.dtype"]], "dtype (torch.quint2x4storage attribute)": [[1919, "torch.QUInt2x4Storage.dtype"]], "dtype (torch.quint4x2storage attribute)": [[1919, "torch.QUInt4x2Storage.dtype"]], "dtype (torch.quint8storage attribute)": [[1919, "torch.QUInt8Storage.dtype"]], "dtype (torch.shortstorage attribute)": [[1919, "torch.ShortStorage.dtype"]], "dtype (torch.typedstorage attribute)": [[1919, "torch.TypedStorage.dtype"]], "element_size() (torch.typedstorage method)": [[1919, "torch.TypedStorage.element_size"]], "element_size() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.element_size"]], "fill_() (torch.typedstorage method)": [[1919, "torch.TypedStorage.fill_"]], "fill_() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.fill_"]], "float() (torch.typedstorage method)": [[1919, "torch.TypedStorage.float"]], "float() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.float"]], "from_buffer() (torch.typedstorage class method)": [[1919, "torch.TypedStorage.from_buffer"]], "from_buffer() (torch.untypedstorage static method)": [[1919, "torch.UntypedStorage.from_buffer"]], "from_file() (torch.typedstorage class method)": [[1919, "torch.TypedStorage.from_file"]], "from_file() (torch.untypedstorage static method)": [[1919, "torch.UntypedStorage.from_file"]], "get_device() (torch.typedstorage method)": [[1919, "torch.TypedStorage.get_device"]], "get_device() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.get_device"]], "half() (torch.typedstorage method)": [[1919, "torch.TypedStorage.half"]], "half() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.half"]], "int() (torch.typedstorage method)": [[1919, "torch.TypedStorage.int"]], "int() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.int"]], "is_cuda (torch.typedstorage property)": [[1919, "torch.TypedStorage.is_cuda"]], "is_cuda (torch.untypedstorage property)": [[1919, "torch.UntypedStorage.is_cuda"]], "is_pinned() (torch.typedstorage method)": [[1919, "torch.TypedStorage.is_pinned"]], "is_pinned() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.is_pinned"]], "is_shared() (torch.typedstorage method)": [[1919, "torch.TypedStorage.is_shared"]], "is_shared() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.is_shared"]], "is_sparse (torch.typedstorage attribute)": [[1919, "torch.TypedStorage.is_sparse"]], "is_sparse (torch.untypedstorage attribute)": [[1919, "torch.UntypedStorage.is_sparse"]], "is_sparse_csr (torch.untypedstorage attribute)": [[1919, "torch.UntypedStorage.is_sparse_csr"]], "long() (torch.typedstorage method)": [[1919, "torch.TypedStorage.long"]], "long() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.long"]], "mps() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.mps"]], "nbytes() (torch.typedstorage method)": [[1919, "torch.TypedStorage.nbytes"]], "nbytes() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.nbytes"]], "new() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.new"]], "pickle_storage_type() (torch.typedstorage method)": [[1919, "torch.TypedStorage.pickle_storage_type"]], "pin_memory() (torch.typedstorage method)": [[1919, "torch.TypedStorage.pin_memory"]], "pin_memory() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.pin_memory"]], "resize_() (torch.typedstorage method)": [[1919, "torch.TypedStorage.resize_"]], "resize_() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.resize_"]], "share_memory_() (torch.typedstorage method)": [[1919, "torch.TypedStorage.share_memory_"]], "share_memory_() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.share_memory_"]], "short() (torch.typedstorage method)": [[1919, "torch.TypedStorage.short"]], "short() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.short"]], "size() (torch.typedstorage method)": [[1919, "torch.TypedStorage.size"]], "size() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.size"]], "tolist() (torch.typedstorage method)": [[1919, "torch.TypedStorage.tolist"]], "tolist() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.tolist"]], "type() (torch.typedstorage method)": [[1919, "torch.TypedStorage.type"]], "type() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.type"]], "untyped() (torch.typedstorage method)": [[1919, "torch.TypedStorage.untyped"]], "untyped() (torch.untypedstorage method)": [[1919, "torch.UntypedStorage.untyped"]], "device (class in torch)": [[1920, "torch.device"]], "dtype (class in torch)": [[1920, "torch.dtype"]], "layout (class in torch)": [[1920, "torch.layout"]], "memory_format (class in torch)": [[1920, "torch.memory_format"]], "summarywriter (class in torch.utils.tensorboard.writer)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter"]], "__init__() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.__init__"]], "add_audio() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_audio"]], "add_custom_scalars() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars"]], "add_embedding() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_embedding"]], "add_figure() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_figure"]], "add_graph() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_graph"]], "add_histogram() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_histogram"]], "add_hparams() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_hparams"]], "add_image() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_image"]], "add_images() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_images"]], "add_mesh() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_mesh"]], "add_pr_curve() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve"]], "add_scalar() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_scalar"]], "add_scalars() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_scalars"]], "add_text() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_text"]], "add_video() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.add_video"]], "close() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.close"]], "flush() (torch.utils.tensorboard.writer.summarywriter method)": [[1922, "torch.utils.tensorboard.writer.SummaryWriter.flush"]], "torch.utils.tensorboard": [[1922, "module-torch.utils.tensorboard"]], "h (torch.tensor attribute)": [[1923, "torch.Tensor.H"]], "t (torch.tensor attribute)": [[1923, "torch.Tensor.T"]], "tensor (class in torch)": [[1923, "torch.Tensor"]], "mh (torch.tensor attribute)": [[1923, "torch.Tensor.mH"]], "mt (torch.tensor attribute)": [[1923, "torch.Tensor.mT"]], "assert_allclose() (in module torch.testing)": [[1924, "torch.testing.assert_allclose"]], "assert_close() (in module torch.testing)": [[1924, "torch.testing.assert_close"]], "make_tensor() (in module torch.testing)": [[1924, "torch.testing.make_tensor"]], "torch.testing": [[1924, "module-torch.testing"]], "symbool (class in torch)": [[1925, "torch.SymBool"]], "symfloat (class in torch)": [[1925, "torch.SymFloat"]], "symint (class in torch)": [[1925, "torch.SymInt"]], "tag (class in torch)": [[1925, "torch.Tag"]], "default_generator (torch.torch attribute)": [[1925, "torch.torch.default_generator"]], "name (torch.tag property)": [[1925, "torch.Tag.name"]], "torch": [[1925, "module-torch"]], "torch.contrib": [[1925, "module-torch.contrib"]], "torch.utils": [[1925, "module-torch.utils"]], "torch.utils.backcompat": [[1925, "module-torch.utils.backcompat"]], "torch.utils.hipify": [[1925, "module-torch.utils.hipify"]], "torch.utils.model_dump": [[1925, "module-torch.utils.model_dump"]], "logger (class in torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.Logger"]], "outputlogger (class in torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.OutputLogger"]], "shadow (class in torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.Shadow"]], "shadowlogger (class in torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.ShadowLogger"]], "add() (torch.ao.ns._numeric_suite.shadow method)": [[1926, "torch.ao.ns._numeric_suite.Shadow.add"]], "add_relu() (torch.ao.ns._numeric_suite.shadow method)": [[1926, "torch.ao.ns._numeric_suite.Shadow.add_relu"]], "add_scalar() (torch.ao.ns._numeric_suite.shadow method)": [[1926, "torch.ao.ns._numeric_suite.Shadow.add_scalar"]], "cat() (torch.ao.ns._numeric_suite.shadow method)": [[1926, "torch.ao.ns._numeric_suite.Shadow.cat"]], "compare_model_outputs() (in module torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.compare_model_outputs"]], "compare_model_stub() (in module torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.compare_model_stub"]], "compare_weights() (in module torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.compare_weights"]], "forward() (torch.ao.ns._numeric_suite.logger method)": [[1926, "torch.ao.ns._numeric_suite.Logger.forward"]], "forward() (torch.ao.ns._numeric_suite.outputlogger method)": [[1926, "torch.ao.ns._numeric_suite.OutputLogger.forward"]], "forward() (torch.ao.ns._numeric_suite.shadow method)": [[1926, "torch.ao.ns._numeric_suite.Shadow.forward"]], "forward() (torch.ao.ns._numeric_suite.shadowlogger method)": [[1926, "torch.ao.ns._numeric_suite.ShadowLogger.forward"]], "get_logger_dict() (in module torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.get_logger_dict"]], "get_matching_activations() (in module torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.get_matching_activations"]], "mul() (torch.ao.ns._numeric_suite.shadow method)": [[1926, "torch.ao.ns._numeric_suite.Shadow.mul"]], "mul_scalar() (torch.ao.ns._numeric_suite.shadow method)": [[1926, "torch.ao.ns._numeric_suite.Shadow.mul_scalar"]], "prepare_model_outputs() (in module torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.prepare_model_outputs"]], "prepare_model_with_stubs() (in module torch.ao.ns._numeric_suite)": [[1926, "torch.ao.ns._numeric_suite.prepare_model_with_stubs"]], "torch.ao.ns._numeric_suite": [[1926, "module-torch.ao.ns._numeric_suite"]], "nstracer (class in torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.NSTracer"]], "outputcomparisonlogger (class in torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.OutputComparisonLogger"]], "outputlogger (class in torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.OutputLogger"]], "add_loggers() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.add_loggers"]], "add_shadow_loggers() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.add_shadow_loggers"]], "compute_cosine_similarity() (in module torch.ao.ns.fx.utils)": [[1927, "torch.ao.ns.fx.utils.compute_cosine_similarity"]], "compute_normalized_l2_error() (in module torch.ao.ns.fx.utils)": [[1927, "torch.ao.ns.fx.utils.compute_normalized_l2_error"]], "compute_sqnr() (in module torch.ao.ns.fx.utils)": [[1927, "torch.ao.ns.fx.utils.compute_sqnr"]], "convert_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.convert_n_shadows_model"]], "extend_logger_results_with_comparison() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.extend_logger_results_with_comparison"]], "extract_logger_info() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.extract_logger_info"]], "extract_results_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.extract_results_n_shadows_model"]], "extract_shadow_logger_info() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.extract_shadow_logger_info"]], "extract_weights() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.extract_weights"]], "forward() (torch.ao.ns._numeric_suite_fx.outputcomparisonlogger method)": [[1927, "torch.ao.ns._numeric_suite_fx.OutputComparisonLogger.forward"]], "forward() (torch.ao.ns._numeric_suite_fx.outputlogger method)": [[1927, "torch.ao.ns._numeric_suite_fx.OutputLogger.forward"]], "is_leaf_module() (torch.ao.ns._numeric_suite_fx.nstracer method)": [[1927, "torch.ao.ns._numeric_suite_fx.NSTracer.is_leaf_module"]], "loggers_set_enabled() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.loggers_set_enabled"]], "loggers_set_save_activations() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.loggers_set_save_activations"]], "prepare_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.prepare_n_shadows_model"]], "print_comparisons_n_shadows_model() (in module torch.ao.ns._numeric_suite_fx)": [[1927, "torch.ao.ns._numeric_suite_fx.print_comparisons_n_shadows_model"]], "torch.ao.ns._numeric_suite_fx": [[1927, "module-torch.ao.ns._numeric_suite_fx"]], "get_ignored_functions() (in module torch.overrides)": [[1928, "torch.overrides.get_ignored_functions"]], "get_overridable_functions() (in module torch.overrides)": [[1928, "torch.overrides.get_overridable_functions"]], "get_testing_overrides() (in module torch.overrides)": [[1928, "torch.overrides.get_testing_overrides"]], "handle_torch_function() (in module torch.overrides)": [[1928, "torch.overrides.handle_torch_function"]], "has_torch_function() (in module torch.overrides)": [[1928, "torch.overrides.has_torch_function"]], "is_tensor_like() (in module torch.overrides)": [[1928, "torch.overrides.is_tensor_like"]], "is_tensor_method_or_property() (in module torch.overrides)": [[1928, "torch.overrides.is_tensor_method_or_property"]], "resolve_name() (in module torch.overrides)": [[1928, "torch.overrides.resolve_name"]], "wrap_torch_function() (in module torch.overrides)": [[1928, "torch.overrides.wrap_torch_function"]], "torch.finfo (class in torch)": [[1929, "torch.torch.finfo"]], "torch.iinfo (class in torch)": [[1929, "torch.torch.iinfo"]]}})